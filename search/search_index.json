{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Teal Agents","text":""},{"location":"#chat-completion-factories","title":"Chat Completion Factories","text":""},{"location":"#background","title":"Background","text":"<p>If you hadn't noticed, Teal Agents Framework is built on top of the open source Semantic Kernel library. Semantic Kernel leverages the concept of the Kernel to which certain capabilities are added, which can then be used to interact with LLMs for things like agents.</p> <p>One of the core components you add to a Kernel is the ChatCompletionClient. This object provides connection details to the specific LLM you want to enable for a given Kernel (and in this context, an Agent). ChatCompletionClient's come in many flavors with the ability to connect to things like standard OpenAI APIs, Azure OpenAI and Anthropic APIs, Anthropic APIs, Ollama APIs, etc. Due to the early nature of this product, there is limited, in-built support for the different model hosting options (indeed only standard OpenAI at the time of writing).</p>"},{"location":"#chatcompletion-factories","title":"ChatCompletion Factories","text":"<p>In the <code>ska_types</code> module, there is defined a ChatCompletionFactory abstract class. Within the <code>chat_completion</code> package, there is a default implementation of this class called <code>DefaultChatCompletionFactory</code>. Standard, widely supported ChatCompletions should be included here, and we welcome contributions to build out the available standard models.</p>"},{"location":"#custom-factories","title":"Custom Factories","text":"<p>There is also the ability for users to add a supplementary ChatCompletionFactory of their own writing. To do so, you'll need to create a module with a class that extends the ChatCompletionFactory abstract class and implement three methods:</p> <ul> <li><code>get_configs</code> - Static method you should implement if your chat completions    require additional configuration (via environment variables).</li> <li><code>get_chat_completion_for_model_name</code> - Method that returns an instance of   <code>ChatCompletionClientBase</code> for connecting to a model with a given name. When   implemented, the model name can then be used for an agent's <code>model</code> property   in the agent config YAML.</li> <li><code>get_model_type_for_name</code> - Method that returns the appropriate <code>ModelType</code>    for a given model name. This is currently only used to determine the correct    way to calculate the token usage for a model response and if someone can    think of a better way to do it, I'd like this method to go away.</li> </ul> <p>Once you've created your custom factory, enable it by setting the two following environment variables:</p> <ul> <li>TA_CUSTOM_CHAT_COMPLETION_FACTORY_MODULE - The relative path to the python   file containing your factory class</li> <li>TA_CUSTOM_CHAT_COMPLETION_FACTORY_CLASS_NAME - The class name of your custom   factory class</li> </ul> <p>Once enabled, you have the ability to use any model your factory can handle with a given agent by specifying the model name in the <code>model</code> field of the agent's YAML configuration.</p> <p>Included is an example of a custom chat completion factory (non-working unless you have Azure OpenAI endpoints): </p>"},{"location":"#sk_agents.chat_completion.custom.example_custom_chat_completion_factory.ExampleCustomChatCompletionFactory","title":"sk_agents.chat_completion.custom.example_custom_chat_completion_factory.ExampleCustomChatCompletionFactory","text":"<p>               Bases: <code>ChatCompletionFactory</code></p> Source code in <code>src/sk_agents/chat_completion/custom/example_custom_chat_completion_factory.py</code> <pre><code>class ExampleCustomChatCompletionFactory(ChatCompletionFactory):\n    _OPENAI_MODELS: list[str] = [\n        \"gpt-35-turbo-1106\",\n        \"gpt-35-turbo-0125\",\n        \"gpt-4o-2024-05-13\",\n        \"gpt-4o-2024-08-06\",\n        \"gpt-4o-mini-2024-07-18\",\n        \"gpt-4-turbo-2024-04-09\",\n    ]\n    _ANTHROPIC_MODELS: list[str] = [\n        \"claude-3-5-sonnet-20240620\",\n        \"claude-3-haiku-20240307\",\n    ]\n\n    _GOOGLE_MODELS: list[str] = [\n        \"gemini-2-5-pro-preview-03-25\",\n        \"gemini-2-5-flash-preview-04-17\",\n        \"gemini-2-0-flash\",\n        \"gemini-2-0-flash-lite\",\n    ]\n\n    TA_BASE_URL = UtilConfig(\n        env_name=\"TA_BASE_URL\",\n        is_required=False,\n        default_value=\"https://&lt;Your AI Service Endpoint&gt;\",\n    )\n    TA_API_VERSION = UtilConfig(\n        env_name=\"TA_API_VERSION\", is_required=False, default_value=\"2024-10-21\"\n    )\n\n    _CONFIGS: list[UtilConfig] = [TA_BASE_URL, TA_API_VERSION]\n\n    def __init__(self, app_config: AppConfig):\n        super().__init__(app_config)\n        self.api_key = app_config.get(TA_API_KEY.env_name)\n        self.url_base = app_config.get(ExampleCustomChatCompletionFactory.TA_BASE_URL.env_name)\n        self.api_version = app_config.get(\n            ExampleCustomChatCompletionFactory.TA_API_VERSION.env_name\n        )\n\n    @staticmethod\n    def get_configs() -&gt; list[UtilConfig]:\n        return ExampleCustomChatCompletionFactory._CONFIGS\n\n    def get_chat_completion_for_model_name(\n        self, model_name: str, service_id: str\n    ) -&gt; ChatCompletionClientBase:\n        if model_name in ExampleCustomChatCompletionFactory._OPENAI_MODELS:\n            return AzureChatCompletion(\n                service_id=service_id,\n                deployment_name=model_name,\n                api_key=self.api_key,\n                base_url=f\"{self.url_base}/openai\",\n                api_version=self.api_version,\n            )\n        elif model_name in ExampleCustomChatCompletionFactory._ANTHROPIC_MODELS:\n            return AnthropicChatCompletion(\n                service_id=service_id,\n                api_key=\"unused\",\n                ai_model_id=model_name,\n                async_client=AsyncAnthropic(\n                    api_key=\"unused\",\n                    base_url=f\"{self.url_base}/anthropic/{model_name}-v1\",\n                    default_headers={\"X-Custom-Header\": self.api_key},\n                ),\n            )\n        elif model_name in ExampleCustomChatCompletionFactory._GOOGLE_MODELS:\n            return GoogleAIChatCompletion(\n                service_id=service_id,\n                deployment_name=model_name,\n                api_key=self.api_key,\n            )\n        else:\n            raise ValueError(\"Model type not supported\")\n\n    def get_model_type_for_name(self, model_name: str) -&gt; ModelType:\n        if model_name in ExampleCustomChatCompletionFactory._OPENAI_MODELS:\n            return ModelType.OPENAI\n        elif model_name in ExampleCustomChatCompletionFactory._ANTHROPIC_MODELS:\n            return ModelType.ANTHROPIC\n        elif model_name in ExampleCustomChatCompletionFactory._GOOGLE_MODELS:\n            return ModelType.GOOGLE\n        else:\n            raise ValueError(f\"Unknown model name {model_name}\")\n\n    def model_supports_structured_output(self, model_name: str) -&gt; bool:\n        if model_name in ExampleCustomChatCompletionFactory._OPENAI_MODELS:\n            return True\n        elif model_name in ExampleCustomChatCompletionFactory._ANTHROPIC_MODELS:\n            return False\n        elif model_name in ExampleCustomChatCompletionFactory._GOOGLE_MODELS:\n            return True\n        else:\n            raise ValueError(f\"Unknown model name {model_name}\")\n</code></pre>"},{"location":"#notes","title":"Notes","text":"<ol> <li>A custom factory takes precedence over the default factory, so if your    factory provides a chat completion with a model name matching one in the    default factory, yours will be selected.</li> <li>While not exactly on-topic, there is an additional configuration property    <code>TA_STRUCTURED_OUTPUT_TRANSFORMER_MODEL</code> which specifies which model should    be used to convert agent results in to structured output whenever an    <code>output_type</code> is defined. This defaults to <code>openai-gpt-4o</code> but if you've    implemented a custom factory, you can override this property to be one of    your models.</li> </ol>"},{"location":"MCP_PR_REVIEW_GUIDE/","title":"MCP Integration PR Review Guide","text":"<p>This guide helps reviewers understand, test, and review the MCP (Model Context Protocol) integration.</p>"},{"location":"MCP_PR_REVIEW_GUIDE/#pr-summary","title":"PR Summary","text":"<p>This PR introduces MCP support to Teal Agents, enabling agents to discover and use tools from external MCP servers. The integration follows a session-scoped discovery, request-scoped connection pattern that supports horizontal scaling.</p>"},{"location":"MCP_PR_REVIEW_GUIDE/#key-features","title":"Key Features","text":"Feature Description HTTP Transport Primary focus - connects to remote MCP servers Session-Scoped Discovery Tools discovered once per session, stored externally Request-Scoped Connections Lazy connection pooling within each request Governance/HITL Secure-by-default with trust levels External State Storage In-memory (dev) or Redis (prod)"},{"location":"MCP_PR_REVIEW_GUIDE/#known-limitations","title":"Known Limitations","text":"<ol> <li>OAuth 2.1: Implemented and unit tested, but NOT tested end-to-end with real OAuth providers</li> <li>stdio transport: Supported but secondary to HTTP transport</li> </ol>"},{"location":"MCP_PR_REVIEW_GUIDE/#architecture-overview","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         SESSION START                                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  McpPluginRegistry.discover_and_materialize()                        \u2502\n\u2502    \u251c\u2500\u2500 For each MCP server:                                          \u2502\n\u2502    \u2502     \u251c\u2500\u2500 Resolve OAuth tokens (if configured)                    \u2502\n\u2502    \u2502     \u251c\u2500\u2500 Connect to MCP server                                   \u2502\n\u2502    \u2502     \u251c\u2500\u2500 List tools from server                                  \u2502\n\u2502    \u2502     \u251c\u2500\u2500 Register tools in PluginCatalog (governance)            \u2502\n\u2502    \u2502     \u2514\u2500\u2500 Store tool metadata in McpStateManager                  \u2502\n\u2502    \u2514\u2500\u2500 Close connections (discovery complete)                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n                                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         EACH REQUEST                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Handler.invoke()                                                     \u2502\n\u2502    \u251c\u2500\u2500 Create McpConnectionManager (request-scoped)                  \u2502\n\u2502    \u251c\u2500\u2500 Load McpPlugin instances from stored state                    \u2502\n\u2502    \u251c\u2500\u2500 Execute agent with LLM                                        \u2502\n\u2502    \u2502     \u2514\u2500\u2500 Tool calls use connection_manager.get_connection()      \u2502\n\u2502    \u2502         (connections created lazily, reused within request)     \u2502\n\u2502    \u2514\u2500\u2500 Cleanup: close all connections                                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"MCP_PR_REVIEW_GUIDE/#recommended-review-order","title":"Recommended Review Order","text":"<p>Review files in this order to build understanding progressively:</p>"},{"location":"MCP_PR_REVIEW_GUIDE/#1-configuration-start-here","title":"1. Configuration (Start Here)","text":"<p>Understand how MCP servers are configured:</p> File Purpose <code>sk_agents/tealagents/v1alpha1/config.py</code> <code>McpServerConfig</code> - all config options"},{"location":"MCP_PR_REVIEW_GUIDE/#2-state-management","title":"2. State Management","text":"<p>Understand how discovery state is stored:</p> File Purpose <code>sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <code>McpState</code> model, <code>DiscoveryManager</code> interface <code>sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> Default in-memory implementation <code>sk_agents/mcp_discovery/redis_discovery_manager.py</code> Production Redis implementation"},{"location":"MCP_PR_REVIEW_GUIDE/#3-connection-management","title":"3. Connection Management","text":"<p>Understand request-scoped connection pooling:</p> File Purpose <code>sk_agents/mcp_connection_manager.py</code> <code>McpConnectionManager</code> - lazy connections"},{"location":"MCP_PR_REVIEW_GUIDE/#4-discovery-plugin-registration","title":"4. Discovery &amp; Plugin Registration","text":"<p>Understand how tools are discovered:</p> File Purpose <code>sk_agents/mcp_plugin_registry.py</code> <code>McpPluginRegistry</code> - discovery orchestration <code>sk_agents/mcp_client.py</code> <code>McpTool</code>, <code>McpPlugin</code> - SK integration"},{"location":"MCP_PR_REVIEW_GUIDE/#5-handler-integration","title":"5. Handler Integration","text":"<p>Understand how it all comes together:</p> File Purpose <code>sk_agents/tealagents/v1alpha1/agent/handler.py</code> Handler integration points"},{"location":"MCP_PR_REVIEW_GUIDE/#6-authentication","title":"6. Authentication","text":"<p>Understand OAuth 2.1 flow:</p> File Purpose <code>sk_agents/auth/oauth21_client.py</code> OAuth 2.1 with PKCE implementation <code>sk_agents/auth_storage/</code> Token storage abstraction"},{"location":"MCP_PR_REVIEW_GUIDE/#testing-guide","title":"Testing Guide","text":""},{"location":"MCP_PR_REVIEW_GUIDE/#running-unit-tests","title":"Running Unit Tests","text":"<pre><code># Run all MCP tests\ncd src/sk-agents\npytest tests/mcp/ -v\n\n# Run specific test categories\npytest tests/mcp/test_mcp_client.py -v           # Core MCP client tests\npytest tests/mcp/test_connection_manager.py -v   # Connection management\npytest tests/mcp/test_state_manager.py -v        # State persistence\npytest tests/mcp/test_plugin_registry.py -v      # Discovery flow\npytest tests/mcp/test_auth*.py -v                # Authentication tests\n\n# Expected result: 140 passed, 5 skipped\n</code></pre>"},{"location":"MCP_PR_REVIEW_GUIDE/#local-integration-testing","title":"Local Integration Testing","text":"<p>To test with a real MCP server (like Arcade), follow this pattern:</p>"},{"location":"MCP_PR_REVIEW_GUIDE/#1-set-up-environment","title":"1. Set Up Environment","text":""},{"location":"MCP_PR_REVIEW_GUIDE/#2-create-agent-config","title":"2. Create Agent Config","text":"<pre><code># config.yaml\napiVersion: tealagents/v1alpha1\nkind: Chat\nname: TestAgent\nspec:\n  agent:\n    name: test_agent\n    role: Test Assistant\n    model: gpt-4o-mini\n    system_prompt: &gt;\n      You are a helpful assistant with access to external tools.\n\n    mcp_servers:\n      # Arcade MCP Server (requires API key)\n      - name: arcade\n        transport: http\n        url: https://api.arcade.dev/mcp/your-project-id\n        headers:\n          Authorization: \"Bearer your-arcade-api-key\"\n        user_id_header: Arcade-User-Id\n        user_id_source: env\n        user_id_env_var: ARCADE_USER_ID\n        trust_level: trusted\n        verify_ssl: false\n\n      # AWS Knowledge MCP (public, no auth)\n      - name: aws-knowledge\n        transport: http\n        url: https://knowledge-mcp.global.api.aws\n        trust_level: trusted\n        verify_ssl: false\n</code></pre>"},{"location":"MCP_PR_REVIEW_GUIDE/#3-run-the-agent","title":"3. Run the Agent","text":"<pre><code># run_agent.py\nimport uvicorn\nfrom sk_agents.tealagents.v1alpha1.chat_runner import TealAgentsV1Alpha1ChatRunner\n\nrunner = TealAgentsV1Alpha1ChatRunner(\"config.yaml\")\napp = runner.app\n\nif __name__ == \"__main__\":\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n</code></pre> <pre><code># Start the agent\npython run_agent.py\n\n# Test with curl\ncurl -X POST http://localhost:8000/tealagents/v1alpha1/chat \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"messages\": [{\"role\": \"user\", \"content\": \"What tools do you have access to?\"}]}'\n</code></pre>"},{"location":"MCP_PR_REVIEW_GUIDE/#what-to-verify-during-testing","title":"What to Verify During Testing","text":"Aspect How to Verify Discovery Check logs for \"Discovered N tools from server X\" Tool Registration Ask agent \"What tools do you have?\" Tool Execution Invoke an MCP tool and verify response Connection Reuse Multiple tool calls in one request should reuse connection Error Handling Test with invalid server URL - should fail gracefully"},{"location":"MCP_PR_REVIEW_GUIDE/#key-files-to-focus-on","title":"Key Files to Focus On","text":""},{"location":"MCP_PR_REVIEW_GUIDE/#critical-path-must-review","title":"Critical Path (Must Review)","text":"File Lines Changed Complexity <code>mcp_connection_manager.py</code> ~200 High - core connection logic <code>mcp_plugin_registry.py</code> ~300 High - discovery orchestration <code>mcp_client.py</code> ~400 High - SK integration <code>mcp_discovery/mcp_discovery_manager.py</code> ~100 Medium - state model"},{"location":"MCP_PR_REVIEW_GUIDE/#supporting-files-quick-review","title":"Supporting Files (Quick Review)","text":"File Purpose <code>mcp_discovery/in_memory_discovery_manager.py</code> In-memory state storage <code>mcp_discovery/redis_discovery_manager.py</code> Redis state storage <code>auth/oauth21_client.py</code> OAuth implementation"},{"location":"MCP_PR_REVIEW_GUIDE/#test-files-verify-coverage","title":"Test Files (Verify Coverage)","text":"File What It Tests <code>tests/mcp/test_mcp_client.py</code> McpTool, McpPlugin, governance mapping <code>tests/mcp/test_connection_manager.py</code> Connection lifecycle, pooling <code>tests/mcp/test_state_manager.py</code> State persistence, isolation <code>tests/mcp/test_plugin_registry.py</code> Discovery flow"},{"location":"MCP_PR_REVIEW_GUIDE/#configuration-quick-reference","title":"Configuration Quick Reference","text":""},{"location":"MCP_PR_REVIEW_GUIDE/#minimal-http-config","title":"Minimal HTTP Config","text":"<pre><code>mcp_servers:\n  - name: my-server\n    url: https://api.example.com/mcp\n</code></pre>"},{"location":"MCP_PR_REVIEW_GUIDE/#full-http-config-with-oauth","title":"Full HTTP Config with OAuth","text":"<pre><code>mcp_servers:\n  - name: github\n    transport: http\n    url: https://api.github.com/mcp\n    auth_server: https://github.com/login/oauth\n    scopes: [\"repo\", \"read:user\"]\n    trust_level: trusted\n    timeout: 30.0\n    sse_read_timeout: 300.0\n    verify_ssl: true\n    tool_governance_overrides:\n      delete_repository:\n        requires_hitl: true\n        cost: high\n</code></pre>"},{"location":"MCP_PR_REVIEW_GUIDE/#state-manager-configuration","title":"State Manager Configuration","text":"<pre><code># In-Memory (Default - for development)\n# No configuration needed\n\n# Redis (Production)\nexport TA_MCP_DISCOVERY_MODULE=\"sk_agents.mcp_discovery.redis_discovery_manager\"\nexport TA_MCP_DISCOVERY_CLASS=\"RedisStateManager\"\nexport TA_REDIS_HOST=\"your-redis-host\"\nexport TA_REDIS_PORT=\"6379\"\nexport TA_REDIS_DB=\"0\"\nexport TA_REDIS_PWD=\"your-password\"  # optional\nexport TA_REDIS_SSL=\"true\"           # optional\nexport TA_REDIS_TTL=\"86400\"          # optional, default 24h\n</code></pre>"},{"location":"MCP_PR_REVIEW_GUIDE/#common-review-questions","title":"Common Review Questions","text":""},{"location":"MCP_PR_REVIEW_GUIDE/#q-why-session-scoped-discovery-instead-of-per-request","title":"Q: Why session-scoped discovery instead of per-request?","text":"<p>A: Tool discovery involves HTTP calls to MCP servers and catalog registration. Doing this per-request would be slow and wasteful. Discovery happens once per session, with state stored externally (Redis in prod) to support horizontal scaling.</p>"},{"location":"MCP_PR_REVIEW_GUIDE/#q-why-request-scoped-connections-instead-of-persistent","title":"Q: Why request-scoped connections instead of persistent?","text":"<p>A: MCP connections are stateful and tied to a specific MCP session. Request-scoped connections: - Avoid connection staleness issues - Work correctly with load balancers - Allow clean resource cleanup - Are lazy (only created when tools are actually called)</p>"},{"location":"MCP_PR_REVIEW_GUIDE/#q-how-does-auth-work-across-multiple-servers","title":"Q: How does auth work across multiple servers?","text":"<p>A: Each MCP server can have its own OAuth configuration. Tokens are stored with a composite key: <code>(user_id, auth_server, sorted_scopes)</code>. This allows: - Per-user token isolation - Multiple tokens per user for different servers - Scope-specific token storage</p>"},{"location":"MCP_PR_REVIEW_GUIDE/#q-what-happens-if-an-mcp-server-is-down","title":"Q: What happens if an MCP server is down?","text":"<p>A: Discovery continues for other servers - one failure doesn't block others. Failed servers are logged and their tools won't be available. At runtime, tool calls to unavailable servers will raise appropriate errors.</p>"},{"location":"MCP_PR_REVIEW_GUIDE/#documentation-links","title":"Documentation Links","text":"Document Purpose MCP Integration Guide User-facing configuration guide MCP Client Specification Technical architecture spec MCP Tests README Testing documentation"},{"location":"PR_MESSAGE/","title":"Add MCP (Model Context Protocol) Integration","text":"<p>Introduces MCP support enabling agents to discover and use tools from external MCP servers.</p>"},{"location":"PR_MESSAGE/#changes","title":"Changes","text":"<ul> <li>Add HTTP transport with OAuth 2.1 (PKCE) authentication</li> <li>Add stdio transport for local subprocess MCP servers</li> <li>Add session-scoped tool discovery with external state storage</li> <li>Add request-scoped connection pooling for horizontal scaling</li> <li>Add governance/HITL integration with secure-by-default policies</li> <li>Add trust levels (trusted/sandboxed/untrusted) for MCP servers</li> <li>Add tool governance overrides for fine-grained control</li> <li>Add Redis state manager for production deployments</li> <li>Add in-memory state manager for development</li> <li>Add user ID propagation to MCP servers</li> <li>Add comprehensive test coverage (140 tests)</li> </ul>"},{"location":"PR_MESSAGE/#key-components","title":"Key Components","text":"<ul> <li><code>McpServerConfig</code> - MCP server configuration model</li> <li><code>McpConnectionManager</code> - Request-scoped lazy connection pooling</li> <li><code>McpPluginRegistry</code> - Tool discovery and catalog registration</li> <li><code>McpTool</code> - Individual MCP tool representation</li> <li><code>McpPlugin</code> - Semantic Kernel plugin wrapping MCP tools</li> <li><code>McpState</code> - Discovery state model</li> <li><code>InMemoryStateManager</code> - Development state storage</li> <li><code>RedisStateManager</code> - Production state storage</li> <li><code>OAuth21Client</code> - OAuth 2.1 with PKCE implementation</li> <li><code>AuthStorage</code> - Per-user token storage</li> </ul>"},{"location":"PR_MESSAGE/#known-limitations","title":"Known Limitations","text":"<ul> <li>OAuth 2.1 not end-to-end tested with real providers</li> <li>HTTP transport is primary focus (stdio secondary)</li> </ul>"},{"location":"PR_MESSAGE/#docs","title":"Docs","text":"<ul> <li><code>docs/mcp-integration.md</code> - User-facing configuration guide</li> <li><code>docs/mcp-client-specification.md</code> - Technical architecture spec</li> <li><code>docs/MCP_PR_REVIEW_GUIDE.md</code> - Detailed review instructions</li> </ul> Category Files Lines Source code (src/sk-agents/src/) 27 +6,231 Tests (src/sk-agents/tests/) 15 +3,997 Documentation (.md files) 5 +2,459 Other (examples, configs) 8 ~150 Total 55 +12,840"},{"location":"mcp-client-specification/","title":"MCP Client Technical Specification","text":"<p>Version: 3.0 Last Updated: 2025-01</p>"},{"location":"mcp-client-specification/#1-overview","title":"1. Overview","text":"<p>This specification describes the technical architecture and implementation of Model Context Protocol (MCP) client integration for the Teal Agents platform.</p>"},{"location":"mcp-client-specification/#11-design-principles","title":"1.1 Design Principles","text":"<ul> <li>Session-scoped discovery: Tools are discovered once per session and stored externally</li> <li>Request-scoped connections: Connections are created, pooled, and closed within each request</li> <li>Stateless tool wrappers: <code>McpTool</code> and <code>McpPlugin</code> store configuration, not connections</li> <li>External state storage: Discovery state stored in Redis for horizontal scaling</li> <li>Secure-by-default: Unknown tools require HITL approval</li> </ul>"},{"location":"mcp-client-specification/#12-key-design-decisions","title":"1.2 Key Design Decisions","text":"Decision Rationale Session-level discovery Avoid repeated discovery overhead; tools rarely change mid-session Request-scoped connection pooling Balance efficiency (reuse within request) with resource cleanup External state storage Enable horizontal scaling and persistence across restarts Lazy connection creation Only connect to servers when tools are actually called MCP session ID persistence Support stateful MCP servers across requests"},{"location":"mcp-client-specification/#2-architecture","title":"2. Architecture","text":""},{"location":"mcp-client-specification/#21-component-diagram","title":"2.1 Component Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                              Teal Agents MCP Architecture                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502                         CONFIGURATION LAYER                          \u2502    \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502    \u2502\n\u2502  \u2502  \u2502 McpServerConfig \u2502  \u2502GovernanceOverride\u2502  \u2502   AgentConfig       \u2502  \u2502    \u2502\n\u2502  \u2502  \u2502 - name          \u2502  \u2502 - requires_hitl  \u2502  \u2502 - mcp_servers[]     \u2502  \u2502    \u2502\n\u2502  \u2502  \u2502 - transport     \u2502  \u2502 - cost           \u2502  \u2502 - plugins[]         \u2502  \u2502    \u2502\n\u2502  \u2502  \u2502 - url/command   \u2502  \u2502 - data_sensitivity\u2502  \u2502 - system_prompt    \u2502  \u2502    \u2502\n\u2502  \u2502  \u2502 - auth_server   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502    \u2502\n\u2502  \u2502  \u2502 - scopes        \u2502                                                 \u2502    \u2502\n\u2502  \u2502  \u2502 - trust_level   \u2502                                                 \u2502    \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                 \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                      \u2502                                       \u2502\n\u2502                                      \u25bc                                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502                         DISCOVERY LAYER                              \u2502    \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502    \u2502\n\u2502  \u2502  \u2502                    McpPluginRegistry                         \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502  - discover_and_materialize(servers, user_id, session_id)   \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502  - get_tools_for_session(user_id, session_id)               \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502  - _register_tool_in_catalog(tool, server_config)           \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502  - _serialize_plugin_data(tools, server_name)               \u2502    \u2502    \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2502\n\u2502  \u2502                              \u2502                                       \u2502    \u2502\n\u2502  \u2502                              \u25bc                                       \u2502    \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502    \u2502\n\u2502  \u2502  \u2502                    McpStateManager                           \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502  - create_discovery() / load_discovery()                    \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502  - mark_completed() / is_completed()                        \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502  - store_mcp_session() / get_mcp_session()                  \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502                                                              \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502  Implementations:                                            \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502  - InMemoryStateManager (dev/test)                          \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502  - RedisStateManager (production)                           \u2502    \u2502    \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                      \u2502                                       \u2502\n\u2502                                      \u25bc                                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502                         CONNECTION LAYER                             \u2502    \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502    \u2502\n\u2502  \u2502  \u2502                  McpConnectionManager                        \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502  - __aenter__(): Load stored session IDs                    \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502  - __aexit__(): Persist session IDs, close connections      \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502  - get_or_create_session(server_name): Lazy connection      \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502                                                              \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502  Lifecycle: Created per-request, used as async context mgr  \u2502    \u2502    \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2502\n\u2502  \u2502                              \u2502                                       \u2502    \u2502\n\u2502  \u2502                              \u25bc                                       \u2502    \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502    \u2502\n\u2502  \u2502  \u2502              create_mcp_session_with_retry()                 \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502  - Transport selection (stdio / http)                       \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502  - OAuth token resolution                                   \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502  - MCP session initialization                               \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502  - Stale session recovery                                   \u2502    \u2502    \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                      \u2502                                       \u2502\n\u2502                                      \u25bc                                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502                         EXECUTION LAYER                              \u2502    \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502    \u2502\n\u2502  \u2502  \u2502       McpTool        \u2502      \u2502         McpPlugin            \u2502     \u2502    \u2502\n\u2502  \u2502  \u2502  - tool_name         \u2502      \u2502  - tools: List[McpTool]      \u2502     \u2502    \u2502\n\u2502  \u2502  \u2502  - input_schema      \u2502      \u2502  - server_name               \u2502     \u2502    \u2502\n\u2502  \u2502  \u2502  - server_config     \u2502      \u2502  - user_id                   \u2502     \u2502    \u2502\n\u2502  \u2502  \u2502  - invoke(conn_mgr)  \u2502      \u2502  - connection_manager        \u2502     \u2502    \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502  - @kernel_function methods  \u2502     \u2502    \u2502\n\u2502  \u2502           \u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502    \u2502\n\u2502  \u2502           \u2502                                 \u2502                        \u2502    \u2502\n\u2502  \u2502           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                        \u2502    \u2502\n\u2502  \u2502                         \u25bc                                            \u2502    \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502    \u2502\n\u2502  \u2502  \u2502                   Semantic Kernel                            \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502  - Plugins registered with kernel.add_plugin()              \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502  - Tools exposed as @kernel_function                        \u2502    \u2502    \u2502\n\u2502  \u2502  \u2502  - LLM invokes tools via function calling                   \u2502    \u2502    \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"mcp-client-specification/#22-data-flow","title":"2.2 Data Flow","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                            Complete Request Flow                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502 PHASE 1: SESSION DISCOVERY (once per session)                        \u2502    \u2502\n\u2502  \u2502                                                                       \u2502    \u2502\n\u2502  \u2502  User Request \u2500\u2500\u25b6 Handler.invoke()                                   \u2502    \u2502\n\u2502  \u2502       \u2502                                                               \u2502    \u2502\n\u2502  \u2502       \u25bc                                                               \u2502    \u2502\n\u2502  \u2502  _ensure_session_discovery(user_id, session_id)                      \u2502    \u2502\n\u2502  \u2502       \u2502                                                               \u2502    \u2502\n\u2502  \u2502       \u251c\u2500\u2500\u25b6 McpStateManager.is_completed()? \u2500\u2500\u25b6 Skip if true         \u2502    \u2502\n\u2502  \u2502       \u2502                                                               \u2502    \u2502\n\u2502  \u2502       \u25bc                                                               \u2502    \u2502\n\u2502  \u2502  McpPluginRegistry.discover_and_materialize()                        \u2502    \u2502\n\u2502  \u2502       \u2502                                                               \u2502    \u2502\n\u2502  \u2502       \u251c\u2500\u2500\u25b6 For each server:                                          \u2502    \u2502\n\u2502  \u2502       \u2502      \u2502                                                        \u2502    \u2502\n\u2502  \u2502       \u2502      \u251c\u2500\u2500\u25b6 resolve_server_auth_headers()                      \u2502    \u2502\n\u2502  \u2502       \u2502      \u2502      \u2514\u2500\u2500\u25b6 AuthRequiredError if no token               \u2502    \u2502\n\u2502  \u2502       \u2502      \u2502                                                        \u2502    \u2502\n\u2502  \u2502       \u2502      \u251c\u2500\u2500\u25b6 create_mcp_session_with_retry()                    \u2502    \u2502\n\u2502  \u2502       \u2502      \u2502      \u251c\u2500\u2500\u25b6 stdio_client() or streamablehttp_client()   \u2502    \u2502\n\u2502  \u2502       \u2502      \u2502      \u2514\u2500\u2500\u25b6 initialize_mcp_session()                    \u2502    \u2502\n\u2502  \u2502       \u2502      \u2502                                                        \u2502    \u2502\n\u2502  \u2502       \u2502      \u251c\u2500\u2500\u25b6 session.list_tools()                               \u2502    \u2502\n\u2502  \u2502       \u2502      \u2502                                                        \u2502    \u2502\n\u2502  \u2502       \u2502      \u251c\u2500\u2500\u25b6 _register_tool_in_catalog() (for governance)       \u2502    \u2502\n\u2502  \u2502       \u2502      \u2502                                                        \u2502    \u2502\n\u2502  \u2502       \u2502      \u2514\u2500\u2500\u25b6 _serialize_plugin_data() \u2500\u2500\u25b6 McpStateManager       \u2502    \u2502\n\u2502  \u2502       \u2502                                                               \u2502    \u2502\n\u2502  \u2502       \u2514\u2500\u2500\u25b6 McpStateManager.mark_completed()                          \u2502    \u2502\n\u2502  \u2502                                                                       \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                      \u2502                                       \u2502\n\u2502                                      \u25bc                                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502 PHASE 2: REQUEST EXECUTION (every request)                           \u2502    \u2502\n\u2502  \u2502                                                                       \u2502    \u2502\n\u2502  \u2502  McpConnectionManager created (request-scoped)                       \u2502    \u2502\n\u2502  \u2502       \u2502                                                               \u2502    \u2502\n\u2502  \u2502       \u251c\u2500\u2500\u25b6 __aenter__(): Load stored MCP session IDs                \u2502    \u2502\n\u2502  \u2502       \u2502                                                               \u2502    \u2502\n\u2502  \u2502       \u25bc                                                               \u2502    \u2502\n\u2502  \u2502  KernelBuilder.load_mcp_plugins()                                    \u2502    \u2502\n\u2502  \u2502       \u2502                                                               \u2502    \u2502\n\u2502  \u2502       \u251c\u2500\u2500\u25b6 McpPluginRegistry.get_tools_for_session()                \u2502    \u2502\n\u2502  \u2502       \u2502                                                               \u2502    \u2502\n\u2502  \u2502       \u251c\u2500\u2500\u25b6 Create McpPlugin instances (with connection_manager)      \u2502    \u2502\n\u2502  \u2502       \u2502                                                               \u2502    \u2502\n\u2502  \u2502       \u2514\u2500\u2500\u25b6 kernel.add_plugin() for each server                       \u2502    \u2502\n\u2502  \u2502                                                                       \u2502    \u2502\n\u2502  \u2502       \u25bc                                                               \u2502    \u2502\n\u2502  \u2502  Agent execution (LLM + tool calls)                                  \u2502    \u2502\n\u2502  \u2502       \u2502                                                               \u2502    \u2502\n\u2502  \u2502       \u251c\u2500\u2500\u25b6 LLM decides to call MCP tool                              \u2502    \u2502\n\u2502  \u2502       \u2502                                                               \u2502    \u2502\n\u2502  \u2502       \u251c\u2500\u2500\u25b6 McpPlugin.tool_function() called                          \u2502    \u2502\n\u2502  \u2502       \u2502      \u2502                                                        \u2502    \u2502\n\u2502  \u2502       \u2502      \u2514\u2500\u2500\u25b6 McpTool.invoke(connection_manager)                 \u2502    \u2502\n\u2502  \u2502       \u2502             \u2502                                                 \u2502    \u2502\n\u2502  \u2502       \u2502             \u251c\u2500\u2500\u25b6 connection_manager.get_or_create_session()  \u2502    \u2502\n\u2502  \u2502       \u2502             \u2502      \u2514\u2500\u2500\u25b6 Lazy connection (reused if exists)   \u2502    \u2502\n\u2502  \u2502       \u2502             \u2502                                                 \u2502    \u2502\n\u2502  \u2502       \u2502             \u2514\u2500\u2500\u25b6 session.call_tool(tool_name, args)          \u2502    \u2502\n\u2502  \u2502       \u2502                                                               \u2502    \u2502\n\u2502  \u2502       \u2514\u2500\u2500\u25b6 Return result to LLM                                      \u2502    \u2502\n\u2502  \u2502                                                                       \u2502    \u2502\n\u2502  \u2502       \u25bc                                                               \u2502    \u2502\n\u2502  \u2502  McpConnectionManager.__aexit__()                                    \u2502    \u2502\n\u2502  \u2502       \u2502                                                               \u2502    \u2502\n\u2502  \u2502       \u251c\u2500\u2500\u25b6 Persist MCP session IDs to McpStateManager               \u2502    \u2502\n\u2502  \u2502       \u2502                                                               \u2502    \u2502\n\u2502  \u2502       \u2514\u2500\u2500\u25b6 Close all connections                                     \u2502    \u2502\n\u2502  \u2502                                                                       \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"mcp-client-specification/#3-core-components","title":"3. Core Components","text":""},{"location":"mcp-client-specification/#31-mcpserverconfig","title":"3.1 McpServerConfig","text":"<p>Location: <code>tealagents/v1alpha1/config.py</code></p> <p>Configuration model for MCP server connections.</p> <pre><code>class McpServerConfig(BaseModel):\n    # Identity\n    name: str                                           # Unique server identifier\n    transport: Literal[\"stdio\", \"http\"] | None = None   # Inferred if omitted\n\n    # Stdio transport\n    command: str | None = None                          # Executable command\n    args: list[str] = []                                # Command arguments\n    env: dict[str, str] | None = None                   # Environment variables\n\n    # HTTP transport\n    url: str | None = None                              # MCP endpoint URL\n    headers: dict[str, str] | None = None               # Non-sensitive headers\n    timeout: float | None = 30.0                        # Connection timeout\n    sse_read_timeout: float | None = 300.0              # SSE read timeout\n    verify_ssl: bool = True                             # SSL verification\n\n    # OAuth 2.1\n    auth_server: str | None = None                      # Authorization server URL\n    scopes: list[str] = []                              # Required OAuth scopes\n    oauth_client_id: str | None = None                  # Pre-registered client ID\n    oauth_client_secret: str | None = None              # Client secret\n    canonical_uri: str | None = None                    # Explicit canonical URI\n    enable_dynamic_registration: bool = True            # Try RFC 7591\n    protocol_version: str | None = None                 # MCP protocol version\n\n    # Governance\n    trust_level: Literal[\"trusted\", \"sandboxed\", \"untrusted\"] = \"untrusted\"\n    tool_governance_overrides: dict[str, GovernanceOverride] | None = None\n\n    # User context\n    user_id_header: str | None = None                   # Header for user ID injection\n    user_id_source: Literal[\"auth\", \"env\"] | None = None\n\n    @property\n    def effective_transport(self) -&gt; str:\n        \"\"\"Infer transport from configuration.\"\"\"\n        if self.transport:\n            return self.transport\n        if self.url and not self.command:\n            return \"http\"\n        if self.command and not self.url:\n            return \"stdio\"\n        raise ValueError(\"Cannot infer transport\")\n\n    @property\n    def effective_canonical_uri(self) -&gt; str:\n        \"\"\"Get canonical URI for OAuth resource binding.\"\"\"\n        return self.canonical_uri or self.url\n</code></pre> <p>Validation Rules: - <code>name</code> is required - <code>url</code> required for HTTP transport - <code>command</code> required for stdio transport - Warn if HTTP without <code>auth_server</code> (security) - Validate HTTPS for OAuth endpoints</p>"},{"location":"mcp-client-specification/#32-mcpstatemanager","title":"3.2 McpStateManager","text":"<p>Location: <code>mcp_discovery/mcp_discovery_manager.py</code></p> <p>Abstract interface for session-scoped state persistence.</p> <pre><code>class McpState:\n    user_id: str                              # User ID for scoping\n    session_id: str                           # Session ID for isolation\n    discovered_servers: dict[str, dict]       # server_name \u2192 {plugin_data, session}\n    discovery_completed: bool                 # Discovery completion flag\n    failed_servers: dict[str, str]            # Failed servers with error messages\n    created_at: datetime                      # State creation timestamp\n\nclass McpStateManager(ABC):\n    @abstractmethod\n    async def create_discovery(self, state: McpState) -&gt; None: ...\n\n    @abstractmethod\n    async def load_discovery(self, user_id: str, session_id: str) -&gt; McpState | None: ...\n\n    @abstractmethod\n    async def update_discovery(self, state: McpState) -&gt; None: ...\n\n    @abstractmethod\n    async def delete_discovery(self, user_id: str, session_id: str) -&gt; None: ...\n\n    @abstractmethod\n    async def mark_completed(self, user_id: str, session_id: str) -&gt; None: ...\n\n    @abstractmethod\n    async def is_completed(self, user_id: str, session_id: str) -&gt; bool: ...\n\n    @abstractmethod\n    async def store_mcp_session(\n        self, user_id: str, session_id: str, server_name: str, mcp_session_id: str\n    ) -&gt; None: ...\n\n    @abstractmethod\n    async def get_mcp_session(\n        self, user_id: str, session_id: str, server_name: str\n    ) -&gt; str | None: ...\n\n    @abstractmethod\n    async def clear_mcp_session(\n        self, user_id: str, session_id: str, server_name: str,\n        expected_session_id: str | None = None\n    ) -&gt; None: ...\n</code></pre> <p>Implementations:</p> Class Storage Use Case <code>InMemoryStateManager</code> Dict with asyncio.Lock Development, testing <code>RedisStateManager</code> Redis with Lua scripts Production, horizontal scaling <p>Redis Key Format: <code>mcp_state:{user_id}:{session_id}</code></p> <p>Redis Features: - TTL support (default 24 hours) - Atomic operations via Lua scripts - JSON serialization</p>"},{"location":"mcp-client-specification/#33-mcppluginregistry","title":"3.3 McpPluginRegistry","text":"<p>Location: <code>mcp_plugin_registry.py</code></p> <p>Stateless class with class methods for tool discovery and retrieval.</p> <pre><code>class McpPluginRegistry:\n    @classmethod\n    async def discover_and_materialize(\n        cls,\n        mcp_servers: list[McpServerConfig],\n        user_id: str,\n        session_id: str,\n        discovery_manager: McpStateManager,\n        app_config: AppConfig,\n    ) -&gt; None:\n        \"\"\"\n        Discover tools from MCP servers and store in state manager.\n\n        Flow:\n        1. Load/create discovery state\n        2. For each server:\n           a. Resolve OAuth tokens (pre-flight auth check)\n           b. Connect to server\n           c. Initialize MCP session\n           d. List tools\n           e. Register in catalog (governance)\n           f. Serialize and store\n        3. Mark discovery completed\n        4. Raise first AuthRequiredError if any\n        \"\"\"\n\n    @classmethod\n    async def get_tools_for_session(\n        cls,\n        user_id: str,\n        session_id: str,\n        discovery_manager: McpStateManager,\n    ) -&gt; dict[str, list[McpTool]]:\n        \"\"\"\n        Get discovered tools for a session.\n\n        Returns: {server_name: [McpTool, ...]}\n        \"\"\"\n\n    @classmethod\n    def _register_tool_in_catalog(\n        cls,\n        tool_info: Tool,\n        server_config: McpServerConfig,\n    ) -&gt; None:\n        \"\"\"Register tool in PluginCatalog for governance/HITL.\"\"\"\n\n    @classmethod\n    def _serialize_plugin_data(\n        cls,\n        tools: list[McpTool],\n        server_name: str,\n        server_config: McpServerConfig,\n    ) -&gt; dict:\n        \"\"\"Serialize tools for external storage (secrets stripped).\"\"\"\n</code></pre>"},{"location":"mcp-client-specification/#34-mcpconnectionmanager","title":"3.4 McpConnectionManager","text":"<p>Location: <code>mcp_client.py</code></p> <p>Request-scoped connection manager with lazy connection creation.</p> <pre><code>class McpConnectionManager:\n    def __init__(\n        self,\n        server_configs: dict[str, McpServerConfig],\n        user_id: str,\n        session_id: str,\n        state_manager: McpStateManager,\n        app_config: AppConfig,\n    ):\n        self._server_configs = server_configs\n        self._user_id = user_id\n        self._session_id = session_id\n        self._state_manager = state_manager\n        self._app_config = app_config\n\n        # Runtime state\n        self._sessions: dict[str, ClientSession] = {}\n        self._get_session_id_callbacks: dict[str, Callable] = {}\n        self._stored_session_ids: dict[str, str] = {}\n        self._connection_stack = AsyncExitStack()\n\n    async def __aenter__(self) -&gt; \"McpConnectionManager\":\n        \"\"\"\n        Enter context: Load stored MCP session IDs.\n        \"\"\"\n        for server_name in self._server_configs:\n            stored_id = await self._state_manager.get_mcp_session(\n                self._user_id, self._session_id, server_name\n            )\n            if stored_id:\n                self._stored_session_ids[server_name] = stored_id\n        return self\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb) -&gt; None:\n        \"\"\"\n        Exit context: Persist session IDs and close connections.\n        \"\"\"\n        # Persist MCP session IDs for servers that were connected\n        for server_name, get_session_id in self._get_session_id_callbacks.items():\n            current_id = get_session_id()\n            if current_id:\n                await self._state_manager.store_mcp_session(\n                    self._user_id, self._session_id, server_name, current_id\n                )\n\n        # Close all connections\n        await self._connection_stack.__aexit__(exc_type, exc_val, exc_tb)\n\n    async def get_or_create_session(self, server_name: str) -&gt; ClientSession:\n        \"\"\"\n        Get existing session or create new one (lazy).\n\n        Sessions are reused within the request scope.\n        \"\"\"\n        if server_name in self._sessions:\n            return self._sessions[server_name]\n\n        server_config = self._server_configs[server_name]\n\n        session, get_session_id = await create_mcp_session_with_retry(\n            server_config,\n            self._connection_stack,\n            self._user_id,\n            mcp_session_id=self._stored_session_ids.get(server_name),\n            on_stale_session=self._create_stale_handler(server_name),\n            app_config=self._app_config,\n        )\n\n        self._sessions[server_name] = session\n        self._get_session_id_callbacks[server_name] = get_session_id\n\n        return session\n</code></pre>"},{"location":"mcp-client-specification/#35-mcptool","title":"3.5 McpTool","text":"<p>Location: <code>mcp_client.py</code></p> <p>Stateless tool wrapper that stores configuration for invocation.</p> <pre><code>class McpTool:\n    def __init__(\n        self,\n        tool_name: str,\n        description: str,\n        input_schema: dict[str, Any],\n        output_schema: dict[str, Any] | None,\n        server_config: McpServerConfig,\n        server_name: str,\n    ):\n        self.tool_name = tool_name\n        self.description = description\n        self.input_schema = input_schema\n        self.output_schema = output_schema\n        self.server_config = server_config  # Sanitized (no secrets)\n        self.server_name = server_name\n\n    async def invoke(\n        self,\n        connection_manager: McpConnectionManager,\n        **kwargs: Any,\n    ) -&gt; str:\n        \"\"\"\n        Invoke tool via connection manager.\n\n        1. Validate inputs against JSON schema\n        2. Get/create session via connection manager\n        3. Execute tool\n        4. Parse result to string\n        \"\"\"\n        self._validate_inputs(kwargs)\n\n        session = await connection_manager.get_or_create_session(self.server_name)\n\n        result = await session.call_tool(self.tool_name, kwargs)\n\n        return self._parse_result(result)\n\n    def _validate_inputs(self, kwargs: dict) -&gt; None:\n        \"\"\"Validate inputs against JSON schema.\"\"\"\n        # Check required properties\n        required = self.input_schema.get(\"required\", [])\n        for prop in required:\n            if prop not in kwargs:\n                raise ValueError(f\"Missing required parameter: {prop}\")\n\n    def _parse_result(self, result: CallToolResult) -&gt; str:\n        \"\"\"Parse MCP result to string.\"\"\"\n        if result.isError:\n            error_text = \"\\n\".join(\n                c.text for c in result.content if hasattr(c, \"text\")\n            )\n            raise RuntimeError(f\"MCP tool error: {error_text}\")\n\n        return \"\\n\".join(\n            c.text for c in result.content if hasattr(c, \"text\")\n        )\n</code></pre>"},{"location":"mcp-client-specification/#36-mcpplugin","title":"3.6 McpPlugin","text":"<p>Location: <code>mcp_client.py</code></p> <p>Semantic Kernel plugin wrapper that dynamically creates kernel functions.</p> <pre><code>class McpPlugin(BasePlugin):\n    def __init__(\n        self,\n        tools: list[McpTool],\n        server_name: str,\n        user_id: str,\n        connection_manager: McpConnectionManager,\n    ):\n        if not user_id:\n            raise ValueError(\"MCP plugins require user_id for OAuth2 resolution\")\n        if not connection_manager:\n            raise ValueError(\"MCP plugins require connection_manager\")\n\n        self.server_name = server_name\n        self.user_id = user_id\n        self.connection_manager = connection_manager\n\n        # Dynamically add kernel functions for each tool\n        for tool in tools:\n            self._add_tool_function(tool)\n\n    def _add_tool_function(self, tool: McpTool) -&gt; None:\n        \"\"\"Create @kernel_function method for tool.\"\"\"\n\n        @kernel_function(\n            name=f\"{self.server_name}_{tool.tool_name}\",\n            description=tool.description,\n        )\n        async def tool_function(**kwargs: Any) -&gt; str:\n            return await tool.invoke(\n                connection_manager=self.connection_manager,\n                **kwargs,\n            )\n\n        # Set parameter metadata from JSON schema\n        tool_function.__kernel_function_parameters__ = self._build_parameters(\n            tool.input_schema\n        )\n\n        # Add as instance method\n        sanitized_name = self._sanitize_name(tool.tool_name)\n        setattr(self, sanitized_name, tool_function)\n\n    def _build_parameters(self, input_schema: dict) -&gt; list[dict]:\n        \"\"\"Convert JSON schema to Semantic Kernel parameter format.\"\"\"\n        parameters = []\n        properties = input_schema.get(\"properties\", {})\n        required = input_schema.get(\"required\", [])\n\n        for name, prop in properties.items():\n            parameters.append({\n                \"name\": name,\n                \"description\": prop.get(\"description\", \"\"),\n                \"type\": self._json_type_to_python(prop.get(\"type\")),\n                \"required\": name in required,\n                \"default_value\": prop.get(\"default\"),\n            })\n\n        return parameters\n</code></pre>"},{"location":"mcp-client-specification/#4-authentication","title":"4. Authentication","text":""},{"location":"mcp-client-specification/#41-oauth-21-implementation","title":"4.1 OAuth 2.1 Implementation","text":"<p>Location: <code>auth/oauth_client.py</code></p> <pre><code>class OAuthClient:\n    async def initiate_authorization_flow(\n        self,\n        server_config: McpServerConfig,\n        user_id: str,\n    ) -&gt; str:\n        \"\"\"\n        Initiate OAuth authorization flow.\n\n        1. Discover Protected Resource Metadata (RFC 9728)\n        2. Determine if resource parameter needed (protocol version check)\n        3. Generate PKCE pair (verifier, challenge)\n        4. Generate state (CSRF protection)\n        5. Store flow state\n        6. Discover auth server metadata (RFC 8414)\n        7. Try dynamic client registration (RFC 7591) if no client_id\n        8. Build authorization URL\n\n        Returns: Authorization URL for user redirect\n        \"\"\"\n\n    async def handle_callback(\n        self,\n        code: str,\n        state: str,\n        user_id: str,\n        server_config: McpServerConfig,\n    ) -&gt; OAuth2AuthData:\n        \"\"\"\n        Handle OAuth callback after user authorization.\n\n        1. Validate state (CSRF + user_id match)\n        2. Exchange code for tokens (with PKCE verifier)\n        3. Validate scopes (prevent escalation)\n        4. Store tokens in AuthStorage\n        5. Clean up flow state\n\n        Returns: Stored OAuth2AuthData\n        \"\"\"\n\n    async def refresh_access_token(\n        self,\n        refresh_request: RefreshTokenRequest,\n    ) -&gt; TokenResponse:\n        \"\"\"Refresh expired access token.\"\"\"\n\n    @staticmethod\n    def validate_token_scopes(\n        requested_scopes: list[str] | None,\n        token_response: TokenResponse,\n    ) -&gt; None:\n        \"\"\"\n        Validate that returned scopes don't exceed requested scopes.\n\n        Prevents scope escalation attacks per OAuth 2.1 Section 3.3.\n        \"\"\"\n</code></pre>"},{"location":"mcp-client-specification/#42-token-resolution","title":"4.2 Token Resolution","text":"<p>Location: <code>mcp_client.py</code></p> <pre><code>async def resolve_server_auth_headers(\n    server_config: McpServerConfig,\n    user_id: str | None = None,\n    app_config: AppConfig | None = None,\n) -&gt; dict[str, str]:\n    \"\"\"\n    Resolve authentication headers for MCP server.\n\n    Priority:\n    1. User ID header injection (if configured)\n    2. Static headers (non-Authorization)\n    3. OAuth token from AuthStorage\n\n    Raises:\n        AuthRequiredError: If OAuth configured but no token available\n    \"\"\"\n    headers = {}\n\n    # User ID injection\n    if server_config.user_id_header and user_id:\n        headers[server_config.user_id_header] = user_id\n\n    # Static headers (filter out Authorization if OAuth configured)\n    if server_config.headers:\n        for k, v in server_config.headers.items():\n            if k.lower() != \"authorization\" or not server_config.auth_server:\n                headers[k] = v\n\n    # OAuth token resolution\n    if server_config.auth_server and server_config.scopes:\n        auth_storage = AuthStorageFactory(app_config).get_auth_storage_manager()\n        composite_key = build_auth_storage_key(\n            server_config.auth_server,\n            server_config.scopes\n        )\n\n        auth_data = auth_storage.retrieve(user_id, composite_key)\n\n        if not auth_data:\n            raise AuthRequiredError(\n                server_name=server_config.name,\n                auth_server=server_config.auth_server,\n                scopes=server_config.scopes,\n            )\n\n        # Validate token\n        resource_uri = server_config.effective_canonical_uri\n        if not auth_data.is_valid_for_resource(resource_uri):\n            # Try refresh\n            if auth_data.refresh_token:\n                # ... refresh logic ...\n                pass\n            else:\n                raise AuthRequiredError(...)\n\n        headers[\"Authorization\"] = f\"Bearer {auth_data.access_token}\"\n\n    return headers\n</code></pre>"},{"location":"mcp-client-specification/#43-auth-storage-key","title":"4.3 Auth Storage Key","text":"<pre><code>def build_auth_storage_key(auth_server: str, scopes: list[str]) -&gt; str:\n    \"\"\"\n    Build composite key for auth storage.\n\n    Format: {auth_server}|{sorted_scopes}\n\n    Scopes are sorted for consistency:\n    - [\"write\", \"read\"] \u2192 \"read|write\"\n    \"\"\"\n    sorted_scopes = sorted(scopes)\n    return f\"{auth_server}|{'|'.join(sorted_scopes)}\"\n</code></pre>"},{"location":"mcp-client-specification/#5-governance","title":"5. Governance","text":""},{"location":"mcp-client-specification/#51-governance-mapping","title":"5.1 Governance Mapping","text":"<p>Location: <code>mcp_client.py</code></p> <pre><code>def map_mcp_annotations_to_governance(\n    annotations: dict[str, Any],\n    tool_description: str = \"\",\n) -&gt; Governance:\n    \"\"\"\n    Map MCP tool annotations to governance policy.\n\n    SECURE-BY-DEFAULT: Start with HITL required, relax only with\n    explicit safe annotations.\n    \"\"\"\n    requires_hitl = True\n    cost = \"high\"\n    data_sensitivity = \"sensitive\"\n\n    # Relax for explicit read-only\n    if annotations.get(\"readOnlyHint\"):\n        requires_hitl = False\n        cost = \"low\"\n        data_sensitivity = \"public\"\n\n    # Strengthen for explicit destructive\n    if annotations.get(\"destructiveHint\"):\n        requires_hitl = True\n        cost = \"high\"\n        data_sensitivity = \"sensitive\"\n\n    # Check description for high-risk keywords\n    high_risk_keywords = [\n        \"http\", \"network\", \"api\", \"file\", \"execute\", \"database\",\n        \"delete\", \"remove\", \"modify\", \"write\", \"create\", \"send\",\n    ]\n    description_lower = tool_description.lower()\n    if any(kw in description_lower for kw in high_risk_keywords):\n        requires_hitl = True\n\n    return Governance(\n        requires_hitl=requires_hitl,\n        cost=cost,\n        data_sensitivity=data_sensitivity,\n    )\n</code></pre>"},{"location":"mcp-client-specification/#52-trust-level-application","title":"5.2 Trust Level Application","text":"<pre><code>def apply_trust_level_governance(\n    base_governance: Governance,\n    trust_level: str,\n    tool_description: str = \"\",\n) -&gt; Governance:\n    \"\"\"\n    Apply trust level to base governance.\n\n    Trust levels:\n    - untrusted: Force HITL for ALL tools\n    - sandboxed: Elevated restrictions\n    - trusted: Use annotation-based (with defense-in-depth)\n    \"\"\"\n    if trust_level == \"untrusted\":\n        return Governance(\n            requires_hitl=True,\n            cost=\"high\",\n            data_sensitivity=\"sensitive\",\n        )\n\n    if trust_level == \"sandboxed\":\n        return Governance(\n            requires_hitl=True,\n            cost=base_governance.cost,\n            data_sensitivity=base_governance.data_sensitivity,\n        )\n\n    # trusted: Check for high-risk even on trusted servers\n    if _has_high_risk_indicators(tool_description):\n        return Governance(\n            requires_hitl=True,\n            cost=\"high\",\n            data_sensitivity=\"sensitive\",\n        )\n\n    return base_governance\n</code></pre>"},{"location":"mcp-client-specification/#53-governance-overrides","title":"5.3 Governance Overrides","text":"<pre><code>def apply_governance_overrides(\n    base_governance: Governance,\n    tool_name: str,\n    overrides: dict[str, GovernanceOverride] | None,\n) -&gt; Governance:\n    \"\"\"\n    Apply per-tool governance overrides.\n\n    Overrides take precedence over base governance.\n    Only specified fields are overridden.\n    \"\"\"\n    if not overrides or tool_name not in overrides:\n        return base_governance\n\n    override = overrides[tool_name]\n\n    return Governance(\n        requires_hitl=(\n            override.requires_hitl\n            if override.requires_hitl is not None\n            else base_governance.requires_hitl\n        ),\n        cost=override.cost or base_governance.cost,\n        data_sensitivity=override.data_sensitivity or base_governance.data_sensitivity,\n    )\n</code></pre>"},{"location":"mcp-client-specification/#6-handler-integration","title":"6. Handler Integration","text":""},{"location":"mcp-client-specification/#61-session-discovery","title":"6.1 Session Discovery","text":"<p>Location: <code>tealagents/v1alpha1/agent/handler.py</code></p> <pre><code>async def _ensure_session_discovery(\n    self,\n    user_id: str,\n    session_id: str,\n    task_id: str,\n    request_id: str,\n) -&gt; AuthChallengeResponse | None:\n    \"\"\"\n    Ensure MCP discovery is completed for session.\n\n    Returns AuthChallengeResponse if authentication required.\n    \"\"\"\n    # Check if already completed\n    if await self.discovery_manager.is_completed(user_id, session_id):\n        return None\n\n    # Create state if needed\n    state = await self.discovery_manager.load_discovery(user_id, session_id)\n    if not state:\n        state = McpState(\n            user_id=user_id,\n            session_id=session_id,\n            discovered_servers={},\n            discovery_completed=False,\n        )\n        await self.discovery_manager.create_discovery(state)\n\n    # Run discovery\n    try:\n        await McpPluginRegistry.discover_and_materialize(\n            self.config.get_agent().mcp_servers,\n            user_id,\n            session_id,\n            self.discovery_manager,\n            self.app_config,\n        )\n        await self.discovery_manager.mark_completed(user_id, session_id)\n        return None\n\n    except AuthRequiredError as e:\n        # Generate OAuth authorization URL\n        auth_url = await self.oauth_client.initiate_authorization_flow(\n            self._get_server_config(e.server_name),\n            user_id,\n        )\n\n        return AuthChallengeResponse(\n            session_id=session_id,\n            task_id=task_id,\n            auth_challenges=[{\n                \"server_name\": e.server_name,\n                \"auth_server\": e.auth_server,\n                \"scopes\": e.scopes,\n                \"auth_url\": auth_url,\n            }],\n            resume_url=f\"/tealagents/v1alpha1/invoke\",\n        )\n</code></pre>"},{"location":"mcp-client-specification/#62-request-execution","title":"6.2 Request Execution","text":"<pre><code>async def invoke(self, auth_token: str, inputs: dict) -&gt; AgentResponse:\n    # 1. Authenticate user\n    user_id = await self.authenticate_user(auth_token)\n    session_id, task_id, request_id = self._handle_state_ids(inputs)\n\n    # 2. MCP Discovery (once per session)\n    if self.config.get_agent().mcp_servers:\n        auth_challenge = await self._ensure_session_discovery(\n            user_id, session_id, task_id, request_id\n        )\n        if auth_challenge:\n            return auth_challenge\n\n    # 3. Create request-scoped connection manager\n    connection_manager = await self._create_mcp_connection_manager(\n        user_id, session_id\n    )\n\n    # 4. Execute with connection manager context\n    if connection_manager:\n        async with connection_manager:\n            return await self._execute_agent(\n                inputs, user_id, session_id, connection_manager\n            )\n    else:\n        return await self._execute_agent(inputs, user_id, session_id)\n</code></pre>"},{"location":"mcp-client-specification/#7-file-structure","title":"7. File Structure","text":"<pre><code>src/sk_agents/\n\u251c\u2500\u2500 mcp_client.py                    # Core MCP client (McpTool, McpPlugin, McpConnectionManager)\n\u251c\u2500\u2500 mcp_plugin_registry.py           # Tool discovery and registration\n\u251c\u2500\u2500 mcp_discovery/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 mcp_discovery_manager.py     # Abstract McpStateManager\n\u2502   \u251c\u2500\u2500 in_memory_discovery_manager.py\n\u2502   \u251c\u2500\u2500 redis_discovery_manager.py\n\u2502   \u2514\u2500\u2500 discovery_manager_factory.py\n\u251c\u2500\u2500 auth/\n\u2502   \u251c\u2500\u2500 oauth_client.py              # OAuth 2.1 client\n\u2502   \u251c\u2500\u2500 oauth_models.py              # Request/response models\n\u2502   \u251c\u2500\u2500 oauth_pkce.py                # PKCE implementation\n\u2502   \u251c\u2500\u2500 oauth_state_manager.py       # Flow state management\n\u2502   \u251c\u2500\u2500 server_metadata.py           # RFC 8414/9728 discovery\n\u2502   \u2514\u2500\u2500 client_registration.py       # RFC 7591 dynamic registration\n\u251c\u2500\u2500 auth_storage/\n\u2502   \u251c\u2500\u2500 models.py                    # OAuth2AuthData model\n\u2502   \u251c\u2500\u2500 auth_storage_factory.py\n\u2502   \u251c\u2500\u2500 in_memory_secure_auth_storage_manager.py\n\u2502   \u2514\u2500\u2500 secure_auth_storage_manager.py\n\u251c\u2500\u2500 tealagents/v1alpha1/\n\u2502   \u251c\u2500\u2500 config.py                    # McpServerConfig, GovernanceOverride\n\u2502   \u251c\u2500\u2500 agent/handler.py             # Handler with MCP integration\n\u2502   \u2514\u2500\u2500 kernel_builder.py            # load_mcp_plugins()\n\u2514\u2500\u2500 plugin_catalog/\n    \u251c\u2500\u2500 models.py                    # Governance, PluginTool\n    \u2514\u2500\u2500 local_plugin_catalog.py      # Catalog with dynamic registration\n</code></pre>"},{"location":"mcp-client-specification/#8-security-considerations","title":"8. Security Considerations","text":"Concern Mitigation Token storage Encrypted storage with user isolation Secret serialization Secrets stripped before state storage HTTPS enforcement OAuth requires HTTPS by default Scope escalation validate_token_scopes() checks CSRF protection State parameter in OAuth flow Trust boundaries Trust levels with HITL requirements Session hijacking MCP session IDs scoped to user+session"},{"location":"mcp-client-specification/#9-known-limitations","title":"9. Known Limitations","text":"<ol> <li>OAuth 2.1 E2E Testing: Implementation complete but not tested with real OAuth providers</li> <li>stdio Transport: Supported but not primary focus</li> <li>WebSocket Transport: Not supported (pending MCP SDK)</li> <li>Tool Hot-Reload: Tools discovered at session start only</li> <li>Connection Pooling: Within request only, not cross-request</li> </ol>"},{"location":"mcp-client-specification/#10-future-enhancements","title":"10. Future Enhancements","text":"Priority Enhancement P1 E2E OAuth testing with real providers P1 Connection health monitoring P2 Cross-request connection pooling P2 Tool hot-reload P3 WebSocket transport P3 stdio transport hardening"},{"location":"mcp-integration/","title":"MCP Integration Guide","text":"<p>This guide explains how to integrate Model Context Protocol (MCP) servers with Teal Agents, enabling your agents to discover and use tools from external MCP servers.</p>"},{"location":"mcp-integration/#overview","title":"Overview","text":"<p>The MCP integration provides:</p> <ul> <li>Automatic tool discovery - Tools are discovered at session start and made available to the agent</li> <li>Session-scoped isolation - Each user session has its own discovered tools and MCP sessions</li> <li>Request-scoped connections - Connections are pooled within a request and reused for efficiency</li> <li>OAuth 2.1 authentication - Full support for OAuth2 with PKCE for HTTP MCP servers</li> <li>Governance controls - HITL (Human-in-the-Loop) integration with secure-by-default policies</li> <li>External state storage - Redis support for horizontal scaling in production</li> </ul>"},{"location":"mcp-integration/#supported-transports","title":"Supported Transports","text":"Transport Use Case Authentication HTTP (primary) Remote MCP servers OAuth 2.1 with PKCE stdio Local subprocess servers Environment variables <p>Note: HTTP transport is the primary focus of this implementation. stdio transport is supported but secondary.</p>"},{"location":"mcp-integration/#quick-start","title":"Quick Start","text":""},{"location":"mcp-integration/#basic-http-server-with-oauth2","title":"Basic HTTP Server (with OAuth2)","text":"<pre><code>apiVersion: tealagents/v1alpha1\nname: my-agent\nspec:\n  name: my-agent\n  model: gpt-4\n  system_prompt: \"You are a helpful assistant with access to external tools.\"\n\n  mcp_servers:\n    - name: github\n      url: \"https://api.github.com/mcp\"\n      auth_server: \"https://github.com/login/oauth\"\n      scopes: [\"repo\", \"read:user\"]\n</code></pre>"},{"location":"mcp-integration/#basic-stdio-server-local","title":"Basic stdio Server (local)","text":"<pre><code>mcp_servers:\n  - name: filesystem\n    command: npx\n    args:\n      - \"@modelcontextprotocol/server-filesystem\"\n      - \"/safe/directory\"\n</code></pre>"},{"location":"mcp-integration/#configuration-reference","title":"Configuration Reference","text":""},{"location":"mcp-integration/#mcpserverconfig-fields","title":"McpServerConfig Fields","text":""},{"location":"mcp-integration/#required-fields","title":"Required Fields","text":"Field Type Description <code>name</code> string Unique identifier for the server"},{"location":"mcp-integration/#transport-selection","title":"Transport Selection","text":"<p>Transport is inferred automatically: - If <code>url</code> is provided (without <code>command</code>) \u2192 <code>http</code> - If <code>command</code> is provided (without <code>url</code>) \u2192 <code>stdio</code> - If both provided \u2192 must set <code>transport</code> explicitly</p> Field Type Description <code>transport</code> <code>\"http\"</code> | <code>\"stdio\"</code> Explicit transport selection (optional)"},{"location":"mcp-integration/#http-transport-fields","title":"HTTP Transport Fields","text":"Field Type Default Description <code>url</code> string - MCP server endpoint URL <code>auth_server</code> string - OAuth2 authorization server URL <code>scopes</code> list[string] <code>[]</code> Required OAuth2 scopes <code>headers</code> dict - Non-sensitive HTTP headers (routing, feature flags) <code>timeout</code> float <code>30.0</code> Connection timeout in seconds <code>sse_read_timeout</code> float <code>300.0</code> SSE read timeout in seconds <code>verify_ssl</code> bool <code>true</code> SSL certificate verification"},{"location":"mcp-integration/#stdio-transport-fields","title":"stdio Transport Fields","text":"Field Type Description <code>command</code> string Executable command (e.g., <code>npx</code>, <code>python</code>) <code>args</code> list[string] Command arguments <code>env</code> dict Environment variables for the subprocess"},{"location":"mcp-integration/#oauth2-configuration","title":"OAuth2 Configuration","text":"Field Type Description <code>oauth_client_id</code> string Pre-registered OAuth client ID <code>oauth_client_secret</code> string Client secret (confidential clients) <code>canonical_uri</code> string Explicit canonical URI override <code>enable_dynamic_registration</code> bool Try RFC 7591 dynamic registration (default: true) <code>protocol_version</code> string MCP protocol version (e.g., \"2025-06-18\")"},{"location":"mcp-integration/#governance-configuration","title":"Governance Configuration","text":"Field Type Description <code>trust_level</code> <code>\"trusted\"</code> | <code>\"sandboxed\"</code> | <code>\"untrusted\"</code> Server trust level (default: <code>\"untrusted\"</code>) <code>tool_governance_overrides</code> dict Per-tool governance overrides"},{"location":"mcp-integration/#user-context","title":"User Context","text":"Field Type Description <code>user_id_header</code> string Header name for user ID injection (e.g., <code>\"X-User-Id\"</code>) <code>user_id_source</code> <code>\"auth\"</code> | <code>\"env\"</code> Source for user ID value"},{"location":"mcp-integration/#authentication","title":"Authentication","text":""},{"location":"mcp-integration/#oauth-21-flow","title":"OAuth 2.1 Flow","text":"<p>When an MCP server requires authentication:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     OAuth 2.1 Authentication Flow                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                  \u2502\n\u2502  1. User makes request to agent                                  \u2502\n\u2502     \u2514\u2500\u25b6 Discovery starts for MCP servers                        \u2502\n\u2502                                                                  \u2502\n\u2502  2. No token found for (auth_server, scopes)                    \u2502\n\u2502     \u2514\u2500\u25b6 AuthRequiredError raised                                \u2502\n\u2502                                                                  \u2502\n\u2502  3. Handler generates OAuth authorization URL                    \u2502\n\u2502     \u2514\u2500\u25b6 PKCE challenge generated                                \u2502\n\u2502     \u2514\u2500\u25b6 State parameter for CSRF protection                     \u2502\n\u2502     \u2514\u2500\u25b6 Auth challenge returned to client                       \u2502\n\u2502                                                                  \u2502\n\u2502  4. User authenticates with OAuth provider                       \u2502\n\u2502     \u2514\u2500\u25b6 Redirected to callback with auth code                   \u2502\n\u2502                                                                  \u2502\n\u2502  5. Code exchanged for tokens                                    \u2502\n\u2502     \u2514\u2500\u25b6 Tokens stored in AuthStorage                            \u2502\n\u2502     \u2514\u2500\u25b6 Scoped to (user_id, auth_server, scopes)               \u2502\n\u2502                                                                  \u2502\n\u2502  6. User retries original request                                \u2502\n\u2502     \u2514\u2500\u25b6 Token found, discovery succeeds                         \u2502\n\u2502                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"mcp-integration/#token-storage","title":"Token Storage","text":"<p>Tokens are stored with a composite key: <code>(user_id, auth_server, sorted_scopes)</code></p> <p>This enables: - Per-user token isolation - Multiple tokens per user for different servers - Scope-specific token storage</p>"},{"location":"mcp-integration/#token-refresh","title":"Token Refresh","text":"<p>Tokens are automatically refreshed when: - Access token is expired - Refresh token is available - Resource binding matches (if applicable)</p>"},{"location":"mcp-integration/#governance-hitl","title":"Governance &amp; HITL","text":""},{"location":"mcp-integration/#secure-by-default-policy","title":"Secure-by-Default Policy","text":"<p>MCP tools use a secure-by-default governance model:</p> Scenario HITL Required Cost Sensitivity Unknown tool Yes High Sensitive <code>readOnlyHint: true</code> No Low Public <code>destructiveHint: true</code> Yes High Sensitive High-risk keywords in description Yes High Sensitive"},{"location":"mcp-integration/#trust-levels","title":"Trust Levels","text":"Trust Level Behavior <code>untrusted</code> (default) All tools require HITL <code>sandboxed</code> Elevated restrictions, most tools require HITL <code>trusted</code> Use annotation-based governance (still checks for high-risk operations)"},{"location":"mcp-integration/#governance-overrides","title":"Governance Overrides","text":"<p>Override automatic governance for specific tools:</p> <pre><code>mcp_servers:\n  - name: github\n    url: \"https://api.github.com/mcp\"\n    auth_server: \"https://github.com/login/oauth\"\n    scopes: [\"repo\"]\n    trust_level: trusted\n    tool_governance_overrides:\n      list_repositories:\n        requires_hitl: false\n        cost: \"low\"\n        data_sensitivity: \"public\"\n      delete_repository:\n        requires_hitl: true\n        cost: \"high\"\n        data_sensitivity: \"sensitive\"\n</code></pre>"},{"location":"mcp-integration/#governance-fields","title":"Governance Fields","text":"Field Values Description <code>requires_hitl</code> bool Whether human approval is required <code>cost</code> <code>\"low\"</code> | <code>\"medium\"</code> | <code>\"high\"</code> Resource cost level <code>data_sensitivity</code> <code>\"public\"</code> | <code>\"proprietary\"</code> | <code>\"sensitive\"</code> Data classification"},{"location":"mcp-integration/#architecture","title":"Architecture","text":""},{"location":"mcp-integration/#discovery-flow","title":"Discovery Flow","text":"<pre><code>Session Start\n    \u2502\n    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  McpPluginRegistry.discover_and_materialize()                    \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 For each MCP server:                                        \u2502 \u2502\n\u2502  \u2502   1. Resolve OAuth tokens (if configured)                   \u2502 \u2502\n\u2502  \u2502   2. Connect to MCP server                                  \u2502 \u2502\n\u2502  \u2502   3. Initialize MCP session (protocol handshake)            \u2502 \u2502\n\u2502  \u2502   4. List tools from server                                 \u2502 \u2502\n\u2502  \u2502   5. Register tools in PluginCatalog (for governance)       \u2502 \u2502\n\u2502  \u2502   6. Serialize tool data to McpStateManager                 \u2502 \u2502\n\u2502  \u2502   7. Close connection                                       \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                  \u2502\n\u2502  Result: Tools stored in session-scoped state                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"mcp-integration/#request-flow","title":"Request Flow","text":"<pre><code>User Request\n    \u2502\n    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Handler.invoke()                                                \u2502\n\u2502                                                                  \u2502\n\u2502  1. Check if discovery completed (McpStateManager)               \u2502\n\u2502     \u2514\u2500\u25b6 If not, run discovery first                             \u2502\n\u2502                                                                  \u2502\n\u2502  2. Create McpConnectionManager (request-scoped)                 \u2502\n\u2502     \u2514\u2500\u25b6 Load stored MCP session IDs from state                  \u2502\n\u2502                                                                  \u2502\n\u2502  3. Load MCP plugins into kernel                                 \u2502\n\u2502     \u2514\u2500\u25b6 Get tool data from McpStateManager                      \u2502\n\u2502     \u2514\u2500\u25b6 Create McpPlugin instances with connection manager      \u2502\n\u2502                                                                  \u2502\n\u2502  4. Execute agent with LLM                                       \u2502\n\u2502     \u2514\u2500\u25b6 Tool calls use connection manager for MCP servers       \u2502\n\u2502     \u2514\u2500\u25b6 Connections created lazily on first tool call           \u2502\n\u2502     \u2514\u2500\u25b6 Connections reused within request                       \u2502\n\u2502                                                                  \u2502\n\u2502  5. Cleanup                                                      \u2502\n\u2502     \u2514\u2500\u25b6 Persist MCP session IDs to state                        \u2502\n\u2502     \u2514\u2500\u25b6 Close all connections                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"mcp-integration/#state-management","title":"State Management","text":""},{"location":"mcp-integration/#mcpstatemanager","title":"McpStateManager","text":"<p>Stores discovery results and MCP session IDs:</p> <pre><code>{\n    \"server_name\": {\n        \"plugin_data\": {\n            \"tools\": [...]  # Serialized tool metadata\n        },\n        \"session\": {\n            \"mcp_session_id\": \"...\",  # For stateful MCP servers\n            \"created_at\": \"...\",\n            \"last_used_at\": \"...\"\n        }\n    }\n}\n</code></pre>"},{"location":"mcp-integration/#storage-backends","title":"Storage Backends","text":"Backend Use Case Configuration In-Memory Development, testing Default (no configuration needed) Redis Production, horizontal scaling Set environment variables below"},{"location":"mcp-integration/#in-memory-default","title":"In-Memory (Default)","text":"<p>No configuration needed - this is the default for development:</p> <pre><code># These are the defaults, you don't need to set them\nexport TA_MCP_DISCOVERY_MODULE=\"sk_agents.mcp_discovery.in_memory_discovery_manager\"\nexport TA_MCP_DISCOVERY_CLASS=\"InMemoryStateManager\"\n</code></pre>"},{"location":"mcp-integration/#redis-production","title":"Redis (Production)","text":"<p>For production with horizontal scaling, configure Redis storage:</p> <pre><code># Switch to Redis state manager\nexport TA_MCP_DISCOVERY_MODULE=\"sk_agents.mcp_discovery.redis_discovery_manager\"\nexport TA_MCP_DISCOVERY_CLASS=\"RedisStateManager\"\n\n# Redis connection (required)\nexport TA_REDIS_HOST=\"your-redis-host.example.com\"\nexport TA_REDIS_PORT=\"6379\"\nexport TA_REDIS_DB=\"0\"\n\n# Redis authentication (optional)\nexport TA_REDIS_PWD=\"your-redis-password\"\nexport TA_REDIS_SSL=\"true\"\n\n# State TTL in seconds (optional, default: 86400 = 24 hours)\nexport TA_REDIS_TTL=\"86400\"\n</code></pre>"},{"location":"mcp-integration/#session-isolation","title":"Session Isolation","text":"<p>State is scoped to <code>(user_id, session_id)</code>: - Each user has isolated tools and sessions - Different sessions for the same user are independent - Enables multi-tenant deployments</p>"},{"location":"mcp-integration/#configuration-examples","title":"Configuration Examples","text":""},{"location":"mcp-integration/#github-mcp-server","title":"GitHub MCP Server","text":"<pre><code>mcp_servers:\n  - name: github\n    url: \"https://api.github.com/mcp\"\n    auth_server: \"https://github.com/login/oauth\"\n    scopes: [\"repo\", \"read:user\"]\n    trust_level: trusted\n    tool_governance_overrides:\n      create_repository:\n        requires_hitl: false\n        cost: \"medium\"\n      delete_repository:\n        requires_hitl: true\n        cost: \"high\"\n</code></pre>"},{"location":"mcp-integration/#internal-api-with-user-context","title":"Internal API with User Context","text":"<pre><code>mcp_servers:\n  - name: internal-api\n    url: \"https://api.internal.example.com/mcp\"\n    auth_server: \"https://auth.internal.example.com/oauth2\"\n    scopes: [\"api.read\", \"api.write\"]\n    user_id_header: \"X-User-Id\"\n    user_id_source: \"auth\"\n    headers:\n      X-Service-Name: \"teal-agents\"\n</code></pre>"},{"location":"mcp-integration/#local-filesystem-server","title":"Local Filesystem Server","text":"<pre><code>mcp_servers:\n  - name: filesystem\n    command: npx\n    args:\n      - \"@modelcontextprotocol/server-filesystem\"\n      - \"/data/safe-directory\"\n    env:\n      NODE_ENV: production\n    trust_level: sandboxed\n</code></pre>"},{"location":"mcp-integration/#sqlite-database-server","title":"SQLite Database Server","text":"<pre><code>mcp_servers:\n  - name: sqlite\n    command: python\n    args:\n      - \"-m\"\n      - \"mcp_server_sqlite\"\n      - \"--db-path\"\n      - \"/data/app.db\"\n    tool_governance_overrides:\n      execute_query:\n        requires_hitl: true\n        cost: \"medium\"\n</code></pre>"},{"location":"mcp-integration/#multiple-servers","title":"Multiple Servers","text":"<pre><code>mcp_servers:\n  # Remote authenticated server\n  - name: github\n    url: \"https://api.github.com/mcp\"\n    auth_server: \"https://github.com/login/oauth\"\n    scopes: [\"repo\"]\n    trust_level: trusted\n\n  # Local filesystem access\n  - name: filesystem\n    command: npx\n    args: [\"@modelcontextprotocol/server-filesystem\", \"/data\"]\n    trust_level: sandboxed\n\n  # Internal API\n  - name: analytics\n    url: \"https://analytics.internal.example.com/mcp\"\n    auth_server: \"https://auth.internal.example.com/oauth2\"\n    scopes: [\"analytics.read\"]\n</code></pre>"},{"location":"mcp-integration/#environment-variables","title":"Environment Variables","text":""},{"location":"mcp-integration/#mcp-state-storage","title":"MCP State Storage","text":"<p>See Storage Backends section above for detailed configuration examples.</p> Variable Description Default <code>TA_MCP_DISCOVERY_MODULE</code> Python module for state manager <code>sk_agents.mcp_discovery.in_memory_discovery_manager</code> <code>TA_MCP_DISCOVERY_CLASS</code> State manager class name <code>InMemoryStateManager</code> <code>TA_REDIS_HOST</code> Redis host (when using Redis) - <code>TA_REDIS_PORT</code> Redis port <code>6379</code> <code>TA_REDIS_DB</code> Redis database number <code>0</code> <code>TA_REDIS_PWD</code> Redis password - <code>TA_REDIS_SSL</code> Enable SSL for Redis <code>false</code> <code>TA_REDIS_TTL</code> State TTL in seconds <code>86400</code> (24h)"},{"location":"mcp-integration/#oauth-configuration","title":"OAuth Configuration","text":"Variable Description Default <code>TA_OAUTH_CLIENT_NAME</code> Default OAuth client name - <code>TA_MCP_OAUTH_HTTPS_REQUIRED</code> Enforce HTTPS for OAuth endpoints <code>true</code>"},{"location":"mcp-integration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"mcp-integration/#common-issues","title":"Common Issues","text":""},{"location":"mcp-integration/#authrequirederror-on-first-request","title":"\"AuthRequiredError\" on first request","text":"<p>This is expected behavior. The user needs to complete OAuth authentication: 1. Client receives auth challenge with <code>auth_url</code> 2. User visits URL and authenticates 3. Callback stores tokens 4. Retry original request</p>"},{"location":"mcp-integration/#no-tools-discovered","title":"\"No tools discovered\"","text":"<p>Check: 1. MCP server is running and accessible 2. Server returns tools from <code>list_tools()</code> 3. Authentication is configured correctly (for HTTP) 4. Network connectivity to server</p>"},{"location":"mcp-integration/#connection-timeout","title":"\"Connection timeout\"","text":"<p>Increase timeout values: <pre><code>mcp_servers:\n  - name: slow-server\n    url: \"https://api.example.com/mcp\"\n    timeout: 60.0\n    sse_read_timeout: 600.0\n</code></pre></p>"},{"location":"mcp-integration/#hitl-required-for-all-tools","title":"\"HITL required for all tools\"","text":"<p>Check trust level - default is <code>untrusted</code> which requires HITL for everything: <pre><code>mcp_servers:\n  - name: my-server\n    trust_level: trusted  # or sandboxed\n</code></pre></p>"},{"location":"mcp-integration/#debug-logging","title":"Debug Logging","text":"<p>Enable detailed logging:</p> <pre><code>import logging\n\nlogging.getLogger('sk_agents.mcp_client').setLevel(logging.DEBUG)\nlogging.getLogger('sk_agents.mcp_plugin_registry').setLevel(logging.DEBUG)\nlogging.getLogger('sk_agents.mcp_discovery').setLevel(logging.DEBUG)\n</code></pre>"},{"location":"mcp-integration/#known-limitations","title":"Known Limitations","text":"<ol> <li> <p>OAuth 2.1 end-to-end testing: OAuth implementation is complete but not tested end-to-end with real OAuth providers. Unit tests use mocked tokens.</p> </li> <li> <p>stdio transport: Supported but not the primary focus. HTTP transport is recommended for production use.</p> </li> <li> <p>WebSocket transport: Not yet supported (pending MCP SDK support).</p> </li> <li> <p>Tool hot-reload: Tools are discovered at session start only. Changes require a new session.</p> </li> </ol>"},{"location":"mcp-integration/#security-considerations","title":"Security Considerations","text":"<ol> <li>Credential handling: OAuth tokens are stored securely in AuthStorage with user isolation</li> <li>Secret sanitization: Secrets are stripped from serialized state</li> <li>HTTPS enforcement: OAuth flows require HTTPS by default</li> <li>Trust boundaries: Use appropriate trust levels for different server types</li> <li>HITL for destructive operations: Secure-by-default ensures human oversight</li> </ol>"},{"location":"reference/","title":"sk-agents","text":""},{"location":"reference/#sk_agents","title":"sk_agents","text":""},{"location":"reference/#sk_agents.a2a","title":"sk_agents.a2a","text":"sk_agents.a2a.redis_task_store <p>DEPRECATION NOTICE: A2A (Agent-to-Agent) functionality is being deprecated as part of the framework migration evaluation. This module is maintained for backward compatibility only. New development should avoid using A2A functionality.</p> <p>Redis implementation of the TaskStore interface. This implementation uses Redis as the persistent store for Task objects.</p> sk_agents.a2a.redis_task_store.RedisTaskStore <p>               Bases: <code>TaskStore</code></p> <p>Redis implementation of the TaskStore interface.</p> <p>This class provides Redis-based persistence for Task objects.</p> Source code in <code>src/sk_agents/a2a/redis_task_store.py</code> <pre><code>class RedisTaskStore(TaskStore):\n    \"\"\"Redis implementation of the TaskStore interface.\n\n    This class provides Redis-based persistence for Task objects.\n    \"\"\"\n\n    def __init__(self, redis_client: Redis, ttl: int | None = None, key_prefix: str = \"task:\"):\n        \"\"\"Initialize the RedisTaskStore with a Redis client.\n\n        Args:\n            redis_client: An instance of Redis client\n            key_prefix: Prefix used for Redis keys (default: \"task:\")\n        \"\"\"\n        self._redis = redis_client\n        self._ttl = ttl\n        self._key_prefix = key_prefix\n\n    def _get_key(self, task_id: str) -&gt; str:\n        \"\"\"Generate a Redis key for a given task ID.\n\n        Args:\n            task_id: The ID of the task\n\n        Returns:\n            A Redis key string\n        \"\"\"\n        return f\"{self._key_prefix}{task_id}\"\n\n    async def save(self, task: Task):\n        \"\"\"Saves or updates a task in the Redis store.\n\n        Args:\n            task: The Task object to save\n        \"\"\"\n        # Convert the Task object to a serializable dictionary\n        task_dict = task.model_dump(mode=\"json\")\n\n        # Serialize the task dictionary to JSON\n        task_json = json.dumps(task_dict)\n\n        # Store the serialized task in Redis using the task ID as the key\n        await self._redis.set(self._get_key(task.id), task_json, ex=self._ttl)\n\n    async def get(self, task_id: str) -&gt; Task | None:\n        \"\"\"Retrieves a task from the Redis store by ID.\n\n        Args:\n            task_id: The ID of the task to retrieve\n\n        Returns:\n            The Task object if found, None otherwise\n        \"\"\"\n        # Get the serialized task from Redis\n        task_json = await self._redis.get(self._get_key(task_id))\n\n        if task_json is None:\n            return None\n\n        # Deserialize the JSON string to a dictionary\n        task_dict = json.loads(task_json)\n\n        # Create and return a Task object from the dictionary\n        return Task.model_validate(task_dict)\n\n    async def delete(self, task_id: str):\n        \"\"\"Deletes a task from the Redis store by ID.\n\n        Args:\n            task_id: The ID of the task to delete\n        \"\"\"\n        # Delete the task from Redis\n        await self._redis.delete(self._get_key(task_id))\n</code></pre> <code></code> sk_agents.a2a.redis_task_store.RedisTaskStore.__init__ <pre><code>__init__(\n    redis_client: Redis,\n    ttl: int | None = None,\n    key_prefix: str = \"task:\",\n)\n</code></pre> <p>Initialize the RedisTaskStore with a Redis client.</p> <p>Parameters:</p> Name Type Description Default <code>redis_client</code> <code>Redis</code> <p>An instance of Redis client</p> required <code>key_prefix</code> <code>str</code> <p>Prefix used for Redis keys (default: \"task:\")</p> <code>'task:'</code> Source code in <code>src/sk_agents/a2a/redis_task_store.py</code> <pre><code>def __init__(self, redis_client: Redis, ttl: int | None = None, key_prefix: str = \"task:\"):\n    \"\"\"Initialize the RedisTaskStore with a Redis client.\n\n    Args:\n        redis_client: An instance of Redis client\n        key_prefix: Prefix used for Redis keys (default: \"task:\")\n    \"\"\"\n    self._redis = redis_client\n    self._ttl = ttl\n    self._key_prefix = key_prefix\n</code></pre> <code></code> sk_agents.a2a.redis_task_store.RedisTaskStore.save <code>async</code> <pre><code>save(task: Task)\n</code></pre> <p>Saves or updates a task in the Redis store.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>Task</code> <p>The Task object to save</p> required Source code in <code>src/sk_agents/a2a/redis_task_store.py</code> <pre><code>async def save(self, task: Task):\n    \"\"\"Saves or updates a task in the Redis store.\n\n    Args:\n        task: The Task object to save\n    \"\"\"\n    # Convert the Task object to a serializable dictionary\n    task_dict = task.model_dump(mode=\"json\")\n\n    # Serialize the task dictionary to JSON\n    task_json = json.dumps(task_dict)\n\n    # Store the serialized task in Redis using the task ID as the key\n    await self._redis.set(self._get_key(task.id), task_json, ex=self._ttl)\n</code></pre> <code></code> sk_agents.a2a.redis_task_store.RedisTaskStore.get <code>async</code> <pre><code>get(task_id: str) -&gt; Task | None\n</code></pre> <p>Retrieves a task from the Redis store by ID.</p> <p>Parameters:</p> Name Type Description Default <code>task_id</code> <code>str</code> <p>The ID of the task to retrieve</p> required <p>Returns:</p> Type Description <code>Task | None</code> <p>The Task object if found, None otherwise</p> Source code in <code>src/sk_agents/a2a/redis_task_store.py</code> <pre><code>async def get(self, task_id: str) -&gt; Task | None:\n    \"\"\"Retrieves a task from the Redis store by ID.\n\n    Args:\n        task_id: The ID of the task to retrieve\n\n    Returns:\n        The Task object if found, None otherwise\n    \"\"\"\n    # Get the serialized task from Redis\n    task_json = await self._redis.get(self._get_key(task_id))\n\n    if task_json is None:\n        return None\n\n    # Deserialize the JSON string to a dictionary\n    task_dict = json.loads(task_json)\n\n    # Create and return a Task object from the dictionary\n    return Task.model_validate(task_dict)\n</code></pre> <code></code> sk_agents.a2a.redis_task_store.RedisTaskStore.delete <code>async</code> <pre><code>delete(task_id: str)\n</code></pre> <p>Deletes a task from the Redis store by ID.</p> <p>Parameters:</p> Name Type Description Default <code>task_id</code> <code>str</code> <p>The ID of the task to delete</p> required Source code in <code>src/sk_agents/a2a/redis_task_store.py</code> <pre><code>async def delete(self, task_id: str):\n    \"\"\"Deletes a task from the Redis store by ID.\n\n    Args:\n        task_id: The ID of the task to delete\n    \"\"\"\n    # Delete the task from Redis\n    await self._redis.delete(self._get_key(task_id))\n</code></pre> <code></code> sk_agents.a2a.response_classifier <code></code> sk_agents.a2a.response_classifier.A2AResponseClassifier <p>A class to classify responses from the A2A agent.</p> Source code in <code>src/sk_agents/a2a/response_classifier.py</code> <pre><code>class A2AResponseClassifier:\n    \"\"\"\n    A class to classify responses from the A2A agent.\n    \"\"\"\n\n    NAME = \"a2a-response-classifier\"\n    SYSTEM_PROMPT = (\n        \"## System Prompt: Agent Output Classifier\\n\"\n        \"\\n\"\n        \"**You are an AI agent tasked with analyzing the output of another AI agent \"\n        '(referred to as the \"Primary Agent\") and classifying its status. Your output MUST '\n        \"be a JSON object.**\\n\"\n        \"\\n\"\n        \"Your goal is to determine which of the following categories best describes \"\n        \"the Primary Agent's output and structure your response accordingly.\\n\"\n        \"\\n\"\n        \"**Possible Classification Statuses &amp; JSON Output Structures:**\\n\"\n        \"\\n\"\n        \"1.  **Status: `completed`**\\n\"\n        \"    * The Primary Agent has successfully completed the assigned task or answered the \"\n        \"user's query.\\n\"\n        \"    * **JSON Output Structure:**\\n\"\n        \"        ```json\\n\"\n        \"        {\\n\"\n        '          \"status\": \"completed\"\\n'\n        \"        }\\n\"\n        \"        ```\\n\"\n        '    * Keywords/phrases to look for: \"done,\" \"completed,\" \"finished,\" \"success,\" '\n        '\"here is the result,\" \"I have finished,\" \"the task is complete,\" direct answers '\n        \"to questions, generated content that fulfills the request.\\n\"\n        \"    * Context: The output clearly indicates finality and achievement of the original \"\n        \"goal.\\n\"\n        \"\\n\"\n        \"2.  **Status: `failed`**\\n\"\n        \"    * The Primary Agent has failed to complete the assigned task or answered the \"\n        \"user's query.\\n\"\n        \"    * **JSON Output Structure:**\\n\"\n        \"        ```json\\n\"\n        \"        {\\n\"\n        '          \"status\": \"failed\"\\n'\n        \"        }\\n\"\n        \"        ```\\n\"\n        '    * Keywords/phrases to look for: \"failed,\" \"unable to,\" \"cannot complete,\" '\n        '\"error,\" \"encountered a problem,\" \"not possible,\" \"I\\'m sorry, I can\\'t,\" '\n        '\"task aborted.\"\\n'\n        \"    * Context: The output indicates an inability to proceed or a definitive negative \"\n        \"outcome regarding the task. This includes technical errors, lack of capability, \"\n        \"or hitting a dead end.\\n\"\n        \"\\n\"\n        \"3.  **Status: `input-required`**\\n\"\n        \"    * The Primary Agent requires additional information, clarification, or a decision \"\n        \"from the user to continue or complete the task.\\n\"\n        \"    * **JSON Output Structure:**\\n\"\n        \"        ```json\\n\"\n        \"        {\\n\"\n        '          \"status\": \"input-required\",\\n'\n        '          \"message\": \"A description of what info is needed from the user and why.\"\\n'\n        \"        }\\n\"\n        \"        ```\\n\"\n        '    * Keywords/phrases to look for: \"what do you mean by,\" \"could you please '\n        'specify,\" \"which option do you prefer,\" \"do you want to proceed,\" \"please '\n        'provide,\" \"I need more information,\" questions directed at the user.\\n'\n        \"    * Context: The output is a direct or indirect request for user interaction to \"\n        \"resolve ambiguity, make a choice, or provide necessary data. The `message` field \"\n        \"should summarize this request.\\n\"\n        \"\\n\"\n        \"4.  **Status: `auth-required`**\\n\"\n        \"    * The Primary Agent has indicated that it needs to perform some form of \"\n        \"authentication (e.g., login, API key verification, permission grant) before it \"\n        \"can proceed with the task.\\n\"\n        \"    * **JSON Output Structure:**\\n\"\n        \"        ```json\\n\"\n        \"        {\\n\"\n        '          \"status\": \"auth-required\",\\n'\n        '          \"message\": \"A description of what authentication is needed and why.\",\\n'\n        '          \"auth_details\": {} // Likely a JSON structure extracted from the Primary '\n        \"Agent's output containing technical details about the auth request. Can be an \"\n        \"empty object if no specific structure is found.\\n\"\n        \"        }\\n\"\n        \"        ```\\n\"\n        '    * Keywords/phrases to look for: \"please log in,\" \"authentication required,\" '\n        '\"access denied,\" \"invalid credentials,\" \"API key needed,\" \"sign in to continue,\" '\n        '\"verify your identity,\" \"permissions needed.\"\\n'\n        \"    * Context: The output explicitly states or strongly implies that a security or \"\n        \"access barrier is preventing task progression. The `message` field should explain \"\n        \"this. The `auth_details` field should attempt to capture any structured information \"\n        \"(e.g., OAuth URLs, scopes needed, realm info) provided by the Primary Agent \"\n        \"regarding the authentication. If the Primary Agent provides a JSON blob related to \"\n        \"auth, try to pass that through in `auth_details`.\\n\"\n        \"\\n\"\n        \"**Your Analysis Process:**\\n\"\n        \"\\n\"\n        \"1.  **Carefully review the entire output from the Primary Agent.** Understand the \"\n        \"context and the overall message.\\n\"\n        \"2.  **Look for explicit keywords and phrases** associated with each category.\\n\"\n        \"3.  **Consider the intent** behind the Primary Agent's message.\\n\"\n        \"4.  **Prioritize:**\\n\"\n        \"    * If authentication is mentioned as a blocker, classify as `auth-required`. \"\n        \"Extract relevant details for the `message` and `auth_details` fields.\\n\"\n        \"    * If the agent is clearly asking the user a question to proceed (and it's not \"\n        \"primarily an authentication request), classify as `input-required`. Formulate the \"\n        \"`message` field.\\n\"\n        \"    * If the agent explicitly states success, classify as `completed`.\\n\"\n        \"    * If the agent explicitly states failure or an insurmountable error (not related \"\n        \"to needing input or auth), classify as `failed`.\\n\"\n        \"5.  **Extract Information for `message` and `auth_details`:**\\n\"\n        \"    * For `input-required` and `auth-required`, the `message` should be a concise \"\n        \"explanation derived from the Primary Agent's output.\\n\"\n        \"    * For `auth-required`, if the Primary Agent's output includes a structured \"\n        \"(e.g., JSON) segment detailing the authentication requirements, attempt to extract \"\n        \"and place this into the `auth_details` field. If no specific structure is found, \"\n        \"`auth_details` can be an empty object `{}`. Do not invent details; only extract \"\n        \"what is provided.\\n\"\n        \"6.  **If the output is ambiguous, try to infer the most likely category.** If truly \"\n        'unclear, you may need a default or \"UNCLEAR\" category (though this prompt focuses '\n        \"on the four defined). In such a case, defaulting to `failed` with an appropriate \"\n        \"message might be a safe fallback if no other category fits.\\n\"\n        \"\\n\"\n        \"**Output Format:**\\n\"\n        \"\\n\"\n        \"Your output **MUST** be a single JSON object corresponding to one of the structures \"\n        \"defined above.\\n\"\n        \"\\n\"\n        \"**Example Scenarios:**\\n\"\n        \"\\n\"\n        \"* **Primary Agent Output:** \\\"I've finished generating the report you asked for. \"\n        \"It's attached below.\\\"\\n\"\n        \"    * **Your JSON Output:**\\n\"\n        \"        ```json\\n\"\n        \"        {\\n\"\n        '          \"status\": \"completed\"\\n'\n        \"        }\\n\"\n        \"        ```\\n\"\n        \"* **Primary Agent Output:** \\\"I'm sorry, I encountered an unexpected error and cannot \"\n        'process your request at this time. Error code: 503. Please try again later.\"\\n'\n        \"    * **Your JSON Output:**\\n\"\n        \"        ```json\\n\"\n        \"        {\\n\"\n        '          \"status\": \"failed\"\\n'\n        \"        }\\n\"\n        \"        ```\\n\"\n        '* **Primary Agent Output:** \"To help you with that, could you please tell me which '\n        'specific date range you are interested in for the sales data?\"\\n'\n        \"    * **Your JSON Output:**\\n\"\n        \"        ```json\\n\"\n        \"        {\\n\"\n        '          \"status\": \"input-required\",\\n'\n        '          \"message\": \"The agent needs to know the specific date range for the sales '\n        'data to proceed.\"\\n'\n        \"        }\\n\"\n        \"        ```\\n\"\n        '* **Primary Agent Output:** \"Access to this API endpoint requires authentication. '\n        \"Please provide a valid Bearer token. Details: {'type': 'Bearer', 'realm': \"\n        \"'[api.example.com/auth](https://api.example.com/auth)'}}\\\"\\n\"\n        \"    * **Your JSON Output:**\\n\"\n        \"        ```json\\n\"\n        \"        {\\n\"\n        '          \"status\": \"auth-required\",\\n'\n        '          \"message\": \"Access to the API endpoint requires a valid Bearer token.\",\\n'\n        '          \"auth_details\": {\\n'\n        '            \"type\": \"Bearer\",\\n'\n        '            \"realm\": \"[api.example.com/auth](https://api.example.com/auth)\"\\n'\n        \"          }\\n\"\n        \"        }\\n\"\n        \"        ```\\n\"\n        '* **Primary Agent Output:** \"You need to sign in to your account to access your '\n        'profile. Click here to login.\"\\n'\n        \"    * **Your JSON Output:**\\n\"\n        \"        ```json\\n\"\n        \"        {\\n\"\n        '          \"status\": \"auth-required\",\\n'\n        '          \"message\": \"User needs to sign in to their account to access their profile.\",\\n'\n        '          \"auth_details\": {}\\n'\n        \"        }\\n\"\n        \"        ```\\n\"\n        \"\\n\"\n        \"**Critical Considerations:**\\n\"\n        \"\\n\"\n        \"* Ensure your output is always valid JSON.\\n\"\n        \"* Be precise in your classification and in the information extracted for the `message` \"\n        \"and `auth_details` fields.\\n\"\n        \"* Focus solely on the provided output from the Primary Agent.\\n\"\n        \"* Adhere to the prioritization logic.\\n\"\n    )\n\n    def __init__(self, app_config: AppConfig, chat_completion_builder: ChatCompletionBuilder):\n        model_name = app_config.get(TA_A2A_OUTPUT_CLASSIFIER_MODEL.env_name)\n        chat_completion = chat_completion_builder.get_chat_completion_for_model(\n            service_id=self.NAME, model_name=model_name\n        )\n        kernel = Kernel()\n        kernel.add_service(chat_completion)\n        settings = kernel.get_prompt_execution_settings_from_service_id(self.NAME)\n        settings.response_format = A2AResponseClassification\n        self.agent = ChatCompletionAgent(\n            kernel=kernel,\n            name=self.NAME,\n            instructions=self.SYSTEM_PROMPT,\n            arguments=KernelArguments(settings=settings),\n        )\n\n    async def classify_response(self, response: str) -&gt; A2AResponseClassification:\n        \"\"\"\n        Classify the response from the A2A agent.\n\n        Args:\n            response (str): The response from the A2A agent.\n\n        Returns:\n            str: The classification of the response.\n        \"\"\"\n        chat_history = ChatHistory()\n        chat_history.add_user_message(f\"Please classify the following response:\\n\\n{response}\")\n        async for content in self.agent.invoke(messages=chat_history):\n            data = json.loads(str(content.content))\n            return A2AResponseClassification(**data)\n        return A2AResponseClassification(\n            status=A2AResponseStatus.failed,\n            message=\"No response received from response classifier.\",\n        )\n</code></pre> <code></code> sk_agents.a2a.response_classifier.A2AResponseClassifier.classify_response <code>async</code> <pre><code>classify_response(\n    response: str,\n) -&gt; A2AResponseClassification\n</code></pre> <p>Classify the response from the A2A agent.</p> <p>Parameters:</p> Name Type Description Default <code>response</code> <code>str</code> <p>The response from the A2A agent.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>A2AResponseClassification</code> <p>The classification of the response.</p> Source code in <code>src/sk_agents/a2a/response_classifier.py</code> <pre><code>async def classify_response(self, response: str) -&gt; A2AResponseClassification:\n    \"\"\"\n    Classify the response from the A2A agent.\n\n    Args:\n        response (str): The response from the A2A agent.\n\n    Returns:\n        str: The classification of the response.\n    \"\"\"\n    chat_history = ChatHistory()\n    chat_history.add_user_message(f\"Please classify the following response:\\n\\n{response}\")\n    async for content in self.agent.invoke(messages=chat_history):\n        data = json.loads(str(content.content))\n        return A2AResponseClassification(**data)\n    return A2AResponseClassification(\n        status=A2AResponseStatus.failed,\n        message=\"No response received from response classifier.\",\n    )\n</code></pre>"},{"location":"reference/#sk_agents.appv3","title":"sk_agents.appv3","text":"class AppV3 <p>@staticmethod def run(name, version, app_config, config, app):     pass</p>"},{"location":"reference/#sk_agents.auth","title":"sk_agents.auth","text":"<p>MCP OAuth 2.1 Authentication Components</p> <p>This module provides OAuth 2.1 compliant authentication for MCP (Model Context Protocol) servers. All components follow the MCP specification (2025-06-18) for authorization: https://modelcontextprotocol.io/specification/2025-06-18/basic/authorization</p> <p>Key Features: - PKCE (Proof Key for Code Exchange) for authorization code flow - Resource parameter binding for token audience validation - State parameter for CSRF protection - Token refresh with rotation - Server metadata discovery (RFC8414, RFC9728) - Dynamic client registration (RFC7591)</p> <p>Architecture: - This module is isolated from platform authentication (RequestAuthorizer) - Platform auth: Validates user to platform, returns user_id - Service auth (MCP): Manages OAuth tokens for external services per user</p> <p>Components: - oauth_client: Main OAuth 2.1 client for authorization flows - oauth_pkce: PKCE generation and validation - oauth_models: Request/response models for OAuth flows - oauth_state_manager: State and PKCE verifier storage for OAuth flows - server_metadata: Authorization server metadata discovery (RFC8414, RFC9728) - client_registration: Dynamic client registration (RFC7591)</p> sk_agents.auth.client_registration <p>Dynamic Client Registration</p> <p>Implements dynamic client registration per RFC7591. Allows automatic OAuth client registration with authorization servers.</p> <p>References: - RFC 7591: OAuth 2.0 Dynamic Client Registration Protocol</p> sk_agents.auth.client_registration.ClientRegistrationRequest <p>               Bases: <code>BaseModel</code></p> <p>OAuth 2.0 Dynamic Client Registration Request (RFC7591)</p> Source code in <code>src/sk_agents/auth/client_registration.py</code> <pre><code>class ClientRegistrationRequest(BaseModel):\n    \"\"\"\n    OAuth 2.0 Dynamic Client Registration Request (RFC7591)\n    \"\"\"\n\n    client_name: str = \"teal-agents\"\n    redirect_uris: list[HttpUrl]\n    grant_types: list[Literal[\"authorization_code\", \"refresh_token\"]] = [\n        \"authorization_code\",\n        \"refresh_token\",\n    ]\n    token_endpoint_auth_method: Literal[\"none\", \"client_secret_basic\", \"client_secret_post\"] = (\n        \"none\"\n    )\n    response_types: list[str] = [\"code\"]\n    scope: str | None = None\n</code></pre> <code></code> sk_agents.auth.client_registration.ClientRegistrationResponse <p>               Bases: <code>BaseModel</code></p> <p>OAuth 2.0 Dynamic Client Registration Response (RFC7591)</p> Source code in <code>src/sk_agents/auth/client_registration.py</code> <pre><code>class ClientRegistrationResponse(BaseModel):\n    \"\"\"\n    OAuth 2.0 Dynamic Client Registration Response (RFC7591)\n    \"\"\"\n\n    client_id: str\n    client_secret: str | None = None\n    client_id_issued_at: int | None = None\n    client_secret_expires_at: int | None = None\n    registration_access_token: str | None = None\n    registration_client_uri: HttpUrl | None = None\n</code></pre> <code></code> sk_agents.auth.client_registration.DynamicClientRegistration <p>Dynamic Client Registration Client.</p> <p>Handles automatic OAuth client registration. Phase 3 implementation (optional).</p> Source code in <code>src/sk_agents/auth/client_registration.py</code> <pre><code>class DynamicClientRegistration:\n    \"\"\"\n    Dynamic Client Registration Client.\n\n    Handles automatic OAuth client registration.\n    Phase 3 implementation (optional).\n    \"\"\"\n\n    def __init__(self, timeout: float = 30.0):\n        self.timeout = timeout\n\n    async def register_client(\n        self,\n        registration_endpoint: str,\n        request: ClientRegistrationRequest,\n    ) -&gt; ClientRegistrationResponse:\n        \"\"\"\n        Register OAuth client with authorization server.\n\n        Args:\n            registration_endpoint: Registration endpoint URL from server metadata\n            request: Client registration request\n\n        Returns:\n            ClientRegistrationResponse: Registered client credentials\n\n        Raises:\n            httpx.HTTPError: If registration fails\n        \"\"\"\n        # Implementation in Phase 3\n        raise NotImplementedError(\"Dynamic client registration not yet implemented (Phase 3)\")\n\n    async def update_client(\n        self,\n        registration_client_uri: str,\n        registration_access_token: str,\n        request: ClientRegistrationRequest,\n    ) -&gt; ClientRegistrationResponse:\n        \"\"\"\n        Update registered OAuth client configuration.\n\n        Args:\n            registration_client_uri: Client configuration URI\n            registration_access_token: Access token for client management\n            request: Updated client configuration\n\n        Returns:\n            ClientRegistrationResponse: Updated client credentials\n        \"\"\"\n        # Implementation in Phase 3\n        raise NotImplementedError(\"Dynamic client update not yet implemented (Phase 3)\")\n</code></pre> <code></code> sk_agents.auth.client_registration.DynamicClientRegistration.register_client <code>async</code> <pre><code>register_client(\n    registration_endpoint: str,\n    request: ClientRegistrationRequest,\n) -&gt; ClientRegistrationResponse\n</code></pre> <p>Register OAuth client with authorization server.</p> <p>Parameters:</p> Name Type Description Default <code>registration_endpoint</code> <code>str</code> <p>Registration endpoint URL from server metadata</p> required <code>request</code> <code>ClientRegistrationRequest</code> <p>Client registration request</p> required <p>Returns:</p> Name Type Description <code>ClientRegistrationResponse</code> <code>ClientRegistrationResponse</code> <p>Registered client credentials</p> <p>Raises:</p> Type Description <code>HTTPError</code> <p>If registration fails</p> Source code in <code>src/sk_agents/auth/client_registration.py</code> <pre><code>async def register_client(\n    self,\n    registration_endpoint: str,\n    request: ClientRegistrationRequest,\n) -&gt; ClientRegistrationResponse:\n    \"\"\"\n    Register OAuth client with authorization server.\n\n    Args:\n        registration_endpoint: Registration endpoint URL from server metadata\n        request: Client registration request\n\n    Returns:\n        ClientRegistrationResponse: Registered client credentials\n\n    Raises:\n        httpx.HTTPError: If registration fails\n    \"\"\"\n    # Implementation in Phase 3\n    raise NotImplementedError(\"Dynamic client registration not yet implemented (Phase 3)\")\n</code></pre> <code></code> sk_agents.auth.client_registration.DynamicClientRegistration.update_client <code>async</code> <pre><code>update_client(\n    registration_client_uri: str,\n    registration_access_token: str,\n    request: ClientRegistrationRequest,\n) -&gt; ClientRegistrationResponse\n</code></pre> <p>Update registered OAuth client configuration.</p> <p>Parameters:</p> Name Type Description Default <code>registration_client_uri</code> <code>str</code> <p>Client configuration URI</p> required <code>registration_access_token</code> <code>str</code> <p>Access token for client management</p> required <code>request</code> <code>ClientRegistrationRequest</code> <p>Updated client configuration</p> required <p>Returns:</p> Name Type Description <code>ClientRegistrationResponse</code> <code>ClientRegistrationResponse</code> <p>Updated client credentials</p> Source code in <code>src/sk_agents/auth/client_registration.py</code> <pre><code>async def update_client(\n    self,\n    registration_client_uri: str,\n    registration_access_token: str,\n    request: ClientRegistrationRequest,\n) -&gt; ClientRegistrationResponse:\n    \"\"\"\n    Update registered OAuth client configuration.\n\n    Args:\n        registration_client_uri: Client configuration URI\n        registration_access_token: Access token for client management\n        request: Updated client configuration\n\n    Returns:\n        ClientRegistrationResponse: Updated client credentials\n    \"\"\"\n    # Implementation in Phase 3\n    raise NotImplementedError(\"Dynamic client update not yet implemented (Phase 3)\")\n</code></pre> <code></code> sk_agents.auth.oauth_client <p>OAuth 2.1 Client Implementation</p> <p>Main OAuth client for handling authorization code flow with PKCE. Implements MCP specification requirements for OAuth authorization.</p> <p>Key Features: - Authorization URL generation with PKCE + resource parameter - Authorization code exchange for access token - Token refresh with rotation - Resource-bound token acquisition</p> <p>References: - MCP Specification 2025-06-18 - OAuth 2.1 Draft - RFC 8707 (Resource Indicators)</p> <code></code> sk_agents.auth.oauth_client.OAuthClient <p>OAuth 2.1 Client for MCP Server Authentication.</p> <p>Handles complete OAuth authorization code flow with PKCE and resource binding.</p> Source code in <code>src/sk_agents/auth/oauth_client.py</code> <pre><code>class OAuthClient:\n    \"\"\"\n    OAuth 2.1 Client for MCP Server Authentication.\n\n    Handles complete OAuth authorization code flow with PKCE and resource binding.\n    \"\"\"\n\n    def __init__(self, timeout: float = 30.0):\n        \"\"\"\n        Initialize OAuth client.\n\n        Args:\n            timeout: HTTP request timeout in seconds\n        \"\"\"\n        self.timeout = timeout\n        self.pkce_manager = PKCEManager()\n        self.state_manager = OAuthStateManager()\n        self.metadata_cache = ServerMetadataCache(timeout=timeout)\n        self.auth_storage_factory = AuthStorageFactory(AppConfig())\n        self.auth_storage = self.auth_storage_factory.get_auth_storage_manager()\n\n    @staticmethod\n    def should_include_resource_param(\n        protocol_version: str | None = None, has_prm: bool = False\n    ) -&gt; bool:\n        \"\"\"\n        Determine if resource parameter should be included in OAuth requests.\n\n        Per MCP specification 2025-06-18:\n        - resource parameter MUST be included if protocol version &gt;= 2025-06-18\n        - resource parameter MUST be included if Protected Resource Metadata discovered\n        - Otherwise, resource parameter SHOULD be omitted for backward compatibility\n\n        Args:\n            protocol_version: MCP protocol version (e.g., \"2025-06-18\")\n            has_prm: Whether Protected Resource Metadata has been discovered\n\n        Returns:\n            bool: True if resource parameter should be included\n        \"\"\"\n        # If we have Protected Resource Metadata, always include resource param\n        if has_prm:\n            return True\n\n        # If no protocol version provided, don't include resource param (backward compat)\n        if not protocol_version:\n            return False\n\n        # Check if protocol version is 2025-11-25 or later\n        # Simple string comparison works for ISO date format (YYYY-MM-DD)\n        try:\n            return protocol_version &gt;= \"2025-11-25\"\n        except Exception:\n            # If comparison fails, be conservative and include resource param\n            logger.warning(f\"Failed to compare protocol version: {protocol_version}\")\n            return True\n\n    @staticmethod\n    def validate_token_scopes(\n        requested_scopes: list[str] | None, token_response: \"TokenResponse\"\n    ) -&gt; None:\n        \"\"\"\n        Validate that returned scopes don't exceed requested scopes (prevents escalation attacks).\n\n        Per OAuth 2.1 Section 3.3:\n        - If scopes were requested, returned scopes MUST be a subset of requested scopes\n        - Servers MUST NOT grant scopes not requested by the client\n        - This prevents scope escalation attacks\n\n        Args:\n            requested_scopes: Scopes requested in authorization request\n            token_response: Token response from authorization server\n\n        Raises:\n            ValueError: If scope escalation detected (returned &gt; requested)\n        \"\"\"\n\n        # If no scopes were requested, any returned scopes are acceptable\n        if not requested_scopes:\n            return\n\n        # If server didn't return scope field, assume it granted all requested scopes\n        # Per OAuth 2.1: \"If omitted, authorization server defaults to all requested scopes\"\n        if not token_response.scope:\n            logger.debug(\n                \"Token response contains no scope field - assuming all requested scopes granted\"\n            )\n            return\n\n        # Parse returned scopes (space-separated string)\n        requested = set(requested_scopes)\n        returned = set(token_response.scope.split())\n\n        # Check for scope escalation: returned scopes must be subset of requested\n        unauthorized_scopes = returned - requested\n\n        if unauthorized_scopes:\n            logger.error(\n                f\"Scope escalation attack detected! \"\n                f\"Requested: {requested}, Returned: {returned}, Unauthorized: {unauthorized_scopes}\"\n            )\n            raise ValueError(\n                f\"Server granted unauthorized scopes: {unauthorized_scopes}. \"\n                f\"This is a scope escalation attack. Requested: {requested}, Returned: {returned}\"\n            )\n\n        # Log scope reduction (informational - not an error)\n        missing_scopes = requested - returned\n        if missing_scopes:\n            logger.warning(\n                f\"Server granted fewer scopes than requested. \"\n                f\"Requested: {requested}, Granted: {returned}, Missing: {missing_scopes}\"\n            )\n        else:\n            logger.debug(f\"Scope validation passed. Granted scopes: {returned}\")\n\n    def build_authorization_url(self, request: AuthorizationRequest) -&gt; str:\n        \"\"\"\n        Build complete OAuth authorization URL.\n\n        Constructs URL with all required parameters:\n        - response_type=code\n        - client_id, redirect_uri\n        - resource (canonical MCP server URI) - only if protocol version &gt;= 2025-06-18\n        - code_challenge, code_challenge_method=S256\n        - scope, state\n\n        Args:\n            request: Authorization request parameters\n\n        Returns:\n            str: Complete authorization URL for user redirect\n        \"\"\"\n        params = {\n            \"response_type\": request.response_type,\n            \"client_id\": request.client_id,\n            \"redirect_uri\": str(request.redirect_uri),\n            \"scope\": \" \".join(request.scopes),\n            \"state\": request.state,\n            \"code_challenge\": request.code_challenge,\n            \"code_challenge_method\": request.code_challenge_method,\n        }\n\n        # Conditionally include resource parameter per MCP spec 2025-06-18\n        if request.resource:\n            params[\"resource\"] = request.resource\n\n        # Build URL - use discovered authorization_endpoint if available\n        if request.authorization_endpoint:\n            base_url = str(request.authorization_endpoint)\n            logger.debug(f\"Using discovered authorization endpoint: {base_url}\")\n        else:\n            # Fallback: construct from auth_server\n            base_url = str(request.auth_server).rstrip(\"/\")\n            if not base_url.endswith(\"/authorize\"):\n                base_url = f\"{base_url}/authorize\"\n            logger.debug(f\"Using fallback authorization endpoint: {base_url}\")\n\n        auth_url = f\"{base_url}?{urlencode(params)}\"\n        logger.debug(f\"Built authorization URL for resource={request.resource}\")\n        return auth_url\n\n    async def exchange_code_for_tokens(self, token_request: TokenRequest) -&gt; TokenResponse:\n        \"\"\"\n        Exchange authorization code for access token.\n\n        Makes POST request to token endpoint with:\n        - grant_type=authorization_code\n        - code, redirect_uri\n        - code_verifier (PKCE)\n        - resource (canonical URI) - only if protocol version &gt;= 2025-06-18\n        - client_id (+ client_secret if confidential)\n\n        Args:\n            token_request: Token request parameters\n\n        Returns:\n            TokenResponse: Access token and metadata\n\n        Raises:\n            httpx.HTTPError: If token request fails\n            ValueError: If response is invalid\n        \"\"\"\n        # Build request body\n        body = {\n            \"grant_type\": token_request.grant_type,\n            \"client_id\": token_request.client_id,\n        }\n\n        # Conditionally include resource parameter per MCP spec 2025-06-18\n        if token_request.resource:\n            body[\"resource\"] = token_request.resource\n\n        # Add grant-specific parameters\n        if token_request.grant_type == \"authorization_code\":\n            if (\n                not token_request.code\n                or not token_request.redirect_uri\n                or not token_request.code_verifier\n            ):\n                raise ValueError(\"Missing required parameters for authorization_code grant\")\n            body[\"code\"] = token_request.code\n            body[\"redirect_uri\"] = str(token_request.redirect_uri)\n            body[\"code_verifier\"] = token_request.code_verifier\n        elif token_request.grant_type == \"refresh_token\":\n            if not token_request.refresh_token:\n                raise ValueError(\"Missing refresh_token for refresh_token grant\")\n            body[\"refresh_token\"] = token_request.refresh_token\n\n        # Add client secret if provided (confidential client)\n        if token_request.client_secret:\n            body[\"client_secret\"] = token_request.client_secret\n\n        logger.debug(\n            f\"Exchanging code for tokens: endpoint={token_request.token_endpoint}, \"\n            f\"grant_type={token_request.grant_type}\"\n        )\n\n        # Make token request\n        async with httpx.AsyncClient(timeout=self.timeout) as client:\n            response = await client.post(\n                str(token_request.token_endpoint),\n                data=body,\n                headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n            )\n\n            if response.status_code != 200:\n                error_data = (\n                    response.json()\n                    if response.headers.get(\"content-type\") == \"application/json\"\n                    else {}\n                )\n                logger.error(\n                    f\"Token request failed: status={response.status_code}, error={error_data}\"\n                )\n                raise httpx.HTTPError(\n                    f\"Token request failed: {error_data.get('error', 'unknown_error')}\"\n                )\n\n            # Parse response\n            token_data = response.json()\n            token_response = TokenResponse(**token_data)\n\n            # Validate scopes to prevent escalation attacks\n            self.validate_token_scopes(token_request.requested_scopes, token_response)\n\n            logger.info(f\"Successfully obtained access token for resource={token_request.resource}\")\n            return token_response\n\n    async def refresh_access_token(self, refresh_request: RefreshTokenRequest) -&gt; TokenResponse:\n        \"\"\"\n        Refresh expired access token.\n\n        Makes POST request to token endpoint with:\n        - grant_type=refresh_token\n        - refresh_token\n        - resource (must match original)\n        - client_id\n\n        Implements token rotation per OAuth 2.1.\n\n        Args:\n            refresh_request: Refresh token request parameters\n\n        Returns:\n            TokenResponse: New access token (and possibly new refresh token)\n\n        Raises:\n            httpx.HTTPError: If refresh fails\n        \"\"\"\n        token_request = TokenRequest(\n            token_endpoint=refresh_request.token_endpoint,\n            grant_type=\"refresh_token\",\n            refresh_token=refresh_request.refresh_token,\n            resource=refresh_request.resource,\n            client_id=refresh_request.client_id,\n            client_secret=refresh_request.client_secret,\n            requested_scopes=refresh_request.requested_scopes,\n        )\n\n        logger.debug(f\"Refreshing access token for resource={refresh_request.resource}\")\n        return await self.exchange_code_for_tokens(token_request)\n\n    async def revoke_token(\n        self,\n        token: str,\n        revocation_endpoint: str,\n        client_id: str,\n        client_secret: str | None = None,\n        token_type_hint: str = \"access_token\",\n    ) -&gt; None:\n        \"\"\"\n        Revoke an access or refresh token per RFC 7009.\n\n        This allows clients to notify the authorization server that a token\n        is no longer needed, enabling immediate invalidation.\n\n        Args:\n            token: The token to revoke (access or refresh token)\n            revocation_endpoint: Token revocation endpoint URL\n            client_id: OAuth client ID\n            client_secret: OAuth client secret (for confidential clients)\n            token_type_hint: Hint about token type (\"access_token\" or \"refresh_token\")\n\n        Raises:\n            httpx.HTTPError: If revocation request fails\n        \"\"\"\n        # Build request body per RFC 7009\n        body = {\n            \"token\": token,\n            \"token_type_hint\": token_type_hint,\n            \"client_id\": client_id,\n        }\n\n        # Add client secret if provided (confidential clients)\n        if client_secret:\n            body[\"client_secret\"] = client_secret\n\n        logger.debug(f\"Revoking token: endpoint={revocation_endpoint}, type_hint={token_type_hint}\")\n\n        try:\n            async with httpx.AsyncClient(timeout=self.timeout) as client:\n                response = await client.post(\n                    revocation_endpoint,\n                    data=body,\n                    headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n                )\n\n                # Per RFC 7009: Server responds with 200 regardless of token validity\n                # This prevents token scanning attacks\n                if response.status_code == 200:\n                    logger.info(f\"Successfully revoked token (type_hint={token_type_hint})\")\n                else:\n                    logger.warning(\n                        f\"Token revocation returned unexpected status {response.status_code}\"\n                    )\n                    response.raise_for_status()\n\n        except httpx.HTTPError as e:\n            logger.error(f\"Failed to revoke token: {e}\")\n            raise\n\n    async def initiate_authorization_flow(\n        self,\n        server_config: \"McpServerConfig\",\n        user_id: str,\n    ) -&gt; str:\n        \"\"\"\n        Initiate OAuth authorization flow for MCP server.\n\n        Generates PKCE pair, state, stores flow state, and returns authorization URL.\n\n        Args:\n            server_config: MCP server configuration\n            user_id: User ID initiating the flow\n\n        Returns:\n            str: Authorization URL for user redirect\n\n        Raises:\n            ValueError: If server configuration is invalid\n        \"\"\"\n        from ska_utils import AppConfig\n\n        from sk_agents.configs import TA_OAUTH_CLIENT_NAME\n\n        # Discover Protected Resource Metadata (RFC 9728) if HTTP MCP server\n        has_prm = False\n        if server_config.url:  # Only for HTTP MCP servers\n            try:\n                prm = await self.metadata_cache.fetch_protected_resource_metadata(server_config.url)\n                has_prm = prm is not None\n                if prm:\n                    logger.info(\n                        f\"Discovered PRM for {server_config.name}: \"\n                        f\"auth_servers={prm.authorization_servers}\"\n                    )\n            except Exception as e:\n                logger.debug(f\"PRM discovery failed (optional): {e}\")\n                has_prm = False\n\n        # Determine if resource parameter should be included (per MCP spec 2025-06-18)\n        include_resource = self.should_include_resource_param(\n            protocol_version=server_config.protocol_version, has_prm=has_prm\n        )\n\n        # Get canonical resource URI if needed\n        resource = None\n        if include_resource:\n            try:\n                resource = server_config.effective_canonical_uri\n            except ValueError as e:\n                logger.warning(\n                    f\"Cannot determine canonical URI for {server_config.name}: {e}. \"\n                    \"Proceeding without resource parameter.\"\n                )\n                resource = None\n\n        # Generate PKCE pair\n        verifier, challenge = self.pkce_manager.generate_pkce_pair()\n\n        # Generate state\n        state = self.state_manager.generate_state()\n\n        # Store flow state (always store resource for validation, even if not sent in auth request)\n        self.state_manager.store_flow_state(\n            state=state,\n            verifier=verifier,\n            user_id=user_id,\n            server_name=server_config.name,\n            resource=resource or server_config.url or \"\",  # Store for future reference\n            scopes=server_config.scopes,\n        )\n\n        # Get client configuration\n        app_config = AppConfig()\n        client_name = app_config.get(TA_OAUTH_CLIENT_NAME.env_name)\n\n        # Discover authorization server metadata (RFC 8414)\n        authorization_endpoint = None\n        metadata = None\n        try:\n            metadata = await self.metadata_cache.fetch_auth_server_metadata(\n                server_config.auth_server\n            )\n            authorization_endpoint = str(metadata.authorization_endpoint)\n            logger.info(f\"Discovered authorization endpoint: {authorization_endpoint}\")\n        except Exception as e:\n            logger.warning(\n                f\"Failed to discover authorization server metadata: {e}. Using fallback.\"\n            )\n            authorization_endpoint = None\n\n        # Try dynamic client registration if no client_id configured (RFC 7591)\n        client_id = server_config.oauth_client_id or client_name\n\n        if not server_config.oauth_client_id and server_config.enable_dynamic_registration:\n            try:\n                # Check if metadata includes registration_endpoint\n                if metadata and metadata.registration_endpoint:\n                    logger.info(\n                        f\"No client_id configured for {server_config.name}. \"\n                        f\"Attempting dynamic registration...\"\n                    )\n\n                    from sk_agents.auth.client_registration import DynamicClientRegistration\n\n                    registration_client = DynamicClientRegistration(timeout=self.timeout)\n                    registration_response = await registration_client.register_client(\n                        registration_endpoint=str(metadata.registration_endpoint),\n                        redirect_uris=[str(server_config.oauth_redirect_uri)],\n                        client_name=client_name,\n                        scopes=server_config.scopes,\n                    )\n\n                    # Use registered credentials\n                    client_id = registration_response.client_id\n                    # Note: client_secret available in registration_response if needed\n\n                    logger.info(\n                        f\"Successfully registered client for {server_config.name}: \"\n                        f\"client_id={client_id}\"\n                    )\n\n                    # TODO: Optionally persist client_id/secret for reuse\n\n                else:\n                    logger.warning(\n                        f\"Dynamic registration enabled but no registration_endpoint \"\n                        f\"discovered for {server_config.name}\"\n                    )\n            except Exception as e:\n                logger.warning(\n                    f\"Dynamic client registration failed for {server_config.name}: {e}. \"\n                    f\"Falling back to default client_id.\"\n                )\n                # Continue with default client_name\n\n        # Build authorization request\n        auth_request = AuthorizationRequest(\n            auth_server=server_config.auth_server,\n            authorization_endpoint=authorization_endpoint,\n            client_id=client_id,\n            redirect_uri=server_config.oauth_redirect_uri,\n            resource=resource,  # None if protocol version &lt; 2025-06-18\n            scopes=server_config.scopes,\n            state=state,\n            code_challenge=challenge,\n            code_challenge_method=\"S256\",\n        )\n\n        # Build and return authorization URL\n        auth_url = self.build_authorization_url(auth_request)\n        logger.info(\n            f\"Initiated OAuth flow for {server_config.name}: \"\n            f\"user={user_id}, resource={resource}, state={state}\"\n        )\n        return auth_url\n\n    async def handle_callback(\n        self,\n        code: str,\n        state: str,\n        user_id: str,\n        server_config: \"McpServerConfig\",\n    ) -&gt; OAuth2AuthData:\n        \"\"\"\n        Handle OAuth callback after user authorization.\n\n        Validates state, exchanges code for tokens, and stores in AuthStorage.\n\n        Args:\n            code: Authorization code from callback\n            state: State parameter from callback\n            user_id: User ID to validate against\n            server_config: MCP server configuration\n\n        Returns:\n            OAuth2AuthData: Stored token data\n\n        Raises:\n            ValueError: If state invalid or user mismatch\n            httpx.HTTPError: If token exchange fails\n        \"\"\"\n        from datetime import datetime, timedelta\n\n        from ska_utils import AppConfig\n\n        from sk_agents.configs import TA_OAUTH_CLIENT_NAME\n        from sk_agents.mcp_client import build_auth_storage_key\n\n        # Retrieve and validate flow state\n        flow_state = self.state_manager.retrieve_flow_state(state, user_id)\n\n        # Get token endpoint (from server metadata or construct from auth_server)\n        token_endpoint = f\"{server_config.auth_server.rstrip('/')}/token\"\n\n        # Get client configuration\n        app_config = AppConfig()\n        client_name = app_config.get(TA_OAUTH_CLIENT_NAME.env_name)\n\n        # Discover Protected Resource Metadata (RFC 9728) if HTTP MCP server\n        has_prm = False\n        if server_config.url:  # Only for HTTP MCP servers\n            try:\n                prm = await self.metadata_cache.fetch_protected_resource_metadata(server_config.url)\n                has_prm = prm is not None\n                if prm:\n                    logger.info(\n                        f\"Discovered PRM for {server_config.name}: \"\n                        f\"auth_servers={prm.authorization_servers}\"\n                    )\n            except Exception as e:\n                logger.debug(f\"PRM discovery failed (optional): {e}\")\n                has_prm = False\n\n        # Determine if resource parameter should be included (per MCP spec 2025-06-18)\n        include_resource = self.should_include_resource_param(\n            protocol_version=server_config.protocol_version, has_prm=has_prm\n        )\n\n        # Build token request\n        token_request = TokenRequest(\n            token_endpoint=token_endpoint,\n            grant_type=\"authorization_code\",\n            code=code,\n            redirect_uri=server_config.oauth_redirect_uri,\n            code_verifier=flow_state.verifier,\n            resource=flow_state.resource\n            if include_resource\n            else None,  # Conditional per protocol version\n            client_id=server_config.oauth_client_id or client_name,\n            client_secret=server_config.oauth_client_secret,\n            requested_scopes=flow_state.scopes,  # For scope validation\n        )\n\n        # Exchange code for tokens\n        token_response = await self.exchange_code_for_tokens(token_request)\n\n        # Create OAuth2AuthData\n        oauth_data = OAuth2AuthData(\n            access_token=token_response.access_token,\n            refresh_token=token_response.refresh_token,\n            expires_at=datetime.now(UTC) + timedelta(seconds=token_response.expires_in),\n            scopes=token_response.scope.split() if token_response.scope else flow_state.scopes,\n            audience=token_response.aud,\n            resource=flow_state.resource,\n            token_type=token_response.token_type,\n            issued_at=datetime.now(UTC),\n        )\n\n        # Store in AuthStorage\n        composite_key = build_auth_storage_key(server_config.auth_server, oauth_data.scopes)\n        self.auth_storage.store(user_id, composite_key, oauth_data)\n\n        logger.info(\n            f\"OAuth callback successful for {flow_state.server_name}: \"\n            f\"user={user_id}, resource={flow_state.resource}\"\n        )\n\n        # Clean up flow state\n        self.state_manager.delete_flow_state(state, user_id)\n\n        return oauth_data\n</code></pre> <code></code> sk_agents.auth.oauth_client.OAuthClient.__init__ <pre><code>__init__(timeout: float = 30.0)\n</code></pre> <p>Initialize OAuth client.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>float</code> <p>HTTP request timeout in seconds</p> <code>30.0</code> Source code in <code>src/sk_agents/auth/oauth_client.py</code> <pre><code>def __init__(self, timeout: float = 30.0):\n    \"\"\"\n    Initialize OAuth client.\n\n    Args:\n        timeout: HTTP request timeout in seconds\n    \"\"\"\n    self.timeout = timeout\n    self.pkce_manager = PKCEManager()\n    self.state_manager = OAuthStateManager()\n    self.metadata_cache = ServerMetadataCache(timeout=timeout)\n    self.auth_storage_factory = AuthStorageFactory(AppConfig())\n    self.auth_storage = self.auth_storage_factory.get_auth_storage_manager()\n</code></pre> <code></code> sk_agents.auth.oauth_client.OAuthClient.should_include_resource_param <code>staticmethod</code> <pre><code>should_include_resource_param(\n    protocol_version: str | None = None,\n    has_prm: bool = False,\n) -&gt; bool\n</code></pre> <p>Determine if resource parameter should be included in OAuth requests.</p> <p>Per MCP specification 2025-06-18: - resource parameter MUST be included if protocol version &gt;= 2025-06-18 - resource parameter MUST be included if Protected Resource Metadata discovered - Otherwise, resource parameter SHOULD be omitted for backward compatibility</p> <p>Parameters:</p> Name Type Description Default <code>protocol_version</code> <code>str | None</code> <p>MCP protocol version (e.g., \"2025-06-18\")</p> <code>None</code> <code>has_prm</code> <code>bool</code> <p>Whether Protected Resource Metadata has been discovered</p> <code>False</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if resource parameter should be included</p> Source code in <code>src/sk_agents/auth/oauth_client.py</code> <pre><code>@staticmethod\ndef should_include_resource_param(\n    protocol_version: str | None = None, has_prm: bool = False\n) -&gt; bool:\n    \"\"\"\n    Determine if resource parameter should be included in OAuth requests.\n\n    Per MCP specification 2025-06-18:\n    - resource parameter MUST be included if protocol version &gt;= 2025-06-18\n    - resource parameter MUST be included if Protected Resource Metadata discovered\n    - Otherwise, resource parameter SHOULD be omitted for backward compatibility\n\n    Args:\n        protocol_version: MCP protocol version (e.g., \"2025-06-18\")\n        has_prm: Whether Protected Resource Metadata has been discovered\n\n    Returns:\n        bool: True if resource parameter should be included\n    \"\"\"\n    # If we have Protected Resource Metadata, always include resource param\n    if has_prm:\n        return True\n\n    # If no protocol version provided, don't include resource param (backward compat)\n    if not protocol_version:\n        return False\n\n    # Check if protocol version is 2025-11-25 or later\n    # Simple string comparison works for ISO date format (YYYY-MM-DD)\n    try:\n        return protocol_version &gt;= \"2025-11-25\"\n    except Exception:\n        # If comparison fails, be conservative and include resource param\n        logger.warning(f\"Failed to compare protocol version: {protocol_version}\")\n        return True\n</code></pre> <code></code> sk_agents.auth.oauth_client.OAuthClient.validate_token_scopes <code>staticmethod</code> <pre><code>validate_token_scopes(\n    requested_scopes: list[str] | None,\n    token_response: TokenResponse,\n) -&gt; None\n</code></pre> <p>Validate that returned scopes don't exceed requested scopes (prevents escalation attacks).</p> <p>Per OAuth 2.1 Section 3.3: - If scopes were requested, returned scopes MUST be a subset of requested scopes - Servers MUST NOT grant scopes not requested by the client - This prevents scope escalation attacks</p> <p>Parameters:</p> Name Type Description Default <code>requested_scopes</code> <code>list[str] | None</code> <p>Scopes requested in authorization request</p> required <code>token_response</code> <code>TokenResponse</code> <p>Token response from authorization server</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If scope escalation detected (returned &gt; requested)</p> Source code in <code>src/sk_agents/auth/oauth_client.py</code> <pre><code>@staticmethod\ndef validate_token_scopes(\n    requested_scopes: list[str] | None, token_response: \"TokenResponse\"\n) -&gt; None:\n    \"\"\"\n    Validate that returned scopes don't exceed requested scopes (prevents escalation attacks).\n\n    Per OAuth 2.1 Section 3.3:\n    - If scopes were requested, returned scopes MUST be a subset of requested scopes\n    - Servers MUST NOT grant scopes not requested by the client\n    - This prevents scope escalation attacks\n\n    Args:\n        requested_scopes: Scopes requested in authorization request\n        token_response: Token response from authorization server\n\n    Raises:\n        ValueError: If scope escalation detected (returned &gt; requested)\n    \"\"\"\n\n    # If no scopes were requested, any returned scopes are acceptable\n    if not requested_scopes:\n        return\n\n    # If server didn't return scope field, assume it granted all requested scopes\n    # Per OAuth 2.1: \"If omitted, authorization server defaults to all requested scopes\"\n    if not token_response.scope:\n        logger.debug(\n            \"Token response contains no scope field - assuming all requested scopes granted\"\n        )\n        return\n\n    # Parse returned scopes (space-separated string)\n    requested = set(requested_scopes)\n    returned = set(token_response.scope.split())\n\n    # Check for scope escalation: returned scopes must be subset of requested\n    unauthorized_scopes = returned - requested\n\n    if unauthorized_scopes:\n        logger.error(\n            f\"Scope escalation attack detected! \"\n            f\"Requested: {requested}, Returned: {returned}, Unauthorized: {unauthorized_scopes}\"\n        )\n        raise ValueError(\n            f\"Server granted unauthorized scopes: {unauthorized_scopes}. \"\n            f\"This is a scope escalation attack. Requested: {requested}, Returned: {returned}\"\n        )\n\n    # Log scope reduction (informational - not an error)\n    missing_scopes = requested - returned\n    if missing_scopes:\n        logger.warning(\n            f\"Server granted fewer scopes than requested. \"\n            f\"Requested: {requested}, Granted: {returned}, Missing: {missing_scopes}\"\n        )\n    else:\n        logger.debug(f\"Scope validation passed. Granted scopes: {returned}\")\n</code></pre> <code></code> sk_agents.auth.oauth_client.OAuthClient.build_authorization_url <pre><code>build_authorization_url(\n    request: AuthorizationRequest,\n) -&gt; str\n</code></pre> <p>Build complete OAuth authorization URL.</p> <p>Constructs URL with all required parameters: - response_type=code - client_id, redirect_uri - resource (canonical MCP server URI) - only if protocol version &gt;= 2025-06-18 - code_challenge, code_challenge_method=S256 - scope, state</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>AuthorizationRequest</code> <p>Authorization request parameters</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Complete authorization URL for user redirect</p> Source code in <code>src/sk_agents/auth/oauth_client.py</code> <pre><code>def build_authorization_url(self, request: AuthorizationRequest) -&gt; str:\n    \"\"\"\n    Build complete OAuth authorization URL.\n\n    Constructs URL with all required parameters:\n    - response_type=code\n    - client_id, redirect_uri\n    - resource (canonical MCP server URI) - only if protocol version &gt;= 2025-06-18\n    - code_challenge, code_challenge_method=S256\n    - scope, state\n\n    Args:\n        request: Authorization request parameters\n\n    Returns:\n        str: Complete authorization URL for user redirect\n    \"\"\"\n    params = {\n        \"response_type\": request.response_type,\n        \"client_id\": request.client_id,\n        \"redirect_uri\": str(request.redirect_uri),\n        \"scope\": \" \".join(request.scopes),\n        \"state\": request.state,\n        \"code_challenge\": request.code_challenge,\n        \"code_challenge_method\": request.code_challenge_method,\n    }\n\n    # Conditionally include resource parameter per MCP spec 2025-06-18\n    if request.resource:\n        params[\"resource\"] = request.resource\n\n    # Build URL - use discovered authorization_endpoint if available\n    if request.authorization_endpoint:\n        base_url = str(request.authorization_endpoint)\n        logger.debug(f\"Using discovered authorization endpoint: {base_url}\")\n    else:\n        # Fallback: construct from auth_server\n        base_url = str(request.auth_server).rstrip(\"/\")\n        if not base_url.endswith(\"/authorize\"):\n            base_url = f\"{base_url}/authorize\"\n        logger.debug(f\"Using fallback authorization endpoint: {base_url}\")\n\n    auth_url = f\"{base_url}?{urlencode(params)}\"\n    logger.debug(f\"Built authorization URL for resource={request.resource}\")\n    return auth_url\n</code></pre> <code></code> sk_agents.auth.oauth_client.OAuthClient.exchange_code_for_tokens <code>async</code> <pre><code>exchange_code_for_tokens(\n    token_request: TokenRequest,\n) -&gt; TokenResponse\n</code></pre> <p>Exchange authorization code for access token.</p> <p>Makes POST request to token endpoint with: - grant_type=authorization_code - code, redirect_uri - code_verifier (PKCE) - resource (canonical URI) - only if protocol version &gt;= 2025-06-18 - client_id (+ client_secret if confidential)</p> <p>Parameters:</p> Name Type Description Default <code>token_request</code> <code>TokenRequest</code> <p>Token request parameters</p> required <p>Returns:</p> Name Type Description <code>TokenResponse</code> <code>TokenResponse</code> <p>Access token and metadata</p> <p>Raises:</p> Type Description <code>HTTPError</code> <p>If token request fails</p> <code>ValueError</code> <p>If response is invalid</p> Source code in <code>src/sk_agents/auth/oauth_client.py</code> <pre><code>async def exchange_code_for_tokens(self, token_request: TokenRequest) -&gt; TokenResponse:\n    \"\"\"\n    Exchange authorization code for access token.\n\n    Makes POST request to token endpoint with:\n    - grant_type=authorization_code\n    - code, redirect_uri\n    - code_verifier (PKCE)\n    - resource (canonical URI) - only if protocol version &gt;= 2025-06-18\n    - client_id (+ client_secret if confidential)\n\n    Args:\n        token_request: Token request parameters\n\n    Returns:\n        TokenResponse: Access token and metadata\n\n    Raises:\n        httpx.HTTPError: If token request fails\n        ValueError: If response is invalid\n    \"\"\"\n    # Build request body\n    body = {\n        \"grant_type\": token_request.grant_type,\n        \"client_id\": token_request.client_id,\n    }\n\n    # Conditionally include resource parameter per MCP spec 2025-06-18\n    if token_request.resource:\n        body[\"resource\"] = token_request.resource\n\n    # Add grant-specific parameters\n    if token_request.grant_type == \"authorization_code\":\n        if (\n            not token_request.code\n            or not token_request.redirect_uri\n            or not token_request.code_verifier\n        ):\n            raise ValueError(\"Missing required parameters for authorization_code grant\")\n        body[\"code\"] = token_request.code\n        body[\"redirect_uri\"] = str(token_request.redirect_uri)\n        body[\"code_verifier\"] = token_request.code_verifier\n    elif token_request.grant_type == \"refresh_token\":\n        if not token_request.refresh_token:\n            raise ValueError(\"Missing refresh_token for refresh_token grant\")\n        body[\"refresh_token\"] = token_request.refresh_token\n\n    # Add client secret if provided (confidential client)\n    if token_request.client_secret:\n        body[\"client_secret\"] = token_request.client_secret\n\n    logger.debug(\n        f\"Exchanging code for tokens: endpoint={token_request.token_endpoint}, \"\n        f\"grant_type={token_request.grant_type}\"\n    )\n\n    # Make token request\n    async with httpx.AsyncClient(timeout=self.timeout) as client:\n        response = await client.post(\n            str(token_request.token_endpoint),\n            data=body,\n            headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n        )\n\n        if response.status_code != 200:\n            error_data = (\n                response.json()\n                if response.headers.get(\"content-type\") == \"application/json\"\n                else {}\n            )\n            logger.error(\n                f\"Token request failed: status={response.status_code}, error={error_data}\"\n            )\n            raise httpx.HTTPError(\n                f\"Token request failed: {error_data.get('error', 'unknown_error')}\"\n            )\n\n        # Parse response\n        token_data = response.json()\n        token_response = TokenResponse(**token_data)\n\n        # Validate scopes to prevent escalation attacks\n        self.validate_token_scopes(token_request.requested_scopes, token_response)\n\n        logger.info(f\"Successfully obtained access token for resource={token_request.resource}\")\n        return token_response\n</code></pre> <code></code> sk_agents.auth.oauth_client.OAuthClient.refresh_access_token <code>async</code> <pre><code>refresh_access_token(\n    refresh_request: RefreshTokenRequest,\n) -&gt; TokenResponse\n</code></pre> <p>Refresh expired access token.</p> <p>Makes POST request to token endpoint with: - grant_type=refresh_token - refresh_token - resource (must match original) - client_id</p> <p>Implements token rotation per OAuth 2.1.</p> <p>Parameters:</p> Name Type Description Default <code>refresh_request</code> <code>RefreshTokenRequest</code> <p>Refresh token request parameters</p> required <p>Returns:</p> Name Type Description <code>TokenResponse</code> <code>TokenResponse</code> <p>New access token (and possibly new refresh token)</p> <p>Raises:</p> Type Description <code>HTTPError</code> <p>If refresh fails</p> Source code in <code>src/sk_agents/auth/oauth_client.py</code> <pre><code>async def refresh_access_token(self, refresh_request: RefreshTokenRequest) -&gt; TokenResponse:\n    \"\"\"\n    Refresh expired access token.\n\n    Makes POST request to token endpoint with:\n    - grant_type=refresh_token\n    - refresh_token\n    - resource (must match original)\n    - client_id\n\n    Implements token rotation per OAuth 2.1.\n\n    Args:\n        refresh_request: Refresh token request parameters\n\n    Returns:\n        TokenResponse: New access token (and possibly new refresh token)\n\n    Raises:\n        httpx.HTTPError: If refresh fails\n    \"\"\"\n    token_request = TokenRequest(\n        token_endpoint=refresh_request.token_endpoint,\n        grant_type=\"refresh_token\",\n        refresh_token=refresh_request.refresh_token,\n        resource=refresh_request.resource,\n        client_id=refresh_request.client_id,\n        client_secret=refresh_request.client_secret,\n        requested_scopes=refresh_request.requested_scopes,\n    )\n\n    logger.debug(f\"Refreshing access token for resource={refresh_request.resource}\")\n    return await self.exchange_code_for_tokens(token_request)\n</code></pre> <code></code> sk_agents.auth.oauth_client.OAuthClient.revoke_token <code>async</code> <pre><code>revoke_token(\n    token: str,\n    revocation_endpoint: str,\n    client_id: str,\n    client_secret: str | None = None,\n    token_type_hint: str = \"access_token\",\n) -&gt; None\n</code></pre> <p>Revoke an access or refresh token per RFC 7009.</p> <p>This allows clients to notify the authorization server that a token is no longer needed, enabling immediate invalidation.</p> <p>Parameters:</p> Name Type Description Default <code>token</code> <code>str</code> <p>The token to revoke (access or refresh token)</p> required <code>revocation_endpoint</code> <code>str</code> <p>Token revocation endpoint URL</p> required <code>client_id</code> <code>str</code> <p>OAuth client ID</p> required <code>client_secret</code> <code>str | None</code> <p>OAuth client secret (for confidential clients)</p> <code>None</code> <code>token_type_hint</code> <code>str</code> <p>Hint about token type (\"access_token\" or \"refresh_token\")</p> <code>'access_token'</code> <p>Raises:</p> Type Description <code>HTTPError</code> <p>If revocation request fails</p> Source code in <code>src/sk_agents/auth/oauth_client.py</code> <pre><code>async def revoke_token(\n    self,\n    token: str,\n    revocation_endpoint: str,\n    client_id: str,\n    client_secret: str | None = None,\n    token_type_hint: str = \"access_token\",\n) -&gt; None:\n    \"\"\"\n    Revoke an access or refresh token per RFC 7009.\n\n    This allows clients to notify the authorization server that a token\n    is no longer needed, enabling immediate invalidation.\n\n    Args:\n        token: The token to revoke (access or refresh token)\n        revocation_endpoint: Token revocation endpoint URL\n        client_id: OAuth client ID\n        client_secret: OAuth client secret (for confidential clients)\n        token_type_hint: Hint about token type (\"access_token\" or \"refresh_token\")\n\n    Raises:\n        httpx.HTTPError: If revocation request fails\n    \"\"\"\n    # Build request body per RFC 7009\n    body = {\n        \"token\": token,\n        \"token_type_hint\": token_type_hint,\n        \"client_id\": client_id,\n    }\n\n    # Add client secret if provided (confidential clients)\n    if client_secret:\n        body[\"client_secret\"] = client_secret\n\n    logger.debug(f\"Revoking token: endpoint={revocation_endpoint}, type_hint={token_type_hint}\")\n\n    try:\n        async with httpx.AsyncClient(timeout=self.timeout) as client:\n            response = await client.post(\n                revocation_endpoint,\n                data=body,\n                headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n            )\n\n            # Per RFC 7009: Server responds with 200 regardless of token validity\n            # This prevents token scanning attacks\n            if response.status_code == 200:\n                logger.info(f\"Successfully revoked token (type_hint={token_type_hint})\")\n            else:\n                logger.warning(\n                    f\"Token revocation returned unexpected status {response.status_code}\"\n                )\n                response.raise_for_status()\n\n    except httpx.HTTPError as e:\n        logger.error(f\"Failed to revoke token: {e}\")\n        raise\n</code></pre> <code></code> sk_agents.auth.oauth_client.OAuthClient.initiate_authorization_flow <code>async</code> <pre><code>initiate_authorization_flow(\n    server_config: McpServerConfig, user_id: str\n) -&gt; str\n</code></pre> <p>Initiate OAuth authorization flow for MCP server.</p> <p>Generates PKCE pair, state, stores flow state, and returns authorization URL.</p> <p>Parameters:</p> Name Type Description Default <code>server_config</code> <code>McpServerConfig</code> <p>MCP server configuration</p> required <code>user_id</code> <code>str</code> <p>User ID initiating the flow</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Authorization URL for user redirect</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If server configuration is invalid</p> Source code in <code>src/sk_agents/auth/oauth_client.py</code> <pre><code>async def initiate_authorization_flow(\n    self,\n    server_config: \"McpServerConfig\",\n    user_id: str,\n) -&gt; str:\n    \"\"\"\n    Initiate OAuth authorization flow for MCP server.\n\n    Generates PKCE pair, state, stores flow state, and returns authorization URL.\n\n    Args:\n        server_config: MCP server configuration\n        user_id: User ID initiating the flow\n\n    Returns:\n        str: Authorization URL for user redirect\n\n    Raises:\n        ValueError: If server configuration is invalid\n    \"\"\"\n    from ska_utils import AppConfig\n\n    from sk_agents.configs import TA_OAUTH_CLIENT_NAME\n\n    # Discover Protected Resource Metadata (RFC 9728) if HTTP MCP server\n    has_prm = False\n    if server_config.url:  # Only for HTTP MCP servers\n        try:\n            prm = await self.metadata_cache.fetch_protected_resource_metadata(server_config.url)\n            has_prm = prm is not None\n            if prm:\n                logger.info(\n                    f\"Discovered PRM for {server_config.name}: \"\n                    f\"auth_servers={prm.authorization_servers}\"\n                )\n        except Exception as e:\n            logger.debug(f\"PRM discovery failed (optional): {e}\")\n            has_prm = False\n\n    # Determine if resource parameter should be included (per MCP spec 2025-06-18)\n    include_resource = self.should_include_resource_param(\n        protocol_version=server_config.protocol_version, has_prm=has_prm\n    )\n\n    # Get canonical resource URI if needed\n    resource = None\n    if include_resource:\n        try:\n            resource = server_config.effective_canonical_uri\n        except ValueError as e:\n            logger.warning(\n                f\"Cannot determine canonical URI for {server_config.name}: {e}. \"\n                \"Proceeding without resource parameter.\"\n            )\n            resource = None\n\n    # Generate PKCE pair\n    verifier, challenge = self.pkce_manager.generate_pkce_pair()\n\n    # Generate state\n    state = self.state_manager.generate_state()\n\n    # Store flow state (always store resource for validation, even if not sent in auth request)\n    self.state_manager.store_flow_state(\n        state=state,\n        verifier=verifier,\n        user_id=user_id,\n        server_name=server_config.name,\n        resource=resource or server_config.url or \"\",  # Store for future reference\n        scopes=server_config.scopes,\n    )\n\n    # Get client configuration\n    app_config = AppConfig()\n    client_name = app_config.get(TA_OAUTH_CLIENT_NAME.env_name)\n\n    # Discover authorization server metadata (RFC 8414)\n    authorization_endpoint = None\n    metadata = None\n    try:\n        metadata = await self.metadata_cache.fetch_auth_server_metadata(\n            server_config.auth_server\n        )\n        authorization_endpoint = str(metadata.authorization_endpoint)\n        logger.info(f\"Discovered authorization endpoint: {authorization_endpoint}\")\n    except Exception as e:\n        logger.warning(\n            f\"Failed to discover authorization server metadata: {e}. Using fallback.\"\n        )\n        authorization_endpoint = None\n\n    # Try dynamic client registration if no client_id configured (RFC 7591)\n    client_id = server_config.oauth_client_id or client_name\n\n    if not server_config.oauth_client_id and server_config.enable_dynamic_registration:\n        try:\n            # Check if metadata includes registration_endpoint\n            if metadata and metadata.registration_endpoint:\n                logger.info(\n                    f\"No client_id configured for {server_config.name}. \"\n                    f\"Attempting dynamic registration...\"\n                )\n\n                from sk_agents.auth.client_registration import DynamicClientRegistration\n\n                registration_client = DynamicClientRegistration(timeout=self.timeout)\n                registration_response = await registration_client.register_client(\n                    registration_endpoint=str(metadata.registration_endpoint),\n                    redirect_uris=[str(server_config.oauth_redirect_uri)],\n                    client_name=client_name,\n                    scopes=server_config.scopes,\n                )\n\n                # Use registered credentials\n                client_id = registration_response.client_id\n                # Note: client_secret available in registration_response if needed\n\n                logger.info(\n                    f\"Successfully registered client for {server_config.name}: \"\n                    f\"client_id={client_id}\"\n                )\n\n                # TODO: Optionally persist client_id/secret for reuse\n\n            else:\n                logger.warning(\n                    f\"Dynamic registration enabled but no registration_endpoint \"\n                    f\"discovered for {server_config.name}\"\n                )\n        except Exception as e:\n            logger.warning(\n                f\"Dynamic client registration failed for {server_config.name}: {e}. \"\n                f\"Falling back to default client_id.\"\n            )\n            # Continue with default client_name\n\n    # Build authorization request\n    auth_request = AuthorizationRequest(\n        auth_server=server_config.auth_server,\n        authorization_endpoint=authorization_endpoint,\n        client_id=client_id,\n        redirect_uri=server_config.oauth_redirect_uri,\n        resource=resource,  # None if protocol version &lt; 2025-06-18\n        scopes=server_config.scopes,\n        state=state,\n        code_challenge=challenge,\n        code_challenge_method=\"S256\",\n    )\n\n    # Build and return authorization URL\n    auth_url = self.build_authorization_url(auth_request)\n    logger.info(\n        f\"Initiated OAuth flow for {server_config.name}: \"\n        f\"user={user_id}, resource={resource}, state={state}\"\n    )\n    return auth_url\n</code></pre> <code></code> sk_agents.auth.oauth_client.OAuthClient.handle_callback <code>async</code> <pre><code>handle_callback(\n    code: str,\n    state: str,\n    user_id: str,\n    server_config: McpServerConfig,\n) -&gt; OAuth2AuthData\n</code></pre> <p>Handle OAuth callback after user authorization.</p> <p>Validates state, exchanges code for tokens, and stores in AuthStorage.</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>str</code> <p>Authorization code from callback</p> required <code>state</code> <code>str</code> <p>State parameter from callback</p> required <code>user_id</code> <code>str</code> <p>User ID to validate against</p> required <code>server_config</code> <code>McpServerConfig</code> <p>MCP server configuration</p> required <p>Returns:</p> Name Type Description <code>OAuth2AuthData</code> <code>OAuth2AuthData</code> <p>Stored token data</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If state invalid or user mismatch</p> <code>HTTPError</code> <p>If token exchange fails</p> Source code in <code>src/sk_agents/auth/oauth_client.py</code> <pre><code>async def handle_callback(\n    self,\n    code: str,\n    state: str,\n    user_id: str,\n    server_config: \"McpServerConfig\",\n) -&gt; OAuth2AuthData:\n    \"\"\"\n    Handle OAuth callback after user authorization.\n\n    Validates state, exchanges code for tokens, and stores in AuthStorage.\n\n    Args:\n        code: Authorization code from callback\n        state: State parameter from callback\n        user_id: User ID to validate against\n        server_config: MCP server configuration\n\n    Returns:\n        OAuth2AuthData: Stored token data\n\n    Raises:\n        ValueError: If state invalid or user mismatch\n        httpx.HTTPError: If token exchange fails\n    \"\"\"\n    from datetime import datetime, timedelta\n\n    from ska_utils import AppConfig\n\n    from sk_agents.configs import TA_OAUTH_CLIENT_NAME\n    from sk_agents.mcp_client import build_auth_storage_key\n\n    # Retrieve and validate flow state\n    flow_state = self.state_manager.retrieve_flow_state(state, user_id)\n\n    # Get token endpoint (from server metadata or construct from auth_server)\n    token_endpoint = f\"{server_config.auth_server.rstrip('/')}/token\"\n\n    # Get client configuration\n    app_config = AppConfig()\n    client_name = app_config.get(TA_OAUTH_CLIENT_NAME.env_name)\n\n    # Discover Protected Resource Metadata (RFC 9728) if HTTP MCP server\n    has_prm = False\n    if server_config.url:  # Only for HTTP MCP servers\n        try:\n            prm = await self.metadata_cache.fetch_protected_resource_metadata(server_config.url)\n            has_prm = prm is not None\n            if prm:\n                logger.info(\n                    f\"Discovered PRM for {server_config.name}: \"\n                    f\"auth_servers={prm.authorization_servers}\"\n                )\n        except Exception as e:\n            logger.debug(f\"PRM discovery failed (optional): {e}\")\n            has_prm = False\n\n    # Determine if resource parameter should be included (per MCP spec 2025-06-18)\n    include_resource = self.should_include_resource_param(\n        protocol_version=server_config.protocol_version, has_prm=has_prm\n    )\n\n    # Build token request\n    token_request = TokenRequest(\n        token_endpoint=token_endpoint,\n        grant_type=\"authorization_code\",\n        code=code,\n        redirect_uri=server_config.oauth_redirect_uri,\n        code_verifier=flow_state.verifier,\n        resource=flow_state.resource\n        if include_resource\n        else None,  # Conditional per protocol version\n        client_id=server_config.oauth_client_id or client_name,\n        client_secret=server_config.oauth_client_secret,\n        requested_scopes=flow_state.scopes,  # For scope validation\n    )\n\n    # Exchange code for tokens\n    token_response = await self.exchange_code_for_tokens(token_request)\n\n    # Create OAuth2AuthData\n    oauth_data = OAuth2AuthData(\n        access_token=token_response.access_token,\n        refresh_token=token_response.refresh_token,\n        expires_at=datetime.now(UTC) + timedelta(seconds=token_response.expires_in),\n        scopes=token_response.scope.split() if token_response.scope else flow_state.scopes,\n        audience=token_response.aud,\n        resource=flow_state.resource,\n        token_type=token_response.token_type,\n        issued_at=datetime.now(UTC),\n    )\n\n    # Store in AuthStorage\n    composite_key = build_auth_storage_key(server_config.auth_server, oauth_data.scopes)\n    self.auth_storage.store(user_id, composite_key, oauth_data)\n\n    logger.info(\n        f\"OAuth callback successful for {flow_state.server_name}: \"\n        f\"user={user_id}, resource={flow_state.resource}\"\n    )\n\n    # Clean up flow state\n    self.state_manager.delete_flow_state(state, user_id)\n\n    return oauth_data\n</code></pre> <code></code> sk_agents.auth.oauth_error_handler <p>OAuth Error Handler</p> <p>Handles OAuth error responses and WWW-Authenticate header parsing per: - RFC 6750: Bearer Token Usage - RFC 9728: Protected Resource Metadata - MCP Specification 2025-06-18</p> <p>Key functionality: - Parse WWW-Authenticate headers from 401 responses - Extract error codes: invalid_token, insufficient_scope, etc. - Extract scope requirements for re-authorization - Extract resource_metadata URL for RFC 9728 discovery</p> <code></code> sk_agents.auth.oauth_error_handler.WWWAuthenticateChallenge <p>Parsed WWW-Authenticate challenge from 401 response.</p> <p>Per RFC 6750 Section 3: WWW-Authenticate: Bearer realm=\"example\",                   error=\"invalid_token\",                   error_description=\"The access token expired\",                   scope=\"read write\",                   resource_metadata=\"https://api.example.com/.well-known/oauth-protected-resource\"</p> Source code in <code>src/sk_agents/auth/oauth_error_handler.py</code> <pre><code>class WWWAuthenticateChallenge:\n    \"\"\"\n    Parsed WWW-Authenticate challenge from 401 response.\n\n    Per RFC 6750 Section 3:\n    WWW-Authenticate: Bearer realm=\"example\",\n                      error=\"invalid_token\",\n                      error_description=\"The access token expired\",\n                      scope=\"read write\",\n                      resource_metadata=\"https://api.example.com/.well-known/oauth-protected-resource\"\n    \"\"\"\n\n    def __init__(\n        self,\n        realm: str | None = None,\n        error: str | None = None,\n        error_description: str | None = None,\n        error_uri: str | None = None,\n        scope: str | None = None,\n        resource_metadata: str | None = None,\n    ):\n        self.realm = realm\n        self.error = error\n        self.error_description = error_description\n        self.error_uri = error_uri\n        self.scope = scope  # Space-separated scope string\n        self.resource_metadata = resource_metadata\n\n    @property\n    def scopes(self) -&gt; list[str]:\n        \"\"\"Get scopes as list.\"\"\"\n        return self.scope.split() if self.scope else []\n\n    def requires_reauth(self) -&gt; bool:\n        \"\"\"Check if error requires re-authorization.\"\"\"\n        return self.error in (\"invalid_token\", \"insufficient_scope\")\n\n    def is_token_expired(self) -&gt; bool:\n        \"\"\"Check if error indicates token expiry.\"\"\"\n        return self.error == \"invalid_token\"\n\n    def is_insufficient_scope(self) -&gt; bool:\n        \"\"\"Check if error indicates insufficient scopes.\"\"\"\n        return self.error == \"insufficient_scope\"\n\n    def __repr__(self) -&gt; str:\n        return (\n            f\"WWWAuthenticateChallenge(error={self.error}, scope={self.scope}, realm={self.realm})\"\n        )\n</code></pre> <code></code> sk_agents.auth.oauth_error_handler.WWWAuthenticateChallenge.scopes <code>property</code> <pre><code>scopes: list[str]\n</code></pre> <p>Get scopes as list.</p> <code></code> sk_agents.auth.oauth_error_handler.WWWAuthenticateChallenge.requires_reauth <pre><code>requires_reauth() -&gt; bool\n</code></pre> <p>Check if error requires re-authorization.</p> Source code in <code>src/sk_agents/auth/oauth_error_handler.py</code> <pre><code>def requires_reauth(self) -&gt; bool:\n    \"\"\"Check if error requires re-authorization.\"\"\"\n    return self.error in (\"invalid_token\", \"insufficient_scope\")\n</code></pre> <code></code> sk_agents.auth.oauth_error_handler.WWWAuthenticateChallenge.is_token_expired <pre><code>is_token_expired() -&gt; bool\n</code></pre> <p>Check if error indicates token expiry.</p> Source code in <code>src/sk_agents/auth/oauth_error_handler.py</code> <pre><code>def is_token_expired(self) -&gt; bool:\n    \"\"\"Check if error indicates token expiry.\"\"\"\n    return self.error == \"invalid_token\"\n</code></pre> <code></code> sk_agents.auth.oauth_error_handler.WWWAuthenticateChallenge.is_insufficient_scope <pre><code>is_insufficient_scope() -&gt; bool\n</code></pre> <p>Check if error indicates insufficient scopes.</p> Source code in <code>src/sk_agents/auth/oauth_error_handler.py</code> <pre><code>def is_insufficient_scope(self) -&gt; bool:\n    \"\"\"Check if error indicates insufficient scopes.\"\"\"\n    return self.error == \"insufficient_scope\"\n</code></pre> <code></code> sk_agents.auth.oauth_error_handler.OAuthErrorHandler <p>Handler for OAuth error responses.</p> <p>Provides structured error handling for: - 401 Unauthorized (invalid_token, insufficient_scope) - 403 Forbidden (insufficient permissions) - 400 Bad Request (malformed request)</p> Source code in <code>src/sk_agents/auth/oauth_error_handler.py</code> <pre><code>class OAuthErrorHandler:\n    \"\"\"\n    Handler for OAuth error responses.\n\n    Provides structured error handling for:\n    - 401 Unauthorized (invalid_token, insufficient_scope)\n    - 403 Forbidden (insufficient permissions)\n    - 400 Bad Request (malformed request)\n    \"\"\"\n\n    @staticmethod\n    def handle_401_response(response_headers: dict[str, str]) -&gt; WWWAuthenticateChallenge | None:\n        \"\"\"\n        Handle 401 Unauthorized response.\n\n        Extracts WWW-Authenticate challenge for further processing.\n\n        Args:\n            response_headers: HTTP response headers\n\n        Returns:\n            Parsed WWW-Authenticate challenge, or None if header missing\n        \"\"\"\n        www_auth = response_headers.get(\"WWW-Authenticate\") or response_headers.get(\n            \"www-authenticate\"\n        )\n        if not www_auth:\n            logger.warning(\"401 response missing WWW-Authenticate header\")\n            return None\n\n        return parse_www_authenticate_header(www_auth)\n\n    @staticmethod\n    def should_refresh_token(challenge: WWWAuthenticateChallenge | None) -&gt; bool:\n        \"\"\"\n        Determine if token should be refreshed based on error.\n\n        Args:\n            challenge: Parsed WWW-Authenticate challenge\n\n        Returns:\n            True if token refresh should be attempted\n        \"\"\"\n        if not challenge:\n            return False\n\n        # Refresh on invalid_token error\n        return challenge.is_token_expired()\n\n    @staticmethod\n    def should_reauthorize(challenge: WWWAuthenticateChallenge | None) -&gt; bool:\n        \"\"\"\n        Determine if re-authorization is required.\n\n        Args:\n            challenge: Parsed WWW-Authenticate challenge\n\n        Returns:\n            True if re-authorization flow should be initiated\n        \"\"\"\n        if not challenge:\n            return False\n\n        # Re-authorize on insufficient_scope or other auth errors\n        return challenge.is_insufficient_scope() or (\n            challenge.error and challenge.error not in (\"invalid_token\",)\n        )\n\n    @staticmethod\n    def get_required_scopes(challenge: WWWAuthenticateChallenge | None) -&gt; list[str]:\n        \"\"\"\n        Extract required scopes from challenge.\n\n        For insufficient_scope errors, this returns the scopes needed.\n\n        Args:\n            challenge: Parsed WWW-Authenticate challenge\n\n        Returns:\n            List of required scopes, empty if none specified\n        \"\"\"\n        if not challenge:\n            return []\n\n        return challenge.scopes\n</code></pre> <code></code> sk_agents.auth.oauth_error_handler.OAuthErrorHandler.handle_401_response <code>staticmethod</code> <pre><code>handle_401_response(\n    response_headers: dict[str, str],\n) -&gt; WWWAuthenticateChallenge | None\n</code></pre> <p>Handle 401 Unauthorized response.</p> <p>Extracts WWW-Authenticate challenge for further processing.</p> <p>Parameters:</p> Name Type Description Default <code>response_headers</code> <code>dict[str, str]</code> <p>HTTP response headers</p> required <p>Returns:</p> Type Description <code>WWWAuthenticateChallenge | None</code> <p>Parsed WWW-Authenticate challenge, or None if header missing</p> Source code in <code>src/sk_agents/auth/oauth_error_handler.py</code> <pre><code>@staticmethod\ndef handle_401_response(response_headers: dict[str, str]) -&gt; WWWAuthenticateChallenge | None:\n    \"\"\"\n    Handle 401 Unauthorized response.\n\n    Extracts WWW-Authenticate challenge for further processing.\n\n    Args:\n        response_headers: HTTP response headers\n\n    Returns:\n        Parsed WWW-Authenticate challenge, or None if header missing\n    \"\"\"\n    www_auth = response_headers.get(\"WWW-Authenticate\") or response_headers.get(\n        \"www-authenticate\"\n    )\n    if not www_auth:\n        logger.warning(\"401 response missing WWW-Authenticate header\")\n        return None\n\n    return parse_www_authenticate_header(www_auth)\n</code></pre> <code></code> sk_agents.auth.oauth_error_handler.OAuthErrorHandler.should_refresh_token <code>staticmethod</code> <pre><code>should_refresh_token(\n    challenge: WWWAuthenticateChallenge | None,\n) -&gt; bool\n</code></pre> <p>Determine if token should be refreshed based on error.</p> <p>Parameters:</p> Name Type Description Default <code>challenge</code> <code>WWWAuthenticateChallenge | None</code> <p>Parsed WWW-Authenticate challenge</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if token refresh should be attempted</p> Source code in <code>src/sk_agents/auth/oauth_error_handler.py</code> <pre><code>@staticmethod\ndef should_refresh_token(challenge: WWWAuthenticateChallenge | None) -&gt; bool:\n    \"\"\"\n    Determine if token should be refreshed based on error.\n\n    Args:\n        challenge: Parsed WWW-Authenticate challenge\n\n    Returns:\n        True if token refresh should be attempted\n    \"\"\"\n    if not challenge:\n        return False\n\n    # Refresh on invalid_token error\n    return challenge.is_token_expired()\n</code></pre> <code></code> sk_agents.auth.oauth_error_handler.OAuthErrorHandler.should_reauthorize <code>staticmethod</code> <pre><code>should_reauthorize(\n    challenge: WWWAuthenticateChallenge | None,\n) -&gt; bool\n</code></pre> <p>Determine if re-authorization is required.</p> <p>Parameters:</p> Name Type Description Default <code>challenge</code> <code>WWWAuthenticateChallenge | None</code> <p>Parsed WWW-Authenticate challenge</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if re-authorization flow should be initiated</p> Source code in <code>src/sk_agents/auth/oauth_error_handler.py</code> <pre><code>@staticmethod\ndef should_reauthorize(challenge: WWWAuthenticateChallenge | None) -&gt; bool:\n    \"\"\"\n    Determine if re-authorization is required.\n\n    Args:\n        challenge: Parsed WWW-Authenticate challenge\n\n    Returns:\n        True if re-authorization flow should be initiated\n    \"\"\"\n    if not challenge:\n        return False\n\n    # Re-authorize on insufficient_scope or other auth errors\n    return challenge.is_insufficient_scope() or (\n        challenge.error and challenge.error not in (\"invalid_token\",)\n    )\n</code></pre> <code></code> sk_agents.auth.oauth_error_handler.OAuthErrorHandler.get_required_scopes <code>staticmethod</code> <pre><code>get_required_scopes(\n    challenge: WWWAuthenticateChallenge | None,\n) -&gt; list[str]\n</code></pre> <p>Extract required scopes from challenge.</p> <p>For insufficient_scope errors, this returns the scopes needed.</p> <p>Parameters:</p> Name Type Description Default <code>challenge</code> <code>WWWAuthenticateChallenge | None</code> <p>Parsed WWW-Authenticate challenge</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of required scopes, empty if none specified</p> Source code in <code>src/sk_agents/auth/oauth_error_handler.py</code> <pre><code>@staticmethod\ndef get_required_scopes(challenge: WWWAuthenticateChallenge | None) -&gt; list[str]:\n    \"\"\"\n    Extract required scopes from challenge.\n\n    For insufficient_scope errors, this returns the scopes needed.\n\n    Args:\n        challenge: Parsed WWW-Authenticate challenge\n\n    Returns:\n        List of required scopes, empty if none specified\n    \"\"\"\n    if not challenge:\n        return []\n\n    return challenge.scopes\n</code></pre> <code></code> sk_agents.auth.oauth_error_handler.parse_www_authenticate_header <pre><code>parse_www_authenticate_header(\n    header_value: str,\n) -&gt; WWWAuthenticateChallenge | None\n</code></pre> <p>Parse WWW-Authenticate header per RFC 6750 + RFC 9728.</p> Format <p>WWW-Authenticate: Bearer realm=\"example\",                   error=\"invalid_token\",                   error_description=\"The access token expired\",                   scope=\"read write\",                   resource_metadata=\"https://...\"</p> <p>Parameters:</p> Name Type Description Default <code>header_value</code> <code>str</code> <p>Value of WWW-Authenticate header</p> required <p>Returns:</p> Name Type Description <code>WWWAuthenticateChallenge</code> <code>WWWAuthenticateChallenge | None</code> <p>Parsed challenge, or None if not a Bearer challenge</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If header is malformed</p> Source code in <code>src/sk_agents/auth/oauth_error_handler.py</code> <pre><code>def parse_www_authenticate_header(header_value: str) -&gt; WWWAuthenticateChallenge | None:\n    \"\"\"\n    Parse WWW-Authenticate header per RFC 6750 + RFC 9728.\n\n    Format:\n        WWW-Authenticate: Bearer realm=\"example\",\n                          error=\"invalid_token\",\n                          error_description=\"The access token expired\",\n                          scope=\"read write\",\n                          resource_metadata=\"https://...\"\n\n    Args:\n        header_value: Value of WWW-Authenticate header\n\n    Returns:\n        WWWAuthenticateChallenge: Parsed challenge, or None if not a Bearer challenge\n\n    Raises:\n        ValueError: If header is malformed\n    \"\"\"\n    if not header_value:\n        return None\n\n    # Check if it's a Bearer challenge\n    if not header_value.strip().lower().startswith(\"bearer\"):\n        logger.debug(f\"WWW-Authenticate header is not Bearer type: {header_value}\")\n        return None\n\n    # Remove \"Bearer \" prefix\n    params_str = header_value[6:].strip()\n\n    # Parse parameters using regex\n    # Matches: param=\"value\" or param=value (unquoted)\n    pattern = r'(\\w+)=(?:\"([^\"]*)\"|([^\\s,]+))'\n    matches = re.findall(pattern, params_str)\n\n    params: dict[str, str] = {}\n    for match in matches:\n        param_name = match[0]\n        # Use quoted value if present, otherwise unquoted\n        param_value = match[1] if match[1] else match[2]\n        params[param_name] = param_value\n\n    # Build challenge object\n    challenge = WWWAuthenticateChallenge(\n        realm=params.get(\"realm\"),\n        error=params.get(\"error\"),\n        error_description=params.get(\"error_description\"),\n        error_uri=params.get(\"error_uri\"),\n        scope=params.get(\"scope\"),\n        resource_metadata=params.get(\"resource_metadata\"),\n    )\n\n    logger.debug(f\"Parsed WWW-Authenticate challenge: {challenge}\")\n    return challenge\n</code></pre> <code></code> sk_agents.auth.oauth_error_handler.extract_field_from_www_authenticate <pre><code>extract_field_from_www_authenticate(\n    header_value: str, field_name: str\n) -&gt; str | None\n</code></pre> <p>Extract a specific field from WWW-Authenticate header.</p> <p>Convenience function for extracting single fields.</p> <p>Parameters:</p> Name Type Description Default <code>header_value</code> <code>str</code> <p>Value of WWW-Authenticate header</p> required <code>field_name</code> <code>str</code> <p>Field to extract (e.g., \"error\", \"scope\", \"resource_metadata\")</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>Field value, or None if not present</p> Source code in <code>src/sk_agents/auth/oauth_error_handler.py</code> <pre><code>def extract_field_from_www_authenticate(header_value: str, field_name: str) -&gt; str | None:\n    \"\"\"\n    Extract a specific field from WWW-Authenticate header.\n\n    Convenience function for extracting single fields.\n\n    Args:\n        header_value: Value of WWW-Authenticate header\n        field_name: Field to extract (e.g., \"error\", \"scope\", \"resource_metadata\")\n\n    Returns:\n        Field value, or None if not present\n    \"\"\"\n    challenge = parse_www_authenticate_header(header_value)\n    if not challenge:\n        return None\n\n    return getattr(challenge, field_name, None)\n</code></pre> <code></code> sk_agents.auth.oauth_error_handler.build_www_authenticate_header <pre><code>build_www_authenticate_header(\n    error: str,\n    error_description: str | None = None,\n    scope: str | None = None,\n    realm: str | None = None,\n    resource_metadata: str | None = None,\n) -&gt; str\n</code></pre> <p>Build WWW-Authenticate header per RFC 6750 + RFC 9728.</p> <p>For use when implementing MCP servers that need to challenge clients.</p> <p>Parameters:</p> Name Type Description Default <code>error</code> <code>str</code> <p>OAuth error code (e.g., \"invalid_token\", \"insufficient_scope\")</p> required <code>error_description</code> <code>str | None</code> <p>Human-readable error description</p> <code>None</code> <code>scope</code> <code>str | None</code> <p>Required scope(s) (space-separated)</p> <code>None</code> <code>realm</code> <code>str | None</code> <p>Protection realm</p> <code>None</code> <code>resource_metadata</code> <code>str | None</code> <p>URL for Protected Resource Metadata (RFC 9728)</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Formatted WWW-Authenticate header value</p> Example <p>build_www_authenticate_header( ...     error=\"insufficient_scope\", ...     error_description=\"Token lacks required scopes\", ...     scope=\"read write\", ...     resource_metadata=\"https://api.example.com/.well-known/oauth-protected-resource\" ... )  # doctest: +SKIP 'Bearer error=\"insufficient_scope\", ...'</p> Source code in <code>src/sk_agents/auth/oauth_error_handler.py</code> <pre><code>def build_www_authenticate_header(\n    error: str,\n    error_description: str | None = None,\n    scope: str | None = None,\n    realm: str | None = None,\n    resource_metadata: str | None = None,\n) -&gt; str:\n    \"\"\"\n    Build WWW-Authenticate header per RFC 6750 + RFC 9728.\n\n    For use when implementing MCP servers that need to challenge clients.\n\n    Args:\n        error: OAuth error code (e.g., \"invalid_token\", \"insufficient_scope\")\n        error_description: Human-readable error description\n        scope: Required scope(s) (space-separated)\n        realm: Protection realm\n        resource_metadata: URL for Protected Resource Metadata (RFC 9728)\n\n    Returns:\n        str: Formatted WWW-Authenticate header value\n\n    Example:\n        &gt;&gt;&gt; build_www_authenticate_header(\n        ...     error=\"insufficient_scope\",\n        ...     error_description=\"Token lacks required scopes\",\n        ...     scope=\"read write\",\n        ...     resource_metadata=\"https://api.example.com/.well-known/oauth-protected-resource\"\n        ... )  # doctest: +SKIP\n        'Bearer error=\"insufficient_scope\", ...'\n    \"\"\"\n    parts = [\"Bearer\"]\n\n    if realm:\n        parts.append(f'realm=\"{realm}\"')\n\n    parts.append(f'error=\"{error}\"')\n\n    if error_description:\n        parts.append(f'error_description=\"{error_description}\"')\n\n    if scope:\n        parts.append(f'scope=\"{scope}\"')\n\n    if resource_metadata:\n        parts.append(f'resource_metadata=\"{resource_metadata}\"')\n\n    return \", \".join(parts)\n</code></pre> <code></code> sk_agents.auth.oauth_models <p>OAuth 2.1 Request and Response Models</p> <p>Models for OAuth authorization flows following MCP specification.</p> <code></code> sk_agents.auth.oauth_models.AuthorizationRequest <p>               Bases: <code>BaseModel</code></p> <p>OAuth 2.1 Authorization Request</p> <p>Used to construct authorization URL with all required parameters. Follows MCP spec requirement for PKCE and resource parameter.</p> <p>Note: resource parameter is optional and should only be included if: - MCP protocol version &gt;= 2025-06-18, OR - Protected Resource Metadata has been discovered</p> Source code in <code>src/sk_agents/auth/oauth_models.py</code> <pre><code>class AuthorizationRequest(BaseModel):\n    \"\"\"\n    OAuth 2.1 Authorization Request\n\n    Used to construct authorization URL with all required parameters.\n    Follows MCP spec requirement for PKCE and resource parameter.\n\n    Note: resource parameter is optional and should only be included if:\n    - MCP protocol version &gt;= 2025-06-18, OR\n    - Protected Resource Metadata has been discovered\n    \"\"\"\n\n    auth_server: HttpUrl = Field(..., description=\"Authorization server base URL\")\n    authorization_endpoint: HttpUrl | None = Field(\n        None, description=\"Discovered authorization endpoint (RFC 8414)\"\n    )\n    client_id: str = Field(..., description=\"OAuth client ID\")\n    redirect_uri: HttpUrl = Field(..., description=\"OAuth callback URL\")\n    resource: str | None = Field(\n        None,\n        description=\"Canonical MCP server URI (resource binding) per protocol version\",\n    )\n    scopes: list[str] = Field(..., description=\"Requested OAuth scopes\")\n    state: str = Field(..., description=\"CSRF protection state parameter\")\n    code_challenge: str = Field(..., description=\"PKCE code challenge (S256)\")\n    code_challenge_method: Literal[\"S256\"] = Field(\n        default=\"S256\", description=\"PKCE challenge method (must be S256)\"\n    )\n    response_type: Literal[\"code\"] = Field(\n        default=\"code\", description=\"OAuth response type (authorization code flow)\"\n    )\n</code></pre> <code></code> sk_agents.auth.oauth_models.TokenRequest <p>               Bases: <code>BaseModel</code></p> <p>OAuth 2.1 Token Request</p> <p>Used to exchange authorization code for access token. Includes PKCE verifier and resource parameter.</p> <p>Note: resource parameter is optional and should only be included if: - MCP protocol version &gt;= 2025-06-18, OR - Protected Resource Metadata has been discovered</p> Source code in <code>src/sk_agents/auth/oauth_models.py</code> <pre><code>class TokenRequest(BaseModel):\n    \"\"\"\n    OAuth 2.1 Token Request\n\n    Used to exchange authorization code for access token.\n    Includes PKCE verifier and resource parameter.\n\n    Note: resource parameter is optional and should only be included if:\n    - MCP protocol version &gt;= 2025-06-18, OR\n    - Protected Resource Metadata has been discovered\n    \"\"\"\n\n    token_endpoint: HttpUrl = Field(..., description=\"Token endpoint URL\")\n    grant_type: Literal[\"authorization_code\", \"refresh_token\"] = Field(\n        ..., description=\"OAuth grant type\"\n    )\n    code: str | None = Field(None, description=\"Authorization code (for authorization_code grant)\")\n    refresh_token: str | None = Field(None, description=\"Refresh token (for refresh_token grant)\")\n    redirect_uri: HttpUrl | None = Field(None, description=\"OAuth callback URL (must match)\")\n    code_verifier: str | None = Field(None, description=\"PKCE code verifier\")\n    resource: str | None = Field(\n        None,\n        description=\"Canonical MCP server URI (resource binding) per protocol version\",\n    )\n    client_id: str = Field(..., description=\"OAuth client ID\")\n    client_secret: str | None = Field(\n        None, description=\"OAuth client secret (confidential clients only)\"\n    )\n    requested_scopes: list[str] | None = Field(\n        None, description=\"Requested scopes for validation (prevents escalation attacks)\"\n    )\n</code></pre> <code></code> sk_agents.auth.oauth_models.TokenResponse <p>               Bases: <code>BaseModel</code></p> <p>OAuth 2.1 Token Response</p> <p>Token endpoint response with access token and metadata.</p> Source code in <code>src/sk_agents/auth/oauth_models.py</code> <pre><code>class TokenResponse(BaseModel):\n    \"\"\"\n    OAuth 2.1 Token Response\n\n    Token endpoint response with access token and metadata.\n    \"\"\"\n\n    access_token: str = Field(..., description=\"OAuth access token\")\n    token_type: str = Field(..., description=\"Token type (usually 'Bearer')\")\n    expires_in: int = Field(..., description=\"Token lifetime in seconds\")\n    refresh_token: str | None = Field(None, description=\"Refresh token (optional)\")\n    scope: str | None = Field(None, description=\"Granted scopes (space-separated)\")\n    aud: str | None = Field(None, description=\"Token audience (for validation)\")\n</code></pre> <code></code> sk_agents.auth.oauth_models.RefreshTokenRequest <p>               Bases: <code>BaseModel</code></p> <p>OAuth 2.1 Refresh Token Request</p> <p>Request to refresh an expired access token.</p> <p>Note: resource parameter is optional and should only be included if: - MCP protocol version &gt;= 2025-06-18, OR - Protected Resource Metadata has been discovered - Must match the original authorization request resource if included</p> Source code in <code>src/sk_agents/auth/oauth_models.py</code> <pre><code>class RefreshTokenRequest(BaseModel):\n    \"\"\"\n    OAuth 2.1 Refresh Token Request\n\n    Request to refresh an expired access token.\n\n    Note: resource parameter is optional and should only be included if:\n    - MCP protocol version &gt;= 2025-06-18, OR\n    - Protected Resource Metadata has been discovered\n    - Must match the original authorization request resource if included\n    \"\"\"\n\n    token_endpoint: HttpUrl = Field(..., description=\"Token endpoint URL\")\n    refresh_token: str = Field(..., description=\"Refresh token\")\n    resource: str | None = Field(\n        None,\n        description=\"Canonical MCP server URI (must match original) per protocol version\",\n    )\n    client_id: str = Field(..., description=\"OAuth client ID\")\n    client_secret: str | None = Field(\n        None, description=\"OAuth client secret (confidential clients only)\"\n    )\n    grant_type: Literal[\"refresh_token\"] = Field(\n        default=\"refresh_token\", description=\"OAuth grant type\"\n    )\n    requested_scopes: list[str] | None = Field(\n        None, description=\"Original requested scopes for validation (prevents escalation)\"\n    )\n</code></pre> <code></code> sk_agents.auth.oauth_models.OAuthError <p>               Bases: <code>BaseModel</code></p> <p>OAuth Error Response</p> <p>Parsed from WWW-Authenticate header or token endpoint error response.</p> Source code in <code>src/sk_agents/auth/oauth_models.py</code> <pre><code>class OAuthError(BaseModel):\n    \"\"\"\n    OAuth Error Response\n\n    Parsed from WWW-Authenticate header or token endpoint error response.\n    \"\"\"\n\n    error: str = Field(..., description=\"Error code (e.g., 'invalid_token', 'insufficient_scope')\")\n    error_description: str | None = Field(None, description=\"Human-readable error description\")\n    error_uri: str | None = Field(None, description=\"URL with error information\")\n    oauth_server_metadata_url: str | None = Field(\n        None, description=\"Authorization server metadata URL (from WWW-Authenticate)\"\n    )\n</code></pre> <code></code> sk_agents.auth.oauth_models.MCP401Response <p>               Bases: <code>BaseModel</code></p> <p>MCP-compliant 401 Unauthorized response.</p> <p>Per MCP spec, servers should return WWW-Authenticate header with: - error: Error code - error_description: Human-readable description - scope: Required scopes (for insufficient_scope) - resource_metadata: URL for RFC 9728 discovery (optional)</p> Source code in <code>src/sk_agents/auth/oauth_models.py</code> <pre><code>class MCP401Response(BaseModel):\n    \"\"\"\n    MCP-compliant 401 Unauthorized response.\n\n    Per MCP spec, servers should return WWW-Authenticate header with:\n    - error: Error code\n    - error_description: Human-readable description\n    - scope: Required scopes (for insufficient_scope)\n    - resource_metadata: URL for RFC 9728 discovery (optional)\n    \"\"\"\n\n    www_authenticate: str = Field(..., description=\"WWW-Authenticate header value\")\n    error_code: int = Field(401, description=\"HTTP status code\")\n    error_message: str = Field(\n        \"Authentication required\", description=\"Human-readable error message\"\n    )\n</code></pre> <code></code> sk_agents.auth.oauth_models.MCP403Response <p>               Bases: <code>BaseModel</code></p> <p>MCP-compliant 403 Forbidden response.</p> Source code in <code>src/sk_agents/auth/oauth_models.py</code> <pre><code>class MCP403Response(BaseModel):\n    \"\"\"MCP-compliant 403 Forbidden response.\"\"\"\n\n    error_code: int = Field(403, description=\"HTTP status code\")\n    error_message: str = Field(\n        \"Insufficient permissions\", description=\"Human-readable error message\"\n    )\n    required_scopes: list[str] | None = Field(\n        None, description=\"Scopes required for this operation\"\n    )\n</code></pre> <code></code> sk_agents.auth.oauth_pkce <p>PKCE (Proof Key for Code Exchange) Implementation</p> <p>Implements PKCE as required by OAuth 2.1 and MCP specification. PKCE prevents authorization code interception attacks.</p> <p>References: - OAuth 2.1 Section 7.5.2 - RFC 7636: Proof Key for Code Exchange</p> <code></code> sk_agents.auth.oauth_pkce.PKCEManager <p>Manager for PKCE generation and validation.</p> <p>Provides high-level interface for PKCE operations in OAuth flows.</p> Source code in <code>src/sk_agents/auth/oauth_pkce.py</code> <pre><code>class PKCEManager:\n    \"\"\"\n    Manager for PKCE generation and validation.\n\n    Provides high-level interface for PKCE operations in OAuth flows.\n    \"\"\"\n\n    @staticmethod\n    def generate_pkce_pair() -&gt; tuple[str, str]:\n        \"\"\"\n        Generate PKCE verifier and challenge pair.\n\n        Returns:\n            tuple: (verifier, challenge)\n        \"\"\"\n        verifier = generate_code_verifier()\n        challenge = generate_code_challenge(verifier)\n        return verifier, challenge\n\n    @staticmethod\n    def validate_verifier(verifier: str) -&gt; bool:\n        \"\"\"\n        Validate code verifier meets requirements.\n\n        Args:\n            verifier: Code verifier to validate\n\n        Returns:\n            bool: True if valid\n        \"\"\"\n        return validate_code_verifier(verifier)\n\n    @staticmethod\n    def verify_challenge(verifier: str, challenge: str) -&gt; bool:\n        \"\"\"\n        Verify that challenge matches verifier.\n\n        Used by authorization server (not typically by client).\n\n        Args:\n            verifier: Code verifier\n            challenge: Code challenge to verify\n\n        Returns:\n            bool: True if challenge matches verifier\n        \"\"\"\n        expected_challenge = generate_code_challenge(verifier)\n        return expected_challenge == challenge\n</code></pre> <code></code> sk_agents.auth.oauth_pkce.PKCEManager.generate_pkce_pair <code>staticmethod</code> <pre><code>generate_pkce_pair() -&gt; tuple[str, str]\n</code></pre> <p>Generate PKCE verifier and challenge pair.</p> <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[str, str]</code> <p>(verifier, challenge)</p> Source code in <code>src/sk_agents/auth/oauth_pkce.py</code> <pre><code>@staticmethod\ndef generate_pkce_pair() -&gt; tuple[str, str]:\n    \"\"\"\n    Generate PKCE verifier and challenge pair.\n\n    Returns:\n        tuple: (verifier, challenge)\n    \"\"\"\n    verifier = generate_code_verifier()\n    challenge = generate_code_challenge(verifier)\n    return verifier, challenge\n</code></pre> <code></code> sk_agents.auth.oauth_pkce.PKCEManager.validate_verifier <code>staticmethod</code> <pre><code>validate_verifier(verifier: str) -&gt; bool\n</code></pre> <p>Validate code verifier meets requirements.</p> <p>Parameters:</p> Name Type Description Default <code>verifier</code> <code>str</code> <p>Code verifier to validate</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if valid</p> Source code in <code>src/sk_agents/auth/oauth_pkce.py</code> <pre><code>@staticmethod\ndef validate_verifier(verifier: str) -&gt; bool:\n    \"\"\"\n    Validate code verifier meets requirements.\n\n    Args:\n        verifier: Code verifier to validate\n\n    Returns:\n        bool: True if valid\n    \"\"\"\n    return validate_code_verifier(verifier)\n</code></pre> <code></code> sk_agents.auth.oauth_pkce.PKCEManager.verify_challenge <code>staticmethod</code> <pre><code>verify_challenge(verifier: str, challenge: str) -&gt; bool\n</code></pre> <p>Verify that challenge matches verifier.</p> <p>Used by authorization server (not typically by client).</p> <p>Parameters:</p> Name Type Description Default <code>verifier</code> <code>str</code> <p>Code verifier</p> required <code>challenge</code> <code>str</code> <p>Code challenge to verify</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if challenge matches verifier</p> Source code in <code>src/sk_agents/auth/oauth_pkce.py</code> <pre><code>@staticmethod\ndef verify_challenge(verifier: str, challenge: str) -&gt; bool:\n    \"\"\"\n    Verify that challenge matches verifier.\n\n    Used by authorization server (not typically by client).\n\n    Args:\n        verifier: Code verifier\n        challenge: Code challenge to verify\n\n    Returns:\n        bool: True if challenge matches verifier\n    \"\"\"\n    expected_challenge = generate_code_challenge(verifier)\n    return expected_challenge == challenge\n</code></pre> <code></code> sk_agents.auth.oauth_pkce.generate_code_verifier <pre><code>generate_code_verifier() -&gt; str\n</code></pre> <p>Generate cryptographically random code verifier.</p> <p>Per OAuth 2.1 spec, code verifier must be: - 43-128 characters long - Use characters [A-Z] / [a-z] / [0-9] / \"-\" / \".\" / \"_\" / \"~\"</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Base64url-encoded random verifier (43-128 chars)</p> Source code in <code>src/sk_agents/auth/oauth_pkce.py</code> <pre><code>def generate_code_verifier() -&gt; str:\n    \"\"\"\n    Generate cryptographically random code verifier.\n\n    Per OAuth 2.1 spec, code verifier must be:\n    - 43-128 characters long\n    - Use characters [A-Z] / [a-z] / [0-9] / \"-\" / \".\" / \"_\" / \"~\"\n\n    Returns:\n        str: Base64url-encoded random verifier (43-128 chars)\n    \"\"\"\n    # Generate 32 random bytes (provides 43 base64url characters)\n    random_bytes = secrets.token_bytes(32)\n    # Base64url encode (URL-safe, no padding)\n    verifier = base64.urlsafe_b64encode(random_bytes).decode(\"utf-8\").rstrip(\"=\")\n    return verifier\n</code></pre> <code></code> sk_agents.auth.oauth_pkce.generate_code_challenge <pre><code>generate_code_challenge(verifier: str) -&gt; str\n</code></pre> <p>Generate PKCE code challenge from verifier using S256 method.</p> <p>Per OAuth 2.1 spec: - challenge = BASE64URL(SHA256(verifier))</p> <p>Parameters:</p> Name Type Description Default <code>verifier</code> <code>str</code> <p>Code verifier from generate_code_verifier()</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Base64url-encoded SHA256 hash of verifier</p> Source code in <code>src/sk_agents/auth/oauth_pkce.py</code> <pre><code>def generate_code_challenge(verifier: str) -&gt; str:\n    \"\"\"\n    Generate PKCE code challenge from verifier using S256 method.\n\n    Per OAuth 2.1 spec:\n    - challenge = BASE64URL(SHA256(verifier))\n\n    Args:\n        verifier: Code verifier from generate_code_verifier()\n\n    Returns:\n        str: Base64url-encoded SHA256 hash of verifier\n    \"\"\"\n    # SHA256 hash\n    sha256_hash = hashlib.sha256(verifier.encode(\"utf-8\")).digest()\n    # Base64url encode (URL-safe, no padding)\n    challenge = base64.urlsafe_b64encode(sha256_hash).decode(\"utf-8\").rstrip(\"=\")\n    return challenge\n</code></pre> <code></code> sk_agents.auth.oauth_pkce.validate_code_verifier <pre><code>validate_code_verifier(verifier: str) -&gt; bool\n</code></pre> <p>Validate code verifier meets OAuth 2.1 requirements.</p> <p>Parameters:</p> Name Type Description Default <code>verifier</code> <code>str</code> <p>Code verifier to validate</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if valid, False otherwise</p> Source code in <code>src/sk_agents/auth/oauth_pkce.py</code> <pre><code>def validate_code_verifier(verifier: str) -&gt; bool:\n    \"\"\"\n    Validate code verifier meets OAuth 2.1 requirements.\n\n    Args:\n        verifier: Code verifier to validate\n\n    Returns:\n        bool: True if valid, False otherwise\n    \"\"\"\n    # Check length (43-128 characters)\n    if not (43 &lt;= len(verifier) &lt;= 128):\n        return False\n\n    # Check allowed characters\n    allowed_chars = set(\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-._~\")\n    if not all(c in allowed_chars for c in verifier):\n        return False\n\n    return True\n</code></pre> <code></code> sk_agents.auth.oauth_state_manager <p>OAuth State Manager</p> <p>Manages OAuth flow state for CSRF protection. Stores state parameter + PKCE verifier temporarily during OAuth flow.</p> <p>Implementation uses AuthStorage with temporary keys and TTL.</p> <code></code> sk_agents.auth.oauth_state_manager.OAuthFlowState <p>Represents temporary OAuth flow state.</p> <p>Stored during authorization request, retrieved during callback.</p> Source code in <code>src/sk_agents/auth/oauth_state_manager.py</code> <pre><code>class OAuthFlowState:\n    \"\"\"\n    Represents temporary OAuth flow state.\n\n    Stored during authorization request, retrieved during callback.\n    \"\"\"\n\n    def __init__(\n        self,\n        state: str,\n        verifier: str,\n        user_id: str,\n        server_name: str,\n        resource: str,\n        scopes: list[str],\n        created_at: datetime,\n    ):\n        self.state = state\n        self.verifier = verifier\n        self.user_id = user_id\n        self.server_name = server_name\n        self.resource = resource\n        self.scopes = scopes\n        self.created_at = created_at\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        \"\"\"Serialize to dict for storage\"\"\"\n        return {\n            \"state\": self.state,\n            \"verifier\": self.verifier,\n            \"user_id\": self.user_id,\n            \"server_name\": self.server_name,\n            \"resource\": self.resource,\n            \"scopes\": self.scopes,\n            \"created_at\": self.created_at.isoformat(),\n        }\n\n    @classmethod\n    def from_dict(cls, data: dict[str, Any]) -&gt; \"OAuthFlowState\":\n        \"\"\"Deserialize from storage dict\"\"\"\n        return cls(\n            state=data[\"state\"],\n            verifier=data[\"verifier\"],\n            user_id=data[\"user_id\"],\n            server_name=data[\"server_name\"],\n            resource=data[\"resource\"],\n            scopes=data[\"scopes\"],\n            created_at=datetime.fromisoformat(data[\"created_at\"]),\n        )\n\n    def is_expired(self, ttl_seconds: int = 300) -&gt; bool:\n        \"\"\"Check if flow state has expired (default 5 minutes)\"\"\"\n        expires_at = self.created_at + timedelta(seconds=ttl_seconds)\n        return datetime.now(UTC) &gt; expires_at\n</code></pre> <code></code> sk_agents.auth.oauth_state_manager.OAuthFlowState.to_dict <pre><code>to_dict() -&gt; dict[str, Any]\n</code></pre> <p>Serialize to dict for storage</p> Source code in <code>src/sk_agents/auth/oauth_state_manager.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Serialize to dict for storage\"\"\"\n    return {\n        \"state\": self.state,\n        \"verifier\": self.verifier,\n        \"user_id\": self.user_id,\n        \"server_name\": self.server_name,\n        \"resource\": self.resource,\n        \"scopes\": self.scopes,\n        \"created_at\": self.created_at.isoformat(),\n    }\n</code></pre> <code></code> sk_agents.auth.oauth_state_manager.OAuthFlowState.from_dict <code>classmethod</code> <pre><code>from_dict(data: dict[str, Any]) -&gt; OAuthFlowState\n</code></pre> <p>Deserialize from storage dict</p> Source code in <code>src/sk_agents/auth/oauth_state_manager.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict[str, Any]) -&gt; \"OAuthFlowState\":\n    \"\"\"Deserialize from storage dict\"\"\"\n    return cls(\n        state=data[\"state\"],\n        verifier=data[\"verifier\"],\n        user_id=data[\"user_id\"],\n        server_name=data[\"server_name\"],\n        resource=data[\"resource\"],\n        scopes=data[\"scopes\"],\n        created_at=datetime.fromisoformat(data[\"created_at\"]),\n    )\n</code></pre> <code></code> sk_agents.auth.oauth_state_manager.OAuthFlowState.is_expired <pre><code>is_expired(ttl_seconds: int = 300) -&gt; bool\n</code></pre> <p>Check if flow state has expired (default 5 minutes)</p> Source code in <code>src/sk_agents/auth/oauth_state_manager.py</code> <pre><code>def is_expired(self, ttl_seconds: int = 300) -&gt; bool:\n    \"\"\"Check if flow state has expired (default 5 minutes)\"\"\"\n    expires_at = self.created_at + timedelta(seconds=ttl_seconds)\n    return datetime.now(UTC) &gt; expires_at\n</code></pre> <code></code> sk_agents.auth.oauth_state_manager.OAuthStateManager <p>Manager for OAuth flow state and CSRF protection.</p> <p>Uses AuthStorage with temporary keys to store state during OAuth flow.</p> Source code in <code>src/sk_agents/auth/oauth_state_manager.py</code> <pre><code>class OAuthStateManager:\n    \"\"\"\n    Manager for OAuth flow state and CSRF protection.\n\n    Uses AuthStorage with temporary keys to store state during OAuth flow.\n    \"\"\"\n\n    # Use a special user_id for temporary OAuth flow state\n    TEMP_USER_PREFIX = \"oauth_flow_temp\"\n\n    def __init__(self, ttl_seconds: int = 300):\n        \"\"\"\n        Initialize state manager.\n\n        Args:\n            ttl_seconds: Time-to-live for state (default 5 minutes)\n        \"\"\"\n        self.ttl_seconds = ttl_seconds\n        self.auth_storage_factory = AuthStorageFactory(AppConfig())\n        self.auth_storage = self.auth_storage_factory.get_auth_storage_manager()\n\n    @staticmethod\n    def generate_state() -&gt; str:\n        \"\"\"\n        Generate cryptographically random state parameter.\n\n        Returns:\n            str: Random state string (URL-safe, 32 bytes)\n        \"\"\"\n        return secrets.token_urlsafe(32)\n\n    def store_flow_state(\n        self,\n        state: str,\n        verifier: str,\n        user_id: str,\n        server_name: str,\n        resource: str,\n        scopes: list[str],\n    ) -&gt; None:\n        \"\"\"\n        Store OAuth flow state temporarily.\n\n        Stores in two locations:\n        1. User-specific key for validation: oauth_flow_temp:{user_id}\n        2. State-only key for callback retrieval: oauth_flow_temp:by_state\n\n        Args:\n            state: CSRF state parameter\n            verifier: PKCE code verifier\n            user_id: User ID for this flow\n            server_name: MCP server name\n            resource: Canonical server URI\n            scopes: Requested scopes\n        \"\"\"\n        flow_state = OAuthFlowState(\n            state=state,\n            verifier=verifier,\n            user_id=user_id,\n            server_name=server_name,\n            resource=resource,\n            scopes=scopes,\n            created_at=datetime.now(UTC),\n        )\n\n        # Store with temporary key\n        temp_key = f\"oauth_state:{state}\"\n\n        # Note: Current AuthStorage doesn't support TTL natively\n        # We'll implement expiry check on retrieval\n        # For production, consider Redis or other storage with native TTL\n        try:\n            # Store with user-specific key (for retrieve_flow_state with user_id)\n            temp_user = f\"{self.TEMP_USER_PREFIX}:{user_id}\"\n            self.auth_storage.store(temp_user, temp_key, flow_state.to_dict())\n\n            # Also store with state-only key (for OAuth callback without user_id)\n            state_only_user = f\"{self.TEMP_USER_PREFIX}:by_state\"\n            self.auth_storage.store(state_only_user, temp_key, flow_state.to_dict())\n\n            logger.debug(f\"Stored OAuth flow state for state={state}, user={user_id}\")\n        except Exception as e:\n            logger.error(f\"Failed to store OAuth flow state: {e}\")\n            raise\n\n    def retrieve_flow_state(self, state: str, user_id: str) -&gt; OAuthFlowState:\n        \"\"\"\n        Retrieve and validate OAuth flow state.\n\n        Args:\n            state: CSRF state parameter from callback\n            user_id: User ID to validate against\n\n        Returns:\n            OAuthFlowState: Retrieved flow state\n\n        Raises:\n            ValueError: If state not found, expired, or user_id mismatch\n        \"\"\"\n        temp_key = f\"oauth_state:{state}\"\n        temp_user = f\"{self.TEMP_USER_PREFIX}:{user_id}\"\n\n        try:\n            # Retrieve from storage\n            data = self.auth_storage.retrieve(temp_user, temp_key)\n\n            if not data:\n                logger.warning(f\"OAuth flow state not found for state={state}\")\n                raise ValueError(\"Invalid or expired OAuth state\")\n\n            # Handle both dict and object storage\n            if not isinstance(data, dict):\n                # If AuthStorage returns an object, try to convert\n                if hasattr(data, \"to_dict\"):\n                    data = data.to_dict()\n                elif hasattr(data, \"__dict__\"):\n                    data = data.__dict__\n                else:\n                    logger.error(f\"Unexpected flow state data type: {type(data)}\")\n                    raise ValueError(\"Invalid OAuth flow state data\")\n\n            flow_state = OAuthFlowState.from_dict(data)\n\n            # Validate expiry\n            if flow_state.is_expired(self.ttl_seconds):\n                logger.warning(f\"OAuth flow state expired for state={state}\")\n                # Clean up expired state\n                self.delete_flow_state(state, user_id)\n                raise ValueError(\"OAuth state expired\")\n\n            # Validate user_id (CSRF protection)\n            if flow_state.user_id != user_id:\n                logger.error(\n                    f\"OAuth flow user_id mismatch: expected={flow_state.user_id}, got={user_id}\"\n                )\n                raise ValueError(\"OAuth state user mismatch (CSRF attempt?)\")\n\n            logger.debug(f\"Retrieved valid OAuth flow state for state={state}, user={user_id}\")\n            return flow_state\n\n        except Exception as e:\n            logger.error(f\"Failed to retrieve OAuth flow state: {e}\")\n            raise\n\n    def retrieve_flow_state_by_state_only(self, state: str) -&gt; OAuthFlowState:\n        \"\"\"\n        Retrieve OAuth flow state using only the state parameter.\n\n        This is used in OAuth callbacks where we don't have user_id upfront.\n        The flow state contains user_id which we extract after retrieval.\n\n        Note: This method attempts retrieval by trying common patterns.\n        For production, consider using a state\u2192user_id mapping or encoding\n        user_id in the state parameter itself.\n\n        Args:\n            state: CSRF state parameter from callback\n\n        Returns:\n            OAuthFlowState: Retrieved flow state with embedded user_id\n\n        Raises:\n            ValueError: If state not found or expired\n        \"\"\"\n        temp_key = f\"oauth_state:{state}\"\n\n        try:\n            # First, try to retrieve with a wildcard pattern\n            # Since AuthStorage is user-scoped, we need to iterate\n            # This is inefficient but works for now\n            # TODO: Implement better storage pattern (e.g., state\u2192user_id mapping)\n\n            # For now, we'll use a simplified approach:\n            # Store flow state with a well-known temporary user that doesn't include user_id\n            # We'll modify store_flow_state to support this\n\n            # Attempt to retrieve with state-only key\n            state_only_user = f\"{self.TEMP_USER_PREFIX}:by_state\"\n            data = self.auth_storage.retrieve(state_only_user, temp_key)\n\n            if not data:\n                logger.warning(f\"OAuth flow state not found for state={state}\")\n                raise ValueError(\"Invalid or expired OAuth state\")\n\n            # Handle both dict and object storage\n            if not isinstance(data, dict):\n                if hasattr(data, \"to_dict\"):\n                    data = data.to_dict()\n                elif hasattr(data, \"__dict__\"):\n                    data = data.__dict__\n                else:\n                    logger.error(f\"Unexpected flow state data type: {type(data)}\")\n                    raise ValueError(\"Invalid OAuth flow state data\")\n\n            flow_state = OAuthFlowState.from_dict(data)\n\n            # Validate expiry\n            if flow_state.is_expired(self.ttl_seconds):\n                logger.warning(f\"OAuth flow state expired for state={state}\")\n                raise ValueError(\"OAuth state expired\")\n\n            logger.debug(f\"Retrieved OAuth flow state for state={state}, user={flow_state.user_id}\")\n            return flow_state\n\n        except Exception as e:\n            logger.error(f\"Failed to retrieve OAuth flow state by state only: {e}\")\n            raise\n\n    def delete_flow_state(self, state: str, user_id: str) -&gt; None:\n        \"\"\"\n        Delete OAuth flow state after use or expiry.\n\n        Args:\n            state: CSRF state parameter\n            user_id: User ID\n        \"\"\"\n        temp_key = f\"oauth_state:{state}\"\n        temp_user = f\"{self.TEMP_USER_PREFIX}:{user_id}\"\n        state_only_user = f\"{self.TEMP_USER_PREFIX}:by_state\"\n\n        try:\n            # Delete from user-specific storage\n            self.auth_storage.delete(temp_user, temp_key)\n            logger.debug(f\"Deleted OAuth flow state for state={state}, user={user_id}\")\n\n            # Also delete from state-only storage\n            try:\n                self.auth_storage.delete(state_only_user, temp_key)\n                logger.debug(f\"Deleted state-only OAuth flow state for state={state}\")\n            except Exception as e:\n                logger.debug(f\"Failed to delete state-only flow state (non-critical): {e}\")\n\n        except Exception as e:\n            logger.warning(f\"Failed to delete OAuth flow state: {e}\")\n</code></pre> <code></code> sk_agents.auth.oauth_state_manager.OAuthStateManager.__init__ <pre><code>__init__(ttl_seconds: int = 300)\n</code></pre> <p>Initialize state manager.</p> <p>Parameters:</p> Name Type Description Default <code>ttl_seconds</code> <code>int</code> <p>Time-to-live for state (default 5 minutes)</p> <code>300</code> Source code in <code>src/sk_agents/auth/oauth_state_manager.py</code> <pre><code>def __init__(self, ttl_seconds: int = 300):\n    \"\"\"\n    Initialize state manager.\n\n    Args:\n        ttl_seconds: Time-to-live for state (default 5 minutes)\n    \"\"\"\n    self.ttl_seconds = ttl_seconds\n    self.auth_storage_factory = AuthStorageFactory(AppConfig())\n    self.auth_storage = self.auth_storage_factory.get_auth_storage_manager()\n</code></pre> <code></code> sk_agents.auth.oauth_state_manager.OAuthStateManager.generate_state <code>staticmethod</code> <pre><code>generate_state() -&gt; str\n</code></pre> <p>Generate cryptographically random state parameter.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Random state string (URL-safe, 32 bytes)</p> Source code in <code>src/sk_agents/auth/oauth_state_manager.py</code> <pre><code>@staticmethod\ndef generate_state() -&gt; str:\n    \"\"\"\n    Generate cryptographically random state parameter.\n\n    Returns:\n        str: Random state string (URL-safe, 32 bytes)\n    \"\"\"\n    return secrets.token_urlsafe(32)\n</code></pre> <code></code> sk_agents.auth.oauth_state_manager.OAuthStateManager.store_flow_state <pre><code>store_flow_state(\n    state: str,\n    verifier: str,\n    user_id: str,\n    server_name: str,\n    resource: str,\n    scopes: list[str],\n) -&gt; None\n</code></pre> <p>Store OAuth flow state temporarily.</p> <p>Stores in two locations: 1. User-specific key for validation: oauth_flow_temp:{user_id} 2. State-only key for callback retrieval: oauth_flow_temp:by_state</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>str</code> <p>CSRF state parameter</p> required <code>verifier</code> <code>str</code> <p>PKCE code verifier</p> required <code>user_id</code> <code>str</code> <p>User ID for this flow</p> required <code>server_name</code> <code>str</code> <p>MCP server name</p> required <code>resource</code> <code>str</code> <p>Canonical server URI</p> required <code>scopes</code> <code>list[str]</code> <p>Requested scopes</p> required Source code in <code>src/sk_agents/auth/oauth_state_manager.py</code> <pre><code>def store_flow_state(\n    self,\n    state: str,\n    verifier: str,\n    user_id: str,\n    server_name: str,\n    resource: str,\n    scopes: list[str],\n) -&gt; None:\n    \"\"\"\n    Store OAuth flow state temporarily.\n\n    Stores in two locations:\n    1. User-specific key for validation: oauth_flow_temp:{user_id}\n    2. State-only key for callback retrieval: oauth_flow_temp:by_state\n\n    Args:\n        state: CSRF state parameter\n        verifier: PKCE code verifier\n        user_id: User ID for this flow\n        server_name: MCP server name\n        resource: Canonical server URI\n        scopes: Requested scopes\n    \"\"\"\n    flow_state = OAuthFlowState(\n        state=state,\n        verifier=verifier,\n        user_id=user_id,\n        server_name=server_name,\n        resource=resource,\n        scopes=scopes,\n        created_at=datetime.now(UTC),\n    )\n\n    # Store with temporary key\n    temp_key = f\"oauth_state:{state}\"\n\n    # Note: Current AuthStorage doesn't support TTL natively\n    # We'll implement expiry check on retrieval\n    # For production, consider Redis or other storage with native TTL\n    try:\n        # Store with user-specific key (for retrieve_flow_state with user_id)\n        temp_user = f\"{self.TEMP_USER_PREFIX}:{user_id}\"\n        self.auth_storage.store(temp_user, temp_key, flow_state.to_dict())\n\n        # Also store with state-only key (for OAuth callback without user_id)\n        state_only_user = f\"{self.TEMP_USER_PREFIX}:by_state\"\n        self.auth_storage.store(state_only_user, temp_key, flow_state.to_dict())\n\n        logger.debug(f\"Stored OAuth flow state for state={state}, user={user_id}\")\n    except Exception as e:\n        logger.error(f\"Failed to store OAuth flow state: {e}\")\n        raise\n</code></pre> <code></code> sk_agents.auth.oauth_state_manager.OAuthStateManager.retrieve_flow_state <pre><code>retrieve_flow_state(\n    state: str, user_id: str\n) -&gt; OAuthFlowState\n</code></pre> <p>Retrieve and validate OAuth flow state.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>str</code> <p>CSRF state parameter from callback</p> required <code>user_id</code> <code>str</code> <p>User ID to validate against</p> required <p>Returns:</p> Name Type Description <code>OAuthFlowState</code> <code>OAuthFlowState</code> <p>Retrieved flow state</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If state not found, expired, or user_id mismatch</p> Source code in <code>src/sk_agents/auth/oauth_state_manager.py</code> <pre><code>def retrieve_flow_state(self, state: str, user_id: str) -&gt; OAuthFlowState:\n    \"\"\"\n    Retrieve and validate OAuth flow state.\n\n    Args:\n        state: CSRF state parameter from callback\n        user_id: User ID to validate against\n\n    Returns:\n        OAuthFlowState: Retrieved flow state\n\n    Raises:\n        ValueError: If state not found, expired, or user_id mismatch\n    \"\"\"\n    temp_key = f\"oauth_state:{state}\"\n    temp_user = f\"{self.TEMP_USER_PREFIX}:{user_id}\"\n\n    try:\n        # Retrieve from storage\n        data = self.auth_storage.retrieve(temp_user, temp_key)\n\n        if not data:\n            logger.warning(f\"OAuth flow state not found for state={state}\")\n            raise ValueError(\"Invalid or expired OAuth state\")\n\n        # Handle both dict and object storage\n        if not isinstance(data, dict):\n            # If AuthStorage returns an object, try to convert\n            if hasattr(data, \"to_dict\"):\n                data = data.to_dict()\n            elif hasattr(data, \"__dict__\"):\n                data = data.__dict__\n            else:\n                logger.error(f\"Unexpected flow state data type: {type(data)}\")\n                raise ValueError(\"Invalid OAuth flow state data\")\n\n        flow_state = OAuthFlowState.from_dict(data)\n\n        # Validate expiry\n        if flow_state.is_expired(self.ttl_seconds):\n            logger.warning(f\"OAuth flow state expired for state={state}\")\n            # Clean up expired state\n            self.delete_flow_state(state, user_id)\n            raise ValueError(\"OAuth state expired\")\n\n        # Validate user_id (CSRF protection)\n        if flow_state.user_id != user_id:\n            logger.error(\n                f\"OAuth flow user_id mismatch: expected={flow_state.user_id}, got={user_id}\"\n            )\n            raise ValueError(\"OAuth state user mismatch (CSRF attempt?)\")\n\n        logger.debug(f\"Retrieved valid OAuth flow state for state={state}, user={user_id}\")\n        return flow_state\n\n    except Exception as e:\n        logger.error(f\"Failed to retrieve OAuth flow state: {e}\")\n        raise\n</code></pre> <code></code> sk_agents.auth.oauth_state_manager.OAuthStateManager.retrieve_flow_state_by_state_only <pre><code>retrieve_flow_state_by_state_only(\n    state: str,\n) -&gt; OAuthFlowState\n</code></pre> <p>Retrieve OAuth flow state using only the state parameter.</p> <p>This is used in OAuth callbacks where we don't have user_id upfront. The flow state contains user_id which we extract after retrieval.</p> <p>Note: This method attempts retrieval by trying common patterns. For production, consider using a state\u2192user_id mapping or encoding user_id in the state parameter itself.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>str</code> <p>CSRF state parameter from callback</p> required <p>Returns:</p> Name Type Description <code>OAuthFlowState</code> <code>OAuthFlowState</code> <p>Retrieved flow state with embedded user_id</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If state not found or expired</p> Source code in <code>src/sk_agents/auth/oauth_state_manager.py</code> <pre><code>def retrieve_flow_state_by_state_only(self, state: str) -&gt; OAuthFlowState:\n    \"\"\"\n    Retrieve OAuth flow state using only the state parameter.\n\n    This is used in OAuth callbacks where we don't have user_id upfront.\n    The flow state contains user_id which we extract after retrieval.\n\n    Note: This method attempts retrieval by trying common patterns.\n    For production, consider using a state\u2192user_id mapping or encoding\n    user_id in the state parameter itself.\n\n    Args:\n        state: CSRF state parameter from callback\n\n    Returns:\n        OAuthFlowState: Retrieved flow state with embedded user_id\n\n    Raises:\n        ValueError: If state not found or expired\n    \"\"\"\n    temp_key = f\"oauth_state:{state}\"\n\n    try:\n        # First, try to retrieve with a wildcard pattern\n        # Since AuthStorage is user-scoped, we need to iterate\n        # This is inefficient but works for now\n        # TODO: Implement better storage pattern (e.g., state\u2192user_id mapping)\n\n        # For now, we'll use a simplified approach:\n        # Store flow state with a well-known temporary user that doesn't include user_id\n        # We'll modify store_flow_state to support this\n\n        # Attempt to retrieve with state-only key\n        state_only_user = f\"{self.TEMP_USER_PREFIX}:by_state\"\n        data = self.auth_storage.retrieve(state_only_user, temp_key)\n\n        if not data:\n            logger.warning(f\"OAuth flow state not found for state={state}\")\n            raise ValueError(\"Invalid or expired OAuth state\")\n\n        # Handle both dict and object storage\n        if not isinstance(data, dict):\n            if hasattr(data, \"to_dict\"):\n                data = data.to_dict()\n            elif hasattr(data, \"__dict__\"):\n                data = data.__dict__\n            else:\n                logger.error(f\"Unexpected flow state data type: {type(data)}\")\n                raise ValueError(\"Invalid OAuth flow state data\")\n\n        flow_state = OAuthFlowState.from_dict(data)\n\n        # Validate expiry\n        if flow_state.is_expired(self.ttl_seconds):\n            logger.warning(f\"OAuth flow state expired for state={state}\")\n            raise ValueError(\"OAuth state expired\")\n\n        logger.debug(f\"Retrieved OAuth flow state for state={state}, user={flow_state.user_id}\")\n        return flow_state\n\n    except Exception as e:\n        logger.error(f\"Failed to retrieve OAuth flow state by state only: {e}\")\n        raise\n</code></pre> <code></code> sk_agents.auth.oauth_state_manager.OAuthStateManager.delete_flow_state <pre><code>delete_flow_state(state: str, user_id: str) -&gt; None\n</code></pre> <p>Delete OAuth flow state after use or expiry.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>str</code> <p>CSRF state parameter</p> required <code>user_id</code> <code>str</code> <p>User ID</p> required Source code in <code>src/sk_agents/auth/oauth_state_manager.py</code> <pre><code>def delete_flow_state(self, state: str, user_id: str) -&gt; None:\n    \"\"\"\n    Delete OAuth flow state after use or expiry.\n\n    Args:\n        state: CSRF state parameter\n        user_id: User ID\n    \"\"\"\n    temp_key = f\"oauth_state:{state}\"\n    temp_user = f\"{self.TEMP_USER_PREFIX}:{user_id}\"\n    state_only_user = f\"{self.TEMP_USER_PREFIX}:by_state\"\n\n    try:\n        # Delete from user-specific storage\n        self.auth_storage.delete(temp_user, temp_key)\n        logger.debug(f\"Deleted OAuth flow state for state={state}, user={user_id}\")\n\n        # Also delete from state-only storage\n        try:\n            self.auth_storage.delete(state_only_user, temp_key)\n            logger.debug(f\"Deleted state-only OAuth flow state for state={state}\")\n        except Exception as e:\n            logger.debug(f\"Failed to delete state-only flow state (non-critical): {e}\")\n\n    except Exception as e:\n        logger.warning(f\"Failed to delete OAuth flow state: {e}\")\n</code></pre> <code></code> sk_agents.auth.server_metadata <p>Authorization Server Metadata Discovery</p> <p>Implements server metadata discovery per RFC8414 and RFC9728. Used for dynamic discovery of OAuth endpoints and capabilities.</p> <p>References: - RFC 8414: OAuth 2.0 Authorization Server Metadata - RFC 9728: OAuth 2.0 Protected Resource Metadata</p> <code></code> sk_agents.auth.server_metadata.AuthServerMetadata <p>               Bases: <code>BaseModel</code></p> <p>OAuth 2.0 Authorization Server Metadata (RFC8414)</p> <p>Discovered from {auth_server}/.well-known/oauth-authorization-server</p> Source code in <code>src/sk_agents/auth/server_metadata.py</code> <pre><code>class AuthServerMetadata(BaseModel):\n    \"\"\"\n    OAuth 2.0 Authorization Server Metadata (RFC8414)\n\n    Discovered from {auth_server}/.well-known/oauth-authorization-server\n    \"\"\"\n\n    issuer: HttpUrl\n    authorization_endpoint: HttpUrl\n    token_endpoint: HttpUrl\n    revocation_endpoint: HttpUrl | None = None\n    registration_endpoint: HttpUrl | None = None\n    response_types_supported: list[str]\n    grant_types_supported: list[str] | None = None\n    code_challenge_methods_supported: list[str] | None = None\n    scopes_supported: list[str] | None = None\n</code></pre> <code></code> sk_agents.auth.server_metadata.ProtectedResourceMetadata <p>               Bases: <code>BaseModel</code></p> <p>OAuth 2.0 Protected Resource Metadata (RFC9728)</p> <p>Discovered from {mcp_server}/.well-known/oauth-protected-resource</p> Source code in <code>src/sk_agents/auth/server_metadata.py</code> <pre><code>class ProtectedResourceMetadata(BaseModel):\n    \"\"\"\n    OAuth 2.0 Protected Resource Metadata (RFC9728)\n\n    Discovered from {mcp_server}/.well-known/oauth-protected-resource\n    \"\"\"\n\n    resource: HttpUrl\n    authorization_servers: list[HttpUrl]\n    scopes_supported: list[str] | None = None\n    bearer_methods_supported: list[str] | None = None\n</code></pre> <code></code> sk_agents.auth.server_metadata.ServerMetadataCache <p>Cache for server metadata to avoid repeated discovery requests.</p> <p>Implements RFC 8414 and RFC 9728 discovery with TTL-based caching.</p> Source code in <code>src/sk_agents/auth/server_metadata.py</code> <pre><code>class ServerMetadataCache:\n    \"\"\"\n    Cache for server metadata to avoid repeated discovery requests.\n\n    Implements RFC 8414 and RFC 9728 discovery with TTL-based caching.\n    \"\"\"\n\n    def __init__(self, timeout: float = 30.0, ttl: int = 3600):\n        \"\"\"\n        Initialize metadata cache.\n\n        Args:\n            timeout: HTTP request timeout in seconds (default: 30)\n            ttl: Cache TTL in seconds (default: 3600 = 1 hour)\n        \"\"\"\n        self.timeout = timeout\n        self.ttl = ttl\n        self._cache: dict[str, tuple[Any, datetime]] = {}\n        self._lock = asyncio.Lock()\n\n    async def fetch_auth_server_metadata(self, auth_server: str) -&gt; AuthServerMetadata:\n        \"\"\"\n        Fetch authorization server metadata from well-known endpoint.\n\n        Per RFC 8414, discovers OAuth endpoints from:\n        {auth_server}/.well-known/oauth-authorization-server\n\n        Args:\n            auth_server: Authorization server base URL\n\n        Returns:\n            AuthServerMetadata: Parsed metadata\n\n        Raises:\n            httpx.HTTPError: If discovery fails\n            ValueError: If metadata is invalid\n        \"\"\"\n        # Check cache first\n        async with self._lock:\n            if auth_server in self._cache:\n                metadata, cached_at = self._cache[auth_server]\n                if datetime.now(UTC) - cached_at &lt; timedelta(seconds=self.ttl):\n                    logger.debug(f\"Cache hit for auth server metadata: {auth_server}\")\n                    return metadata\n\n        # Fetch from well-known endpoint\n        well_known_url = f\"{auth_server.rstrip('/')}/.well-known/oauth-authorization-server\"\n        logger.info(f\"Discovering authorization server metadata from {well_known_url}\")\n\n        data = None  # Initialize to avoid scope issues\n        try:\n            async with httpx.AsyncClient(timeout=self.timeout) as client:\n                response = await client.get(well_known_url)\n                response.raise_for_status()\n                data = response.json()\n\n            # Parse and validate\n            metadata = AuthServerMetadata(**data)\n\n            # Validate PKCE support (MCP requirement)\n            if metadata.code_challenge_methods_supported:\n                if \"S256\" not in metadata.code_challenge_methods_supported:\n                    logger.warning(\n                        f\"Auth server {auth_server} does not advertise S256 PKCE support. \"\n                        f\"Supported methods: {metadata.code_challenge_methods_supported}\"\n                    )\n            else:\n                logger.warning(\n                    f\"Auth server {auth_server} does not advertise code_challenge_methods_supported\"\n                )\n\n            logger.info(\n                f\"Successfully discovered metadata for {auth_server}: \"\n                f\"authorization_endpoint={metadata.authorization_endpoint}, \"\n                f\"token_endpoint={metadata.token_endpoint}\"\n            )\n\n            # Cache result\n            async with self._lock:\n                self._cache[auth_server] = (metadata, datetime.now(UTC))\n\n            return metadata\n\n        except httpx.HTTPStatusError as e:\n            logger.error(\n                f\"Failed to fetch authorization server metadata from {well_known_url}: \"\n                f\"HTTP {e.response.status_code}\"\n            )\n            raise\n        except httpx.HTTPError as e:\n            logger.error(f\"Network error fetching authorization server metadata: {e}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Failed to parse authorization server metadata: {e}\")\n            raise ValueError(f\"Invalid authorization server metadata: {e}\") from e\n\n    async def fetch_protected_resource_metadata(\n        self, mcp_server: str\n    ) -&gt; ProtectedResourceMetadata | None:\n        \"\"\"\n        Fetch protected resource metadata from MCP server.\n\n        Per RFC 9728, discovers resource metadata from:\n        {mcp_server}/.well-known/oauth-protected-resource\n\n        Note: This metadata is OPTIONAL per RFC 9728. Returns None if not available.\n\n        Args:\n            mcp_server: MCP server base URL\n\n        Returns:\n            ProtectedResourceMetadata: Parsed metadata, or None if not available\n\n        Raises:\n            ValueError: If metadata exists but is invalid\n        \"\"\"\n        # Check cache first\n        cache_key = f\"prm:{mcp_server}\"\n        async with self._lock:\n            if cache_key in self._cache:\n                metadata, cached_at = self._cache[cache_key]\n                if datetime.now(UTC) - cached_at &lt; timedelta(seconds=self.ttl):\n                    logger.debug(f\"Cache hit for protected resource metadata: {mcp_server}\")\n                    return metadata\n\n        # Fetch from well-known endpoint\n        well_known_url = f\"{mcp_server.rstrip('/')}/.well-known/oauth-protected-resource\"\n        logger.info(f\"Discovering protected resource metadata from {well_known_url}\")\n\n        data = None  # Initialize to avoid scope issues\n        try:\n            async with httpx.AsyncClient(timeout=self.timeout) as client:\n                response = await client.get(well_known_url)\n\n                # 404 is acceptable - PRM is optional\n                if response.status_code == 404:\n                    logger.debug(\n                        f\"Protected resource metadata not available for {mcp_server} (404). \"\n                        f\"This is optional per RFC 9728.\"\n                    )\n                    # Cache the None result to avoid repeated requests\n                    async with self._lock:\n                        self._cache[cache_key] = (None, datetime.now(UTC))\n                    return None\n\n                response.raise_for_status()\n                data = response.json()\n\n            # Parse and validate\n            metadata = ProtectedResourceMetadata(**data)\n\n            # Validate authorization_servers is non-empty\n            if not metadata.authorization_servers:\n                raise ValueError(\"Protected resource metadata must include authorization_servers\")\n\n            logger.info(\n                f\"Successfully discovered protected resource metadata for {mcp_server}: \"\n                f\"authorization_servers={metadata.authorization_servers}, \"\n                f\"scopes_supported={metadata.scopes_supported}\"\n            )\n\n            # Cache result\n            async with self._lock:\n                self._cache[cache_key] = (metadata, datetime.now(UTC))\n\n            return metadata\n\n        except httpx.HTTPStatusError as e:\n            if e.response.status_code == 404:\n                # Already handled above, but just in case\n                async with self._lock:\n                    self._cache[cache_key] = (None, datetime.now(UTC))\n                return None\n            logger.error(\n                f\"Failed to fetch protected resource metadata from {well_known_url}: \"\n                f\"HTTP {e.response.status_code}\"\n            )\n            raise\n        except httpx.HTTPError as e:\n            logger.error(f\"Network error fetching protected resource metadata: {e}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Failed to parse protected resource metadata: {e}\")\n            raise ValueError(f\"Invalid protected resource metadata: {e}\") from e\n</code></pre> <code></code> sk_agents.auth.server_metadata.ServerMetadataCache.__init__ <pre><code>__init__(timeout: float = 30.0, ttl: int = 3600)\n</code></pre> <p>Initialize metadata cache.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>float</code> <p>HTTP request timeout in seconds (default: 30)</p> <code>30.0</code> <code>ttl</code> <code>int</code> <p>Cache TTL in seconds (default: 3600 = 1 hour)</p> <code>3600</code> Source code in <code>src/sk_agents/auth/server_metadata.py</code> <pre><code>def __init__(self, timeout: float = 30.0, ttl: int = 3600):\n    \"\"\"\n    Initialize metadata cache.\n\n    Args:\n        timeout: HTTP request timeout in seconds (default: 30)\n        ttl: Cache TTL in seconds (default: 3600 = 1 hour)\n    \"\"\"\n    self.timeout = timeout\n    self.ttl = ttl\n    self._cache: dict[str, tuple[Any, datetime]] = {}\n    self._lock = asyncio.Lock()\n</code></pre> <code></code> sk_agents.auth.server_metadata.ServerMetadataCache.fetch_auth_server_metadata <code>async</code> <pre><code>fetch_auth_server_metadata(\n    auth_server: str,\n) -&gt; AuthServerMetadata\n</code></pre> <p>Fetch authorization server metadata from well-known endpoint.</p> <p>Per RFC 8414, discovers OAuth endpoints from: {auth_server}/.well-known/oauth-authorization-server</p> <p>Parameters:</p> Name Type Description Default <code>auth_server</code> <code>str</code> <p>Authorization server base URL</p> required <p>Returns:</p> Name Type Description <code>AuthServerMetadata</code> <code>AuthServerMetadata</code> <p>Parsed metadata</p> <p>Raises:</p> Type Description <code>HTTPError</code> <p>If discovery fails</p> <code>ValueError</code> <p>If metadata is invalid</p> Source code in <code>src/sk_agents/auth/server_metadata.py</code> <pre><code>async def fetch_auth_server_metadata(self, auth_server: str) -&gt; AuthServerMetadata:\n    \"\"\"\n    Fetch authorization server metadata from well-known endpoint.\n\n    Per RFC 8414, discovers OAuth endpoints from:\n    {auth_server}/.well-known/oauth-authorization-server\n\n    Args:\n        auth_server: Authorization server base URL\n\n    Returns:\n        AuthServerMetadata: Parsed metadata\n\n    Raises:\n        httpx.HTTPError: If discovery fails\n        ValueError: If metadata is invalid\n    \"\"\"\n    # Check cache first\n    async with self._lock:\n        if auth_server in self._cache:\n            metadata, cached_at = self._cache[auth_server]\n            if datetime.now(UTC) - cached_at &lt; timedelta(seconds=self.ttl):\n                logger.debug(f\"Cache hit for auth server metadata: {auth_server}\")\n                return metadata\n\n    # Fetch from well-known endpoint\n    well_known_url = f\"{auth_server.rstrip('/')}/.well-known/oauth-authorization-server\"\n    logger.info(f\"Discovering authorization server metadata from {well_known_url}\")\n\n    data = None  # Initialize to avoid scope issues\n    try:\n        async with httpx.AsyncClient(timeout=self.timeout) as client:\n            response = await client.get(well_known_url)\n            response.raise_for_status()\n            data = response.json()\n\n        # Parse and validate\n        metadata = AuthServerMetadata(**data)\n\n        # Validate PKCE support (MCP requirement)\n        if metadata.code_challenge_methods_supported:\n            if \"S256\" not in metadata.code_challenge_methods_supported:\n                logger.warning(\n                    f\"Auth server {auth_server} does not advertise S256 PKCE support. \"\n                    f\"Supported methods: {metadata.code_challenge_methods_supported}\"\n                )\n        else:\n            logger.warning(\n                f\"Auth server {auth_server} does not advertise code_challenge_methods_supported\"\n            )\n\n        logger.info(\n            f\"Successfully discovered metadata for {auth_server}: \"\n            f\"authorization_endpoint={metadata.authorization_endpoint}, \"\n            f\"token_endpoint={metadata.token_endpoint}\"\n        )\n\n        # Cache result\n        async with self._lock:\n            self._cache[auth_server] = (metadata, datetime.now(UTC))\n\n        return metadata\n\n    except httpx.HTTPStatusError as e:\n        logger.error(\n            f\"Failed to fetch authorization server metadata from {well_known_url}: \"\n            f\"HTTP {e.response.status_code}\"\n        )\n        raise\n    except httpx.HTTPError as e:\n        logger.error(f\"Network error fetching authorization server metadata: {e}\")\n        raise\n    except Exception as e:\n        logger.error(f\"Failed to parse authorization server metadata: {e}\")\n        raise ValueError(f\"Invalid authorization server metadata: {e}\") from e\n</code></pre> <code></code> sk_agents.auth.server_metadata.ServerMetadataCache.fetch_protected_resource_metadata <code>async</code> <pre><code>fetch_protected_resource_metadata(\n    mcp_server: str,\n) -&gt; ProtectedResourceMetadata | None\n</code></pre> <p>Fetch protected resource metadata from MCP server.</p> <p>Per RFC 9728, discovers resource metadata from: {mcp_server}/.well-known/oauth-protected-resource</p> <p>Note: This metadata is OPTIONAL per RFC 9728. Returns None if not available.</p> <p>Parameters:</p> Name Type Description Default <code>mcp_server</code> <code>str</code> <p>MCP server base URL</p> required <p>Returns:</p> Name Type Description <code>ProtectedResourceMetadata</code> <code>ProtectedResourceMetadata | None</code> <p>Parsed metadata, or None if not available</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If metadata exists but is invalid</p> Source code in <code>src/sk_agents/auth/server_metadata.py</code> <pre><code>async def fetch_protected_resource_metadata(\n    self, mcp_server: str\n) -&gt; ProtectedResourceMetadata | None:\n    \"\"\"\n    Fetch protected resource metadata from MCP server.\n\n    Per RFC 9728, discovers resource metadata from:\n    {mcp_server}/.well-known/oauth-protected-resource\n\n    Note: This metadata is OPTIONAL per RFC 9728. Returns None if not available.\n\n    Args:\n        mcp_server: MCP server base URL\n\n    Returns:\n        ProtectedResourceMetadata: Parsed metadata, or None if not available\n\n    Raises:\n        ValueError: If metadata exists but is invalid\n    \"\"\"\n    # Check cache first\n    cache_key = f\"prm:{mcp_server}\"\n    async with self._lock:\n        if cache_key in self._cache:\n            metadata, cached_at = self._cache[cache_key]\n            if datetime.now(UTC) - cached_at &lt; timedelta(seconds=self.ttl):\n                logger.debug(f\"Cache hit for protected resource metadata: {mcp_server}\")\n                return metadata\n\n    # Fetch from well-known endpoint\n    well_known_url = f\"{mcp_server.rstrip('/')}/.well-known/oauth-protected-resource\"\n    logger.info(f\"Discovering protected resource metadata from {well_known_url}\")\n\n    data = None  # Initialize to avoid scope issues\n    try:\n        async with httpx.AsyncClient(timeout=self.timeout) as client:\n            response = await client.get(well_known_url)\n\n            # 404 is acceptable - PRM is optional\n            if response.status_code == 404:\n                logger.debug(\n                    f\"Protected resource metadata not available for {mcp_server} (404). \"\n                    f\"This is optional per RFC 9728.\"\n                )\n                # Cache the None result to avoid repeated requests\n                async with self._lock:\n                    self._cache[cache_key] = (None, datetime.now(UTC))\n                return None\n\n            response.raise_for_status()\n            data = response.json()\n\n        # Parse and validate\n        metadata = ProtectedResourceMetadata(**data)\n\n        # Validate authorization_servers is non-empty\n        if not metadata.authorization_servers:\n            raise ValueError(\"Protected resource metadata must include authorization_servers\")\n\n        logger.info(\n            f\"Successfully discovered protected resource metadata for {mcp_server}: \"\n            f\"authorization_servers={metadata.authorization_servers}, \"\n            f\"scopes_supported={metadata.scopes_supported}\"\n        )\n\n        # Cache result\n        async with self._lock:\n            self._cache[cache_key] = (metadata, datetime.now(UTC))\n\n        return metadata\n\n    except httpx.HTTPStatusError as e:\n        if e.response.status_code == 404:\n            # Already handled above, but just in case\n            async with self._lock:\n                self._cache[cache_key] = (None, datetime.now(UTC))\n            return None\n        logger.error(\n            f\"Failed to fetch protected resource metadata from {well_known_url}: \"\n            f\"HTTP {e.response.status_code}\"\n        )\n        raise\n    except httpx.HTTPError as e:\n        logger.error(f\"Network error fetching protected resource metadata: {e}\")\n        raise\n    except Exception as e:\n        logger.error(f\"Failed to parse protected resource metadata: {e}\")\n        raise ValueError(f\"Invalid protected resource metadata: {e}\") from e\n</code></pre>"},{"location":"reference/#sk_agents.auth_storage","title":"sk_agents.auth_storage","text":"sk_agents.auth_storage.auth_storage_factory sk_agents.auth_storage.auth_storage_factory.AuthStorageFactory Source code in <code>src/sk_agents/auth_storage/auth_storage_factory.py</code> <pre><code>class AuthStorageFactory(metaclass=Singleton):\n    def __init__(self, app_config: AppConfig):\n        self.app_config = app_config\n\n        # Try to load custom module, fallback to default if not configured\n        module_name, class_name = self._get_custom_auth_storage_config()\n        if module_name and class_name:\n            try:\n                self.module = ModuleLoader.load_module(module_name)\n            except Exception as e:\n                raise ImportError(f\"Failed to load module '{module_name}': {e}\") from e\n\n            self.class_name = class_name\n            self._validate_custom_class()\n        else:\n            self.module = None\n            self.class_name = None\n\n    def get_auth_storage_manager(self) -&gt; SecureAuthStorageManager:\n        if self.module and self.class_name:\n            # Use custom implementation\n            custom_class = getattr(self.module, self.class_name)\n            try:\n                return custom_class(app_config=self.app_config)\n            except TypeError:\n                # Fallback if app_config not accepted\n                return custom_class()\n        else:\n            # Use default implementation\n            return InMemorySecureAuthStorageManager()\n\n    def _get_custom_auth_storage_config(self) -&gt; tuple[str | None, str | None]:\n        \"\"\"Get custom auth storage configuration, returning None values if not configured.\"\"\"\n        try:\n            module_name = self.app_config.get(TA_AUTH_STORAGE_MANAGER_MODULE.env_name)\n        except KeyError:\n            return None, None\n\n        try:\n            class_name = self.app_config.get(TA_AUTH_STORAGE_MANAGER_CLASS.env_name)\n        except KeyError:\n            if module_name:\n                raise ValueError(\"Custom Auth Storage Manager class name not provided\") from None\n            return None, None\n\n        return module_name, class_name\n\n    def _validate_custom_class(self):\n        \"\"\"Validate that the custom class is a proper SecureAuthStorageManager subclass.\"\"\"\n        if not hasattr(self.module, self.class_name):\n            module_name = getattr(self.module, \"__name__\", \"unknown module\")\n            raise ValueError(\n                f\"Custom Auth Storage Manager class: {self.class_name} \"\n                f\"Not found in module: {module_name}\"\n            )\n\n        custom_class = getattr(self.module, self.class_name)\n        if not issubclass(custom_class, SecureAuthStorageManager):\n            raise TypeError(\n                f\"Class '{self.class_name}' is not a subclass of SecureAuthStorageManager.\"\n            )\n</code></pre> <code></code> sk_agents.auth_storage.custom <code></code> sk_agents.auth_storage.custom.example_redis_auth_storage <p>Complete Redis Authentication Storage Implementation</p> <p>This example demonstrates a full-featured, production-ready Redis-based authentication storage implementation. It serves as a complete alternative to the default in-memory storage.</p> <p>To use this implementation, set the following environment variables:</p> <p>TA_AUTH_STORAGE_MANAGER_MODULE=src/sk_agents/auth_storage/custom/example_redis_auth_storage.py TA_AUTH_STORAGE_MANAGER_CLASS=RedisSecureAuthStorageManager</p> <p>Required Redis configuration environment variables: - TA_REDIS_HOST (default: localhost) - TA_REDIS_PORT (default: 6379) - TA_REDIS_DB (default: 0) - TA_REDIS_TTL (default: 3600 seconds) - TA_REDIS_PWD (optional) - TA_REDIS_SSL (default: false)</p> <code></code> sk_agents.auth_storage.custom.example_redis_auth_storage.RedisSecureAuthStorageManager <p>               Bases: <code>SecureAuthStorageManager</code></p> Source code in <code>src/sk_agents/auth_storage/custom/example_redis_auth_storage.py</code> <pre><code>class RedisSecureAuthStorageManager(SecureAuthStorageManager):\n    def __init__(self, app_config: AppConfig = None):\n        \"\"\"\n        Initialize the Redis-based auth storage manager.\n\n        Args:\n            app_config: Application configuration object. If None, creates a new one.\n        \"\"\"\n        if app_config is None:\n            app_config = AppConfig()\n\n        self.app_config = app_config\n        self._lock = threading.Lock()\n\n        # Get Redis configuration\n        redis_host = self.app_config.get(TA_REDIS_HOST.env_name) or \"localhost\"\n        redis_port = int(self.app_config.get(TA_REDIS_PORT.env_name) or 6379)\n        redis_db = int(self.app_config.get(TA_REDIS_DB.env_name) or 0)\n        redis_password = self.app_config.get(TA_REDIS_PWD.env_name)\n        redis_ssl = self.app_config.get(TA_REDIS_SSL.env_name) == \"false\"\n        self.ttl = int(self.app_config.get(TA_REDIS_TTL.env_name) or 3600)  # Default 1 hour\n\n        # Initialize Redis client\n        self.redis_client = redis.Redis(\n            host=redis_host,\n            port=redis_port,\n            db=redis_db,\n            password=redis_password,\n            ssl=redis_ssl,\n            decode_responses=True,  # Automatically decode responses to strings\n            socket_connect_timeout=5,\n            socket_timeout=5,\n            retry_on_timeout=True,\n        )\n\n        # Test connection\n        try:\n            self.redis_client.ping()\n        except redis.ConnectionError as e:\n            raise ConnectionError(f\"Failed to connect to Redis: {e}\") from e\n\n    def _get_redis_key(self, user_id: str, key: str) -&gt; str:\n        \"\"\"Generate a Redis key for the given user_id and key.\"\"\"\n        return f\"auth_storage:{user_id}:{key}\"\n\n    def _serialize_auth_data(self, data: AuthData) -&gt; str:\n        \"\"\"Serialize AuthData to JSON string.\"\"\"\n        return data.model_dump_json()\n\n    def _deserialize_auth_data(self, data_str: str) -&gt; AuthData:\n        \"\"\"Deserialize JSON string to AuthData.\"\"\"\n        data_dict = json.loads(data_str)\n        # Import here to avoid circular imports\n        from sk_agents.auth_storage.models import AuthData\n\n        return AuthData.model_validate(data_dict)\n\n    def store(self, user_id: str, key: str, data: AuthData) -&gt; None:\n        \"\"\"Store authorization data for a given user and key with TTL.\"\"\"\n        with self._lock:\n            try:\n                redis_key = self._get_redis_key(user_id, key)\n                serialized_data = self._serialize_auth_data(data)\n\n                # Store with TTL\n                self.redis_client.setex(redis_key, self.ttl, serialized_data)\n\n            except redis.RedisError as e:\n                raise RuntimeError(f\"Failed to store auth data in Redis: {e}\") from e\n\n    def retrieve(self, user_id: str, key: str) -&gt; AuthData | None:\n        \"\"\"Retrieve authorization data for a given user and key.\"\"\"\n        with self._lock:\n            try:\n                redis_key = self._get_redis_key(user_id, key)\n                data_str = self.redis_client.get(redis_key)\n\n                if data_str is None:\n                    return None\n\n                return self._deserialize_auth_data(data_str)\n\n            except redis.RedisError as e:\n                raise RuntimeError(f\"Failed to retrieve auth data from Redis: {e}\") from e\n            except (json.JSONDecodeError, ValueError) as e:\n                # If we can't deserialize the data, it's corrupted, so delete it\n                try:\n                    redis_key = self._get_redis_key(user_id, key)\n                    self.redis_client.delete(redis_key)\n                except redis.RedisError:\n                    pass  # Ignore deletion errors\n                raise ValueError(\n                    f\"Corrupted auth data found for user {user_id}, key {key}: {e}\"\n                ) from e\n\n    def delete(self, user_id: str, key: str) -&gt; None:\n        \"\"\"Delete authorization data for a given user and key.\"\"\"\n        with self._lock:\n            try:\n                redis_key = self._get_redis_key(user_id, key)\n                self.redis_client.delete(redis_key)\n\n            except redis.RedisError as e:\n                raise RuntimeError(f\"Failed to delete auth data from Redis: {e}\") from e\n\n    def clear_user_data(self, user_id: str) -&gt; int:\n        \"\"\"\n        Clear all authorization data for a given user.\n\n        Returns:\n            Number of keys deleted.\n        \"\"\"\n        with self._lock:\n            try:\n                pattern = self._get_redis_key(user_id, \"*\")\n                keys = self.redis_client.keys(pattern)\n\n                if not keys:\n                    return 0\n\n                return self.redis_client.delete(*keys)\n\n            except redis.RedisError as e:\n                raise RuntimeError(f\"Failed to clear user data from Redis: {e}\") from e\n\n    def health_check(self) -&gt; bool:\n        \"\"\"Check if Redis connection is healthy.\"\"\"\n        try:\n            self.redis_client.ping()\n            return True\n        except redis.RedisError:\n            return False\n</code></pre> <code></code> sk_agents.auth_storage.custom.example_redis_auth_storage.RedisSecureAuthStorageManager.__init__ <pre><code>__init__(app_config: AppConfig = None)\n</code></pre> <p>Initialize the Redis-based auth storage manager.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>AppConfig</code> <p>Application configuration object. If None, creates a new one.</p> <code>None</code> Source code in <code>src/sk_agents/auth_storage/custom/example_redis_auth_storage.py</code> <pre><code>def __init__(self, app_config: AppConfig = None):\n    \"\"\"\n    Initialize the Redis-based auth storage manager.\n\n    Args:\n        app_config: Application configuration object. If None, creates a new one.\n    \"\"\"\n    if app_config is None:\n        app_config = AppConfig()\n\n    self.app_config = app_config\n    self._lock = threading.Lock()\n\n    # Get Redis configuration\n    redis_host = self.app_config.get(TA_REDIS_HOST.env_name) or \"localhost\"\n    redis_port = int(self.app_config.get(TA_REDIS_PORT.env_name) or 6379)\n    redis_db = int(self.app_config.get(TA_REDIS_DB.env_name) or 0)\n    redis_password = self.app_config.get(TA_REDIS_PWD.env_name)\n    redis_ssl = self.app_config.get(TA_REDIS_SSL.env_name) == \"false\"\n    self.ttl = int(self.app_config.get(TA_REDIS_TTL.env_name) or 3600)  # Default 1 hour\n\n    # Initialize Redis client\n    self.redis_client = redis.Redis(\n        host=redis_host,\n        port=redis_port,\n        db=redis_db,\n        password=redis_password,\n        ssl=redis_ssl,\n        decode_responses=True,  # Automatically decode responses to strings\n        socket_connect_timeout=5,\n        socket_timeout=5,\n        retry_on_timeout=True,\n    )\n\n    # Test connection\n    try:\n        self.redis_client.ping()\n    except redis.ConnectionError as e:\n        raise ConnectionError(f\"Failed to connect to Redis: {e}\") from e\n</code></pre> <code></code> sk_agents.auth_storage.custom.example_redis_auth_storage.RedisSecureAuthStorageManager.store <pre><code>store(user_id: str, key: str, data: AuthData) -&gt; None\n</code></pre> <p>Store authorization data for a given user and key with TTL.</p> Source code in <code>src/sk_agents/auth_storage/custom/example_redis_auth_storage.py</code> <pre><code>def store(self, user_id: str, key: str, data: AuthData) -&gt; None:\n    \"\"\"Store authorization data for a given user and key with TTL.\"\"\"\n    with self._lock:\n        try:\n            redis_key = self._get_redis_key(user_id, key)\n            serialized_data = self._serialize_auth_data(data)\n\n            # Store with TTL\n            self.redis_client.setex(redis_key, self.ttl, serialized_data)\n\n        except redis.RedisError as e:\n            raise RuntimeError(f\"Failed to store auth data in Redis: {e}\") from e\n</code></pre> <code></code> sk_agents.auth_storage.custom.example_redis_auth_storage.RedisSecureAuthStorageManager.retrieve <pre><code>retrieve(user_id: str, key: str) -&gt; AuthData | None\n</code></pre> <p>Retrieve authorization data for a given user and key.</p> Source code in <code>src/sk_agents/auth_storage/custom/example_redis_auth_storage.py</code> <pre><code>def retrieve(self, user_id: str, key: str) -&gt; AuthData | None:\n    \"\"\"Retrieve authorization data for a given user and key.\"\"\"\n    with self._lock:\n        try:\n            redis_key = self._get_redis_key(user_id, key)\n            data_str = self.redis_client.get(redis_key)\n\n            if data_str is None:\n                return None\n\n            return self._deserialize_auth_data(data_str)\n\n        except redis.RedisError as e:\n            raise RuntimeError(f\"Failed to retrieve auth data from Redis: {e}\") from e\n        except (json.JSONDecodeError, ValueError) as e:\n            # If we can't deserialize the data, it's corrupted, so delete it\n            try:\n                redis_key = self._get_redis_key(user_id, key)\n                self.redis_client.delete(redis_key)\n            except redis.RedisError:\n                pass  # Ignore deletion errors\n            raise ValueError(\n                f\"Corrupted auth data found for user {user_id}, key {key}: {e}\"\n            ) from e\n</code></pre> <code></code> sk_agents.auth_storage.custom.example_redis_auth_storage.RedisSecureAuthStorageManager.delete <pre><code>delete(user_id: str, key: str) -&gt; None\n</code></pre> <p>Delete authorization data for a given user and key.</p> Source code in <code>src/sk_agents/auth_storage/custom/example_redis_auth_storage.py</code> <pre><code>def delete(self, user_id: str, key: str) -&gt; None:\n    \"\"\"Delete authorization data for a given user and key.\"\"\"\n    with self._lock:\n        try:\n            redis_key = self._get_redis_key(user_id, key)\n            self.redis_client.delete(redis_key)\n\n        except redis.RedisError as e:\n            raise RuntimeError(f\"Failed to delete auth data from Redis: {e}\") from e\n</code></pre> <code></code> sk_agents.auth_storage.custom.example_redis_auth_storage.RedisSecureAuthStorageManager.clear_user_data <pre><code>clear_user_data(user_id: str) -&gt; int\n</code></pre> <p>Clear all authorization data for a given user.</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of keys deleted.</p> Source code in <code>src/sk_agents/auth_storage/custom/example_redis_auth_storage.py</code> <pre><code>def clear_user_data(self, user_id: str) -&gt; int:\n    \"\"\"\n    Clear all authorization data for a given user.\n\n    Returns:\n        Number of keys deleted.\n    \"\"\"\n    with self._lock:\n        try:\n            pattern = self._get_redis_key(user_id, \"*\")\n            keys = self.redis_client.keys(pattern)\n\n            if not keys:\n                return 0\n\n            return self.redis_client.delete(*keys)\n\n        except redis.RedisError as e:\n            raise RuntimeError(f\"Failed to clear user data from Redis: {e}\") from e\n</code></pre> <code></code> sk_agents.auth_storage.custom.example_redis_auth_storage.RedisSecureAuthStorageManager.health_check <pre><code>health_check() -&gt; bool\n</code></pre> <p>Check if Redis connection is healthy.</p> Source code in <code>src/sk_agents/auth_storage/custom/example_redis_auth_storage.py</code> <pre><code>def health_check(self) -&gt; bool:\n    \"\"\"Check if Redis connection is healthy.\"\"\"\n    try:\n        self.redis_client.ping()\n        return True\n    except redis.RedisError:\n        return False\n</code></pre> <code></code> sk_agents.auth_storage.in_memory_secure_auth_storage_manager <code></code> sk_agents.auth_storage.in_memory_secure_auth_storage_manager.InMemorySecureAuthStorageManager <p>               Bases: <code>SecureAuthStorageManager</code></p> <p>A thread-safe, in-memory implementation of the SecureAuthStorageManager.</p> Source code in <code>src/sk_agents/auth_storage/in_memory_secure_auth_storage_manager.py</code> <pre><code>class InMemorySecureAuthStorageManager(SecureAuthStorageManager):\n    \"\"\"A thread-safe, in-memory implementation of the SecureAuthStorageManager.\"\"\"\n\n    def __init__(self):\n        self._storage: dict[str, dict[str, AuthData]] = {}\n        self._lock = threading.Lock()\n\n    def store(self, user_id: str, key: str, data: AuthData) -&gt; None:\n        with self._lock:\n            if user_id not in self._storage:\n                self._storage[user_id] = {}\n            self._storage[user_id][key] = data\n\n    def retrieve(self, user_id: str, key: str) -&gt; AuthData | None:\n        with self._lock:\n            return self._storage.get(user_id, {}).get(key)\n\n    def delete(self, user_id: str, key: str) -&gt; None:\n        with self._lock:\n            if user_id in self._storage and key in self._storage[user_id]:\n                del self._storage[user_id][key]\n</code></pre> <code></code> sk_agents.auth_storage.models <code></code> sk_agents.auth_storage.models.OAuth2AuthData <p>               Bases: <code>BaseAuthData</code></p> Source code in <code>src/sk_agents/auth_storage/models.py</code> <pre><code>class OAuth2AuthData(BaseAuthData):\n    auth_type: Literal[\"oauth2\"] = \"oauth2\"\n    access_token: str\n    refresh_token: str | None = None\n    expires_at: datetime\n    # The scopes this token is valid for.\n    scopes: list[str] = []\n\n    # MCP OAuth 2.1 Compliance Fields\n    audience: str | None = None  # Token audience (aud) for validation\n    resource: str | None = None  # Resource binding (canonical MCP server URI)\n    token_type: str = \"Bearer\"  # Token type (usually \"Bearer\")\n    issued_at: datetime | None = None  # Token issue timestamp\n\n    def is_valid_for_resource(self, resource_uri: str) -&gt; bool:\n        \"\"\"\n        Validate token is valid for specific resource.\n\n        Checks:\n        1. Token not expired\n        2. Resource matches (if resource binding present)\n        3. Audience matches (if audience present)\n\n        Args:\n            resource_uri: Canonical MCP server URI to validate against\n\n        Returns:\n            bool: True if token is valid for this resource\n        \"\"\"\n        from datetime import datetime\n\n        # Check expiry\n        if self.expires_at &lt;= datetime.now(UTC):\n            return False\n\n        # Check resource binding (MCP-specific)\n        if self.resource and self.resource != resource_uri:\n            return False\n\n        # Check audience (OAuth 2.1 token audience validation)\n        if self.audience and self.audience != resource_uri:\n            return False\n\n        return True\n</code></pre> <code></code> sk_agents.auth_storage.models.OAuth2AuthData.is_valid_for_resource <pre><code>is_valid_for_resource(resource_uri: str) -&gt; bool\n</code></pre> <p>Validate token is valid for specific resource.</p> <p>Checks: 1. Token not expired 2. Resource matches (if resource binding present) 3. Audience matches (if audience present)</p> <p>Parameters:</p> Name Type Description Default <code>resource_uri</code> <code>str</code> <p>Canonical MCP server URI to validate against</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if token is valid for this resource</p> Source code in <code>src/sk_agents/auth_storage/models.py</code> <pre><code>def is_valid_for_resource(self, resource_uri: str) -&gt; bool:\n    \"\"\"\n    Validate token is valid for specific resource.\n\n    Checks:\n    1. Token not expired\n    2. Resource matches (if resource binding present)\n    3. Audience matches (if audience present)\n\n    Args:\n        resource_uri: Canonical MCP server URI to validate against\n\n    Returns:\n        bool: True if token is valid for this resource\n    \"\"\"\n    from datetime import datetime\n\n    # Check expiry\n    if self.expires_at &lt;= datetime.now(UTC):\n        return False\n\n    # Check resource binding (MCP-specific)\n    if self.resource and self.resource != resource_uri:\n        return False\n\n    # Check audience (OAuth 2.1 token audience validation)\n    if self.audience and self.audience != resource_uri:\n        return False\n\n    return True\n</code></pre> <code></code> sk_agents.auth_storage.secure_auth_storage_manager <code></code> sk_agents.auth_storage.secure_auth_storage_manager.SecureAuthStorageManager <p>               Bases: <code>ABC</code></p> Source code in <code>src/sk_agents/auth_storage/secure_auth_storage_manager.py</code> <pre><code>class SecureAuthStorageManager(ABC):\n    @abstractmethod\n    def store(self, user_id: str, key: str, data: AuthData) -&gt; None:\n        \"\"\"Stores authorization data for a given user and key.\"\"\"\n        pass\n\n    @abstractmethod\n    def retrieve(self, user_id: str, key: str) -&gt; AuthData | None:\n        \"\"\"Retrieves authorization data for a given user and key.\"\"\"\n        pass\n\n    @abstractmethod\n    def delete(self, user_id: str, key: str) -&gt; None:\n        \"\"\"Deletes authorization data for a given user and key.\"\"\"\n        pass\n</code></pre> <code></code> sk_agents.auth_storage.secure_auth_storage_manager.SecureAuthStorageManager.store <code>abstractmethod</code> <pre><code>store(user_id: str, key: str, data: AuthData) -&gt; None\n</code></pre> <p>Stores authorization data for a given user and key.</p> Source code in <code>src/sk_agents/auth_storage/secure_auth_storage_manager.py</code> <pre><code>@abstractmethod\ndef store(self, user_id: str, key: str, data: AuthData) -&gt; None:\n    \"\"\"Stores authorization data for a given user and key.\"\"\"\n    pass\n</code></pre> <code></code> sk_agents.auth_storage.secure_auth_storage_manager.SecureAuthStorageManager.retrieve <code>abstractmethod</code> <pre><code>retrieve(user_id: str, key: str) -&gt; AuthData | None\n</code></pre> <p>Retrieves authorization data for a given user and key.</p> Source code in <code>src/sk_agents/auth_storage/secure_auth_storage_manager.py</code> <pre><code>@abstractmethod\ndef retrieve(self, user_id: str, key: str) -&gt; AuthData | None:\n    \"\"\"Retrieves authorization data for a given user and key.\"\"\"\n    pass\n</code></pre> <code></code> sk_agents.auth_storage.secure_auth_storage_manager.SecureAuthStorageManager.delete <code>abstractmethod</code> <pre><code>delete(user_id: str, key: str) -&gt; None\n</code></pre> <p>Deletes authorization data for a given user and key.</p> Source code in <code>src/sk_agents/auth_storage/secure_auth_storage_manager.py</code> <pre><code>@abstractmethod\ndef delete(self, user_id: str, key: str) -&gt; None:\n    \"\"\"Deletes authorization data for a given user and key.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/#sk_agents.authorization","title":"sk_agents.authorization","text":"sk_agents.authorization.request_authorizer sk_agents.authorization.request_authorizer.RequestAuthorizer <p>               Bases: <code>ABC</code></p> Source code in <code>src/sk_agents/authorization/request_authorizer.py</code> <pre><code>class RequestAuthorizer(ABC):\n    @abstractmethod\n    async def authorize_request(self, auth_header: str) -&gt; str:\n        \"\"\"\n        Validates the given authorization header and returns a unique identifier\n        for the authenticated user.\n\n        Parameters:\n            auth_header (str): The value of the 'Authorization' HTTP header.\n                Typically, this is in the format 'Bearer &lt;token&gt;' or some other\n                scheme depending on the implementation.\n\n        Returns:\n            str: A unique string that identifies the authenticated user.\n                This could be a user ID, username, email, or any other unique\n                identifier suitable for tracking and authorization.\n            Examples:\n                \"user_12345\"\n                \"alice@example.com\"\n\n        Raises:\n            ValueError: If the authorization header is missing, malformed, or invalid.\n            AuthenticationError (optional): If used in your implementation, it may\n                be raised to signal an authentication failure.\n        \"\"\"\n        pass\n</code></pre> <code></code> sk_agents.authorization.request_authorizer.RequestAuthorizer.authorize_request <code>abstractmethod</code> <code>async</code> <pre><code>authorize_request(auth_header: str) -&gt; str\n</code></pre> <p>Validates the given authorization header and returns a unique identifier for the authenticated user.</p> <p>Parameters:</p> Name Type Description Default <code>auth_header</code> <code>str</code> <p>The value of the 'Authorization' HTTP header. Typically, this is in the format 'Bearer ' or some other scheme depending on the implementation. required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A unique string that identifies the authenticated user. This could be a user ID, username, email, or any other unique identifier suitable for tracking and authorization.</p> <code>Examples</code> <code>str</code> <p>\"user_12345\" \"alice@example.com\"</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the authorization header is missing, malformed, or invalid.</p> <code>AuthenticationError(optional)</code> <p>If used in your implementation, it may be raised to signal an authentication failure.</p> Source code in <code>src/sk_agents/authorization/request_authorizer.py</code> <pre><code>@abstractmethod\nasync def authorize_request(self, auth_header: str) -&gt; str:\n    \"\"\"\n    Validates the given authorization header and returns a unique identifier\n    for the authenticated user.\n\n    Parameters:\n        auth_header (str): The value of the 'Authorization' HTTP header.\n            Typically, this is in the format 'Bearer &lt;token&gt;' or some other\n            scheme depending on the implementation.\n\n    Returns:\n        str: A unique string that identifies the authenticated user.\n            This could be a user ID, username, email, or any other unique\n            identifier suitable for tracking and authorization.\n        Examples:\n            \"user_12345\"\n            \"alice@example.com\"\n\n    Raises:\n        ValueError: If the authorization header is missing, malformed, or invalid.\n        AuthenticationError (optional): If used in your implementation, it may\n            be raised to signal an authentication failure.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/#sk_agents.exceptions","title":"sk_agents.exceptions","text":"sk_agents.exceptions.AgentsException <p>               Bases: <code>Exception</code></p> <p>Base class for all exception in SKagents</p> Source code in <code>src/sk_agents/exceptions.py</code> <pre><code>class AgentsException(Exception):\n    \"\"\"Base class for all exception in SKagents\"\"\"\n</code></pre> <code></code> sk_agents.exceptions.InvalidConfigException <p>               Bases: <code>AgentsException</code></p> <p>Exception raised when the provided configuration is invalid</p> Source code in <code>src/sk_agents/exceptions.py</code> <pre><code>class InvalidConfigException(AgentsException):\n    \"\"\"Exception raised when the provided configuration is invalid\"\"\"\n\n    message: str\n\n    def __init__(self, message: str):\n        self.message = message\n</code></pre> <code></code> sk_agents.exceptions.InvalidInputException <p>               Bases: <code>AgentsException</code></p> <p>Exception raised when the provided input type is invalid</p> Source code in <code>src/sk_agents/exceptions.py</code> <pre><code>class InvalidInputException(AgentsException):\n    \"\"\"Exception raised when the provided input type is invalid\"\"\"\n\n    message: str\n\n    def __init__(self, message: str):\n        self.message = message\n</code></pre> <code></code> sk_agents.exceptions.AgentInvokeException <p>               Bases: <code>AgentsException</code></p> <p>Exception raised when invoking an Agent failed</p> Source code in <code>src/sk_agents/exceptions.py</code> <pre><code>class AgentInvokeException(AgentsException):\n    \"\"\"Exception raised when invoking an Agent failed\"\"\"\n\n    message: str\n\n    def __init__(self, message: str):\n        self.message = message\n</code></pre> <code></code> sk_agents.exceptions.PersistenceCreateError <p>               Bases: <code>AgentsException</code></p> <p>Exception raised for errors during task creation.</p> Source code in <code>src/sk_agents/exceptions.py</code> <pre><code>class PersistenceCreateError(AgentsException):\n    \"\"\"Exception raised for errors during task creation.\"\"\"\n\n    message: str\n\n    def __init__(self, message: str):\n        self.message = message\n</code></pre> <code></code> sk_agents.exceptions.PersistenceLoadError <p>               Bases: <code>AgentsException</code></p> <p>Exception raised for errors during task loading.</p> Source code in <code>src/sk_agents/exceptions.py</code> <pre><code>class PersistenceLoadError(AgentsException):\n    \"\"\"Exception raised for errors during task loading.\"\"\"\n\n    message: str\n\n    def __init__(self, message: str):\n        self.message = message\n</code></pre> <code></code> sk_agents.exceptions.PersistenceUpdateError <p>               Bases: <code>AgentsException</code></p> <p>Exception raised for errors during task update.</p> Source code in <code>src/sk_agents/exceptions.py</code> <pre><code>class PersistenceUpdateError(AgentsException):\n    \"\"\"Exception raised for errors during task update.\"\"\"\n\n    message: str\n\n    def __init__(self, message: str):\n        self.message = message\n</code></pre> <code></code> sk_agents.exceptions.PersistenceDeleteError <p>               Bases: <code>AgentsException</code></p> <p>Exception raised for errors during task deletion.</p> Source code in <code>src/sk_agents/exceptions.py</code> <pre><code>class PersistenceDeleteError(AgentsException):\n    \"\"\"Exception raised for errors during task deletion.\"\"\"\n\n    message: str\n\n    def __init__(self, message: str):\n        self.message = message\n</code></pre> <code></code> sk_agents.exceptions.AuthenticationException <p>               Bases: <code>AgentsException</code></p> <p>Exception raised errors when authenticating users</p> Source code in <code>src/sk_agents/exceptions.py</code> <pre><code>class AuthenticationException(AgentsException):\n    \"\"\"Exception raised errors when authenticating users\"\"\"\n\n    message: str\n\n    def __init__(self, message: str):\n        self.message = message\n</code></pre> <code></code> sk_agents.exceptions.PluginCatalogDefinitionException <p>               Bases: <code>AgentsException</code></p> <p>Exception raised when the parsed json does not match the PluginCatalogDefinition Model</p> Source code in <code>src/sk_agents/exceptions.py</code> <pre><code>class PluginCatalogDefinitionException(AgentsException):\n    \"\"\"Exception raised when the parsed json does not match the PluginCatalogDefinition Model\"\"\"\n\n    message: str\n\n    def __init__(self, message: str):\n        self.message = message\n</code></pre> <code></code> sk_agents.exceptions.PluginFileReadException <p>               Bases: <code>AgentsException</code></p> <p>Raise this exception when the plugin file fails to be read</p> Source code in <code>src/sk_agents/exceptions.py</code> <pre><code>class PluginFileReadException(AgentsException):\n    \"\"\"Raise this exception when the plugin file fails to be read\"\"\"\n\n    message: str\n\n    def __init__(self, message: str):\n        self.message = message\n</code></pre>"},{"location":"reference/#sk_agents.hitl","title":"sk_agents.hitl","text":"sk_agents.hitl.hitl_manager sk_agents.hitl.hitl_manager.HitlInterventionRequired <p>               Bases: <code>Exception</code></p> <p>Exception raised when a tool call requires human-in-the-loop intervention.</p> Source code in <code>src/sk_agents/hitl/hitl_manager.py</code> <pre><code>class HitlInterventionRequired(Exception):\n    \"\"\"\n    Exception raised when a tool call\n    requires human-in-the-loop intervention.\n    \"\"\"\n\n    def __init__(self, function_calls: list[FunctionCallContent]):\n        self.function_calls = function_calls\n        if function_calls:\n            self.plugin_name = function_calls[0].plugin_name\n            self.function_name = function_calls[0].function_name\n            message = f\"HITL intervention required for {self.plugin_name}.{self.function_name}\"\n\n        else:\n            message = \"HITL intervention required but no function calls provided (internal error)\"\n        super().__init__(message)\n</code></pre> <code></code> sk_agents.hitl.hitl_manager.check_for_intervention <pre><code>check_for_intervention(\n    tool_call: FunctionCallContent,\n) -&gt; bool\n</code></pre> <p>Checks the plugin catalog to determine if a tool call requires Human-in-the-Loop intervention.</p> Source code in <code>src/sk_agents/hitl/hitl_manager.py</code> <pre><code>def check_for_intervention(tool_call: FunctionCallContent) -&gt; bool:\n    \"\"\"\n    Checks the plugin catalog to determine if a tool call requires\n    Human-in-the-Loop intervention.\n    \"\"\"\n    plugin_factory = PluginCatalogFactory()\n    catalog = plugin_factory.get_catalog()\n    if not catalog:\n        # Fallback if catalog is not configured\n        return False\n\n    tool_id = f\"{tool_call.plugin_name}-{tool_call.function_name}\"\n    tool = catalog.get_tool(tool_id)\n\n    if tool:\n        logger.debug(\n            f\"HITL Check: Intercepted call to {tool_id}. \"\n            f\"Requires HITL: {tool.governance.requires_hitl}\"\n        )\n        return tool.governance.requires_hitl\n    # Default to no intervention if tool is not in the catalog\n    return False\n</code></pre>"},{"location":"reference/#sk_agents.mcp_client","title":"sk_agents.mcp_client","text":"<p>MCP Client for Teal Agents Platform - Clean Implementation</p> <p>This module provides an MCP (Model Context Protocol) client that supports only the transports that are actually available in the MCP Python SDK.</p> <p>ONLY SUPPORTED TRANSPORTS: - stdio: Local subprocess communication - http: HTTP with Server-Sent Events for remote servers</p> <p>WebSocket support will be added when it becomes available in the MCP SDK.</p> sk_agents.mcp_client.AuthRequiredError <p>               Bases: <code>Exception</code></p> <p>Exception raised when MCP server authentication is required but missing.</p> <p>This exception is raised during discovery when a server requires authentication (has auth_server + scopes configured) but the user has no valid token in AuthStorage.</p> Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>class AuthRequiredError(Exception):\n    \"\"\"\n    Exception raised when MCP server authentication is required but missing.\n\n    This exception is raised during discovery when a server requires authentication\n    (has auth_server + scopes configured) but the user has no valid token in AuthStorage.\n    \"\"\"\n\n    def __init__(self, server_name: str, auth_server: str, scopes: list[str], message: str = None):\n        self.server_name = server_name\n        self.auth_server = auth_server\n        self.scopes = scopes\n        self.message = message or f\"Authentication required for MCP server '{server_name}'\"\n        super().__init__(self.message)\n</code></pre> <code></code> sk_agents.mcp_client.McpConnectionManager <p>Request-scoped connection manager for MCP servers.</p> <p>Manages MCP connections within a single agent invoke() request scope: - Lazy connection establishment (connect on first tool call per server) - Connection reuse within the request (all tools on same server share connection) - Automatic cleanup at request end - Session ID persistence via state manager for cross-request continuity</p> Lifecycle <ol> <li>Created at start of invoke() request</li> <li>Connections created lazily when first tool from server is called</li> <li>Connections reused for all subsequent tool calls in same request</li> <li>Cleanup at end of invoke() - close connections, persist session IDs</li> </ol> Usage <p>async with McpConnectionManager(servers, user_id, ...) as conn_mgr:     session = await conn_mgr.get_or_create_session(server_name)     result = await session.call_tool(tool_name, args)</p> Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>class McpConnectionManager:\n    \"\"\"\n    Request-scoped connection manager for MCP servers.\n\n    Manages MCP connections within a single agent invoke() request scope:\n    - Lazy connection establishment (connect on first tool call per server)\n    - Connection reuse within the request (all tools on same server share connection)\n    - Automatic cleanup at request end\n    - Session ID persistence via state manager for cross-request continuity\n\n    Lifecycle:\n        1. Created at start of invoke() request\n        2. Connections created lazily when first tool from server is called\n        3. Connections reused for all subsequent tool calls in same request\n        4. Cleanup at end of invoke() - close connections, persist session IDs\n\n    Usage:\n        async with McpConnectionManager(servers, user_id, ...) as conn_mgr:\n            session = await conn_mgr.get_or_create_session(server_name)\n            result = await session.call_tool(tool_name, args)\n    \"\"\"\n\n    def __init__(\n        self,\n        server_configs: dict[str, McpServerConfig],\n        user_id: str,\n        session_id: str,\n        state_manager=None,  # McpStateManager for session ID persistence\n        app_config: AppConfig = None,\n    ):\n        self._server_configs = server_configs\n        self._user_id = user_id\n        self._session_id = session_id\n        self._state_manager = state_manager\n        self._app_config = app_config\n\n        # Active connections (created lazily)\n        self._sessions: dict[str, ClientSession] = {}\n        self._get_session_id_callbacks: dict[str, Callable[[], str | None]] = {}\n        self._connection_stack: AsyncExitStack | None = None\n\n        # Stored session IDs from previous requests\n        self._stored_session_ids: dict[str, str] = {}\n\n    async def __aenter__(self) -&gt; \"McpConnectionManager\":\n        \"\"\"Enter context - initialize and load stored session IDs.\"\"\"\n        self._connection_stack = AsyncExitStack()\n        await self._connection_stack.__aenter__()\n\n        # Pre-load stored session IDs for all configured servers\n        if self._state_manager:\n            for server_name in self._server_configs:\n                try:\n                    stored_id = await self._state_manager.get_mcp_session(\n                        self._user_id, self._session_id, server_name\n                    )\n                    if stored_id:\n                        self._stored_session_ids[server_name] = stored_id\n                        logger.debug(f\"Loaded stored MCP session for {server_name}\")\n                except Exception as e:\n                    logger.debug(f\"Could not load stored session for {server_name}: {e}\")\n\n        return self\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Exit context - persist session IDs and cleanup connections.\"\"\"\n        try:\n            # Persist session IDs for servers that were connected\n            if self._state_manager:\n                for server_name, get_session_id in self._get_session_id_callbacks.items():\n                    try:\n                        current_id = get_session_id() if get_session_id else None\n                        if current_id:\n                            await self._state_manager.store_mcp_session(\n                                self._user_id, self._session_id, server_name, current_id\n                            )\n                            logger.debug(f\"Persisted MCP session for {server_name}\")\n                    except Exception as e:\n                        logger.warning(f\"Failed to persist MCP session for {server_name}: {e}\")\n        finally:\n            # Close all connections\n            if self._connection_stack:\n                try:\n                    await self._connection_stack.__aexit__(exc_type, exc_val, exc_tb)\n                except RuntimeError as e:\n                    # Handle anyio task affinity errors gracefully.\n                    # This can happen when the connection manager is used across\n                    # recursive handler calls that change the async task context.\n                    # The MCP SDK's streamablehttp_client uses anyio.create_task_group()\n                    # which requires entering/exiting in the same async task.\n                    err_str = str(e)\n                    if \"cancel scope\" in err_str and \"different task\" in err_str:\n                        logger.warning(\n                            f\"MCP cleanup encountered task affinity issue (non-fatal): {e}\"\n                        )\n                    else:\n                        raise\n            self._sessions.clear()\n            self._get_session_id_callbacks.clear()\n\n    async def get_or_create_session(self, server_name: str) -&gt; ClientSession:\n        \"\"\"\n        Get existing session or create new one for server (lazy connection).\n\n        Args:\n            server_name: Name of the MCP server\n\n        Returns:\n            Active MCP ClientSession for the server\n        \"\"\"\n        if server_name in self._sessions:\n            logger.debug(f\"Reusing MCP session for {server_name}\")\n            return self._sessions[server_name]\n\n        server_config = self._server_configs.get(server_name)\n        if not server_config:\n            raise ValueError(f\"Unknown MCP server: {server_name}\")\n\n        if not self._connection_stack:\n            raise RuntimeError(\"McpConnectionManager must be used as async context manager\")\n\n        stored_session_id = self._stored_session_ids.get(server_name)\n\n        session, get_session_id = await create_mcp_session_with_retry(\n            server_config,\n            self._connection_stack,\n            self._user_id,\n            mcp_session_id=stored_session_id,\n            on_stale_session=self._create_stale_handler(server_name),\n            app_config=self._app_config,\n        )\n\n        self._sessions[server_name] = session\n        self._get_session_id_callbacks[server_name] = get_session_id\n        logger.info(f\"Created MCP session for {server_name}\")\n        return session\n\n    def _create_stale_handler(self, server_name: str) -&gt; Callable[[str], Awaitable[None]]:\n        \"\"\"Create callback to handle stale session ID.\"\"\"\n\n        async def handler(stale_id: str):\n            logger.info(f\"Clearing stale MCP session for {server_name}\")\n            if self._state_manager:\n                try:\n                    await self._state_manager.clear_mcp_session(\n                        self._user_id, self._session_id, server_name, expected_session_id=stale_id\n                    )\n                except Exception as e:\n                    logger.debug(f\"Failed to clear stale session: {e}\")\n            self._stored_session_ids.pop(server_name, None)\n\n        return handler\n\n    def has_active_session(self, server_name: str) -&gt; bool:\n        \"\"\"Check if server has an active session in this request.\"\"\"\n        return server_name in self._sessions\n\n    def get_active_servers(self) -&gt; list[str]:\n        \"\"\"Get list of servers with active sessions.\"\"\"\n        return list(self._sessions.keys())\n</code></pre> <code></code> sk_agents.mcp_client.McpConnectionManager.__aenter__ <code>async</code> <pre><code>__aenter__() -&gt; McpConnectionManager\n</code></pre> <p>Enter context - initialize and load stored session IDs.</p> Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>async def __aenter__(self) -&gt; \"McpConnectionManager\":\n    \"\"\"Enter context - initialize and load stored session IDs.\"\"\"\n    self._connection_stack = AsyncExitStack()\n    await self._connection_stack.__aenter__()\n\n    # Pre-load stored session IDs for all configured servers\n    if self._state_manager:\n        for server_name in self._server_configs:\n            try:\n                stored_id = await self._state_manager.get_mcp_session(\n                    self._user_id, self._session_id, server_name\n                )\n                if stored_id:\n                    self._stored_session_ids[server_name] = stored_id\n                    logger.debug(f\"Loaded stored MCP session for {server_name}\")\n            except Exception as e:\n                logger.debug(f\"Could not load stored session for {server_name}: {e}\")\n\n    return self\n</code></pre> <code></code> sk_agents.mcp_client.McpConnectionManager.__aexit__ <code>async</code> <pre><code>__aexit__(exc_type, exc_val, exc_tb)\n</code></pre> <p>Exit context - persist session IDs and cleanup connections.</p> Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>async def __aexit__(self, exc_type, exc_val, exc_tb):\n    \"\"\"Exit context - persist session IDs and cleanup connections.\"\"\"\n    try:\n        # Persist session IDs for servers that were connected\n        if self._state_manager:\n            for server_name, get_session_id in self._get_session_id_callbacks.items():\n                try:\n                    current_id = get_session_id() if get_session_id else None\n                    if current_id:\n                        await self._state_manager.store_mcp_session(\n                            self._user_id, self._session_id, server_name, current_id\n                        )\n                        logger.debug(f\"Persisted MCP session for {server_name}\")\n                except Exception as e:\n                    logger.warning(f\"Failed to persist MCP session for {server_name}: {e}\")\n    finally:\n        # Close all connections\n        if self._connection_stack:\n            try:\n                await self._connection_stack.__aexit__(exc_type, exc_val, exc_tb)\n            except RuntimeError as e:\n                # Handle anyio task affinity errors gracefully.\n                # This can happen when the connection manager is used across\n                # recursive handler calls that change the async task context.\n                # The MCP SDK's streamablehttp_client uses anyio.create_task_group()\n                # which requires entering/exiting in the same async task.\n                err_str = str(e)\n                if \"cancel scope\" in err_str and \"different task\" in err_str:\n                    logger.warning(\n                        f\"MCP cleanup encountered task affinity issue (non-fatal): {e}\"\n                    )\n                else:\n                    raise\n        self._sessions.clear()\n        self._get_session_id_callbacks.clear()\n</code></pre> <code></code> sk_agents.mcp_client.McpConnectionManager.get_or_create_session <code>async</code> <pre><code>get_or_create_session(server_name: str) -&gt; ClientSession\n</code></pre> <p>Get existing session or create new one for server (lazy connection).</p> <p>Parameters:</p> Name Type Description Default <code>server_name</code> <code>str</code> <p>Name of the MCP server</p> required <p>Returns:</p> Type Description <code>ClientSession</code> <p>Active MCP ClientSession for the server</p> Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>async def get_or_create_session(self, server_name: str) -&gt; ClientSession:\n    \"\"\"\n    Get existing session or create new one for server (lazy connection).\n\n    Args:\n        server_name: Name of the MCP server\n\n    Returns:\n        Active MCP ClientSession for the server\n    \"\"\"\n    if server_name in self._sessions:\n        logger.debug(f\"Reusing MCP session for {server_name}\")\n        return self._sessions[server_name]\n\n    server_config = self._server_configs.get(server_name)\n    if not server_config:\n        raise ValueError(f\"Unknown MCP server: {server_name}\")\n\n    if not self._connection_stack:\n        raise RuntimeError(\"McpConnectionManager must be used as async context manager\")\n\n    stored_session_id = self._stored_session_ids.get(server_name)\n\n    session, get_session_id = await create_mcp_session_with_retry(\n        server_config,\n        self._connection_stack,\n        self._user_id,\n        mcp_session_id=stored_session_id,\n        on_stale_session=self._create_stale_handler(server_name),\n        app_config=self._app_config,\n    )\n\n    self._sessions[server_name] = session\n    self._get_session_id_callbacks[server_name] = get_session_id\n    logger.info(f\"Created MCP session for {server_name}\")\n    return session\n</code></pre> <code></code> sk_agents.mcp_client.McpConnectionManager.has_active_session <pre><code>has_active_session(server_name: str) -&gt; bool\n</code></pre> <p>Check if server has an active session in this request.</p> Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>def has_active_session(self, server_name: str) -&gt; bool:\n    \"\"\"Check if server has an active session in this request.\"\"\"\n    return server_name in self._sessions\n</code></pre> <code></code> sk_agents.mcp_client.McpConnectionManager.get_active_servers <pre><code>get_active_servers() -&gt; list[str]\n</code></pre> <p>Get list of servers with active sessions.</p> Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>def get_active_servers(self) -&gt; list[str]:\n    \"\"\"Get list of servers with active sessions.\"\"\"\n    return list(self._sessions.keys())\n</code></pre> <code></code> sk_agents.mcp_client.McpTool <p>Stateless wrapper for MCP tools to make them compatible with Semantic Kernel.</p> <p>This class stores the server configuration and tool metadata, but does NOT store active connections. Each invocation creates a temporary connection.</p> Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>class McpTool:\n    \"\"\"\n    Stateless wrapper for MCP tools to make them compatible with Semantic Kernel.\n\n    This class stores the server configuration and tool metadata, but does NOT\n    store active connections. Each invocation creates a temporary connection.\n    \"\"\"\n\n    def __init__(\n        self,\n        tool_name: str,\n        description: str,\n        input_schema: dict[str, Any],\n        output_schema: dict[str, Any] | None,\n        server_config: \"McpServerConfig\",\n        server_name: str,\n    ):\n        \"\"\"\n        Initialize stateless MCP tool.\n\n        Args:\n            tool_name: Name of the MCP tool\n            description: Tool description\n            input_schema: JSON schema for tool inputs\n            output_schema: JSON schema for tool outputs (optional)\n            server_config: MCP server configuration (for reconnection)\n            server_name: Name of the MCP server\n        \"\"\"\n        self.tool_name = tool_name\n        self.description = description\n        self.input_schema = input_schema\n        self.output_schema = output_schema\n        self.server_config = server_config\n        self.server_name = server_name\n        self.app_config: AppConfig | None = None  # Set via McpPlugin at instantiation time\n\n    async def invoke(\n        self,\n        connection_manager: \"McpConnectionManager\",\n        **kwargs,\n    ) -&gt; str:\n        \"\"\"\n        Invoke the MCP tool using a request-scoped connection manager.\n\n        Args:\n            connection_manager: Request-scoped connection manager for connection reuse\n            **kwargs: Tool arguments\n\n        Returns:\n            Tool execution result as string\n\n        Raises:\n            ValueError: If connection_manager is not provided\n            RuntimeError: If tool execution fails\n        \"\"\"\n        if not connection_manager:\n            raise ValueError(\n                f\"connection_manager is required for MCP tool invocation. \"\n                f\"Tool '{self.tool_name}' cannot be invoked without a connection manager.\"\n            )\n\n        try:\n            if self.input_schema:\n                self._validate_inputs(kwargs)\n\n            logger.debug(f\"Executing MCP tool: {self.server_name}.{self.tool_name}\")\n            session = await connection_manager.get_or_create_session(self.server_name)\n            result = await session.call_tool(self.tool_name, kwargs)\n            parsed = self._parse_result(result)\n            logger.debug(f\"MCP tool {self.tool_name} completed successfully\")\n            return parsed\n\n        except ValueError:\n            # Re-raise validation errors as-is\n            raise\n        except Exception as e:\n            logger.error(f\"Error invoking MCP tool {self.tool_name}: {e}\")\n\n            error_msg = str(e).lower()\n            if \"timeout\" in error_msg:\n                raise RuntimeError(\n                    f\"MCP tool '{self.tool_name}' timed out. Check server responsiveness.\"\n                ) from e\n            elif \"connection\" in error_msg:\n                raise RuntimeError(\n                    f\"MCP tool '{self.tool_name}' connection failed. Check server availability.\"\n                ) from e\n            else:\n                raise RuntimeError(f\"MCP tool '{self.tool_name}' failed: {e}\") from e\n\n    def _parse_result(self, result: Any) -&gt; str:\n        \"\"\"Parse MCP result into string format.\"\"\"\n        if hasattr(result, \"content\"):\n            if isinstance(result.content, list) and len(result.content) &gt; 0:\n                return (\n                    str(result.content[0].text)\n                    if hasattr(result.content[0], \"text\")\n                    else str(result.content[0])\n                )\n            return str(result.content)\n        elif hasattr(result, \"text\"):\n            return result.text\n        else:\n            return str(result)\n\n    def _validate_inputs(self, kwargs: dict[str, Any]) -&gt; None:\n        \"\"\"Basic input validation against the tool's JSON schema.\"\"\"\n        if not isinstance(self.input_schema, dict):\n            return\n\n        properties = self.input_schema.get(\"properties\", {})\n        required = self.input_schema.get(\"required\", [])\n\n        # Check required parameters\n        for req_param in required:\n            if req_param not in kwargs:\n                raise ValueError(\n                    f\"Missing required parameter '{req_param}' for tool '{self.tool_name}'\"\n                )\n\n        # Warn about unexpected parameters\n        for param in kwargs:\n            if param not in properties:\n                logger.warning(f\"Unexpected parameter '{param}' for tool '{self.tool_name}'\")\n</code></pre> <code></code> sk_agents.mcp_client.McpTool.__init__ <pre><code>__init__(\n    tool_name: str,\n    description: str,\n    input_schema: dict[str, Any],\n    output_schema: dict[str, Any] | None,\n    server_config: McpServerConfig,\n    server_name: str,\n)\n</code></pre> <p>Initialize stateless MCP tool.</p> <p>Parameters:</p> Name Type Description Default <code>tool_name</code> <code>str</code> <p>Name of the MCP tool</p> required <code>description</code> <code>str</code> <p>Tool description</p> required <code>input_schema</code> <code>dict[str, Any]</code> <p>JSON schema for tool inputs</p> required <code>output_schema</code> <code>dict[str, Any] | None</code> <p>JSON schema for tool outputs (optional)</p> required <code>server_config</code> <code>McpServerConfig</code> <p>MCP server configuration (for reconnection)</p> required <code>server_name</code> <code>str</code> <p>Name of the MCP server</p> required Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>def __init__(\n    self,\n    tool_name: str,\n    description: str,\n    input_schema: dict[str, Any],\n    output_schema: dict[str, Any] | None,\n    server_config: \"McpServerConfig\",\n    server_name: str,\n):\n    \"\"\"\n    Initialize stateless MCP tool.\n\n    Args:\n        tool_name: Name of the MCP tool\n        description: Tool description\n        input_schema: JSON schema for tool inputs\n        output_schema: JSON schema for tool outputs (optional)\n        server_config: MCP server configuration (for reconnection)\n        server_name: Name of the MCP server\n    \"\"\"\n    self.tool_name = tool_name\n    self.description = description\n    self.input_schema = input_schema\n    self.output_schema = output_schema\n    self.server_config = server_config\n    self.server_name = server_name\n    self.app_config: AppConfig | None = None  # Set via McpPlugin at instantiation time\n</code></pre> <code></code> sk_agents.mcp_client.McpTool.invoke <code>async</code> <pre><code>invoke(\n    connection_manager: McpConnectionManager, **kwargs\n) -&gt; str\n</code></pre> <p>Invoke the MCP tool using a request-scoped connection manager.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>McpConnectionManager</code> <p>Request-scoped connection manager for connection reuse</p> required <code>**kwargs</code> <p>Tool arguments</p> <code>{}</code> <p>Returns:</p> Type Description <code>str</code> <p>Tool execution result as string</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If connection_manager is not provided</p> <code>RuntimeError</code> <p>If tool execution fails</p> Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>async def invoke(\n    self,\n    connection_manager: \"McpConnectionManager\",\n    **kwargs,\n) -&gt; str:\n    \"\"\"\n    Invoke the MCP tool using a request-scoped connection manager.\n\n    Args:\n        connection_manager: Request-scoped connection manager for connection reuse\n        **kwargs: Tool arguments\n\n    Returns:\n        Tool execution result as string\n\n    Raises:\n        ValueError: If connection_manager is not provided\n        RuntimeError: If tool execution fails\n    \"\"\"\n    if not connection_manager:\n        raise ValueError(\n            f\"connection_manager is required for MCP tool invocation. \"\n            f\"Tool '{self.tool_name}' cannot be invoked without a connection manager.\"\n        )\n\n    try:\n        if self.input_schema:\n            self._validate_inputs(kwargs)\n\n        logger.debug(f\"Executing MCP tool: {self.server_name}.{self.tool_name}\")\n        session = await connection_manager.get_or_create_session(self.server_name)\n        result = await session.call_tool(self.tool_name, kwargs)\n        parsed = self._parse_result(result)\n        logger.debug(f\"MCP tool {self.tool_name} completed successfully\")\n        return parsed\n\n    except ValueError:\n        # Re-raise validation errors as-is\n        raise\n    except Exception as e:\n        logger.error(f\"Error invoking MCP tool {self.tool_name}: {e}\")\n\n        error_msg = str(e).lower()\n        if \"timeout\" in error_msg:\n            raise RuntimeError(\n                f\"MCP tool '{self.tool_name}' timed out. Check server responsiveness.\"\n            ) from e\n        elif \"connection\" in error_msg:\n            raise RuntimeError(\n                f\"MCP tool '{self.tool_name}' connection failed. Check server availability.\"\n            ) from e\n        else:\n            raise RuntimeError(f\"MCP tool '{self.tool_name}' failed: {e}\") from e\n</code></pre> <code></code> sk_agents.mcp_client.McpPlugin <p>               Bases: <code>BasePlugin</code></p> <p>Plugin wrapper that holds MCP tools for Semantic Kernel integration.</p> <p>This plugin creates kernel functions with proper type annotations from MCP JSON schemas, allowing Semantic Kernel to expose full parameter information to the LLM.</p> <code></code> sk_agents.mcp_client.build_auth_storage_key <pre><code>build_auth_storage_key(\n    auth_server: str, scopes: list[str]\n) -&gt; str\n</code></pre> <p>Create deterministic key for storing OAuth tokens in AuthStorage.</p> Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>def build_auth_storage_key(auth_server: str, scopes: list[str]) -&gt; str:\n    \"\"\"Create deterministic key for storing OAuth tokens in AuthStorage.\"\"\"\n    normalized_scopes = \"|\".join(sorted(scopes)) if scopes else \"\"\n    return f\"{auth_server}|{normalized_scopes}\" if normalized_scopes else auth_server\n</code></pre> <code></code> sk_agents.mcp_client.normalize_canonical_uri <pre><code>normalize_canonical_uri(uri: str) -&gt; str\n</code></pre> <p>Normalize URI to canonical format for MCP resource parameter.</p> <p>Per MCP specification, canonical URI must be: - Absolute URI with scheme - Lowercase scheme and host - Optional port (only if non-standard) - Optional path</p> <p>Examples:</p> <p>\"HTTPS://API.Example.COM/mcp\" -&gt; \"https://api.example.com/mcp\" \"https://example.com:443/mcp\" -&gt; \"https://example.com/mcp\" \"https://example.com:8443/mcp\" -&gt; \"https://example.com:8443/mcp\"</p> <p>Parameters:</p> Name Type Description Default <code>uri</code> <code>str</code> <p>URI to normalize</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Normalized canonical URI</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If URI is invalid or not absolute</p> Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>def normalize_canonical_uri(uri: str) -&gt; str:\n    \"\"\"\n    Normalize URI to canonical format for MCP resource parameter.\n\n    Per MCP specification, canonical URI must be:\n    - Absolute URI with scheme\n    - Lowercase scheme and host\n    - Optional port (only if non-standard)\n    - Optional path\n\n    Examples:\n        \"HTTPS://API.Example.COM/mcp\" -&gt; \"https://api.example.com/mcp\"\n        \"https://example.com:443/mcp\" -&gt; \"https://example.com/mcp\"\n        \"https://example.com:8443/mcp\" -&gt; \"https://example.com:8443/mcp\"\n\n    Args:\n        uri: URI to normalize\n\n    Returns:\n        str: Normalized canonical URI\n\n    Raises:\n        ValueError: If URI is invalid or not absolute\n    \"\"\"\n    from urllib.parse import urlparse, urlunparse\n\n    if not uri:\n        raise ValueError(\"URI cannot be empty\")\n\n    # Parse URI\n    try:\n        parsed = urlparse(uri)\n    except Exception as e:\n        raise ValueError(f\"Invalid URI format: {e}\") from e\n\n    # Require absolute URI with scheme\n    if not parsed.scheme:\n        raise ValueError(f\"URI must be absolute with scheme (got: {uri})\")\n\n    # Require host\n    if not parsed.netloc:\n        raise ValueError(f\"URI must have a host component (got: {uri})\")\n\n    # Normalize scheme and host to lowercase\n    scheme = parsed.scheme.lower()\n    netloc = parsed.netloc.lower()\n\n    # Remove default ports (80 for http, 443 for https)\n    if \":\" in netloc:\n        host, port = netloc.rsplit(\":\", 1)\n        try:\n            port_num = int(port)\n            # Remove default ports\n            if (scheme == \"http\" and port_num == 80) or (scheme == \"https\" and port_num == 443):\n                netloc = host\n        except ValueError:\n            # Not a valid port number, keep as is\n            pass\n\n    # Reconstruct canonical URI\n    canonical = urlunparse(\n        (\n            scheme,\n            netloc,\n            parsed.path or \"\",  # Include path if present\n            \"\",  # No params\n            \"\",  # No query\n            \"\",  # No fragment\n        )\n    )\n\n    logger.debug(f\"Normalized canonical URI: {uri} -&gt; {canonical}\")\n    return canonical\n</code></pre> <code></code> sk_agents.mcp_client.validate_https_url <pre><code>validate_https_url(\n    url: str, allow_localhost: bool = True\n) -&gt; bool\n</code></pre> <p>Validate that URL uses HTTPS (or localhost for development).</p> <p>Per MCP spec and OAuth 2.1, all endpoints must use HTTPS except localhost.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>URL to validate</p> required <code>allow_localhost</code> <code>bool</code> <p>Allow http://localhost or http://127.0.0.1</p> <code>True</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if valid, False otherwise</p> Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>def validate_https_url(url: str, allow_localhost: bool = True) -&gt; bool:\n    \"\"\"\n    Validate that URL uses HTTPS (or localhost for development).\n\n    Per MCP spec and OAuth 2.1, all endpoints must use HTTPS except localhost.\n\n    Args:\n        url: URL to validate\n        allow_localhost: Allow http://localhost or http://127.0.0.1\n\n    Returns:\n        bool: True if valid, False otherwise\n    \"\"\"\n    from urllib.parse import urlparse\n\n    try:\n        parsed = urlparse(url)\n        scheme = parsed.scheme.lower()\n        hostname = parsed.hostname\n\n        # HTTPS is always valid\n        if scheme == \"https\":\n            return True\n\n        # HTTP is only valid for localhost/127.0.0.1/::1 if allowed\n        if scheme == \"http\" and allow_localhost:\n            if hostname in (\"localhost\", \"127.0.0.1\", \"::1\"):\n                return True\n\n        return False\n    except Exception:\n        return False\n</code></pre> <code></code> sk_agents.mcp_client.get_package_version <pre><code>get_package_version() -&gt; str\n</code></pre> <p>Get package version for MCP client identification.</p> Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>def get_package_version() -&gt; str:\n    \"\"\"Get package version for MCP client identification.\"\"\"\n    try:\n        from importlib.metadata import version\n\n        return version(\"sk-agents\")\n    except Exception:\n        return \"1.0.0\"  # Fallback version\n</code></pre> <code></code> sk_agents.mcp_client.validate_mcp_sdk_version <pre><code>validate_mcp_sdk_version() -&gt; None\n</code></pre> <p>Validate MCP SDK version compatibility.</p> <p>Logs warnings if the installed MCP SDK version is too old to support all features.</p> Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>def validate_mcp_sdk_version() -&gt; None:\n    \"\"\"\n    Validate MCP SDK version compatibility.\n\n    Logs warnings if the installed MCP SDK version is too old to support all features.\n    \"\"\"\n    try:\n        import mcp\n\n        version_str = getattr(mcp, \"__version__\", \"0.0.0\")\n\n        # Parse version components\n        try:\n            from packaging import version as pkg_version\n\n            installed_version = pkg_version.parse(version_str)\n            required_version = pkg_version.parse(\"1.23.0\")\n\n            if installed_version &lt; required_version:\n                logger.warning(\n                    f\"MCP SDK version {version_str} detected. \"\n                    f\"Required: &gt;= 1.23.0 for MCP spec 2025-11-25. \"\n                    f\"Please upgrade the MCP SDK.\"\n                )\n            else:\n                logger.debug(f\"MCP SDK version {version_str} is compatible\")\n        except ImportError:\n            # packaging not available, do basic string comparison\n            logger.debug(f\"MCP SDK version {version_str} (could not validate compatibility)\")\n    except Exception as e:\n        logger.warning(f\"Could not validate MCP SDK version: {e}\")\n</code></pre> <code></code> sk_agents.mcp_client.initialize_mcp_session <code>async</code> <pre><code>initialize_mcp_session(\n    session: ClientSession,\n    server_name: str,\n    server_info_obj: Any = None,\n    protocol_version: str = \"2025-11-25\",\n) -&gt; Any\n</code></pre> <p>Initialize MCP session with proper protocol handshake.</p> <p>This function handles the complete MCP initialization sequence: 1. Send initialize request with protocol version and capabilities 2. Receive initialization result from server 3. Send initialized notification (required by MCP spec)</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>ClientSession</code> <p>The MCP ClientSession to initialize</p> required <code>server_name</code> <code>str</code> <p>Name of the server for logging purposes</p> required <code>server_info_obj</code> <code>Any</code> <p>Optional server info object for logging</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>The initialization result from the server</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If initialization fails</p> Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>async def initialize_mcp_session(\n    session: ClientSession,\n    server_name: str,\n    server_info_obj: Any = None,\n    protocol_version: str = \"2025-11-25\",\n) -&gt; Any:\n    \"\"\"\n    Initialize MCP session with proper protocol handshake.\n\n    This function handles the complete MCP initialization sequence:\n    1. Send initialize request with protocol version and capabilities\n    2. Receive initialization result from server\n    3. Send initialized notification (required by MCP spec)\n\n    Args:\n        session: The MCP ClientSession to initialize\n        server_name: Name of the server for logging purposes\n        server_info_obj: Optional server info object for logging\n\n    Returns:\n        The initialization result from the server\n\n    Raises:\n        ConnectionError: If initialization fails\n    \"\"\"\n    try:\n        # Step 1: Send initialize request (prefers spec path, falls back if SDK lacks args)\n        try:\n            init_result = await session.initialize(\n                protocol_version=protocol_version,\n                client_info={\"name\": \"teal-agents\", \"version\": get_package_version()},\n                capabilities={\n                    # Per MCP spec 2025-11-25: advertise root change notifications if supported\n                    \"roots\": {\"listChanged\": True},\n                    \"sampling\": {},\n                    \"experimental\": {},\n                },\n            )\n        except TypeError as e:\n            # Older SDKs (&lt;=1.22) don't accept keyword args; degrade gracefully.\n            if \"unexpected keyword argument 'protocol_version'\" in str(e):\n                logger.warning(\n                    f\"MCP SDK initialize() does not accept protocol_version/capabilities; \"\n                    f\"falling back to legacy initialize() for '{server_name}'. \"\n                    f\"Upgrade SDK for full 2025-11-25 compliance.\"\n                )\n                init_result = await session.initialize()\n            else:\n                raise\n\n        logger.info(\n            f\"MCP session initialized for '{server_name}': \"\n            f\"server={getattr(init_result, 'server_info', 'unknown')}, \"\n            f\"protocol={getattr(init_result, 'protocol_version', 'unknown')}\"\n        )\n\n        # Step 2: Send initialized notification (MCP protocol requirement)\n        # Per MCP spec: \"After successful initialization, the client MUST send\n        # an initialized notification to indicate it is ready to begin normal operations.\"\n        # The spec requires an initialized notification; if SDK lacks it, warn and continue.\n        if hasattr(session, \"send_initialized\"):\n            await session.send_initialized()\n            logger.debug(f\"Sent initialized notification to '{server_name}'\")\n        elif hasattr(session, \"initialized\"):\n            await session.initialized()\n            logger.debug(f\"Sent initialized notification to '{server_name}'\")\n        else:\n            logger.warning(\n                f\"MCP SDK missing initialized notification method for '{server_name}'. \"\n                f\"Upgrade SDK for full spec compliance.\"\n            )\n\n        return init_result\n\n    except Exception as e:\n        logger.error(f\"Failed to initialize MCP session for '{server_name}': {e}\")\n        raise ConnectionError(f\"MCP session initialization failed for '{server_name}': {e}\") from e\n</code></pre> <code></code> sk_agents.mcp_client.graceful_shutdown_session <code>async</code> <pre><code>graceful_shutdown_session(\n    session: ClientSession, server_name: str\n) -&gt; None\n</code></pre> <p>Attempt graceful MCP session shutdown.</p> <p>Per MCP spec, clients should attempt to notify servers before disconnecting. This is a best-effort operation and failures are logged but not raised.</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>ClientSession</code> <p>The MCP ClientSession to shutdown</p> required <code>server_name</code> <code>str</code> <p>Name of the server for logging purposes</p> required Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>async def graceful_shutdown_session(session: ClientSession, server_name: str) -&gt; None:\n    \"\"\"\n    Attempt graceful MCP session shutdown.\n\n    Per MCP spec, clients should attempt to notify servers before disconnecting.\n    This is a best-effort operation and failures are logged but not raised.\n\n    Args:\n        session: The MCP ClientSession to shutdown\n        server_name: Name of the server for logging purposes\n    \"\"\"\n    try:\n        if hasattr(session, \"send_shutdown\"):\n            await session.send_shutdown()\n            logger.debug(f\"Sent graceful shutdown to MCP server: {server_name}\")\n        elif hasattr(session, \"shutdown\"):\n            await session.shutdown()\n            logger.debug(f\"Sent graceful shutdown to MCP server: {server_name}\")\n        else:\n            logger.warning(\n                f\"MCP SDK missing shutdown method for '{server_name}'. \"\n                f\"Upgrade SDK for full spec compliance.\"\n            )\n    except Exception as e:\n        logger.debug(f\"Graceful shutdown failed for {server_name}: {e}\")\n</code></pre> <code></code> sk_agents.mcp_client.map_mcp_annotations_to_governance <pre><code>map_mcp_annotations_to_governance(\n    annotations: dict[str, Any], tool_description: str = \"\"\n) -&gt; Governance\n</code></pre> <p>Map MCP tool annotations to Teal Agents governance policies using secure-by-default approach.</p> <p>Parameters:</p> Name Type Description Default <code>annotations</code> <code>dict[str, Any]</code> <p>MCP tool annotations</p> required <code>tool_description</code> <code>str</code> <p>Tool description for risk analysis</p> <code>''</code> <p>Returns:</p> Name Type Description <code>Governance</code> <code>Governance</code> <p>Governance settings for the tool</p> Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>def map_mcp_annotations_to_governance(\n    annotations: dict[str, Any], tool_description: str = \"\"\n) -&gt; Governance:\n    \"\"\"\n    Map MCP tool annotations to Teal Agents governance policies using secure-by-default approach.\n\n    Args:\n        annotations: MCP tool annotations\n        tool_description: Tool description for risk analysis\n\n    Returns:\n        Governance: Governance settings for the tool\n    \"\"\"\n    # SECURE-BY-DEFAULT: Start with HITL required for unknown tools\n    requires_hitl = True\n    cost = \"high\"\n    data_sensitivity = \"sensitive\"\n\n    # Only relax restrictions with explicit safe annotations\n    read_only_hint = annotations.get(\"readOnlyHint\", False)\n    if read_only_hint:\n        requires_hitl = False\n        cost = \"low\"\n        data_sensitivity = \"public\"\n\n    # Destructive tools require HITL (already secure)\n    destructive_hint = annotations.get(\"destructiveHint\", False)\n    if destructive_hint:\n        requires_hitl = True\n        cost = \"high\"\n        data_sensitivity = \"sensitive\"\n\n    # Enhanced risk analysis based on tool description\n    if tool_description:\n        description_lower = tool_description.lower()\n\n        # Network/external access indicators\n        if any(\n            keyword in description_lower\n            for keyword in [\n                \"http\",\n                \"https\",\n                \"api\",\n                \"network\",\n                \"request\",\n                \"fetch\",\n                \"download\",\n                \"upload\",\n                \"url\",\n                \"web\",\n                \"internet\",\n                \"remote\",\n                \"curl\",\n                \"wget\",\n            ]\n        ):\n            requires_hitl = True\n            cost = \"high\"\n            data_sensitivity = \"sensitive\"\n\n        # File system access indicators\n        elif any(\n            keyword in description_lower\n            for keyword in [\n                \"file\",\n                \"directory\",\n                \"write\",\n                \"delete\",\n                \"create\",\n                \"modify\",\n                \"save\",\n                \"remove\",\n                \"mkdir\",\n                \"rmdir\",\n                \"chmod\",\n                \"move\",\n                \"copy\",\n            ]\n        ):\n            requires_hitl = True\n            cost = \"medium\" if not destructive_hint else \"high\"\n            data_sensitivity = \"proprietary\"\n\n        # Code execution indicators\n        elif any(\n            keyword in description_lower\n            for keyword in [\"execute\", \"run\", \"command\", \"shell\", \"bash\", \"script\", \"eval\", \"exec\"]\n        ):\n            requires_hitl = True\n            cost = \"high\"\n            data_sensitivity = \"sensitive\"\n\n        # Database/storage access\n        elif any(\n            keyword in description_lower\n            for keyword in [\"database\", \"sql\", \"query\", \"insert\", \"update\", \"delete\", \"drop\"]\n        ):\n            requires_hitl = True\n            cost = \"high\"\n            data_sensitivity = \"sensitive\"\n\n    return Governance(requires_hitl=requires_hitl, cost=cost, data_sensitivity=data_sensitivity)\n</code></pre> <code></code> sk_agents.mcp_client.apply_trust_level_governance <pre><code>apply_trust_level_governance(\n    base_governance: Governance,\n    trust_level: str,\n    tool_description: str = \"\",\n) -&gt; Governance\n</code></pre> <p>Apply server trust level controls to governance settings.</p> <p>Trust levels provide defense-in-depth by applying additional security controls based on the server's trust relationship with the platform: - untrusted: Maximum restrictions, force HITL for all operations - sandboxed: Enhanced restrictions, HITL required unless explicitly safe - trusted: Base governance applies, but still enforce safety on detected risks</p> <p>Parameters:</p> Name Type Description Default <code>base_governance</code> <code>Governance</code> <p>Base governance settings from MCP annotations</p> required <code>trust_level</code> <code>str</code> <p>Server trust level (\"trusted\", \"sandboxed\", \"untrusted\")</p> required <code>tool_description</code> <code>str</code> <p>Tool description for additional risk analysis</p> <code>''</code> <p>Returns:</p> Name Type Description <code>Governance</code> <code>Governance</code> <p>Governance with trust level controls applied</p> Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>def apply_trust_level_governance(\n    base_governance: Governance, trust_level: str, tool_description: str = \"\"\n) -&gt; Governance:\n    \"\"\"\n    Apply server trust level controls to governance settings.\n\n    Trust levels provide defense-in-depth by applying additional security controls\n    based on the server's trust relationship with the platform:\n    - untrusted: Maximum restrictions, force HITL for all operations\n    - sandboxed: Enhanced restrictions, HITL required unless explicitly safe\n    - trusted: Base governance applies, but still enforce safety on detected risks\n\n    Args:\n        base_governance: Base governance settings from MCP annotations\n        trust_level: Server trust level (\"trusted\", \"sandboxed\", \"untrusted\")\n        tool_description: Tool description for additional risk analysis\n\n    Returns:\n        Governance: Governance with trust level controls applied\n    \"\"\"\n    if trust_level == \"untrusted\":\n        # Force HITL for all tools from untrusted servers\n        logger.debug(\"Applying untrusted server governance: forcing HITL\")\n        return Governance(requires_hitl=True, cost=\"high\", data_sensitivity=\"sensitive\")\n    elif trust_level == \"sandboxed\":\n        # Require HITL unless explicitly marked as safe\n        # Sandboxed servers get elevated restrictions\n        logger.debug(\"Applying sandboxed server governance: elevated restrictions\")\n        return Governance(\n            requires_hitl=True,  # Force HITL for sandboxed servers\n            cost=base_governance.cost\n            if base_governance.cost != \"low\"\n            else \"medium\",  # Elevate cost\n            data_sensitivity=base_governance.data_sensitivity,\n        )\n    else:  # trusted\n        # For trusted servers, use base governance but still enforce safety on high-risk operations\n        # This provides defense-in-depth even for trusted sources\n\n        # Check if tool description indicates high-risk operations\n        # Even for trusted servers, certain operations should require HITL\n        description_lower = tool_description.lower()\n        high_risk_operations = [\n            \"delete\",\n            \"remove\",\n            \"drop\",\n            \"truncate\",\n            \"destroy\",\n            \"kill\",\n            \"execute\",\n            \"exec\",\n            \"eval\",\n            \"run command\",\n            \"shell\",\n            \"system\",\n            \"sudo\",\n            \"admin\",\n            \"root\",\n        ]\n\n        has_high_risk = any(keyword in description_lower for keyword in high_risk_operations)\n\n        if has_high_risk and not base_governance.requires_hitl:\n            # Override for high-risk operations even on trusted servers\n            logger.debug(\n                \"Trusted server tool has high-risk indicators in description, \"\n                \"enforcing HITL despite trust level\"\n            )\n            return Governance(\n                requires_hitl=True,  # Override to require HITL\n                cost=\"high\" if base_governance.cost != \"high\" else base_governance.cost,\n                data_sensitivity=base_governance.data_sensitivity,\n            )\n\n        # For non-high-risk operations on trusted servers, use base governance\n        logger.debug(\"Applying trusted server governance: using base governance\")\n        return base_governance\n</code></pre> <code></code> sk_agents.mcp_client.apply_governance_overrides <pre><code>apply_governance_overrides(\n    base_governance: Governance,\n    tool_name: str,\n    overrides: dict[str, GovernanceOverride] | None,\n) -&gt; Governance\n</code></pre> <p>Apply tool-specific governance overrides to base governance settings.</p> <p>Parameters:</p> Name Type Description Default <code>base_governance</code> <code>Governance</code> <p>Auto-inferred governance from MCP annotations</p> required <code>tool_name</code> <code>str</code> <p>Name of the MCP tool</p> required <code>overrides</code> <code>dict[str, GovernanceOverride] | None</code> <p>Optional governance overrides from server config</p> required <p>Returns:</p> Name Type Description <code>Governance</code> <code>Governance</code> <p>Final governance with overrides applied</p> Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>def apply_governance_overrides(\n    base_governance: Governance, tool_name: str, overrides: dict[str, GovernanceOverride] | None\n) -&gt; Governance:\n    \"\"\"\n    Apply tool-specific governance overrides to base governance settings.\n\n    Args:\n        base_governance: Auto-inferred governance from MCP annotations\n        tool_name: Name of the MCP tool\n        overrides: Optional governance overrides from server config\n\n    Returns:\n        Governance: Final governance with overrides applied\n    \"\"\"\n    if not overrides or tool_name not in overrides:\n        return base_governance\n\n    override = overrides[tool_name]\n\n    # Apply selective overrides - only override specified fields\n    return Governance(\n        requires_hitl=override.requires_hitl\n        if override.requires_hitl is not None\n        else base_governance.requires_hitl,\n        cost=override.cost if override.cost is not None else base_governance.cost,\n        data_sensitivity=override.data_sensitivity\n        if override.data_sensitivity is not None\n        else base_governance.data_sensitivity,\n    )\n</code></pre> <code></code> sk_agents.mcp_client.resolve_server_auth_headers <code>async</code> <pre><code>resolve_server_auth_headers(\n    server_config: McpServerConfig,\n    user_id: str = \"default\",\n    app_config: AppConfig | None = None,\n) -&gt; dict[str, str]\n</code></pre> <p>Resolve authentication headers for MCP server connection.</p> <p>Now supports automatic token refresh with OAuth 2.1 compliance: - Validates token audience matches resource - Automatically refreshes expired tokens - Implements token rotation per OAuth 2.1</p> <p>Parameters:</p> Name Type Description Default <code>server_config</code> <code>McpServerConfig</code> <p>MCP server configuration</p> required <code>user_id</code> <code>str</code> <p>User ID for auth lookup</p> <code>'default'</code> <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dict[str, str]: Headers to use for server connection</p> <p>Raises:</p> Type Description <code>AuthRequiredError</code> <p>If no valid token and refresh fails</p> Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>async def resolve_server_auth_headers(\n    server_config: McpServerConfig,\n    user_id: str = \"default\",\n    app_config: AppConfig | None = None,\n) -&gt; dict[str, str]:\n    \"\"\"\n    Resolve authentication headers for MCP server connection.\n\n    Now supports automatic token refresh with OAuth 2.1 compliance:\n    - Validates token audience matches resource\n    - Automatically refreshes expired tokens\n    - Implements token rotation per OAuth 2.1\n\n    Args:\n        server_config: MCP server configuration\n        user_id: User ID for auth lookup\n\n    Returns:\n        Dict[str, str]: Headers to use for server connection\n\n    Raises:\n        AuthRequiredError: If no valid token and refresh fails\n    \"\"\"\n    headers = {}\n\n    # Optional per-server user header injection (opt-in via config)\n    if server_config.user_id_header:\n        header_name = server_config.user_id_header\n        source = server_config.user_id_source\n        if source == \"auth\" and user_id and user_id != \"default\":\n            headers[header_name] = user_id\n            logger.info(f\"Set {header_name} from auth user_id for {server_config.name}\")\n        elif source == \"env\":\n            env_var = server_config.user_id_env_var or header_name.upper()\n            env_val = os.getenv(env_var)\n            if env_val:\n                headers[header_name] = env_val\n                logger.info(f\"Set {header_name} from env {env_var} for {server_config.name}\")\n            else:\n                logger.warning(\n                    f\"user_id_source=env configured for {server_config.name} \"\n                    f\"but env var {env_var} is not set\"\n                )\n\n    # Start with any manually configured headers\n    if server_config.headers:\n        # If OAuth is configured, filter out Authorization headers (OAuth takes precedence)\n        # If OAuth is NOT configured, keep all headers including Authorization\n        for header_key, header_value in server_config.headers.items():\n            if header_key.lower() == \"authorization\" and (\n                server_config.auth_server and server_config.scopes\n            ):\n                logger.warning(\n                    \"Ignoring static Authorization header for MCP server %s (OAuth configured). \"\n                    \"OAuth token will be used instead.\",\n                    server_config.name,\n                )\n                continue\n            headers[header_key] = header_value\n\n    # Override Arcade-User-Id with runtime user_id; fallback to env when user_id is default/absent\n    fallback_arcade_user = os.getenv(\"ARCADE_USER_ID\")\n    if user_id and user_id != \"default\":\n        headers[\"Arcade-User-Id\"] = user_id\n        logger.info(f\"Overriding Arcade-User-Id header with runtime user: {user_id}\")\n    elif fallback_arcade_user:\n        headers[\"Arcade-User-Id\"] = fallback_arcade_user\n        logger.info(f\"Using fallback Arcade-User-Id from env: {fallback_arcade_user}\")\n\n    # Precompute canonical resource URI for HTTP servers (enforce presence for spec compliance)\n    resource_uri: str | None = None\n    if server_config.transport == \"http\":\n        try:\n            resource_uri = server_config.effective_canonical_uri\n        except Exception as e:\n            logger.error(f\"Unable to determine canonical URI for {server_config.name}: {e}\")\n            raise AuthRequiredError(\n                server_name=server_config.name,\n                auth_server=server_config.auth_server or \"unknown\",\n                scopes=server_config.scopes or [],\n                message=f\"Missing or invalid canonical URI for HTTP MCP server \"\n                f\"'{server_config.name}'\",\n            ) from e\n\n    # If server has OAuth configuration, resolve tokens using OAuth flow\n    if server_config.auth_server and server_config.scopes:\n        try:\n            # Use AuthStorageFactory directly - no wrapper needed\n            from datetime import datetime, timedelta\n\n            from sk_agents.auth.oauth_client import OAuthClient\n            from sk_agents.auth.oauth_models import RefreshTokenRequest\n            from sk_agents.configs import (\n                TA_MCP_OAUTH_ENABLE_AUDIENCE_VALIDATION,\n                TA_MCP_OAUTH_ENABLE_TOKEN_REFRESH,\n            )\n\n            if app_config is None:\n                from ska_utils import AppConfig as SkaAppConfig\n\n                app_config = SkaAppConfig()\n            auth_storage_factory = AuthStorageFactory(app_config)\n            auth_storage = auth_storage_factory.get_auth_storage_manager()\n\n            # Check feature flags\n            enable_refresh = (\n                app_config.get(TA_MCP_OAUTH_ENABLE_TOKEN_REFRESH.env_name).lower() == \"true\"\n            )\n            # Enforce audience/resource validation for HTTP servers regardless of flag\n            if server_config.transport == \"http\":\n                enable_audience = True\n            else:\n                enable_audience = (\n                    app_config.get(TA_MCP_OAUTH_ENABLE_AUDIENCE_VALIDATION.env_name).lower()\n                    == \"true\"\n                )\n\n            # Generate composite key for OAuth2 token lookup\n            composite_key = build_auth_storage_key(server_config.auth_server, server_config.scopes)\n\n            # Retrieve stored auth data\n            auth_data = auth_storage.retrieve(user_id, composite_key)\n\n            if not auth_data or not isinstance(auth_data, OAuth2AuthData):\n                logger.warning(f\"No valid auth token found for MCP server: {server_config.name}\")\n                raise AuthRequiredError(\n                    server_name=server_config.name,\n                    auth_server=server_config.auth_server,\n                    scopes=server_config.scopes,\n                )\n\n            # Validate token for this resource (expiry + audience + resource binding)\n            if enable_audience and resource_uri:\n                is_valid = auth_data.is_valid_for_resource(resource_uri)\n            else:\n                # Legacy behavior: only check expiry\n                is_valid = auth_data.expires_at &gt; datetime.now(UTC)\n\n            # Token expired or invalid - try refresh\n            if not is_valid:\n                if enable_refresh and auth_data.refresh_token and resource_uri:\n                    logger.info(\n                        f\"Token expired/invalid for {server_config.name}, attempting refresh\"\n                    )\n\n                    try:\n                        # Initialize OAuth client\n                        oauth_client = OAuthClient()\n\n                        # Discover Protected Resource Metadata (RFC 9728) for HTTP MCP\n                        has_prm = False\n                        if server_config.url:  # Only for HTTP MCP servers\n                            try:\n                                cache = oauth_client.metadata_cache\n                                prm = await cache.fetch_protected_resource_metadata(\n                                    server_config.url\n                                )\n                                has_prm = prm is not None\n                                if prm:\n                                    logger.debug(\n                                        f\"Discovered PRM for {server_config.name} \"\n                                        \"during token refresh\"\n                                    )\n                            except Exception as e:\n                                logger.debug(f\"PRM discovery failed (optional): {e}\")\n                                has_prm = False\n\n                        # Determine if resource param should be included (MCP spec 2025-06-18)\n                        include_resource = oauth_client.should_include_resource_param(\n                            protocol_version=server_config.protocol_version, has_prm=has_prm\n                        )\n\n                        # Discover token endpoint from authorization server metadata (RFC 8414)\n                        token_endpoint = None\n                        try:\n                            metadata = await oauth_client.metadata_cache.fetch_auth_server_metadata(\n                                server_config.auth_server\n                            )\n                            token_endpoint = str(metadata.token_endpoint)\n                            logger.debug(f\"Discovered token endpoint for refresh: {token_endpoint}\")\n                        except Exception as e:\n                            logger.debug(f\"Failed to discover token endpoint: {e}. Using fallback.\")\n                            token_endpoint = f\"{server_config.auth_server.rstrip('/')}/token\"\n\n                        # Build refresh request\n                        refresh_request = RefreshTokenRequest(\n                            token_endpoint=token_endpoint,\n                            refresh_token=auth_data.refresh_token,\n                            resource=resource_uri\n                            if include_resource\n                            else None,  # Conditional per protocol version\n                            client_id=server_config.oauth_client_id\n                            or app_config.get(\"TA_OAUTH_CLIENT_NAME\"),\n                            client_secret=server_config.oauth_client_secret,\n                            requested_scopes=auth_data.scopes,  # For scope validation\n                        )\n\n                        # Refresh token\n                        token_response = await oauth_client.refresh_access_token(refresh_request)\n\n                        # Update auth data with new tokens\n                        auth_data.access_token = token_response.access_token\n                        auth_data.expires_at = datetime.now(UTC) + timedelta(\n                            seconds=token_response.expires_in\n                        )\n                        auth_data.issued_at = datetime.now(UTC)\n\n                        # Handle refresh token rotation (OAuth 2.1)\n                        if token_response.refresh_token:\n                            auth_data.refresh_token = token_response.refresh_token\n                            logger.debug(f\"Refresh token rotated for {server_config.name}\")\n\n                        # Update audience if provided\n                        if token_response.aud:\n                            auth_data.audience = token_response.aud\n\n                        # Store updated auth data\n                        auth_storage.store(user_id, composite_key, auth_data)\n\n                        logger.info(f\"Successfully refreshed token for {server_config.name}\")\n\n                    except httpx.HTTPStatusError as http_error:\n                        # Handle 401 WWW-Authenticate challenges\n                        if http_error.response.status_code == 401:\n                            challenge = OAuthErrorHandler.handle_401_response(\n                                dict(http_error.response.headers)\n                            )\n\n                            if challenge and OAuthErrorHandler.should_reauthorize(challenge):\n                                logger.info(\n                                    f\"Received 401 with WWW-Authenticate challenge \"\n                                    f\"during token refresh for {server_config.name}. \"\n                                    f\"Error: {challenge.error}, \"\n                                    f\"Description: {challenge.error_description}\"\n                                )\n                                # Extract required scopes from challenge or use configured\n                                required_scopes = (\n                                    challenge.scopes if challenge.scopes else server_config.scopes\n                                )\n                                err_msg = challenge.error_description or challenge.error\n                                raise AuthRequiredError(\n                                    server_name=server_config.name,\n                                    auth_server=server_config.auth_server,\n                                    scopes=required_scopes,\n                                    message=f\"Token rejected by server: {err_msg}\",\n                                ) from http_error\n\n                        # Re-raise other HTTP errors\n                        logger.error(\n                            f\"HTTP error during token refresh for \"\n                            f\"{server_config.name}: {http_error}\"\n                        )\n                        raise AuthRequiredError(\n                            server_name=server_config.name,\n                            auth_server=server_config.auth_server,\n                            scopes=server_config.scopes,\n                            message=f\"Token refresh HTTP error: {http_error}\",\n                        ) from http_error\n\n                    except Exception as refresh_error:\n                        logger.error(\n                            f\"Token refresh failed for {server_config.name}: {refresh_error}\"\n                        )\n                        # Refresh failed - require re-authentication\n                        raise AuthRequiredError(\n                            server_name=server_config.name,\n                            auth_server=server_config.auth_server,\n                            scopes=server_config.scopes,\n                            message=f\"Token refresh failed for '{server_config.name}'. \"\n                            \"Re-authentication required.\",\n                        ) from refresh_error\n                else:\n                    # Refresh not enabled or no refresh token\n                    logger.warning(\n                        f\"Token expired for {server_config.name} and refresh not available\"\n                    )\n                    raise AuthRequiredError(\n                        server_name=server_config.name,\n                        auth_server=server_config.auth_server,\n                        scopes=server_config.scopes,\n                        message=f\"Token expired for '{server_config.name}'\",\n                    )\n\n            # Token is valid (or was successfully refreshed)\n            headers[\"Authorization\"] = f\"{auth_data.token_type} {auth_data.access_token}\"\n            logger.info(f\"Resolved auth headers for MCP server: {server_config.name}\")\n\n        except AuthRequiredError:\n            # Re-raise auth errors\n            raise\n        except Exception as e:\n            logger.error(f\"Failed to resolve auth for MCP server {server_config.name}: {e}\")\n            raise AuthRequiredError(\n                server_name=server_config.name,\n                auth_server=server_config.auth_server if server_config.auth_server else \"unknown\",\n                scopes=server_config.scopes if server_config.scopes else [],\n                message=f\"Auth resolution failed: {e}\",\n            ) from e\n\n    # Debug logging: show what headers we're about to send\n    safe_headers = {}\n    for k, v in headers.items():\n        if k.lower() == \"authorization\":\n            # Redact token but show format\n            if v.startswith(\"Bearer \"):\n                safe_headers[k] = \"Bearer [REDACTED]\"\n            elif v.startswith(\"ghp_\"):\n                safe_headers[k] = \"ghp_[REDACTED]\"\n            else:\n                safe_headers[k] = \"[REDACTED]\"\n        else:\n            safe_headers[k] = v\n    logger.info(f\"Resolved headers for {server_config.name}: {safe_headers}\")\n\n    return headers\n</code></pre> <code></code> sk_agents.mcp_client.revoke_mcp_server_tokens <code>async</code> <pre><code>revoke_mcp_server_tokens(\n    server_config: McpServerConfig, user_id: str = \"default\"\n) -&gt; None\n</code></pre> <p>Revoke all tokens for an MCP server.</p> <p>Useful when: - User logs out - Security incident detected - Server access no longer needed</p> <p>Parameters:</p> Name Type Description Default <code>server_config</code> <code>McpServerConfig</code> <p>MCP server configuration</p> required <code>user_id</code> <code>str</code> <p>User ID for token lookup</p> <code>'default'</code> <p>Raises:</p> Type Description <code>Exception</code> <p>If revocation fails</p> Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>async def revoke_mcp_server_tokens(\n    server_config: McpServerConfig, user_id: str = \"default\"\n) -&gt; None:\n    \"\"\"\n    Revoke all tokens for an MCP server.\n\n    Useful when:\n    - User logs out\n    - Security incident detected\n    - Server access no longer needed\n\n    Args:\n        server_config: MCP server configuration\n        user_id: User ID for token lookup\n\n    Raises:\n        Exception: If revocation fails\n    \"\"\"\n    from ska_utils import AppConfig\n\n    from sk_agents.auth.oauth_client import OAuthClient\n\n    if not server_config.auth_server or not server_config.scopes:\n        logger.debug(f\"Server {server_config.name} has no OAuth config, skipping revocation\")\n        return\n\n    app_config = AppConfig()\n    auth_storage_factory = AuthStorageFactory(app_config)\n    auth_storage = auth_storage_factory.get_auth_storage_manager()\n    oauth_client = OAuthClient()\n\n    # Retrieve stored tokens\n    composite_key = build_auth_storage_key(server_config.auth_server, server_config.scopes)\n    auth_data = auth_storage.retrieve(user_id, composite_key)\n\n    if not auth_data or not isinstance(auth_data, OAuth2AuthData):\n        logger.debug(f\"No tokens found for {server_config.name}, skipping revocation\")\n        return\n\n    try:\n        # Discover revocation endpoint\n        metadata = await oauth_client.metadata_cache.fetch_auth_server_metadata(\n            server_config.auth_server\n        )\n\n        if not metadata.revocation_endpoint:\n            logger.warning(\n                f\"No revocation_endpoint discovered for {server_config.auth_server}. \"\n                f\"Cannot revoke tokens.\"\n            )\n            return\n\n        # Revoke access token\n        await oauth_client.revoke_token(\n            token=auth_data.access_token,\n            revocation_endpoint=str(metadata.revocation_endpoint),\n            client_id=server_config.oauth_client_id or app_config.get(\"TA_OAUTH_CLIENT_NAME\"),\n            client_secret=server_config.oauth_client_secret,\n            token_type_hint=\"access_token\",\n        )\n\n        # Revoke refresh token if present\n        if auth_data.refresh_token:\n            await oauth_client.revoke_token(\n                token=auth_data.refresh_token,\n                revocation_endpoint=str(metadata.revocation_endpoint),\n                client_id=server_config.oauth_client_id or app_config.get(\"TA_OAUTH_CLIENT_NAME\"),\n                client_secret=server_config.oauth_client_secret,\n                token_type_hint=\"refresh_token\",\n            )\n\n        # Remove from storage\n        auth_storage.delete(user_id, composite_key)\n\n        logger.info(f\"Successfully revoked and removed tokens for {server_config.name}\")\n\n    except Exception as e:\n        logger.error(f\"Failed to revoke tokens for {server_config.name}: {e}\")\n        raise\n</code></pre> <code></code> sk_agents.mcp_client.create_mcp_session_with_retry <code>async</code> <pre><code>create_mcp_session_with_retry(\n    server_config: McpServerConfig,\n    connection_stack: AsyncExitStack,\n    user_id: str = \"default\",\n    max_retries: int = 3,\n    mcp_session_id: str | None = None,\n    on_stale_session: Callable[[str], Awaitable[None]]\n    | None = None,\n    app_config: AppConfig | None = None,\n) -&gt; tuple[ClientSession, Callable[[], str | None]]\n</code></pre> <p>Create MCP session with retry logic for transient failures.</p> <p>This function wraps create_mcp_session with exponential backoff retry logic to handle transient network issues and temporary server unavailability.</p> <p>Parameters:</p> Name Type Description Default <code>server_config</code> <code>McpServerConfig</code> <p>MCP server configuration</p> required <code>connection_stack</code> <code>AsyncExitStack</code> <p>AsyncExitStack for resource management</p> required <code>user_id</code> <code>str</code> <p>User ID for authentication</p> <code>'default'</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts (default: 3)</p> <code>3</code> <p>Returns:</p> Name Type Description <code>ClientSession</code> <code>tuple[ClientSession, Callable[[], str | None]]</code> <p>Initialized MCP session</p> <p>Raises:</p> Type Description <code>ConnectionError</code> <p>If all retry attempts fail</p> <code>ValueError</code> <p>If server configuration is invalid</p> Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>async def create_mcp_session_with_retry(\n    server_config: McpServerConfig,\n    connection_stack: AsyncExitStack,\n    user_id: str = \"default\",\n    max_retries: int = 3,\n    mcp_session_id: str | None = None,\n    on_stale_session: Callable[[str], Awaitable[None]] | None = None,\n    app_config: AppConfig | None = None,\n) -&gt; tuple[ClientSession, Callable[[], str | None]]:\n    \"\"\"\n    Create MCP session with retry logic for transient failures.\n\n    This function wraps create_mcp_session with exponential backoff retry logic\n    to handle transient network issues and temporary server unavailability.\n\n    Args:\n        server_config: MCP server configuration\n        connection_stack: AsyncExitStack for resource management\n        user_id: User ID for authentication\n        max_retries: Maximum number of retry attempts (default: 3)\n\n    Returns:\n        ClientSession: Initialized MCP session\n\n    Raises:\n        ConnectionError: If all retry attempts fail\n        ValueError: If server configuration is invalid\n    \"\"\"\n    last_error = None\n\n    for attempt in range(max_retries):\n        try:\n            session, get_session_id = await create_mcp_session(\n                server_config,\n                connection_stack,\n                user_id,\n                mcp_session_id=mcp_session_id,\n                app_config=app_config,\n            )\n\n            # If we succeed after retries, log it\n            if attempt &gt; 0:\n                logger.info(\n                    f\"Successfully connected to MCP server '{server_config.name}' \"\n                    f\"after {attempt + 1} attempt(s)\"\n                )\n\n            return session, get_session_id\n\n        except (ConnectionError, TimeoutError, OSError) as e:\n            last_error = e\n\n            # If the first attempt with a stored session id fails, clear and retry fresh once\n            if mcp_session_id and on_stale_session:\n                try:\n                    await on_stale_session(mcp_session_id)\n                except Exception:\n                    logger.debug(\"Failed to clear stale MCP session id during retry path\")\n                mcp_session_id = None\n\n            # Don't retry on the last attempt\n            if attempt &lt; max_retries - 1:\n                backoff_seconds = 2**attempt  # 1s, 2s, 4s\n                logger.warning(\n                    f\"MCP connection attempt {attempt + 1}/{max_retries} failed for \"\n                    f\"'{server_config.name}': {e}. Retrying in {backoff_seconds}s...\"\n                )\n                await asyncio.sleep(backoff_seconds)\n            else:\n                # Final attempt failed\n                logger.error(\n                    f\"Failed to connect to MCP server '{server_config.name}' \"\n                    f\"after {max_retries} attempts\"\n                )\n\n        except Exception as e:\n            # If failure might be due to stale session id, clear once then re-raise\n            if mcp_session_id and on_stale_session:\n                try:\n                    await on_stale_session(mcp_session_id)\n                except Exception:\n                    logger.debug(\"Failed to clear stale MCP session id during retry path\")\n            logger.error(\n                f\"Non-retryable error connecting to MCP server '{server_config.name}': {e}\"\n            )\n            raise\n\n    # All retries exhausted\n    raise ConnectionError(\n        f\"Failed to connect to MCP server '{server_config.name}' after {max_retries} attempts. \"\n        f\"Last error: {last_error}\"\n    ) from last_error\n</code></pre> <code></code> sk_agents.mcp_client.create_mcp_session <code>async</code> <pre><code>create_mcp_session(\n    server_config: McpServerConfig,\n    connection_stack: AsyncExitStack,\n    user_id: str = \"default\",\n    mcp_session_id: str | None = None,\n    app_config: AppConfig | None = None,\n) -&gt; tuple[ClientSession, Callable[[], str | None]]\n</code></pre> <p>Create MCP session using SDK transport factories.</p> Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>async def create_mcp_session(\n    server_config: McpServerConfig,\n    connection_stack: AsyncExitStack,\n    user_id: str = \"default\",\n    mcp_session_id: str | None = None,\n    app_config: AppConfig | None = None,\n) -&gt; tuple[ClientSession, Callable[[], str | None]]:\n    \"\"\"Create MCP session using SDK transport factories.\"\"\"\n    transport_type = server_config.transport\n\n    if transport_type == \"stdio\":\n        from mcp.client.stdio import stdio_client\n\n        server_params = StdioServerParameters(\n            command=server_config.command, args=server_config.args, env=server_config.env or {}\n        )\n\n        read, write = await connection_stack.enter_async_context(stdio_client(server_params))\n        session = await connection_stack.enter_async_context(ClientSession(read, write))\n\n        await initialize_mcp_session(\n            session,\n            server_config.name,\n            protocol_version=server_config.protocol_version or \"2025-11-25\",\n        )\n        return session, (lambda: None)\n\n    elif transport_type == \"http\":\n        # Resolve auth headers for HTTP transport\n        resolved_headers = await resolve_server_auth_headers(\n            server_config, user_id, app_config=app_config\n        )\n\n        # Try streamable HTTP first (preferred), fall back to SSE\n        try:\n            from mcp.client.streamable_http import streamablehttp_client\n\n            # Create custom httpx client factory if SSL verification is disabled\n            httpx_client_factory = None\n            if getattr(server_config, \"verify_ssl\", True) is False:\n                logger.warning(\n                    f\"SSL verification disabled for MCP server '{server_config.name}'. \"\n                    f\"Creating custom httpx client factory with verify=False\"\n                )\n\n                def create_insecure_http_client(\n                    headers: dict[str, str] | None = None,\n                    timeout: httpx.Timeout | None = None,\n                    auth: httpx.Auth | None = None,\n                ) -&gt; httpx.AsyncClient:\n                    \"\"\"Create httpx client with SSL verification disabled.\"\"\"\n                    logger.debug(\n                        f\"Creating insecure httpx client for {server_config.name} with verify=False\"\n                    )\n                    kwargs: dict[str, Any] = {\n                        \"follow_redirects\": True,\n                        \"verify\": False,  # Disable SSL verification\n                    }\n                    if timeout is None:\n                        kwargs[\"timeout\"] = httpx.Timeout(30.0)\n                    else:\n                        kwargs[\"timeout\"] = timeout\n                    if headers is not None:\n                        kwargs[\"headers\"] = headers\n                    if auth is not None:\n                        kwargs[\"auth\"] = auth\n\n                    logger.debug(f\"httpx.AsyncClient kwargs: {kwargs}\")\n                    return httpx.AsyncClient(**kwargs)\n\n                httpx_client_factory = create_insecure_http_client\n\n            # Build kwargs for streamablehttp_client\n            headers_with_session = resolved_headers.copy()\n            if mcp_session_id:\n                headers_with_session[\"Mcp-Session-Id\"] = mcp_session_id\n\n            client_kwargs = {\n                \"url\": server_config.url,\n                \"headers\": headers_with_session,\n                \"timeout\": server_config.timeout or 30.0,\n                \"sse_read_timeout\": server_config.sse_read_timeout or 300.0,\n            }\n            if httpx_client_factory is not None:\n                client_kwargs[\"httpx_client_factory\"] = httpx_client_factory\n                logger.info(\n                    f\"Passing custom httpx_client_factory to streamablehttp_client \"\n                    f\"for {server_config.name}\"\n                )\n            else:\n                logger.debug(\n                    f\"No custom httpx_client_factory for {server_config.name}, \"\n                    \"using default SSL verification\"\n                )\n\n            # Use streamable HTTP transport\n            read, write, get_session_id = await connection_stack.enter_async_context(\n                streamablehttp_client(**client_kwargs)\n            )\n            session = await connection_stack.enter_async_context(ClientSession(read, write))\n\n            await initialize_mcp_session(\n                session,\n                server_config.name,\n                protocol_version=server_config.protocol_version or \"2025-11-25\",\n            )\n            return session, get_session_id\n\n        except ImportError as err:\n            raise NotImplementedError(\n                \"HTTP transport is not available. Please install the MCP SDK with HTTP support\"\n            ) from err\n            # # Fall back to SSE transport if streamable HTTP not available\n            # try:\n            #     from mcp.client.sse import sse_client\n\n            #     read, write = await connection_stack.enter_async_context(\n            #         sse_client(\n            #             url=server_config.url,\n            #             headers=resolved_headers,\n            #             timeout=server_config.timeout or 30.0,\n            #             sse_read_timeout=server_config.sse_read_timeout or 300.0\n            #         )\n            #     )\n            #     session = await connection_stack.enter_async_context(\n            #         ClientSession(read, write)\n            #     )\n\n            #     return session\n\n            # except ImportError:\n            #     raise NotImplementedError(\n            #         \"HTTP transport is not available. \"\n            #         \"Please install the MCP SDK with HTTP support: \"\n            #         \"pip install 'mcp[http]' or 'mcp[sse]'\"\n            #     )\n    else:\n        raise ValueError(f\"Unsupported transport type: {transport_type}\")\n</code></pre> <code></code> sk_agents.mcp_client.get_transport_info <pre><code>get_transport_info(server_config: McpServerConfig) -&gt; str\n</code></pre> <p>Get transport info for logging.</p> Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>def get_transport_info(server_config: McpServerConfig) -&gt; str:\n    \"\"\"Get transport info for logging.\"\"\"\n    if server_config.transport == \"stdio\":\n        # Sanitize sensitive arguments\n        safe_args = []\n        for arg in server_config.args:\n            if any(\n                keyword in arg.lower() for keyword in [\"token\", \"key\", \"secret\", \"password\", \"auth\"]\n            ):\n                safe_args.append(\"[REDACTED]\")\n            else:\n                safe_args.append(arg)\n        return f\"stdio:{server_config.command} {' '.join(safe_args)}\"\n    elif server_config.transport == \"http\":\n        # Sanitize URL for logging\n        url = server_config.url or \"\"\n        if \"?\" in url:\n            url = url.split(\"?\")[0]\n        return f\"http:{url}\"\n    else:\n        return f\"{server_config.transport}:unknown\"\n</code></pre>"},{"location":"reference/#sk_agents.mcp_client.McpPlugin--mcp-specific-design-note","title":"MCP-Specific Design Note:","text":"<p>MCP plugins require both user_id and connection_manager:</p> <ol> <li> <p>Per-User Authentication: MCP tools connect to external services that require OAuth2    authentication. Tokens are stored per-user in AuthStorage.</p> </li> <li> <p>Connection Reuse: All tool calls within a request share connections via the    connection_manager, reducing overhead from per-tool-call to per-request per-server.</p> </li> </ol> <p>Parameters:</p> Name Type Description Default <code>tools</code> <code>list[McpTool]</code> <p>List of MCP tools discovered from the server</p> required <code>server_name</code> <code>str</code> <p>Name of the MCP server (used for logging and namespacing)</p> required <code>user_id</code> <code>str</code> <p>User ID for OAuth2 token resolution (REQUIRED)</p> required <code>connection_manager</code> <code>McpConnectionManager</code> <p>Request-scoped connection manager (REQUIRED)</p> required <code>authorization</code> <code>str | None</code> <p>Optional standard authorization header (rarely used with MCP)</p> <code>None</code> <code>extra_data_collector</code> <p>Optional collector for extra response data</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If user_id or connection_manager is not provided</p> Example <p>async with McpConnectionManager(configs, user_id, session_id) as conn_mgr: ...     plugin_instance = plugin_class( ...         user_id=\"user123\", ...         connection_manager=conn_mgr, ...         extra_data_collector=collector ...     ) ...     kernel.add_plugin(plugin_instance, \"mcp_github\")</p> Source code in <code>src/sk_agents/mcp_client.py</code> <pre><code>class McpPlugin(BasePlugin):\n    \"\"\"\n    Plugin wrapper that holds MCP tools for Semantic Kernel integration.\n\n    This plugin creates kernel functions with proper type annotations from MCP JSON schemas,\n    allowing Semantic Kernel to expose full parameter information to the LLM.\n\n    MCP-Specific Design Note:\n    -------------------------\n    MCP plugins require both user_id and connection_manager:\n\n    1. **Per-User Authentication**: MCP tools connect to external services that require OAuth2\n       authentication. Tokens are stored per-user in AuthStorage.\n\n    2. **Connection Reuse**: All tool calls within a request share connections via the\n       connection_manager, reducing overhead from per-tool-call to per-request per-server.\n\n    Args:\n        tools: List of MCP tools discovered from the server\n        server_name: Name of the MCP server (used for logging and namespacing)\n        user_id: User ID for OAuth2 token resolution (REQUIRED)\n        connection_manager: Request-scoped connection manager (REQUIRED)\n        authorization: Optional standard authorization header (rarely used with MCP)\n        extra_data_collector: Optional collector for extra response data\n\n    Raises:\n        ValueError: If user_id or connection_manager is not provided\n\n    Example:\n        &gt;&gt;&gt; async with McpConnectionManager(configs, user_id, session_id) as conn_mgr:\n        ...     plugin_instance = plugin_class(\n        ...         user_id=\"user123\",\n        ...         connection_manager=conn_mgr,\n        ...         extra_data_collector=collector\n        ...     )\n        ...     kernel.add_plugin(plugin_instance, \"mcp_github\")\n    \"\"\"\n\n    def __init__(\n        self,\n        tools: list[McpTool],\n        server_name: str,\n        user_id: str,\n        connection_manager: \"McpConnectionManager\",\n        authorization: str | None = None,\n        extra_data_collector=None,\n    ):\n        if not user_id:\n            raise ValueError(\n                \"MCP plugins require a user_id for per-request OAuth2 token resolution.\"\n            )\n        if not connection_manager:\n            raise ValueError(\n                \"MCP plugins require a connection_manager for request-scoped connection reuse. \"\n                \"Create one using McpConnectionManager and pass it to the plugin.\"\n            )\n\n        super().__init__(authorization, extra_data_collector)\n        self.tools = tools\n        self.server_name = server_name\n        self.user_id = user_id\n        self.connection_manager = connection_manager\n\n        # Dynamically add kernel functions for each tool\n        for tool in tools:\n            self._add_tool_function(tool)\n\n    def _add_tool_function(self, tool: McpTool):\n        \"\"\"\n        Add a tool as a kernel function with proper type annotations.\n\n        Converts MCP JSON schema to Python type hints so SK can expose\n        full parameter information to the LLM.\n        \"\"\"\n\n        # Create a closure that captures the specific tool instance\n        def create_tool_function(captured_tool: McpTool):\n            # Create unique tool name to avoid collisions\n            function_name = f\"{self.server_name}_{captured_tool.tool_name}\"\n\n            @kernel_function(\n                name=function_name,\n                description=f\"[{self.server_name}] {captured_tool.description}\",\n            )\n            async def tool_function(**kwargs):\n                return await captured_tool.invoke(\n                    connection_manager=self.connection_manager,\n                    **kwargs,\n                )\n\n            # CRITICAL FIX: Override __kernel_function_parameters__ after decoration\n            # This is the CORRECT way to set function parameters in Semantic Kernel\n            # The decorator has already read inspect.signature() (which only sees **kwargs),\n            # but we can override the parameters it uses to build the LLM schema\n            tool_function.__kernel_function_parameters__ = self._build_sk_parameters(\n                captured_tool.input_schema\n            )\n\n            return tool_function\n\n        # Create the function and set as attribute\n        tool_function = create_tool_function(tool)\n\n        # Sanitize tool name for Python attribute\n        attr_name = self._sanitize_name(f\"{self.server_name}_{tool.tool_name}\")\n\n        setattr(self, attr_name, tool_function)\n\n    def _build_sk_parameters(self, input_schema: dict[str, Any]) -&gt; list[dict[str, Any]]:\n        \"\"\"\n        Build Semantic Kernel parameter dictionaries from MCP JSON schema.\n\n        This creates the parameter metadata in the format expected by\n        KernelParameterMetadata, which Semantic Kernel uses to build\n        the schema sent to the LLM.\n\n        This is the CORRECT way to override function parameters in SK -\n        by setting __kernel_function_parameters__ after decoration.\n\n        Args:\n            input_schema: MCP tool's JSON schema for inputs\n\n        Returns:\n            List of parameter dictionaries for SK\n        \"\"\"\n        if not input_schema or not isinstance(input_schema, dict):\n            return []\n\n        properties = input_schema.get(\"properties\", {})\n        required = input_schema.get(\"required\", [])\n        params = []\n\n        for param_name, param_schema in properties.items():\n            if not isinstance(param_schema, dict):\n                continue\n\n            # Build parameter dict in SK format\n            param_dict = {\n                \"name\": param_name,\n                \"description\": param_schema.get(\"description\", \"\"),\n                \"is_required\": param_name in required,\n                \"type_\": param_schema.get(\"type\", \"string\"),  # JSON type string\n                \"default_value\": param_schema.get(\"default\", None),\n                \"schema_data\": param_schema,  # Full JSON schema sent to LLM\n            }\n\n            # Add Python type object for better type handling\n            json_type = param_schema.get(\"type\", \"string\")\n            param_dict[\"type_object\"] = self._json_type_to_python(json_type)\n\n            params.append(param_dict)\n\n        return params\n\n    @staticmethod\n    def _json_type_to_python(json_type: str) -&gt; type:\n        \"\"\"\n        Map JSON schema types to Python types.\n\n        Args:\n            json_type: JSON schema type string\n\n        Returns:\n            Corresponding Python type\n        \"\"\"\n        type_map = {\n            \"string\": str,\n            \"number\": float,\n            \"integer\": int,\n            \"boolean\": bool,\n            \"array\": list,\n            \"object\": dict,\n        }\n        return type_map.get(json_type, str)\n\n    @staticmethod\n    def _sanitize_name(name: str) -&gt; str:\n        \"\"\"Sanitize name for Python attribute.\"\"\"\n        sanitized = \"\".join(c if c.isalnum() or c == \"_\" else \"_\" for c in name)\n        if not sanitized[0].isalpha() and sanitized[0] != \"_\":\n            sanitized = f\"tool_{sanitized}\"\n        return sanitized\n</code></pre>"},{"location":"reference/#sk_agents.mcp_discovery","title":"sk_agents.mcp_discovery","text":"<p>MCP State Management Module.</p> sk_agents.mcp_discovery.DiscoveryManagerFactory <p>Factory for MCP state manager with dependency injection.</p> <p>Uses singleton pattern to ensure only one factory instance exists. Dynamically loads state manager implementation based on environment variables.</p> Configuration <p>TA_MCP_DISCOVERY_MODULE: Python module containing manager class TA_MCP_DISCOVERY_CLASS: Manager class name</p> <p>Defaults to InMemoryStateManager for development.</p> Source code in <code>src/sk_agents/mcp_discovery/discovery_manager_factory.py</code> <pre><code>class DiscoveryManagerFactory(metaclass=Singleton):\n    \"\"\"\n    Factory for MCP state manager with dependency injection.\n\n    Uses singleton pattern to ensure only one factory instance exists.\n    Dynamically loads state manager implementation based on\n    environment variables.\n\n    Configuration:\n        TA_MCP_DISCOVERY_MODULE: Python module containing manager class\n        TA_MCP_DISCOVERY_CLASS: Manager class name\n\n    Defaults to InMemoryStateManager for development.\n    \"\"\"\n\n    def __init__(self, app_config: AppConfig):\n        \"\"\"\n        Initialize factory with app configuration.\n\n        Args:\n            app_config: Application configuration for env vars\n        \"\"\"\n        self.app_config = app_config\n        self._manager: McpStateManager | None = None  # noqa: F821\n\n    def get_discovery_manager(self) -&gt; \"McpStateManager\":  # noqa: F821\n        \"\"\"\n        Get state manager instance (cached singleton).\n\n        Loads manager implementation on first call based on configuration,\n        then caches for subsequent calls.\n\n        Returns:\n            McpStateManager instance\n\n        Raises:\n            Exception: If manager class cannot be loaded (falls back to in-memory)\n        \"\"\"\n        if self._manager is None:\n            # Import here to avoid circular dependency\n            from sk_agents.configs import TA_MCP_DISCOVERY_CLASS, TA_MCP_DISCOVERY_MODULE\n\n            module_name = self.app_config.get(TA_MCP_DISCOVERY_MODULE.env_name)\n            class_name = self.app_config.get(TA_MCP_DISCOVERY_CLASS.env_name)\n\n            try:\n                # Dynamic module loading\n                module = __import__(module_name, fromlist=[class_name])\n                manager_class = getattr(module, class_name)\n                self._manager = manager_class(self.app_config)\n                logger.info(f\"Initialized MCP state manager: {class_name}\")\n\n            except Exception as e:\n                logger.error(\n                    f\"Failed to load state manager {class_name} from {module_name}: {e}. \"\n                    f\"Falling back to InMemoryStateManager\"\n                )\n\n                # Fallback to in-memory implementation\n                try:\n                    from sk_agents.mcp_discovery.in_memory_discovery_manager import (\n                        InMemoryStateManager,\n                    )\n\n                    self._manager = InMemoryStateManager(self.app_config)\n                    logger.info(\"Fallback to InMemoryStateManager successful\")\n\n                except Exception as fallback_error:\n                    logger.critical(\n                        f\"Failed to load fallback InMemoryStateManager: {fallback_error}\"\n                    )\n                    raise\n\n        return self._manager\n</code></pre> <code></code> sk_agents.mcp_discovery.DiscoveryManagerFactory.__init__ <pre><code>__init__(app_config: AppConfig)\n</code></pre> <p>Initialize factory with app configuration.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>AppConfig</code> <p>Application configuration for env vars</p> required Source code in <code>src/sk_agents/mcp_discovery/discovery_manager_factory.py</code> <pre><code>def __init__(self, app_config: AppConfig):\n    \"\"\"\n    Initialize factory with app configuration.\n\n    Args:\n        app_config: Application configuration for env vars\n    \"\"\"\n    self.app_config = app_config\n    self._manager: McpStateManager | None = None  # noqa: F821\n</code></pre> <code></code> sk_agents.mcp_discovery.DiscoveryManagerFactory.get_discovery_manager <pre><code>get_discovery_manager() -&gt; McpStateManager\n</code></pre> <p>Get state manager instance (cached singleton).</p> <p>Loads manager implementation on first call based on configuration, then caches for subsequent calls.</p> <p>Returns:</p> Type Description <code>McpStateManager</code> <p>McpStateManager instance</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If manager class cannot be loaded (falls back to in-memory)</p> Source code in <code>src/sk_agents/mcp_discovery/discovery_manager_factory.py</code> <pre><code>def get_discovery_manager(self) -&gt; \"McpStateManager\":  # noqa: F821\n    \"\"\"\n    Get state manager instance (cached singleton).\n\n    Loads manager implementation on first call based on configuration,\n    then caches for subsequent calls.\n\n    Returns:\n        McpStateManager instance\n\n    Raises:\n        Exception: If manager class cannot be loaded (falls back to in-memory)\n    \"\"\"\n    if self._manager is None:\n        # Import here to avoid circular dependency\n        from sk_agents.configs import TA_MCP_DISCOVERY_CLASS, TA_MCP_DISCOVERY_MODULE\n\n        module_name = self.app_config.get(TA_MCP_DISCOVERY_MODULE.env_name)\n        class_name = self.app_config.get(TA_MCP_DISCOVERY_CLASS.env_name)\n\n        try:\n            # Dynamic module loading\n            module = __import__(module_name, fromlist=[class_name])\n            manager_class = getattr(module, class_name)\n            self._manager = manager_class(self.app_config)\n            logger.info(f\"Initialized MCP state manager: {class_name}\")\n\n        except Exception as e:\n            logger.error(\n                f\"Failed to load state manager {class_name} from {module_name}: {e}. \"\n                f\"Falling back to InMemoryStateManager\"\n            )\n\n            # Fallback to in-memory implementation\n            try:\n                from sk_agents.mcp_discovery.in_memory_discovery_manager import (\n                    InMemoryStateManager,\n                )\n\n                self._manager = InMemoryStateManager(self.app_config)\n                logger.info(\"Fallback to InMemoryStateManager successful\")\n\n            except Exception as fallback_error:\n                logger.critical(\n                    f\"Failed to load fallback InMemoryStateManager: {fallback_error}\"\n                )\n                raise\n\n    return self._manager\n</code></pre> <code></code> sk_agents.mcp_discovery.InMemoryStateManager <p>               Bases: <code>McpStateManager</code></p> <p>In-memory implementation of MCP state manager.</p> <p>Stores MCP state in memory with thread-safe access. Suitable for: - Development and testing - Single-instance deployments - Scenarios where persistence is not required</p> <p>Note: State is lost on server restart.</p> Source code in <code>src/sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> <pre><code>class InMemoryStateManager(McpStateManager):\n    \"\"\"\n    In-memory implementation of MCP state manager.\n\n    Stores MCP state in memory with thread-safe access.\n    Suitable for:\n    - Development and testing\n    - Single-instance deployments\n    - Scenarios where persistence is not required\n\n    Note: State is lost on server restart.\n    \"\"\"\n\n    def __init__(self, app_config):\n        \"\"\"\n        Initialize in-memory state manager.\n\n        Args:\n            app_config: Application configuration (for consistency with other managers)\n        \"\"\"\n        self.app_config = app_config\n        # Storage: {(user_id, session_id): McpState}\n        self._storage: dict[tuple[str, str], McpState] = {}\n        self._lock = asyncio.Lock()\n\n    def _make_key(self, user_id: str, session_id: str) -&gt; tuple[str, str]:\n        \"\"\"\n        Create composite key for storage.\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n\n        Returns:\n            Tuple of (user_id, session_id)\n        \"\"\"\n        return (user_id, session_id)\n\n    async def create_discovery(self, state: McpState) -&gt; None:\n        \"\"\"\n        Create initial MCP state.\n\n        Args:\n            state: MCP state to create\n\n        Raises:\n            DiscoveryCreateError: If state already exists\n        \"\"\"\n        async with self._lock:\n            key = self._make_key(state.user_id, state.session_id)\n            if key in self._storage:\n                raise DiscoveryCreateError(\n                    f\"MCP state already exists for user={state.user_id}, session={state.session_id}\"\n                )\n            self._storage[key] = state\n            logger.debug(f\"Created MCP state for user={state.user_id}, session={state.session_id}\")\n\n    async def load_discovery(self, user_id: str, session_id: str) -&gt; McpState | None:\n        \"\"\"\n        Load MCP state.\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n\n        Returns:\n            Deep copy of MCP state if exists, None otherwise.\n            Returns a copy to prevent external mutations.\n        \"\"\"\n        async with self._lock:\n            key = self._make_key(user_id, session_id)\n            state = self._storage.get(key)\n            if state is None:\n                return None\n            # Return deep copy to prevent external mutations bypassing update_discovery\n            return copy.deepcopy(state)\n\n    async def update_discovery(self, state: McpState) -&gt; None:\n        \"\"\"\n        Update existing MCP state.\n\n        Args:\n            state: Updated MCP state\n\n        Raises:\n            DiscoveryUpdateError: If state does not exist\n        \"\"\"\n        async with self._lock:\n            key = self._make_key(state.user_id, state.session_id)\n            if key not in self._storage:\n                raise DiscoveryUpdateError(\n                    f\"MCP state not found for user={state.user_id}, session={state.session_id}\"\n                )\n            self._storage[key] = state\n            logger.debug(f\"Updated MCP state for user={state.user_id}, session={state.session_id}\")\n\n    async def delete_discovery(self, user_id: str, session_id: str) -&gt; None:\n        \"\"\"\n        Delete MCP state.\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n        \"\"\"\n        async with self._lock:\n            key = self._make_key(user_id, session_id)\n            if key in self._storage:\n                del self._storage[key]\n                logger.debug(f\"Deleted MCP state for user={user_id}, session={session_id}\")\n\n    async def mark_completed(self, user_id: str, session_id: str) -&gt; None:\n        \"\"\"\n        Mark discovery as completed.\n\n        If state doesn't exist, auto-creates it with discovery_completed=True\n        and empty discovered_servers dict. A warning is logged when auto-creating.\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n        \"\"\"\n        async with self._lock:\n            key = self._make_key(user_id, session_id)\n            if key in self._storage:\n                self._storage[key].discovery_completed = True\n                logger.debug(f\"Marked discovery completed for user={user_id}, session={session_id}\")\n            else:\n                # Auto-create state if it doesn't exist\n                logger.warning(\n                    f\"MCP state not found for user={user_id}, session={session_id}. \"\n                    f\"Auto-creating with discovery_completed=True.\"\n                )\n                state = McpState(\n                    user_id=user_id,\n                    session_id=session_id,\n                    discovered_servers={},\n                    discovery_completed=True,\n                    created_at=datetime.now(UTC),\n                )\n                self._storage[key] = state\n\n    async def is_completed(self, user_id: str, session_id: str) -&gt; bool:\n        \"\"\"\n        Check if discovery is completed.\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n\n        Returns:\n            True if discovery completed, False otherwise\n        \"\"\"\n        async with self._lock:\n            key = self._make_key(user_id, session_id)\n            state = self._storage.get(key)\n            return state.discovery_completed if state else False\n\n    async def store_mcp_session(\n        self, user_id: str, session_id: str, server_name: str, mcp_session_id: str\n    ) -&gt; None:\n        \"\"\"\n        Store MCP session ID for a server.\n\n        Args:\n            user_id: User ID\n            session_id: Teal agent session ID\n            server_name: Name of the MCP server\n            mcp_session_id: MCP session ID from server\n        \"\"\"\n        async with self._lock:\n            key = self._make_key(user_id, session_id)\n            state = self._storage.get(key)\n\n            # Auto-create state if doesn't exist\n            if not state:\n                logger.warning(\n                    f\"MCP state not found for user={user_id}, session={session_id}. \"\n                    f\"Auto-creating to store session for {server_name}.\"\n                )\n                state = McpState(\n                    user_id=user_id,\n                    session_id=session_id,\n                    discovered_servers={},\n                    discovery_completed=False,\n                    created_at=datetime.now(UTC),\n                )\n                self._storage[key] = state\n\n            # Ensure server entry exists and preserve plugin_data if present\n            existing_entry = state.discovered_servers.get(server_name, {})\n            plugin_data = existing_entry.get(\"plugin_data\")\n            state.discovered_servers[server_name] = {\n                \"plugin_data\": plugin_data,\n                **(\n                    {\"session\": existing_entry.get(\"session\")}\n                    if existing_entry.get(\"session\")\n                    else {}\n                ),\n            }\n\n            # Store session data\n            session_bucket = state.discovered_servers[server_name].get(\"session\", {})\n            now_iso = datetime.now(UTC).isoformat()\n            session_bucket.update(\n                {\n                    \"mcp_session_id\": mcp_session_id,\n                    \"created_at\": session_bucket.get(\"created_at\", now_iso),\n                    \"last_used_at\": now_iso,\n                }\n            )\n            state.discovered_servers[server_name][\"session\"] = session_bucket\n\n            logger.debug(\n                f\"Stored MCP session {mcp_session_id} for server={server_name}, \"\n                f\"user={user_id}, session={session_id}\"\n            )\n\n    async def get_mcp_session(self, user_id: str, session_id: str, server_name: str) -&gt; str | None:\n        \"\"\"\n        Get MCP session ID for a server.\n\n        Args:\n            user_id: User ID\n            session_id: Teal agent session ID\n            server_name: Name of the MCP server\n\n        Returns:\n            MCP session ID if exists, None otherwise\n        \"\"\"\n        async with self._lock:\n            key = self._make_key(user_id, session_id)\n            state = self._storage.get(key)\n\n            if not state:\n                return None\n\n            server_data = state.discovered_servers.get(server_name)\n            if not server_data:\n                return None\n\n            session_bucket = server_data.get(\"session\")\n            if not session_bucket:\n                return None\n            return session_bucket.get(\"mcp_session_id\")\n\n    async def update_session_last_used(\n        self, user_id: str, session_id: str, server_name: str\n    ) -&gt; None:\n        \"\"\"\n        Update last_used timestamp for an MCP session.\n\n        Args:\n            user_id: User ID\n            session_id: Teal agent session ID\n            server_name: Name of the MCP server\n\n        Raises:\n            DiscoveryUpdateError: If state or server doesn't exist\n        \"\"\"\n        async with self._lock:\n            key = self._make_key(user_id, session_id)\n            state = self._storage.get(key)\n\n            if not state:\n                raise DiscoveryUpdateError(\n                    f\"MCP state not found for user={user_id}, session={session_id}\"\n                )\n\n            if server_name not in state.discovered_servers:\n                raise DiscoveryUpdateError(\n                    f\"Server {server_name} not found in state for \"\n                    f\"user={user_id}, session={session_id}\"\n                )\n\n            session_bucket = state.discovered_servers[server_name].get(\"session\")\n            if not session_bucket:\n                session_bucket = {}\n            session_bucket[\"last_used_at\"] = datetime.now(UTC).isoformat()\n            state.discovered_servers[server_name][\"session\"] = session_bucket\n\n            logger.debug(\n                f\"Updated last_used for server={server_name}, user={user_id}, session={session_id}\"\n            )\n\n    async def clear_mcp_session(\n        self,\n        user_id: str,\n        session_id: str,\n        server_name: str,\n        expected_session_id: str | None = None,\n    ) -&gt; None:\n        \"\"\"Remove stored MCP session info for a server if present.\"\"\"\n        async with self._lock:\n            key = self._make_key(user_id, session_id)\n            state = self._storage.get(key)\n            if not state:\n                return\n            entry = state.discovered_servers.get(server_name)\n            if not entry:\n                return\n            if \"session\" in entry:\n                if expected_session_id:\n                    current = entry.get(\"session\", {}).get(\"mcp_session_id\")\n                    if current and current != expected_session_id:\n                        # Another session already replaced it; do not clear\n                        return\n                entry.pop(\"session\", None)\n                state.discovered_servers[server_name] = entry\n                logger.debug(\n                    f\"Cleared MCP session for server={server_name}, \"\n                    f\"user={user_id}, session={session_id}\"\n                )\n</code></pre> <code></code> sk_agents.mcp_discovery.InMemoryStateManager.__init__ <pre><code>__init__(app_config)\n</code></pre> <p>Initialize in-memory state manager.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <p>Application configuration (for consistency with other managers)</p> required Source code in <code>src/sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> <pre><code>def __init__(self, app_config):\n    \"\"\"\n    Initialize in-memory state manager.\n\n    Args:\n        app_config: Application configuration (for consistency with other managers)\n    \"\"\"\n    self.app_config = app_config\n    # Storage: {(user_id, session_id): McpState}\n    self._storage: dict[tuple[str, str], McpState] = {}\n    self._lock = asyncio.Lock()\n</code></pre> <code></code> sk_agents.mcp_discovery.InMemoryStateManager.create_discovery <code>async</code> <pre><code>create_discovery(state: McpState) -&gt; None\n</code></pre> <p>Create initial MCP state.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>McpState</code> <p>MCP state to create</p> required <p>Raises:</p> Type Description <code>DiscoveryCreateError</code> <p>If state already exists</p> Source code in <code>src/sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> <pre><code>async def create_discovery(self, state: McpState) -&gt; None:\n    \"\"\"\n    Create initial MCP state.\n\n    Args:\n        state: MCP state to create\n\n    Raises:\n        DiscoveryCreateError: If state already exists\n    \"\"\"\n    async with self._lock:\n        key = self._make_key(state.user_id, state.session_id)\n        if key in self._storage:\n            raise DiscoveryCreateError(\n                f\"MCP state already exists for user={state.user_id}, session={state.session_id}\"\n            )\n        self._storage[key] = state\n        logger.debug(f\"Created MCP state for user={state.user_id}, session={state.session_id}\")\n</code></pre> <code></code> sk_agents.mcp_discovery.InMemoryStateManager.load_discovery <code>async</code> <pre><code>load_discovery(\n    user_id: str, session_id: str\n) -&gt; McpState | None\n</code></pre> <p>Load MCP state.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required <p>Returns:</p> Type Description <code>McpState | None</code> <p>Deep copy of MCP state if exists, None otherwise.</p> <code>McpState | None</code> <p>Returns a copy to prevent external mutations.</p> Source code in <code>src/sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> <pre><code>async def load_discovery(self, user_id: str, session_id: str) -&gt; McpState | None:\n    \"\"\"\n    Load MCP state.\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n\n    Returns:\n        Deep copy of MCP state if exists, None otherwise.\n        Returns a copy to prevent external mutations.\n    \"\"\"\n    async with self._lock:\n        key = self._make_key(user_id, session_id)\n        state = self._storage.get(key)\n        if state is None:\n            return None\n        # Return deep copy to prevent external mutations bypassing update_discovery\n        return copy.deepcopy(state)\n</code></pre> <code></code> sk_agents.mcp_discovery.InMemoryStateManager.update_discovery <code>async</code> <pre><code>update_discovery(state: McpState) -&gt; None\n</code></pre> <p>Update existing MCP state.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>McpState</code> <p>Updated MCP state</p> required <p>Raises:</p> Type Description <code>DiscoveryUpdateError</code> <p>If state does not exist</p> Source code in <code>src/sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> <pre><code>async def update_discovery(self, state: McpState) -&gt; None:\n    \"\"\"\n    Update existing MCP state.\n\n    Args:\n        state: Updated MCP state\n\n    Raises:\n        DiscoveryUpdateError: If state does not exist\n    \"\"\"\n    async with self._lock:\n        key = self._make_key(state.user_id, state.session_id)\n        if key not in self._storage:\n            raise DiscoveryUpdateError(\n                f\"MCP state not found for user={state.user_id}, session={state.session_id}\"\n            )\n        self._storage[key] = state\n        logger.debug(f\"Updated MCP state for user={state.user_id}, session={state.session_id}\")\n</code></pre> <code></code> sk_agents.mcp_discovery.InMemoryStateManager.delete_discovery <code>async</code> <pre><code>delete_discovery(user_id: str, session_id: str) -&gt; None\n</code></pre> <p>Delete MCP state.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required Source code in <code>src/sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> <pre><code>async def delete_discovery(self, user_id: str, session_id: str) -&gt; None:\n    \"\"\"\n    Delete MCP state.\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n    \"\"\"\n    async with self._lock:\n        key = self._make_key(user_id, session_id)\n        if key in self._storage:\n            del self._storage[key]\n            logger.debug(f\"Deleted MCP state for user={user_id}, session={session_id}\")\n</code></pre> <code></code> sk_agents.mcp_discovery.InMemoryStateManager.mark_completed <code>async</code> <pre><code>mark_completed(user_id: str, session_id: str) -&gt; None\n</code></pre> <p>Mark discovery as completed.</p> <p>If state doesn't exist, auto-creates it with discovery_completed=True and empty discovered_servers dict. A warning is logged when auto-creating.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required Source code in <code>src/sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> <pre><code>async def mark_completed(self, user_id: str, session_id: str) -&gt; None:\n    \"\"\"\n    Mark discovery as completed.\n\n    If state doesn't exist, auto-creates it with discovery_completed=True\n    and empty discovered_servers dict. A warning is logged when auto-creating.\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n    \"\"\"\n    async with self._lock:\n        key = self._make_key(user_id, session_id)\n        if key in self._storage:\n            self._storage[key].discovery_completed = True\n            logger.debug(f\"Marked discovery completed for user={user_id}, session={session_id}\")\n        else:\n            # Auto-create state if it doesn't exist\n            logger.warning(\n                f\"MCP state not found for user={user_id}, session={session_id}. \"\n                f\"Auto-creating with discovery_completed=True.\"\n            )\n            state = McpState(\n                user_id=user_id,\n                session_id=session_id,\n                discovered_servers={},\n                discovery_completed=True,\n                created_at=datetime.now(UTC),\n            )\n            self._storage[key] = state\n</code></pre> <code></code> sk_agents.mcp_discovery.InMemoryStateManager.is_completed <code>async</code> <pre><code>is_completed(user_id: str, session_id: str) -&gt; bool\n</code></pre> <p>Check if discovery is completed.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if discovery completed, False otherwise</p> Source code in <code>src/sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> <pre><code>async def is_completed(self, user_id: str, session_id: str) -&gt; bool:\n    \"\"\"\n    Check if discovery is completed.\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n\n    Returns:\n        True if discovery completed, False otherwise\n    \"\"\"\n    async with self._lock:\n        key = self._make_key(user_id, session_id)\n        state = self._storage.get(key)\n        return state.discovery_completed if state else False\n</code></pre> <code></code> sk_agents.mcp_discovery.InMemoryStateManager.store_mcp_session <code>async</code> <pre><code>store_mcp_session(\n    user_id: str,\n    session_id: str,\n    server_name: str,\n    mcp_session_id: str,\n) -&gt; None\n</code></pre> <p>Store MCP session ID for a server.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Teal agent session ID</p> required <code>server_name</code> <code>str</code> <p>Name of the MCP server</p> required <code>mcp_session_id</code> <code>str</code> <p>MCP session ID from server</p> required Source code in <code>src/sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> <pre><code>async def store_mcp_session(\n    self, user_id: str, session_id: str, server_name: str, mcp_session_id: str\n) -&gt; None:\n    \"\"\"\n    Store MCP session ID for a server.\n\n    Args:\n        user_id: User ID\n        session_id: Teal agent session ID\n        server_name: Name of the MCP server\n        mcp_session_id: MCP session ID from server\n    \"\"\"\n    async with self._lock:\n        key = self._make_key(user_id, session_id)\n        state = self._storage.get(key)\n\n        # Auto-create state if doesn't exist\n        if not state:\n            logger.warning(\n                f\"MCP state not found for user={user_id}, session={session_id}. \"\n                f\"Auto-creating to store session for {server_name}.\"\n            )\n            state = McpState(\n                user_id=user_id,\n                session_id=session_id,\n                discovered_servers={},\n                discovery_completed=False,\n                created_at=datetime.now(UTC),\n            )\n            self._storage[key] = state\n\n        # Ensure server entry exists and preserve plugin_data if present\n        existing_entry = state.discovered_servers.get(server_name, {})\n        plugin_data = existing_entry.get(\"plugin_data\")\n        state.discovered_servers[server_name] = {\n            \"plugin_data\": plugin_data,\n            **(\n                {\"session\": existing_entry.get(\"session\")}\n                if existing_entry.get(\"session\")\n                else {}\n            ),\n        }\n\n        # Store session data\n        session_bucket = state.discovered_servers[server_name].get(\"session\", {})\n        now_iso = datetime.now(UTC).isoformat()\n        session_bucket.update(\n            {\n                \"mcp_session_id\": mcp_session_id,\n                \"created_at\": session_bucket.get(\"created_at\", now_iso),\n                \"last_used_at\": now_iso,\n            }\n        )\n        state.discovered_servers[server_name][\"session\"] = session_bucket\n\n        logger.debug(\n            f\"Stored MCP session {mcp_session_id} for server={server_name}, \"\n            f\"user={user_id}, session={session_id}\"\n        )\n</code></pre> <code></code> sk_agents.mcp_discovery.InMemoryStateManager.get_mcp_session <code>async</code> <pre><code>get_mcp_session(\n    user_id: str, session_id: str, server_name: str\n) -&gt; str | None\n</code></pre> <p>Get MCP session ID for a server.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Teal agent session ID</p> required <code>server_name</code> <code>str</code> <p>Name of the MCP server</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>MCP session ID if exists, None otherwise</p> Source code in <code>src/sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> <pre><code>async def get_mcp_session(self, user_id: str, session_id: str, server_name: str) -&gt; str | None:\n    \"\"\"\n    Get MCP session ID for a server.\n\n    Args:\n        user_id: User ID\n        session_id: Teal agent session ID\n        server_name: Name of the MCP server\n\n    Returns:\n        MCP session ID if exists, None otherwise\n    \"\"\"\n    async with self._lock:\n        key = self._make_key(user_id, session_id)\n        state = self._storage.get(key)\n\n        if not state:\n            return None\n\n        server_data = state.discovered_servers.get(server_name)\n        if not server_data:\n            return None\n\n        session_bucket = server_data.get(\"session\")\n        if not session_bucket:\n            return None\n        return session_bucket.get(\"mcp_session_id\")\n</code></pre> <code></code> sk_agents.mcp_discovery.InMemoryStateManager.update_session_last_used <code>async</code> <pre><code>update_session_last_used(\n    user_id: str, session_id: str, server_name: str\n) -&gt; None\n</code></pre> <p>Update last_used timestamp for an MCP session.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Teal agent session ID</p> required <code>server_name</code> <code>str</code> <p>Name of the MCP server</p> required <p>Raises:</p> Type Description <code>DiscoveryUpdateError</code> <p>If state or server doesn't exist</p> Source code in <code>src/sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> <pre><code>async def update_session_last_used(\n    self, user_id: str, session_id: str, server_name: str\n) -&gt; None:\n    \"\"\"\n    Update last_used timestamp for an MCP session.\n\n    Args:\n        user_id: User ID\n        session_id: Teal agent session ID\n        server_name: Name of the MCP server\n\n    Raises:\n        DiscoveryUpdateError: If state or server doesn't exist\n    \"\"\"\n    async with self._lock:\n        key = self._make_key(user_id, session_id)\n        state = self._storage.get(key)\n\n        if not state:\n            raise DiscoveryUpdateError(\n                f\"MCP state not found for user={user_id}, session={session_id}\"\n            )\n\n        if server_name not in state.discovered_servers:\n            raise DiscoveryUpdateError(\n                f\"Server {server_name} not found in state for \"\n                f\"user={user_id}, session={session_id}\"\n            )\n\n        session_bucket = state.discovered_servers[server_name].get(\"session\")\n        if not session_bucket:\n            session_bucket = {}\n        session_bucket[\"last_used_at\"] = datetime.now(UTC).isoformat()\n        state.discovered_servers[server_name][\"session\"] = session_bucket\n\n        logger.debug(\n            f\"Updated last_used for server={server_name}, user={user_id}, session={session_id}\"\n        )\n</code></pre> <code></code> sk_agents.mcp_discovery.InMemoryStateManager.clear_mcp_session <code>async</code> <pre><code>clear_mcp_session(\n    user_id: str,\n    session_id: str,\n    server_name: str,\n    expected_session_id: str | None = None,\n) -&gt; None\n</code></pre> <p>Remove stored MCP session info for a server if present.</p> Source code in <code>src/sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> <pre><code>async def clear_mcp_session(\n    self,\n    user_id: str,\n    session_id: str,\n    server_name: str,\n    expected_session_id: str | None = None,\n) -&gt; None:\n    \"\"\"Remove stored MCP session info for a server if present.\"\"\"\n    async with self._lock:\n        key = self._make_key(user_id, session_id)\n        state = self._storage.get(key)\n        if not state:\n            return\n        entry = state.discovered_servers.get(server_name)\n        if not entry:\n            return\n        if \"session\" in entry:\n            if expected_session_id:\n                current = entry.get(\"session\", {}).get(\"mcp_session_id\")\n                if current and current != expected_session_id:\n                    # Another session already replaced it; do not clear\n                    return\n            entry.pop(\"session\", None)\n            state.discovered_servers[server_name] = entry\n            logger.debug(\n                f\"Cleared MCP session for server={server_name}, \"\n                f\"user={user_id}, session={session_id}\"\n            )\n</code></pre> <code></code> sk_agents.mcp_discovery.McpState <p>MCP state for a specific user session.</p> <p>Stores the results of MCP server discovery and session management including: - Which servers have been discovered - Serialized plugin data for each server - MCP session IDs for stateful servers - Completion status</p> <p>Scoped to (user_id, session_id) for session-level isolation.</p> <p>Structure of discovered_servers: {     \"server_name\": {         \"tools\": [...],  # Plugin metadata         \"mcp_session_id\": \"session-abc123\",  # Optional, for stateful servers         \"last_used_at\": \"2025-01-15T10:30:00Z\",  # Optional, session activity timestamp         \"created_at\": \"2025-01-15T10:00:00Z\"  # Optional, session creation timestamp     } }</p> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>class McpState:\n    \"\"\"\n    MCP state for a specific user session.\n\n    Stores the results of MCP server discovery and session management including:\n    - Which servers have been discovered\n    - Serialized plugin data for each server\n    - MCP session IDs for stateful servers\n    - Completion status\n\n    Scoped to (user_id, session_id) for session-level isolation.\n\n    Structure of discovered_servers:\n    {\n        \"server_name\": {\n            \"tools\": [...],  # Plugin metadata\n            \"mcp_session_id\": \"session-abc123\",  # Optional, for stateful servers\n            \"last_used_at\": \"2025-01-15T10:30:00Z\",  # Optional, session activity timestamp\n            \"created_at\": \"2025-01-15T10:00:00Z\"  # Optional, session creation timestamp\n        }\n    }\n    \"\"\"\n\n    def __init__(\n        self,\n        user_id: str,\n        session_id: str,\n        discovered_servers: dict[str, dict],\n        discovery_completed: bool,\n        created_at: datetime | None = None,\n        failed_servers: dict[str, str] | None = None,\n    ):\n        \"\"\"\n        Initialize MCP state.\n\n        Args:\n            user_id: User ID for authentication and scoping\n            session_id: Session ID for conversation grouping\n            discovered_servers: Mapping of server_name to plugin data and session info\n            discovery_completed: Whether discovery has finished successfully\n            created_at: Timestamp of state creation (defaults to now)\n            failed_servers: Dictionary of failed servers and their error messages\n        \"\"\"\n        self.user_id = user_id\n        self.session_id = session_id\n        self.discovered_servers = discovered_servers\n        self.discovery_completed = discovery_completed\n        self.created_at = created_at or datetime.now(UTC)\n        self.failed_servers = failed_servers or {}\n</code></pre> <code></code> sk_agents.mcp_discovery.McpState.__init__ <pre><code>__init__(\n    user_id: str,\n    session_id: str,\n    discovered_servers: dict[str, dict],\n    discovery_completed: bool,\n    created_at: datetime | None = None,\n    failed_servers: dict[str, str] | None = None,\n)\n</code></pre> <p>Initialize MCP state.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID for authentication and scoping</p> required <code>session_id</code> <code>str</code> <p>Session ID for conversation grouping</p> required <code>discovered_servers</code> <code>dict[str, dict]</code> <p>Mapping of server_name to plugin data and session info</p> required <code>discovery_completed</code> <code>bool</code> <p>Whether discovery has finished successfully</p> required <code>created_at</code> <code>datetime | None</code> <p>Timestamp of state creation (defaults to now)</p> <code>None</code> <code>failed_servers</code> <code>dict[str, str] | None</code> <p>Dictionary of failed servers and their error messages</p> <code>None</code> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>def __init__(\n    self,\n    user_id: str,\n    session_id: str,\n    discovered_servers: dict[str, dict],\n    discovery_completed: bool,\n    created_at: datetime | None = None,\n    failed_servers: dict[str, str] | None = None,\n):\n    \"\"\"\n    Initialize MCP state.\n\n    Args:\n        user_id: User ID for authentication and scoping\n        session_id: Session ID for conversation grouping\n        discovered_servers: Mapping of server_name to plugin data and session info\n        discovery_completed: Whether discovery has finished successfully\n        created_at: Timestamp of state creation (defaults to now)\n        failed_servers: Dictionary of failed servers and their error messages\n    \"\"\"\n    self.user_id = user_id\n    self.session_id = session_id\n    self.discovered_servers = discovered_servers\n    self.discovery_completed = discovery_completed\n    self.created_at = created_at or datetime.now(UTC)\n    self.failed_servers = failed_servers or {}\n</code></pre> <code></code> sk_agents.mcp_discovery.McpStateManager <p>               Bases: <code>ABC</code></p> <p>Abstract interface for MCP state management (discovery + sessions).</p> <p>Implementations must provide storage for MCP state scoped to (user_id, session_id) combinations. This enables: - Session-level tool isolation - Shared discovery across tasks in the same session - MCP session persistence for stateful servers - External state storage (Redis, in-memory, etc.)</p> <p>Pattern matches: - TaskPersistenceManager (for task state) - SecureAuthStorageManager (for OAuth tokens)</p> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>class McpStateManager(ABC):\n    \"\"\"\n    Abstract interface for MCP state management (discovery + sessions).\n\n    Implementations must provide storage for MCP state scoped to\n    (user_id, session_id) combinations. This enables:\n    - Session-level tool isolation\n    - Shared discovery across tasks in the same session\n    - MCP session persistence for stateful servers\n    - External state storage (Redis, in-memory, etc.)\n\n    Pattern matches:\n    - TaskPersistenceManager (for task state)\n    - SecureAuthStorageManager (for OAuth tokens)\n    \"\"\"\n\n    @abstractmethod\n    async def create_discovery(self, state: McpState) -&gt; None:\n        \"\"\"\n        Create initial state for (user_id, session_id).\n\n        Args:\n            state: MCP state to create\n\n        Raises:\n            DiscoveryCreateError: If state already exists for this (user_id, session_id)\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def load_discovery(self, user_id: str, session_id: str) -&gt; McpState | None:\n        \"\"\"\n        Load MCP state for (user_id, session_id).\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n\n        Returns:\n            MCP state if exists, None otherwise\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def update_discovery(self, state: McpState) -&gt; None:\n        \"\"\"\n        Update existing MCP state.\n\n        Args:\n            state: Updated MCP state\n\n        Raises:\n            DiscoveryUpdateError: If state does not exist\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def delete_discovery(self, user_id: str, session_id: str) -&gt; None:\n        \"\"\"\n        Delete MCP state for (user_id, session_id).\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def mark_completed(self, user_id: str, session_id: str) -&gt; None:\n        \"\"\"\n        Mark discovery as completed for (user_id, session_id).\n\n        If the state does not exist, it will be created automatically\n        with an empty discovered_servers dict and discovery_completed=True.\n        A warning will be logged when auto-creating.\n\n        This operation is idempotent - calling it multiple times has the same\n        effect as calling it once.\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def is_completed(self, user_id: str, session_id: str) -&gt; bool:\n        \"\"\"\n        Check if discovery is completed for (user_id, session_id).\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n\n        Returns:\n            True if discovery completed, False otherwise\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def store_mcp_session(\n        self, user_id: str, session_id: str, server_name: str, mcp_session_id: str\n    ) -&gt; None:\n        \"\"\"\n        Store MCP session ID for a server.\n\n        If state doesn't exist, it will be created. If server doesn't exist\n        in discovered_servers, it will be added.\n\n        Args:\n            user_id: User ID\n            session_id: Teal agent session ID\n            server_name: Name of the MCP server\n            mcp_session_id: MCP session ID from server\n\n        Raises:\n            DiscoveryUpdateError: If state update fails\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def get_mcp_session(self, user_id: str, session_id: str, server_name: str) -&gt; str | None:\n        \"\"\"\n        Get MCP session ID for a server.\n\n        Args:\n            user_id: User ID\n            session_id: Teal agent session ID\n            server_name: Name of the MCP server\n\n        Returns:\n            MCP session ID if exists, None otherwise\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def update_session_last_used(\n        self, user_id: str, session_id: str, server_name: str\n    ) -&gt; None:\n        \"\"\"\n        Update last_used timestamp for an MCP session.\n\n        Args:\n            user_id: User ID\n            session_id: Teal agent session ID\n            server_name: Name of the MCP server\n\n        Raises:\n            DiscoveryUpdateError: If state or server doesn't exist\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def clear_mcp_session(\n        self,\n        user_id: str,\n        session_id: str,\n        server_name: str,\n        expected_session_id: str | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Clear the stored MCP session for a given server (if present).\n\n        Args:\n            user_id: User ID\n            session_id: Teal agent session ID\n            server_name: Name of the MCP server\n            expected_session_id: Optional session id to match before clearing\n        \"\"\"\n        pass\n</code></pre> <code></code> sk_agents.mcp_discovery.McpStateManager.create_discovery <code>abstractmethod</code> <code>async</code> <pre><code>create_discovery(state: McpState) -&gt; None\n</code></pre> <p>Create initial state for (user_id, session_id).</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>McpState</code> <p>MCP state to create</p> required <p>Raises:</p> Type Description <code>DiscoveryCreateError</code> <p>If state already exists for this (user_id, session_id)</p> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>@abstractmethod\nasync def create_discovery(self, state: McpState) -&gt; None:\n    \"\"\"\n    Create initial state for (user_id, session_id).\n\n    Args:\n        state: MCP state to create\n\n    Raises:\n        DiscoveryCreateError: If state already exists for this (user_id, session_id)\n    \"\"\"\n    pass\n</code></pre> <code></code> sk_agents.mcp_discovery.McpStateManager.load_discovery <code>abstractmethod</code> <code>async</code> <pre><code>load_discovery(\n    user_id: str, session_id: str\n) -&gt; McpState | None\n</code></pre> <p>Load MCP state for (user_id, session_id).</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required <p>Returns:</p> Type Description <code>McpState | None</code> <p>MCP state if exists, None otherwise</p> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>@abstractmethod\nasync def load_discovery(self, user_id: str, session_id: str) -&gt; McpState | None:\n    \"\"\"\n    Load MCP state for (user_id, session_id).\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n\n    Returns:\n        MCP state if exists, None otherwise\n    \"\"\"\n    pass\n</code></pre> <code></code> sk_agents.mcp_discovery.McpStateManager.update_discovery <code>abstractmethod</code> <code>async</code> <pre><code>update_discovery(state: McpState) -&gt; None\n</code></pre> <p>Update existing MCP state.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>McpState</code> <p>Updated MCP state</p> required <p>Raises:</p> Type Description <code>DiscoveryUpdateError</code> <p>If state does not exist</p> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>@abstractmethod\nasync def update_discovery(self, state: McpState) -&gt; None:\n    \"\"\"\n    Update existing MCP state.\n\n    Args:\n        state: Updated MCP state\n\n    Raises:\n        DiscoveryUpdateError: If state does not exist\n    \"\"\"\n    pass\n</code></pre> <code></code> sk_agents.mcp_discovery.McpStateManager.delete_discovery <code>abstractmethod</code> <code>async</code> <pre><code>delete_discovery(user_id: str, session_id: str) -&gt; None\n</code></pre> <p>Delete MCP state for (user_id, session_id).</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>@abstractmethod\nasync def delete_discovery(self, user_id: str, session_id: str) -&gt; None:\n    \"\"\"\n    Delete MCP state for (user_id, session_id).\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n    \"\"\"\n    pass\n</code></pre> <code></code> sk_agents.mcp_discovery.McpStateManager.mark_completed <code>abstractmethod</code> <code>async</code> <pre><code>mark_completed(user_id: str, session_id: str) -&gt; None\n</code></pre> <p>Mark discovery as completed for (user_id, session_id).</p> <p>If the state does not exist, it will be created automatically with an empty discovered_servers dict and discovery_completed=True. A warning will be logged when auto-creating.</p> <p>This operation is idempotent - calling it multiple times has the same effect as calling it once.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>@abstractmethod\nasync def mark_completed(self, user_id: str, session_id: str) -&gt; None:\n    \"\"\"\n    Mark discovery as completed for (user_id, session_id).\n\n    If the state does not exist, it will be created automatically\n    with an empty discovered_servers dict and discovery_completed=True.\n    A warning will be logged when auto-creating.\n\n    This operation is idempotent - calling it multiple times has the same\n    effect as calling it once.\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n    \"\"\"\n    pass\n</code></pre> <code></code> sk_agents.mcp_discovery.McpStateManager.is_completed <code>abstractmethod</code> <code>async</code> <pre><code>is_completed(user_id: str, session_id: str) -&gt; bool\n</code></pre> <p>Check if discovery is completed for (user_id, session_id).</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if discovery completed, False otherwise</p> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>@abstractmethod\nasync def is_completed(self, user_id: str, session_id: str) -&gt; bool:\n    \"\"\"\n    Check if discovery is completed for (user_id, session_id).\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n\n    Returns:\n        True if discovery completed, False otherwise\n    \"\"\"\n    pass\n</code></pre> <code></code> sk_agents.mcp_discovery.McpStateManager.store_mcp_session <code>abstractmethod</code> <code>async</code> <pre><code>store_mcp_session(\n    user_id: str,\n    session_id: str,\n    server_name: str,\n    mcp_session_id: str,\n) -&gt; None\n</code></pre> <p>Store MCP session ID for a server.</p> <p>If state doesn't exist, it will be created. If server doesn't exist in discovered_servers, it will be added.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Teal agent session ID</p> required <code>server_name</code> <code>str</code> <p>Name of the MCP server</p> required <code>mcp_session_id</code> <code>str</code> <p>MCP session ID from server</p> required <p>Raises:</p> Type Description <code>DiscoveryUpdateError</code> <p>If state update fails</p> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>@abstractmethod\nasync def store_mcp_session(\n    self, user_id: str, session_id: str, server_name: str, mcp_session_id: str\n) -&gt; None:\n    \"\"\"\n    Store MCP session ID for a server.\n\n    If state doesn't exist, it will be created. If server doesn't exist\n    in discovered_servers, it will be added.\n\n    Args:\n        user_id: User ID\n        session_id: Teal agent session ID\n        server_name: Name of the MCP server\n        mcp_session_id: MCP session ID from server\n\n    Raises:\n        DiscoveryUpdateError: If state update fails\n    \"\"\"\n    pass\n</code></pre> <code></code> sk_agents.mcp_discovery.McpStateManager.get_mcp_session <code>abstractmethod</code> <code>async</code> <pre><code>get_mcp_session(\n    user_id: str, session_id: str, server_name: str\n) -&gt; str | None\n</code></pre> <p>Get MCP session ID for a server.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Teal agent session ID</p> required <code>server_name</code> <code>str</code> <p>Name of the MCP server</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>MCP session ID if exists, None otherwise</p> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>@abstractmethod\nasync def get_mcp_session(self, user_id: str, session_id: str, server_name: str) -&gt; str | None:\n    \"\"\"\n    Get MCP session ID for a server.\n\n    Args:\n        user_id: User ID\n        session_id: Teal agent session ID\n        server_name: Name of the MCP server\n\n    Returns:\n        MCP session ID if exists, None otherwise\n    \"\"\"\n    pass\n</code></pre> <code></code> sk_agents.mcp_discovery.McpStateManager.update_session_last_used <code>abstractmethod</code> <code>async</code> <pre><code>update_session_last_used(\n    user_id: str, session_id: str, server_name: str\n) -&gt; None\n</code></pre> <p>Update last_used timestamp for an MCP session.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Teal agent session ID</p> required <code>server_name</code> <code>str</code> <p>Name of the MCP server</p> required <p>Raises:</p> Type Description <code>DiscoveryUpdateError</code> <p>If state or server doesn't exist</p> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>@abstractmethod\nasync def update_session_last_used(\n    self, user_id: str, session_id: str, server_name: str\n) -&gt; None:\n    \"\"\"\n    Update last_used timestamp for an MCP session.\n\n    Args:\n        user_id: User ID\n        session_id: Teal agent session ID\n        server_name: Name of the MCP server\n\n    Raises:\n        DiscoveryUpdateError: If state or server doesn't exist\n    \"\"\"\n    pass\n</code></pre> <code></code> sk_agents.mcp_discovery.McpStateManager.clear_mcp_session <code>abstractmethod</code> <code>async</code> <pre><code>clear_mcp_session(\n    user_id: str,\n    session_id: str,\n    server_name: str,\n    expected_session_id: str | None = None,\n) -&gt; None\n</code></pre> <p>Clear the stored MCP session for a given server (if present).</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Teal agent session ID</p> required <code>server_name</code> <code>str</code> <p>Name of the MCP server</p> required <code>expected_session_id</code> <code>str | None</code> <p>Optional session id to match before clearing</p> <code>None</code> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>@abstractmethod\nasync def clear_mcp_session(\n    self,\n    user_id: str,\n    session_id: str,\n    server_name: str,\n    expected_session_id: str | None = None,\n) -&gt; None:\n    \"\"\"\n    Clear the stored MCP session for a given server (if present).\n\n    Args:\n        user_id: User ID\n        session_id: Teal agent session ID\n        server_name: Name of the MCP server\n        expected_session_id: Optional session id to match before clearing\n    \"\"\"\n    pass\n</code></pre> <code></code> sk_agents.mcp_discovery.RedisStateManager <p>               Bases: <code>McpStateManager</code></p> <p>Redis-backed implementation of MCP state manager.</p> <p>Stores MCP state in Redis for: - Production deployments - Multi-instance horizontal scaling - Persistence across server restarts - Shared state across distributed systems</p> <p>Uses the same Redis configuration as other components (TA_REDIS_*).</p> Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>class RedisStateManager(McpStateManager):\n    \"\"\"\n    Redis-backed implementation of MCP state manager.\n\n    Stores MCP state in Redis for:\n    - Production deployments\n    - Multi-instance horizontal scaling\n    - Persistence across server restarts\n    - Shared state across distributed systems\n\n    Uses the same Redis configuration as other components (TA_REDIS_*).\n    \"\"\"\n\n    def __init__(self, app_config: AppConfig, redis_client: Redis | None = None):\n        \"\"\"\n        Initialize Redis state manager.\n\n        Args:\n            app_config: Application configuration for Redis connection\n            redis_client: Optional pre-configured Redis client (for testing)\n        \"\"\"\n        self.app_config = app_config\n        self.redis = redis_client or self._create_redis_client()\n        self.key_prefix = \"mcp_state\"\n\n        # TTL support: Default to 24 hours (86400 seconds)\n        from sk_agents.configs import TA_REDIS_TTL\n\n        ttl_str = self.app_config.get(TA_REDIS_TTL.env_name)\n        if ttl_str:\n            self.ttl = int(ttl_str)\n        else:\n            # Default to 24 hours for discovery state\n            self.ttl = 86400\n\n        logger.debug(f\"Redis state manager initialized with TTL={self.ttl}s\")\n\n    async def close(self) -&gt; None:\n        \"\"\"Close Redis connection and cleanup resources.\"\"\"\n        if self.redis:\n            await self.redis.close()\n            logger.debug(\"Redis state manager connection closed\")\n\n    async def __aenter__(self):\n        \"\"\"Async context manager entry.\"\"\"\n        return self\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Async context manager exit.\"\"\"\n        await self.close()\n\n    def _create_redis_client(self) -&gt; Redis:\n        \"\"\"\n        Create Redis client from app configuration.\n\n        Reuses existing TA_REDIS_* environment variables for consistency\n        with other persistence components.\n\n        Returns:\n            Configured Redis client\n\n        Raises:\n            ValueError: If required Redis config is missing\n        \"\"\"\n        from sk_agents.configs import (\n            TA_REDIS_DB,\n            TA_REDIS_HOST,\n            TA_REDIS_PORT,\n            TA_REDIS_PWD,\n            TA_REDIS_SSL,\n        )\n\n        host = self.app_config.get(TA_REDIS_HOST.env_name)\n        port_str = self.app_config.get(TA_REDIS_PORT.env_name)\n        db_str = self.app_config.get(TA_REDIS_DB.env_name, default=\"0\")\n        ssl_str = self.app_config.get(TA_REDIS_SSL.env_name, default=\"false\")\n        pwd = self.app_config.get(TA_REDIS_PWD.env_name, default=None)\n\n        if not host:\n            raise ValueError(\"TA_REDIS_HOST must be configured for Redis discovery manager\")\n        if not port_str:\n            raise ValueError(\"TA_REDIS_PORT must be configured for Redis discovery manager\")\n\n        port = int(port_str)\n        db = int(db_str)\n        ssl = strtobool(ssl_str)\n\n        logger.info(\n            f\"Creating Redis discovery client: host={host}, port={port}, db={db}, ssl={ssl}\"\n        )\n\n        return Redis(host=host, port=port, db=db, ssl=ssl, password=pwd)\n\n    def _make_key(self, user_id: str, session_id: str) -&gt; str:\n        \"\"\"\n        Create Redis key for storage.\n\n        Format: mcp_state:{user_id}:{session_id}\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n\n        Returns:\n            Redis key string\n        \"\"\"\n        return f\"{self.key_prefix}:{user_id}:{session_id}\"\n\n    async def create_discovery(self, state: McpState) -&gt; None:\n        \"\"\"\n        Create initial MCP state in Redis.\n\n        Args:\n            state: MCP state to create\n\n        Raises:\n            DiscoveryCreateError: If state already exists\n        \"\"\"\n        key = self._make_key(state.user_id, state.session_id)\n        exists = await self.redis.exists(key)\n        if exists:\n            raise DiscoveryCreateError(\n                f\"MCP state already exists for user={state.user_id}, session={state.session_id}\"\n            )\n\n        data = self._serialize(state)\n        # Set with TTL\n        await self.redis.set(key, data, ex=self.ttl)\n        logger.debug(\n            f\"Created Redis MCP state: user={state.user_id}, session={state.session_id}, \"\n            f\"TTL={self.ttl}s\"\n        )\n\n    async def load_discovery(self, user_id: str, session_id: str) -&gt; McpState | None:\n        \"\"\"\n        Load MCP state from Redis.\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n\n        Returns:\n            MCP state if exists, None otherwise\n        \"\"\"\n        key = self._make_key(user_id, session_id)\n        data = await self.redis.get(key)\n        if not data:\n            return None\n        return self._deserialize(data, user_id, session_id)\n\n    async def update_discovery(self, state: McpState) -&gt; None:\n        \"\"\"\n        Update existing MCP state in Redis.\n\n        Args:\n            state: Updated MCP state\n\n        Raises:\n            DiscoveryUpdateError: If state does not exist\n        \"\"\"\n        key = self._make_key(state.user_id, state.session_id)\n        # Check existence before updating\n        exists = await self.redis.exists(key)\n        if not exists:\n            raise DiscoveryUpdateError(\n                f\"MCP state not found for user={state.user_id}, session={state.session_id}\"\n            )\n\n        data = self._serialize(state)\n        # Update with TTL to extend expiration\n        await self.redis.set(key, data, ex=self.ttl)\n        logger.debug(f\"Updated Redis MCP state: user={state.user_id}, session={state.session_id}\")\n\n    async def delete_discovery(self, user_id: str, session_id: str) -&gt; None:\n        \"\"\"\n        Delete discovery state from Redis.\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n        \"\"\"\n        key = self._make_key(user_id, session_id)\n        await self.redis.delete(key)\n        logger.debug(f\"Deleted Redis discovery state: user={user_id}, session={session_id}\")\n\n    async def mark_completed(self, user_id: str, session_id: str) -&gt; None:\n        \"\"\"\n        Mark discovery as completed in Redis using atomic operation.\n\n        If state doesn't exist, auto-creates it with discovery_completed=True\n        and empty discovered_servers dict. A warning is logged when auto-creating.\n\n        Uses Lua script for atomic read-modify-write to prevent race conditions\n        in multi-worker deployments.\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n        \"\"\"\n        key = self._make_key(user_id, session_id)\n\n        # Lua script for atomic mark_completed operation\n        lua_script = \"\"\"\n        local key = KEYS[1]\n        local ttl = tonumber(ARGV[1])\n        local data = redis.call('GET', key)\n\n        if data then\n            -- State exists, update discovery_completed field\n            local obj = cjson.decode(data)\n            obj.discovery_completed = true\n            local updated_data = cjson.encode(obj)\n            redis.call('SET', key, updated_data, 'EX', ttl)\n            return 1\n        else\n            -- State doesn't exist, return 0 to signal auto-create\n            return 0\n        end\n        \"\"\"\n\n        result = await self.redis.eval(lua_script, 1, key, self.ttl)\n\n        if result == 1:\n            logger.debug(f\"Marked discovery completed: user={user_id}, session={session_id}\")\n        else:\n            # Auto-create state if it doesn't exist\n            logger.warning(\n                f\"MCP state not found for user={user_id}, session={session_id}. \"\n                f\"Auto-creating with discovery_completed=True.\"\n            )\n            state = McpState(\n                user_id=user_id,\n                session_id=session_id,\n                discovered_servers={},\n                discovery_completed=True,\n                created_at=datetime.now(UTC),\n            )\n            data = self._serialize(state)\n            await self.redis.set(key, data, ex=self.ttl)\n            logger.debug(f\"Auto-created discovery state: user={user_id}, session={session_id}\")\n\n    async def is_completed(self, user_id: str, session_id: str) -&gt; bool:\n        \"\"\"\n        Check if discovery is completed in Redis.\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n\n        Returns:\n            True if discovery completed, False otherwise\n        \"\"\"\n        state = await self.load_discovery(user_id, session_id)\n        return state.discovery_completed if state else False\n\n    async def store_mcp_session(\n        self, user_id: str, session_id: str, server_name: str, mcp_session_id: str\n    ) -&gt; None:\n        \"\"\"\n        Store MCP session ID for a server using atomic Lua script.\n\n        Args:\n            user_id: User ID\n            session_id: Teal agent session ID\n            server_name: Name of the MCP server\n            mcp_session_id: MCP session ID from server\n        \"\"\"\n        key = self._make_key(user_id, session_id)\n\n        # Lua script for atomic store operation\n        lua_script = \"\"\"\n        local key = KEYS[1]\n        local ttl = tonumber(ARGV[1])\n        local server_name = ARGV[2]\n        local mcp_session_id = ARGV[3]\n        local timestamp = ARGV[4]\n\n        local data = redis.call('GET', key)\n        local obj\n\n        if data then\n            -- State exists, update it\n            obj = cjson.decode(data)\n        else\n            -- State doesn't exist, create minimal state\n            obj = {\n                user_id = ARGV[5],\n                session_id = ARGV[6],\n                discovered_servers = {},\n                discovery_completed = false,\n                created_at = timestamp\n            }\n        end\n\n        -- Ensure server entry exists\n        if not obj.discovered_servers[server_name] then\n            obj.discovered_servers[server_name] = {}\n        end\n\n        -- Store session data\n        if not obj.discovered_servers[server_name].session then\n            obj.discovered_servers[server_name].session = {}\n        end\n\n        obj.discovered_servers[server_name].session.mcp_session_id = mcp_session_id\n        local sess = obj.discovered_servers[server_name].session\n        sess.created_at = sess.created_at or timestamp\n        sess.last_used_at = timestamp\n\n        local updated_data = cjson.encode(obj)\n        redis.call('SET', key, updated_data, 'EX', ttl)\n        return 1\n        \"\"\"\n\n        timestamp = datetime.now(UTC).isoformat()\n        await self.redis.eval(\n            lua_script,\n            1,\n            key,\n            self.ttl,\n            server_name,\n            mcp_session_id,\n            timestamp,\n            user_id,\n            session_id,\n        )\n\n        logger.debug(\n            f\"Stored MCP session {mcp_session_id} for server={server_name}, \"\n            f\"user={user_id}, session={session_id}\"\n        )\n\n    async def get_mcp_session(self, user_id: str, session_id: str, server_name: str) -&gt; str | None:\n        \"\"\"\n        Get MCP session ID for a server.\n\n        Args:\n            user_id: User ID\n            session_id: Teal agent session ID\n            server_name: Name of the MCP server\n\n        Returns:\n            MCP session ID if exists, None otherwise\n        \"\"\"\n        state = await self.load_discovery(user_id, session_id)\n\n        if not state:\n            return None\n\n        server_data = state.discovered_servers.get(server_name)\n        if not server_data:\n            return None\n\n        session_bucket = server_data.get(\"session\")\n        if not session_bucket:\n            return None\n\n        return session_bucket.get(\"mcp_session_id\")\n\n    async def update_session_last_used(\n        self, user_id: str, session_id: str, server_name: str\n    ) -&gt; None:\n        \"\"\"\n        Update last_used timestamp using atomic Lua script.\n\n        Args:\n            user_id: User ID\n            session_id: Teal agent session ID\n            server_name: Name of the MCP server\n\n        Raises:\n            DiscoveryUpdateError: If state or server doesn't exist\n        \"\"\"\n        key = self._make_key(user_id, session_id)\n\n        # Lua script for atomic update\n        lua_script = \"\"\"\n        local key = KEYS[1]\n        local ttl = tonumber(ARGV[1])\n        local server_name = ARGV[2]\n        local timestamp = ARGV[3]\n\n        local data = redis.call('GET', key)\n        if not data then\n            return 0  -- State not found\n        end\n\n        local obj = cjson.decode(data)\n\n        if not obj.discovered_servers[server_name] then\n            return -1  -- Server not found\n        end\n\n        if not obj.discovered_servers[server_name].session then\n            obj.discovered_servers[server_name].session = {}\n        end\n        obj.discovered_servers[server_name].session.last_used_at = timestamp\n\n        local updated_data = cjson.encode(obj)\n        redis.call('SET', key, updated_data, 'EX', ttl)\n        return 1\n        \"\"\"\n\n        timestamp = datetime.now(UTC).isoformat()\n        result = await self.redis.eval(lua_script, 1, key, self.ttl, server_name, timestamp)\n\n        if result == 0:\n            raise DiscoveryUpdateError(\n                f\"MCP state not found for user={user_id}, session={session_id}\"\n            )\n        elif result == -1:\n            raise DiscoveryUpdateError(\n                f\"Server {server_name} not found in state for user={user_id}, session={session_id}\"\n            )\n\n        logger.debug(\n            f\"Updated last_used for server={server_name}, user={user_id}, session={session_id}\"\n        )\n\n    async def clear_mcp_session(\n        self,\n        user_id: str,\n        session_id: str,\n        server_name: str,\n        expected_session_id: str | None = None,\n    ) -&gt; None:\n        \"\"\"Remove stored MCP session info for a server if present.\"\"\"\n        key = self._make_key(user_id, session_id)\n\n        lua_script = \"\"\"\n        local key = KEYS[1]\n        local server_name = ARGV[1]\n        local ttl = tonumber(ARGV[2])\n        local expected_session_id = ARGV[3]\n\n        local data = redis.call('GET', key)\n        if not data then\n            return 0 -- state missing\n        end\n\n        local obj = cjson.decode(data)\n        if not obj.discovered_servers[server_name] then\n            return -1 -- server missing\n        end\n\n        -- Only clear if expected matches or no expectation provided\n        if obj.discovered_servers[server_name].session then\n            local current = obj.discovered_servers[server_name].session.mcp_session_id\n            if expected_session_id ~= nil and expected_session_id ~= '' then\n                if current ~= expected_session_id then\n                    return -2  -- session changed, skip clear\n                end\n            end\n        end\n\n        obj.discovered_servers[server_name].session = nil\n\n        local updated_data = cjson.encode(obj)\n        redis.call('SET', key, updated_data, 'EX', ttl)\n        return 1\n        \"\"\"\n\n        expected_arg = expected_session_id or \"\"\n        result = await self.redis.eval(lua_script, 1, key, server_name, self.ttl, expected_arg)\n        if result == 0:\n            logger.debug(\n                f\"clear_mcp_session: state missing for user={user_id}, session={session_id}\"\n            )\n        elif result == -1:\n            logger.debug(\n                f\"clear_mcp_session: server missing for user={user_id}, \"\n                f\"session={session_id}, server={server_name}\"\n            )\n        elif result == -2:\n            logger.debug(\n                f\"clear_mcp_session: session changed for user={user_id}, \"\n                f\"session={session_id}, server={server_name}\"\n            )\n        else:\n            logger.debug(\n                f\"Cleared MCP session for server={server_name}, \"\n                f\"user={user_id}, session={session_id}\"\n            )\n\n    def _serialize(self, state: McpState) -&gt; str:\n        \"\"\"\n        Serialize MCP state to JSON.\n\n        Args:\n            state: MCP state to serialize\n\n        Returns:\n            JSON string representation\n        \"\"\"\n        return json.dumps(\n            {\n                \"user_id\": state.user_id,\n                \"session_id\": state.session_id,\n                \"discovered_servers\": state.discovered_servers,\n                \"discovery_completed\": state.discovery_completed,\n                \"created_at\": state.created_at.isoformat(),\n                \"failed_servers\": state.failed_servers,\n            }\n        )\n\n    def _deserialize(self, data: str | bytes, user_id: str, session_id: str) -&gt; McpState:\n        \"\"\"\n        Deserialize JSON to MCP state object.\n\n        Args:\n            data: JSON string or bytes from Redis\n            user_id: User ID (for validation)\n            session_id: Session ID (for validation)\n\n        Returns:\n            McpState object\n\n        Raises:\n            ValueError: If deserialized user_id/session_id don't match parameters\n        \"\"\"\n        # Handle bytes from Redis\n        if isinstance(data, bytes):\n            data = data.decode(\"utf-8\")\n\n        obj = json.loads(data)\n\n        # Validate that serialized data matches the key parameters\n        if obj[\"user_id\"] != user_id:\n            raise ValueError(\n                f\"Deserialized user_id '{obj['user_id']}' does not match \"\n                f\"expected user_id '{user_id}'\"\n            )\n        if obj[\"session_id\"] != session_id:\n            raise ValueError(\n                f\"Deserialized session_id '{obj['session_id']}' does not match \"\n                f\"expected session_id '{session_id}'\"\n            )\n\n        return McpState(\n            user_id=user_id,\n            session_id=session_id,\n            discovered_servers=obj[\"discovered_servers\"],\n            discovery_completed=obj[\"discovery_completed\"],\n            created_at=datetime.fromisoformat(obj[\"created_at\"]),\n            failed_servers=obj.get(\"failed_servers\", {}),\n        )\n</code></pre> <code></code> sk_agents.mcp_discovery.RedisStateManager.__init__ <pre><code>__init__(\n    app_config: AppConfig, redis_client: Redis | None = None\n)\n</code></pre> <p>Initialize Redis state manager.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>AppConfig</code> <p>Application configuration for Redis connection</p> required <code>redis_client</code> <code>Redis | None</code> <p>Optional pre-configured Redis client (for testing)</p> <code>None</code> Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>def __init__(self, app_config: AppConfig, redis_client: Redis | None = None):\n    \"\"\"\n    Initialize Redis state manager.\n\n    Args:\n        app_config: Application configuration for Redis connection\n        redis_client: Optional pre-configured Redis client (for testing)\n    \"\"\"\n    self.app_config = app_config\n    self.redis = redis_client or self._create_redis_client()\n    self.key_prefix = \"mcp_state\"\n\n    # TTL support: Default to 24 hours (86400 seconds)\n    from sk_agents.configs import TA_REDIS_TTL\n\n    ttl_str = self.app_config.get(TA_REDIS_TTL.env_name)\n    if ttl_str:\n        self.ttl = int(ttl_str)\n    else:\n        # Default to 24 hours for discovery state\n        self.ttl = 86400\n\n    logger.debug(f\"Redis state manager initialized with TTL={self.ttl}s\")\n</code></pre> <code></code> sk_agents.mcp_discovery.RedisStateManager.close <code>async</code> <pre><code>close() -&gt; None\n</code></pre> <p>Close Redis connection and cleanup resources.</p> Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"Close Redis connection and cleanup resources.\"\"\"\n    if self.redis:\n        await self.redis.close()\n        logger.debug(\"Redis state manager connection closed\")\n</code></pre> <code></code> sk_agents.mcp_discovery.RedisStateManager.__aenter__ <code>async</code> <pre><code>__aenter__()\n</code></pre> <p>Async context manager entry.</p> Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def __aenter__(self):\n    \"\"\"Async context manager entry.\"\"\"\n    return self\n</code></pre> <code></code> sk_agents.mcp_discovery.RedisStateManager.__aexit__ <code>async</code> <pre><code>__aexit__(exc_type, exc_val, exc_tb)\n</code></pre> <p>Async context manager exit.</p> Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def __aexit__(self, exc_type, exc_val, exc_tb):\n    \"\"\"Async context manager exit.\"\"\"\n    await self.close()\n</code></pre> <code></code> sk_agents.mcp_discovery.RedisStateManager.create_discovery <code>async</code> <pre><code>create_discovery(state: McpState) -&gt; None\n</code></pre> <p>Create initial MCP state in Redis.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>McpState</code> <p>MCP state to create</p> required <p>Raises:</p> Type Description <code>DiscoveryCreateError</code> <p>If state already exists</p> Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def create_discovery(self, state: McpState) -&gt; None:\n    \"\"\"\n    Create initial MCP state in Redis.\n\n    Args:\n        state: MCP state to create\n\n    Raises:\n        DiscoveryCreateError: If state already exists\n    \"\"\"\n    key = self._make_key(state.user_id, state.session_id)\n    exists = await self.redis.exists(key)\n    if exists:\n        raise DiscoveryCreateError(\n            f\"MCP state already exists for user={state.user_id}, session={state.session_id}\"\n        )\n\n    data = self._serialize(state)\n    # Set with TTL\n    await self.redis.set(key, data, ex=self.ttl)\n    logger.debug(\n        f\"Created Redis MCP state: user={state.user_id}, session={state.session_id}, \"\n        f\"TTL={self.ttl}s\"\n    )\n</code></pre> <code></code> sk_agents.mcp_discovery.RedisStateManager.load_discovery <code>async</code> <pre><code>load_discovery(\n    user_id: str, session_id: str\n) -&gt; McpState | None\n</code></pre> <p>Load MCP state from Redis.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required <p>Returns:</p> Type Description <code>McpState | None</code> <p>MCP state if exists, None otherwise</p> Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def load_discovery(self, user_id: str, session_id: str) -&gt; McpState | None:\n    \"\"\"\n    Load MCP state from Redis.\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n\n    Returns:\n        MCP state if exists, None otherwise\n    \"\"\"\n    key = self._make_key(user_id, session_id)\n    data = await self.redis.get(key)\n    if not data:\n        return None\n    return self._deserialize(data, user_id, session_id)\n</code></pre> <code></code> sk_agents.mcp_discovery.RedisStateManager.update_discovery <code>async</code> <pre><code>update_discovery(state: McpState) -&gt; None\n</code></pre> <p>Update existing MCP state in Redis.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>McpState</code> <p>Updated MCP state</p> required <p>Raises:</p> Type Description <code>DiscoveryUpdateError</code> <p>If state does not exist</p> Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def update_discovery(self, state: McpState) -&gt; None:\n    \"\"\"\n    Update existing MCP state in Redis.\n\n    Args:\n        state: Updated MCP state\n\n    Raises:\n        DiscoveryUpdateError: If state does not exist\n    \"\"\"\n    key = self._make_key(state.user_id, state.session_id)\n    # Check existence before updating\n    exists = await self.redis.exists(key)\n    if not exists:\n        raise DiscoveryUpdateError(\n            f\"MCP state not found for user={state.user_id}, session={state.session_id}\"\n        )\n\n    data = self._serialize(state)\n    # Update with TTL to extend expiration\n    await self.redis.set(key, data, ex=self.ttl)\n    logger.debug(f\"Updated Redis MCP state: user={state.user_id}, session={state.session_id}\")\n</code></pre> <code></code> sk_agents.mcp_discovery.RedisStateManager.delete_discovery <code>async</code> <pre><code>delete_discovery(user_id: str, session_id: str) -&gt; None\n</code></pre> <p>Delete discovery state from Redis.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def delete_discovery(self, user_id: str, session_id: str) -&gt; None:\n    \"\"\"\n    Delete discovery state from Redis.\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n    \"\"\"\n    key = self._make_key(user_id, session_id)\n    await self.redis.delete(key)\n    logger.debug(f\"Deleted Redis discovery state: user={user_id}, session={session_id}\")\n</code></pre> <code></code> sk_agents.mcp_discovery.RedisStateManager.mark_completed <code>async</code> <pre><code>mark_completed(user_id: str, session_id: str) -&gt; None\n</code></pre> <p>Mark discovery as completed in Redis using atomic operation.</p> <p>If state doesn't exist, auto-creates it with discovery_completed=True and empty discovered_servers dict. A warning is logged when auto-creating.</p> <p>Uses Lua script for atomic read-modify-write to prevent race conditions in multi-worker deployments.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def mark_completed(self, user_id: str, session_id: str) -&gt; None:\n    \"\"\"\n    Mark discovery as completed in Redis using atomic operation.\n\n    If state doesn't exist, auto-creates it with discovery_completed=True\n    and empty discovered_servers dict. A warning is logged when auto-creating.\n\n    Uses Lua script for atomic read-modify-write to prevent race conditions\n    in multi-worker deployments.\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n    \"\"\"\n    key = self._make_key(user_id, session_id)\n\n    # Lua script for atomic mark_completed operation\n    lua_script = \"\"\"\n    local key = KEYS[1]\n    local ttl = tonumber(ARGV[1])\n    local data = redis.call('GET', key)\n\n    if data then\n        -- State exists, update discovery_completed field\n        local obj = cjson.decode(data)\n        obj.discovery_completed = true\n        local updated_data = cjson.encode(obj)\n        redis.call('SET', key, updated_data, 'EX', ttl)\n        return 1\n    else\n        -- State doesn't exist, return 0 to signal auto-create\n        return 0\n    end\n    \"\"\"\n\n    result = await self.redis.eval(lua_script, 1, key, self.ttl)\n\n    if result == 1:\n        logger.debug(f\"Marked discovery completed: user={user_id}, session={session_id}\")\n    else:\n        # Auto-create state if it doesn't exist\n        logger.warning(\n            f\"MCP state not found for user={user_id}, session={session_id}. \"\n            f\"Auto-creating with discovery_completed=True.\"\n        )\n        state = McpState(\n            user_id=user_id,\n            session_id=session_id,\n            discovered_servers={},\n            discovery_completed=True,\n            created_at=datetime.now(UTC),\n        )\n        data = self._serialize(state)\n        await self.redis.set(key, data, ex=self.ttl)\n        logger.debug(f\"Auto-created discovery state: user={user_id}, session={session_id}\")\n</code></pre> <code></code> sk_agents.mcp_discovery.RedisStateManager.is_completed <code>async</code> <pre><code>is_completed(user_id: str, session_id: str) -&gt; bool\n</code></pre> <p>Check if discovery is completed in Redis.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if discovery completed, False otherwise</p> Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def is_completed(self, user_id: str, session_id: str) -&gt; bool:\n    \"\"\"\n    Check if discovery is completed in Redis.\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n\n    Returns:\n        True if discovery completed, False otherwise\n    \"\"\"\n    state = await self.load_discovery(user_id, session_id)\n    return state.discovery_completed if state else False\n</code></pre> <code></code> sk_agents.mcp_discovery.RedisStateManager.store_mcp_session <code>async</code> <pre><code>store_mcp_session(\n    user_id: str,\n    session_id: str,\n    server_name: str,\n    mcp_session_id: str,\n) -&gt; None\n</code></pre> <p>Store MCP session ID for a server using atomic Lua script.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Teal agent session ID</p> required <code>server_name</code> <code>str</code> <p>Name of the MCP server</p> required <code>mcp_session_id</code> <code>str</code> <p>MCP session ID from server</p> required Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def store_mcp_session(\n    self, user_id: str, session_id: str, server_name: str, mcp_session_id: str\n) -&gt; None:\n    \"\"\"\n    Store MCP session ID for a server using atomic Lua script.\n\n    Args:\n        user_id: User ID\n        session_id: Teal agent session ID\n        server_name: Name of the MCP server\n        mcp_session_id: MCP session ID from server\n    \"\"\"\n    key = self._make_key(user_id, session_id)\n\n    # Lua script for atomic store operation\n    lua_script = \"\"\"\n    local key = KEYS[1]\n    local ttl = tonumber(ARGV[1])\n    local server_name = ARGV[2]\n    local mcp_session_id = ARGV[3]\n    local timestamp = ARGV[4]\n\n    local data = redis.call('GET', key)\n    local obj\n\n    if data then\n        -- State exists, update it\n        obj = cjson.decode(data)\n    else\n        -- State doesn't exist, create minimal state\n        obj = {\n            user_id = ARGV[5],\n            session_id = ARGV[6],\n            discovered_servers = {},\n            discovery_completed = false,\n            created_at = timestamp\n        }\n    end\n\n    -- Ensure server entry exists\n    if not obj.discovered_servers[server_name] then\n        obj.discovered_servers[server_name] = {}\n    end\n\n    -- Store session data\n    if not obj.discovered_servers[server_name].session then\n        obj.discovered_servers[server_name].session = {}\n    end\n\n    obj.discovered_servers[server_name].session.mcp_session_id = mcp_session_id\n    local sess = obj.discovered_servers[server_name].session\n    sess.created_at = sess.created_at or timestamp\n    sess.last_used_at = timestamp\n\n    local updated_data = cjson.encode(obj)\n    redis.call('SET', key, updated_data, 'EX', ttl)\n    return 1\n    \"\"\"\n\n    timestamp = datetime.now(UTC).isoformat()\n    await self.redis.eval(\n        lua_script,\n        1,\n        key,\n        self.ttl,\n        server_name,\n        mcp_session_id,\n        timestamp,\n        user_id,\n        session_id,\n    )\n\n    logger.debug(\n        f\"Stored MCP session {mcp_session_id} for server={server_name}, \"\n        f\"user={user_id}, session={session_id}\"\n    )\n</code></pre> <code></code> sk_agents.mcp_discovery.RedisStateManager.get_mcp_session <code>async</code> <pre><code>get_mcp_session(\n    user_id: str, session_id: str, server_name: str\n) -&gt; str | None\n</code></pre> <p>Get MCP session ID for a server.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Teal agent session ID</p> required <code>server_name</code> <code>str</code> <p>Name of the MCP server</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>MCP session ID if exists, None otherwise</p> Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def get_mcp_session(self, user_id: str, session_id: str, server_name: str) -&gt; str | None:\n    \"\"\"\n    Get MCP session ID for a server.\n\n    Args:\n        user_id: User ID\n        session_id: Teal agent session ID\n        server_name: Name of the MCP server\n\n    Returns:\n        MCP session ID if exists, None otherwise\n    \"\"\"\n    state = await self.load_discovery(user_id, session_id)\n\n    if not state:\n        return None\n\n    server_data = state.discovered_servers.get(server_name)\n    if not server_data:\n        return None\n\n    session_bucket = server_data.get(\"session\")\n    if not session_bucket:\n        return None\n\n    return session_bucket.get(\"mcp_session_id\")\n</code></pre> <code></code> sk_agents.mcp_discovery.RedisStateManager.update_session_last_used <code>async</code> <pre><code>update_session_last_used(\n    user_id: str, session_id: str, server_name: str\n) -&gt; None\n</code></pre> <p>Update last_used timestamp using atomic Lua script.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Teal agent session ID</p> required <code>server_name</code> <code>str</code> <p>Name of the MCP server</p> required <p>Raises:</p> Type Description <code>DiscoveryUpdateError</code> <p>If state or server doesn't exist</p> Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def update_session_last_used(\n    self, user_id: str, session_id: str, server_name: str\n) -&gt; None:\n    \"\"\"\n    Update last_used timestamp using atomic Lua script.\n\n    Args:\n        user_id: User ID\n        session_id: Teal agent session ID\n        server_name: Name of the MCP server\n\n    Raises:\n        DiscoveryUpdateError: If state or server doesn't exist\n    \"\"\"\n    key = self._make_key(user_id, session_id)\n\n    # Lua script for atomic update\n    lua_script = \"\"\"\n    local key = KEYS[1]\n    local ttl = tonumber(ARGV[1])\n    local server_name = ARGV[2]\n    local timestamp = ARGV[3]\n\n    local data = redis.call('GET', key)\n    if not data then\n        return 0  -- State not found\n    end\n\n    local obj = cjson.decode(data)\n\n    if not obj.discovered_servers[server_name] then\n        return -1  -- Server not found\n    end\n\n    if not obj.discovered_servers[server_name].session then\n        obj.discovered_servers[server_name].session = {}\n    end\n    obj.discovered_servers[server_name].session.last_used_at = timestamp\n\n    local updated_data = cjson.encode(obj)\n    redis.call('SET', key, updated_data, 'EX', ttl)\n    return 1\n    \"\"\"\n\n    timestamp = datetime.now(UTC).isoformat()\n    result = await self.redis.eval(lua_script, 1, key, self.ttl, server_name, timestamp)\n\n    if result == 0:\n        raise DiscoveryUpdateError(\n            f\"MCP state not found for user={user_id}, session={session_id}\"\n        )\n    elif result == -1:\n        raise DiscoveryUpdateError(\n            f\"Server {server_name} not found in state for user={user_id}, session={session_id}\"\n        )\n\n    logger.debug(\n        f\"Updated last_used for server={server_name}, user={user_id}, session={session_id}\"\n    )\n</code></pre> <code></code> sk_agents.mcp_discovery.RedisStateManager.clear_mcp_session <code>async</code> <pre><code>clear_mcp_session(\n    user_id: str,\n    session_id: str,\n    server_name: str,\n    expected_session_id: str | None = None,\n) -&gt; None\n</code></pre> <p>Remove stored MCP session info for a server if present.</p> Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def clear_mcp_session(\n    self,\n    user_id: str,\n    session_id: str,\n    server_name: str,\n    expected_session_id: str | None = None,\n) -&gt; None:\n    \"\"\"Remove stored MCP session info for a server if present.\"\"\"\n    key = self._make_key(user_id, session_id)\n\n    lua_script = \"\"\"\n    local key = KEYS[1]\n    local server_name = ARGV[1]\n    local ttl = tonumber(ARGV[2])\n    local expected_session_id = ARGV[3]\n\n    local data = redis.call('GET', key)\n    if not data then\n        return 0 -- state missing\n    end\n\n    local obj = cjson.decode(data)\n    if not obj.discovered_servers[server_name] then\n        return -1 -- server missing\n    end\n\n    -- Only clear if expected matches or no expectation provided\n    if obj.discovered_servers[server_name].session then\n        local current = obj.discovered_servers[server_name].session.mcp_session_id\n        if expected_session_id ~= nil and expected_session_id ~= '' then\n            if current ~= expected_session_id then\n                return -2  -- session changed, skip clear\n            end\n        end\n    end\n\n    obj.discovered_servers[server_name].session = nil\n\n    local updated_data = cjson.encode(obj)\n    redis.call('SET', key, updated_data, 'EX', ttl)\n    return 1\n    \"\"\"\n\n    expected_arg = expected_session_id or \"\"\n    result = await self.redis.eval(lua_script, 1, key, server_name, self.ttl, expected_arg)\n    if result == 0:\n        logger.debug(\n            f\"clear_mcp_session: state missing for user={user_id}, session={session_id}\"\n        )\n    elif result == -1:\n        logger.debug(\n            f\"clear_mcp_session: server missing for user={user_id}, \"\n            f\"session={session_id}, server={server_name}\"\n        )\n    elif result == -2:\n        logger.debug(\n            f\"clear_mcp_session: session changed for user={user_id}, \"\n            f\"session={session_id}, server={server_name}\"\n        )\n    else:\n        logger.debug(\n            f\"Cleared MCP session for server={server_name}, \"\n            f\"user={user_id}, session={session_id}\"\n        )\n</code></pre> <code></code> sk_agents.mcp_discovery.discovery_manager_factory <p>MCP State Manager Factory</p> <p>Provides singleton factory for creating MCP state manager instances with dynamic module loading and dependency injection.</p> <p>Follows the same pattern as PersistenceFactory and AuthStorageFactory.</p> <code></code> sk_agents.mcp_discovery.discovery_manager_factory.DiscoveryManagerFactory <p>Factory for MCP state manager with dependency injection.</p> <p>Uses singleton pattern to ensure only one factory instance exists. Dynamically loads state manager implementation based on environment variables.</p> Configuration <p>TA_MCP_DISCOVERY_MODULE: Python module containing manager class TA_MCP_DISCOVERY_CLASS: Manager class name</p> <p>Defaults to InMemoryStateManager for development.</p> Source code in <code>src/sk_agents/mcp_discovery/discovery_manager_factory.py</code> <pre><code>class DiscoveryManagerFactory(metaclass=Singleton):\n    \"\"\"\n    Factory for MCP state manager with dependency injection.\n\n    Uses singleton pattern to ensure only one factory instance exists.\n    Dynamically loads state manager implementation based on\n    environment variables.\n\n    Configuration:\n        TA_MCP_DISCOVERY_MODULE: Python module containing manager class\n        TA_MCP_DISCOVERY_CLASS: Manager class name\n\n    Defaults to InMemoryStateManager for development.\n    \"\"\"\n\n    def __init__(self, app_config: AppConfig):\n        \"\"\"\n        Initialize factory with app configuration.\n\n        Args:\n            app_config: Application configuration for env vars\n        \"\"\"\n        self.app_config = app_config\n        self._manager: McpStateManager | None = None  # noqa: F821\n\n    def get_discovery_manager(self) -&gt; \"McpStateManager\":  # noqa: F821\n        \"\"\"\n        Get state manager instance (cached singleton).\n\n        Loads manager implementation on first call based on configuration,\n        then caches for subsequent calls.\n\n        Returns:\n            McpStateManager instance\n\n        Raises:\n            Exception: If manager class cannot be loaded (falls back to in-memory)\n        \"\"\"\n        if self._manager is None:\n            # Import here to avoid circular dependency\n            from sk_agents.configs import TA_MCP_DISCOVERY_CLASS, TA_MCP_DISCOVERY_MODULE\n\n            module_name = self.app_config.get(TA_MCP_DISCOVERY_MODULE.env_name)\n            class_name = self.app_config.get(TA_MCP_DISCOVERY_CLASS.env_name)\n\n            try:\n                # Dynamic module loading\n                module = __import__(module_name, fromlist=[class_name])\n                manager_class = getattr(module, class_name)\n                self._manager = manager_class(self.app_config)\n                logger.info(f\"Initialized MCP state manager: {class_name}\")\n\n            except Exception as e:\n                logger.error(\n                    f\"Failed to load state manager {class_name} from {module_name}: {e}. \"\n                    f\"Falling back to InMemoryStateManager\"\n                )\n\n                # Fallback to in-memory implementation\n                try:\n                    from sk_agents.mcp_discovery.in_memory_discovery_manager import (\n                        InMemoryStateManager,\n                    )\n\n                    self._manager = InMemoryStateManager(self.app_config)\n                    logger.info(\"Fallback to InMemoryStateManager successful\")\n\n                except Exception as fallback_error:\n                    logger.critical(\n                        f\"Failed to load fallback InMemoryStateManager: {fallback_error}\"\n                    )\n                    raise\n\n        return self._manager\n</code></pre> <code></code> sk_agents.mcp_discovery.discovery_manager_factory.DiscoveryManagerFactory.__init__ <pre><code>__init__(app_config: AppConfig)\n</code></pre> <p>Initialize factory with app configuration.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>AppConfig</code> <p>Application configuration for env vars</p> required Source code in <code>src/sk_agents/mcp_discovery/discovery_manager_factory.py</code> <pre><code>def __init__(self, app_config: AppConfig):\n    \"\"\"\n    Initialize factory with app configuration.\n\n    Args:\n        app_config: Application configuration for env vars\n    \"\"\"\n    self.app_config = app_config\n    self._manager: McpStateManager | None = None  # noqa: F821\n</code></pre> <code></code> sk_agents.mcp_discovery.discovery_manager_factory.DiscoveryManagerFactory.get_discovery_manager <pre><code>get_discovery_manager() -&gt; McpStateManager\n</code></pre> <p>Get state manager instance (cached singleton).</p> <p>Loads manager implementation on first call based on configuration, then caches for subsequent calls.</p> <p>Returns:</p> Type Description <code>McpStateManager</code> <p>McpStateManager instance</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If manager class cannot be loaded (falls back to in-memory)</p> Source code in <code>src/sk_agents/mcp_discovery/discovery_manager_factory.py</code> <pre><code>def get_discovery_manager(self) -&gt; \"McpStateManager\":  # noqa: F821\n    \"\"\"\n    Get state manager instance (cached singleton).\n\n    Loads manager implementation on first call based on configuration,\n    then caches for subsequent calls.\n\n    Returns:\n        McpStateManager instance\n\n    Raises:\n        Exception: If manager class cannot be loaded (falls back to in-memory)\n    \"\"\"\n    if self._manager is None:\n        # Import here to avoid circular dependency\n        from sk_agents.configs import TA_MCP_DISCOVERY_CLASS, TA_MCP_DISCOVERY_MODULE\n\n        module_name = self.app_config.get(TA_MCP_DISCOVERY_MODULE.env_name)\n        class_name = self.app_config.get(TA_MCP_DISCOVERY_CLASS.env_name)\n\n        try:\n            # Dynamic module loading\n            module = __import__(module_name, fromlist=[class_name])\n            manager_class = getattr(module, class_name)\n            self._manager = manager_class(self.app_config)\n            logger.info(f\"Initialized MCP state manager: {class_name}\")\n\n        except Exception as e:\n            logger.error(\n                f\"Failed to load state manager {class_name} from {module_name}: {e}. \"\n                f\"Falling back to InMemoryStateManager\"\n            )\n\n            # Fallback to in-memory implementation\n            try:\n                from sk_agents.mcp_discovery.in_memory_discovery_manager import (\n                    InMemoryStateManager,\n                )\n\n                self._manager = InMemoryStateManager(self.app_config)\n                logger.info(\"Fallback to InMemoryStateManager successful\")\n\n            except Exception as fallback_error:\n                logger.critical(\n                    f\"Failed to load fallback InMemoryStateManager: {fallback_error}\"\n                )\n                raise\n\n    return self._manager\n</code></pre> <code></code> sk_agents.mcp_discovery.in_memory_discovery_manager <p>In-Memory MCP State Manager</p> <p>Provides in-memory implementation for development and testing. Follows the same pattern as InMemoryPersistenceManager.</p> <code></code> sk_agents.mcp_discovery.in_memory_discovery_manager.InMemoryStateManager <p>               Bases: <code>McpStateManager</code></p> <p>In-memory implementation of MCP state manager.</p> <p>Stores MCP state in memory with thread-safe access. Suitable for: - Development and testing - Single-instance deployments - Scenarios where persistence is not required</p> <p>Note: State is lost on server restart.</p> Source code in <code>src/sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> <pre><code>class InMemoryStateManager(McpStateManager):\n    \"\"\"\n    In-memory implementation of MCP state manager.\n\n    Stores MCP state in memory with thread-safe access.\n    Suitable for:\n    - Development and testing\n    - Single-instance deployments\n    - Scenarios where persistence is not required\n\n    Note: State is lost on server restart.\n    \"\"\"\n\n    def __init__(self, app_config):\n        \"\"\"\n        Initialize in-memory state manager.\n\n        Args:\n            app_config: Application configuration (for consistency with other managers)\n        \"\"\"\n        self.app_config = app_config\n        # Storage: {(user_id, session_id): McpState}\n        self._storage: dict[tuple[str, str], McpState] = {}\n        self._lock = asyncio.Lock()\n\n    def _make_key(self, user_id: str, session_id: str) -&gt; tuple[str, str]:\n        \"\"\"\n        Create composite key for storage.\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n\n        Returns:\n            Tuple of (user_id, session_id)\n        \"\"\"\n        return (user_id, session_id)\n\n    async def create_discovery(self, state: McpState) -&gt; None:\n        \"\"\"\n        Create initial MCP state.\n\n        Args:\n            state: MCP state to create\n\n        Raises:\n            DiscoveryCreateError: If state already exists\n        \"\"\"\n        async with self._lock:\n            key = self._make_key(state.user_id, state.session_id)\n            if key in self._storage:\n                raise DiscoveryCreateError(\n                    f\"MCP state already exists for user={state.user_id}, session={state.session_id}\"\n                )\n            self._storage[key] = state\n            logger.debug(f\"Created MCP state for user={state.user_id}, session={state.session_id}\")\n\n    async def load_discovery(self, user_id: str, session_id: str) -&gt; McpState | None:\n        \"\"\"\n        Load MCP state.\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n\n        Returns:\n            Deep copy of MCP state if exists, None otherwise.\n            Returns a copy to prevent external mutations.\n        \"\"\"\n        async with self._lock:\n            key = self._make_key(user_id, session_id)\n            state = self._storage.get(key)\n            if state is None:\n                return None\n            # Return deep copy to prevent external mutations bypassing update_discovery\n            return copy.deepcopy(state)\n\n    async def update_discovery(self, state: McpState) -&gt; None:\n        \"\"\"\n        Update existing MCP state.\n\n        Args:\n            state: Updated MCP state\n\n        Raises:\n            DiscoveryUpdateError: If state does not exist\n        \"\"\"\n        async with self._lock:\n            key = self._make_key(state.user_id, state.session_id)\n            if key not in self._storage:\n                raise DiscoveryUpdateError(\n                    f\"MCP state not found for user={state.user_id}, session={state.session_id}\"\n                )\n            self._storage[key] = state\n            logger.debug(f\"Updated MCP state for user={state.user_id}, session={state.session_id}\")\n\n    async def delete_discovery(self, user_id: str, session_id: str) -&gt; None:\n        \"\"\"\n        Delete MCP state.\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n        \"\"\"\n        async with self._lock:\n            key = self._make_key(user_id, session_id)\n            if key in self._storage:\n                del self._storage[key]\n                logger.debug(f\"Deleted MCP state for user={user_id}, session={session_id}\")\n\n    async def mark_completed(self, user_id: str, session_id: str) -&gt; None:\n        \"\"\"\n        Mark discovery as completed.\n\n        If state doesn't exist, auto-creates it with discovery_completed=True\n        and empty discovered_servers dict. A warning is logged when auto-creating.\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n        \"\"\"\n        async with self._lock:\n            key = self._make_key(user_id, session_id)\n            if key in self._storage:\n                self._storage[key].discovery_completed = True\n                logger.debug(f\"Marked discovery completed for user={user_id}, session={session_id}\")\n            else:\n                # Auto-create state if it doesn't exist\n                logger.warning(\n                    f\"MCP state not found for user={user_id}, session={session_id}. \"\n                    f\"Auto-creating with discovery_completed=True.\"\n                )\n                state = McpState(\n                    user_id=user_id,\n                    session_id=session_id,\n                    discovered_servers={},\n                    discovery_completed=True,\n                    created_at=datetime.now(UTC),\n                )\n                self._storage[key] = state\n\n    async def is_completed(self, user_id: str, session_id: str) -&gt; bool:\n        \"\"\"\n        Check if discovery is completed.\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n\n        Returns:\n            True if discovery completed, False otherwise\n        \"\"\"\n        async with self._lock:\n            key = self._make_key(user_id, session_id)\n            state = self._storage.get(key)\n            return state.discovery_completed if state else False\n\n    async def store_mcp_session(\n        self, user_id: str, session_id: str, server_name: str, mcp_session_id: str\n    ) -&gt; None:\n        \"\"\"\n        Store MCP session ID for a server.\n\n        Args:\n            user_id: User ID\n            session_id: Teal agent session ID\n            server_name: Name of the MCP server\n            mcp_session_id: MCP session ID from server\n        \"\"\"\n        async with self._lock:\n            key = self._make_key(user_id, session_id)\n            state = self._storage.get(key)\n\n            # Auto-create state if doesn't exist\n            if not state:\n                logger.warning(\n                    f\"MCP state not found for user={user_id}, session={session_id}. \"\n                    f\"Auto-creating to store session for {server_name}.\"\n                )\n                state = McpState(\n                    user_id=user_id,\n                    session_id=session_id,\n                    discovered_servers={},\n                    discovery_completed=False,\n                    created_at=datetime.now(UTC),\n                )\n                self._storage[key] = state\n\n            # Ensure server entry exists and preserve plugin_data if present\n            existing_entry = state.discovered_servers.get(server_name, {})\n            plugin_data = existing_entry.get(\"plugin_data\")\n            state.discovered_servers[server_name] = {\n                \"plugin_data\": plugin_data,\n                **(\n                    {\"session\": existing_entry.get(\"session\")}\n                    if existing_entry.get(\"session\")\n                    else {}\n                ),\n            }\n\n            # Store session data\n            session_bucket = state.discovered_servers[server_name].get(\"session\", {})\n            now_iso = datetime.now(UTC).isoformat()\n            session_bucket.update(\n                {\n                    \"mcp_session_id\": mcp_session_id,\n                    \"created_at\": session_bucket.get(\"created_at\", now_iso),\n                    \"last_used_at\": now_iso,\n                }\n            )\n            state.discovered_servers[server_name][\"session\"] = session_bucket\n\n            logger.debug(\n                f\"Stored MCP session {mcp_session_id} for server={server_name}, \"\n                f\"user={user_id}, session={session_id}\"\n            )\n\n    async def get_mcp_session(self, user_id: str, session_id: str, server_name: str) -&gt; str | None:\n        \"\"\"\n        Get MCP session ID for a server.\n\n        Args:\n            user_id: User ID\n            session_id: Teal agent session ID\n            server_name: Name of the MCP server\n\n        Returns:\n            MCP session ID if exists, None otherwise\n        \"\"\"\n        async with self._lock:\n            key = self._make_key(user_id, session_id)\n            state = self._storage.get(key)\n\n            if not state:\n                return None\n\n            server_data = state.discovered_servers.get(server_name)\n            if not server_data:\n                return None\n\n            session_bucket = server_data.get(\"session\")\n            if not session_bucket:\n                return None\n            return session_bucket.get(\"mcp_session_id\")\n\n    async def update_session_last_used(\n        self, user_id: str, session_id: str, server_name: str\n    ) -&gt; None:\n        \"\"\"\n        Update last_used timestamp for an MCP session.\n\n        Args:\n            user_id: User ID\n            session_id: Teal agent session ID\n            server_name: Name of the MCP server\n\n        Raises:\n            DiscoveryUpdateError: If state or server doesn't exist\n        \"\"\"\n        async with self._lock:\n            key = self._make_key(user_id, session_id)\n            state = self._storage.get(key)\n\n            if not state:\n                raise DiscoveryUpdateError(\n                    f\"MCP state not found for user={user_id}, session={session_id}\"\n                )\n\n            if server_name not in state.discovered_servers:\n                raise DiscoveryUpdateError(\n                    f\"Server {server_name} not found in state for \"\n                    f\"user={user_id}, session={session_id}\"\n                )\n\n            session_bucket = state.discovered_servers[server_name].get(\"session\")\n            if not session_bucket:\n                session_bucket = {}\n            session_bucket[\"last_used_at\"] = datetime.now(UTC).isoformat()\n            state.discovered_servers[server_name][\"session\"] = session_bucket\n\n            logger.debug(\n                f\"Updated last_used for server={server_name}, user={user_id}, session={session_id}\"\n            )\n\n    async def clear_mcp_session(\n        self,\n        user_id: str,\n        session_id: str,\n        server_name: str,\n        expected_session_id: str | None = None,\n    ) -&gt; None:\n        \"\"\"Remove stored MCP session info for a server if present.\"\"\"\n        async with self._lock:\n            key = self._make_key(user_id, session_id)\n            state = self._storage.get(key)\n            if not state:\n                return\n            entry = state.discovered_servers.get(server_name)\n            if not entry:\n                return\n            if \"session\" in entry:\n                if expected_session_id:\n                    current = entry.get(\"session\", {}).get(\"mcp_session_id\")\n                    if current and current != expected_session_id:\n                        # Another session already replaced it; do not clear\n                        return\n                entry.pop(\"session\", None)\n                state.discovered_servers[server_name] = entry\n                logger.debug(\n                    f\"Cleared MCP session for server={server_name}, \"\n                    f\"user={user_id}, session={session_id}\"\n                )\n</code></pre> <code></code> sk_agents.mcp_discovery.in_memory_discovery_manager.InMemoryStateManager.__init__ <pre><code>__init__(app_config)\n</code></pre> <p>Initialize in-memory state manager.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <p>Application configuration (for consistency with other managers)</p> required Source code in <code>src/sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> <pre><code>def __init__(self, app_config):\n    \"\"\"\n    Initialize in-memory state manager.\n\n    Args:\n        app_config: Application configuration (for consistency with other managers)\n    \"\"\"\n    self.app_config = app_config\n    # Storage: {(user_id, session_id): McpState}\n    self._storage: dict[tuple[str, str], McpState] = {}\n    self._lock = asyncio.Lock()\n</code></pre> <code></code> sk_agents.mcp_discovery.in_memory_discovery_manager.InMemoryStateManager.create_discovery <code>async</code> <pre><code>create_discovery(state: McpState) -&gt; None\n</code></pre> <p>Create initial MCP state.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>McpState</code> <p>MCP state to create</p> required <p>Raises:</p> Type Description <code>DiscoveryCreateError</code> <p>If state already exists</p> Source code in <code>src/sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> <pre><code>async def create_discovery(self, state: McpState) -&gt; None:\n    \"\"\"\n    Create initial MCP state.\n\n    Args:\n        state: MCP state to create\n\n    Raises:\n        DiscoveryCreateError: If state already exists\n    \"\"\"\n    async with self._lock:\n        key = self._make_key(state.user_id, state.session_id)\n        if key in self._storage:\n            raise DiscoveryCreateError(\n                f\"MCP state already exists for user={state.user_id}, session={state.session_id}\"\n            )\n        self._storage[key] = state\n        logger.debug(f\"Created MCP state for user={state.user_id}, session={state.session_id}\")\n</code></pre> <code></code> sk_agents.mcp_discovery.in_memory_discovery_manager.InMemoryStateManager.load_discovery <code>async</code> <pre><code>load_discovery(\n    user_id: str, session_id: str\n) -&gt; McpState | None\n</code></pre> <p>Load MCP state.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required <p>Returns:</p> Type Description <code>McpState | None</code> <p>Deep copy of MCP state if exists, None otherwise.</p> <code>McpState | None</code> <p>Returns a copy to prevent external mutations.</p> Source code in <code>src/sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> <pre><code>async def load_discovery(self, user_id: str, session_id: str) -&gt; McpState | None:\n    \"\"\"\n    Load MCP state.\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n\n    Returns:\n        Deep copy of MCP state if exists, None otherwise.\n        Returns a copy to prevent external mutations.\n    \"\"\"\n    async with self._lock:\n        key = self._make_key(user_id, session_id)\n        state = self._storage.get(key)\n        if state is None:\n            return None\n        # Return deep copy to prevent external mutations bypassing update_discovery\n        return copy.deepcopy(state)\n</code></pre> <code></code> sk_agents.mcp_discovery.in_memory_discovery_manager.InMemoryStateManager.update_discovery <code>async</code> <pre><code>update_discovery(state: McpState) -&gt; None\n</code></pre> <p>Update existing MCP state.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>McpState</code> <p>Updated MCP state</p> required <p>Raises:</p> Type Description <code>DiscoveryUpdateError</code> <p>If state does not exist</p> Source code in <code>src/sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> <pre><code>async def update_discovery(self, state: McpState) -&gt; None:\n    \"\"\"\n    Update existing MCP state.\n\n    Args:\n        state: Updated MCP state\n\n    Raises:\n        DiscoveryUpdateError: If state does not exist\n    \"\"\"\n    async with self._lock:\n        key = self._make_key(state.user_id, state.session_id)\n        if key not in self._storage:\n            raise DiscoveryUpdateError(\n                f\"MCP state not found for user={state.user_id}, session={state.session_id}\"\n            )\n        self._storage[key] = state\n        logger.debug(f\"Updated MCP state for user={state.user_id}, session={state.session_id}\")\n</code></pre> <code></code> sk_agents.mcp_discovery.in_memory_discovery_manager.InMemoryStateManager.delete_discovery <code>async</code> <pre><code>delete_discovery(user_id: str, session_id: str) -&gt; None\n</code></pre> <p>Delete MCP state.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required Source code in <code>src/sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> <pre><code>async def delete_discovery(self, user_id: str, session_id: str) -&gt; None:\n    \"\"\"\n    Delete MCP state.\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n    \"\"\"\n    async with self._lock:\n        key = self._make_key(user_id, session_id)\n        if key in self._storage:\n            del self._storage[key]\n            logger.debug(f\"Deleted MCP state for user={user_id}, session={session_id}\")\n</code></pre> <code></code> sk_agents.mcp_discovery.in_memory_discovery_manager.InMemoryStateManager.mark_completed <code>async</code> <pre><code>mark_completed(user_id: str, session_id: str) -&gt; None\n</code></pre> <p>Mark discovery as completed.</p> <p>If state doesn't exist, auto-creates it with discovery_completed=True and empty discovered_servers dict. A warning is logged when auto-creating.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required Source code in <code>src/sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> <pre><code>async def mark_completed(self, user_id: str, session_id: str) -&gt; None:\n    \"\"\"\n    Mark discovery as completed.\n\n    If state doesn't exist, auto-creates it with discovery_completed=True\n    and empty discovered_servers dict. A warning is logged when auto-creating.\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n    \"\"\"\n    async with self._lock:\n        key = self._make_key(user_id, session_id)\n        if key in self._storage:\n            self._storage[key].discovery_completed = True\n            logger.debug(f\"Marked discovery completed for user={user_id}, session={session_id}\")\n        else:\n            # Auto-create state if it doesn't exist\n            logger.warning(\n                f\"MCP state not found for user={user_id}, session={session_id}. \"\n                f\"Auto-creating with discovery_completed=True.\"\n            )\n            state = McpState(\n                user_id=user_id,\n                session_id=session_id,\n                discovered_servers={},\n                discovery_completed=True,\n                created_at=datetime.now(UTC),\n            )\n            self._storage[key] = state\n</code></pre> <code></code> sk_agents.mcp_discovery.in_memory_discovery_manager.InMemoryStateManager.is_completed <code>async</code> <pre><code>is_completed(user_id: str, session_id: str) -&gt; bool\n</code></pre> <p>Check if discovery is completed.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if discovery completed, False otherwise</p> Source code in <code>src/sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> <pre><code>async def is_completed(self, user_id: str, session_id: str) -&gt; bool:\n    \"\"\"\n    Check if discovery is completed.\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n\n    Returns:\n        True if discovery completed, False otherwise\n    \"\"\"\n    async with self._lock:\n        key = self._make_key(user_id, session_id)\n        state = self._storage.get(key)\n        return state.discovery_completed if state else False\n</code></pre> <code></code> sk_agents.mcp_discovery.in_memory_discovery_manager.InMemoryStateManager.store_mcp_session <code>async</code> <pre><code>store_mcp_session(\n    user_id: str,\n    session_id: str,\n    server_name: str,\n    mcp_session_id: str,\n) -&gt; None\n</code></pre> <p>Store MCP session ID for a server.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Teal agent session ID</p> required <code>server_name</code> <code>str</code> <p>Name of the MCP server</p> required <code>mcp_session_id</code> <code>str</code> <p>MCP session ID from server</p> required Source code in <code>src/sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> <pre><code>async def store_mcp_session(\n    self, user_id: str, session_id: str, server_name: str, mcp_session_id: str\n) -&gt; None:\n    \"\"\"\n    Store MCP session ID for a server.\n\n    Args:\n        user_id: User ID\n        session_id: Teal agent session ID\n        server_name: Name of the MCP server\n        mcp_session_id: MCP session ID from server\n    \"\"\"\n    async with self._lock:\n        key = self._make_key(user_id, session_id)\n        state = self._storage.get(key)\n\n        # Auto-create state if doesn't exist\n        if not state:\n            logger.warning(\n                f\"MCP state not found for user={user_id}, session={session_id}. \"\n                f\"Auto-creating to store session for {server_name}.\"\n            )\n            state = McpState(\n                user_id=user_id,\n                session_id=session_id,\n                discovered_servers={},\n                discovery_completed=False,\n                created_at=datetime.now(UTC),\n            )\n            self._storage[key] = state\n\n        # Ensure server entry exists and preserve plugin_data if present\n        existing_entry = state.discovered_servers.get(server_name, {})\n        plugin_data = existing_entry.get(\"plugin_data\")\n        state.discovered_servers[server_name] = {\n            \"plugin_data\": plugin_data,\n            **(\n                {\"session\": existing_entry.get(\"session\")}\n                if existing_entry.get(\"session\")\n                else {}\n            ),\n        }\n\n        # Store session data\n        session_bucket = state.discovered_servers[server_name].get(\"session\", {})\n        now_iso = datetime.now(UTC).isoformat()\n        session_bucket.update(\n            {\n                \"mcp_session_id\": mcp_session_id,\n                \"created_at\": session_bucket.get(\"created_at\", now_iso),\n                \"last_used_at\": now_iso,\n            }\n        )\n        state.discovered_servers[server_name][\"session\"] = session_bucket\n\n        logger.debug(\n            f\"Stored MCP session {mcp_session_id} for server={server_name}, \"\n            f\"user={user_id}, session={session_id}\"\n        )\n</code></pre> <code></code> sk_agents.mcp_discovery.in_memory_discovery_manager.InMemoryStateManager.get_mcp_session <code>async</code> <pre><code>get_mcp_session(\n    user_id: str, session_id: str, server_name: str\n) -&gt; str | None\n</code></pre> <p>Get MCP session ID for a server.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Teal agent session ID</p> required <code>server_name</code> <code>str</code> <p>Name of the MCP server</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>MCP session ID if exists, None otherwise</p> Source code in <code>src/sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> <pre><code>async def get_mcp_session(self, user_id: str, session_id: str, server_name: str) -&gt; str | None:\n    \"\"\"\n    Get MCP session ID for a server.\n\n    Args:\n        user_id: User ID\n        session_id: Teal agent session ID\n        server_name: Name of the MCP server\n\n    Returns:\n        MCP session ID if exists, None otherwise\n    \"\"\"\n    async with self._lock:\n        key = self._make_key(user_id, session_id)\n        state = self._storage.get(key)\n\n        if not state:\n            return None\n\n        server_data = state.discovered_servers.get(server_name)\n        if not server_data:\n            return None\n\n        session_bucket = server_data.get(\"session\")\n        if not session_bucket:\n            return None\n        return session_bucket.get(\"mcp_session_id\")\n</code></pre> <code></code> sk_agents.mcp_discovery.in_memory_discovery_manager.InMemoryStateManager.update_session_last_used <code>async</code> <pre><code>update_session_last_used(\n    user_id: str, session_id: str, server_name: str\n) -&gt; None\n</code></pre> <p>Update last_used timestamp for an MCP session.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Teal agent session ID</p> required <code>server_name</code> <code>str</code> <p>Name of the MCP server</p> required <p>Raises:</p> Type Description <code>DiscoveryUpdateError</code> <p>If state or server doesn't exist</p> Source code in <code>src/sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> <pre><code>async def update_session_last_used(\n    self, user_id: str, session_id: str, server_name: str\n) -&gt; None:\n    \"\"\"\n    Update last_used timestamp for an MCP session.\n\n    Args:\n        user_id: User ID\n        session_id: Teal agent session ID\n        server_name: Name of the MCP server\n\n    Raises:\n        DiscoveryUpdateError: If state or server doesn't exist\n    \"\"\"\n    async with self._lock:\n        key = self._make_key(user_id, session_id)\n        state = self._storage.get(key)\n\n        if not state:\n            raise DiscoveryUpdateError(\n                f\"MCP state not found for user={user_id}, session={session_id}\"\n            )\n\n        if server_name not in state.discovered_servers:\n            raise DiscoveryUpdateError(\n                f\"Server {server_name} not found in state for \"\n                f\"user={user_id}, session={session_id}\"\n            )\n\n        session_bucket = state.discovered_servers[server_name].get(\"session\")\n        if not session_bucket:\n            session_bucket = {}\n        session_bucket[\"last_used_at\"] = datetime.now(UTC).isoformat()\n        state.discovered_servers[server_name][\"session\"] = session_bucket\n\n        logger.debug(\n            f\"Updated last_used for server={server_name}, user={user_id}, session={session_id}\"\n        )\n</code></pre> <code></code> sk_agents.mcp_discovery.in_memory_discovery_manager.InMemoryStateManager.clear_mcp_session <code>async</code> <pre><code>clear_mcp_session(\n    user_id: str,\n    session_id: str,\n    server_name: str,\n    expected_session_id: str | None = None,\n) -&gt; None\n</code></pre> <p>Remove stored MCP session info for a server if present.</p> Source code in <code>src/sk_agents/mcp_discovery/in_memory_discovery_manager.py</code> <pre><code>async def clear_mcp_session(\n    self,\n    user_id: str,\n    session_id: str,\n    server_name: str,\n    expected_session_id: str | None = None,\n) -&gt; None:\n    \"\"\"Remove stored MCP session info for a server if present.\"\"\"\n    async with self._lock:\n        key = self._make_key(user_id, session_id)\n        state = self._storage.get(key)\n        if not state:\n            return\n        entry = state.discovered_servers.get(server_name)\n        if not entry:\n            return\n        if \"session\" in entry:\n            if expected_session_id:\n                current = entry.get(\"session\", {}).get(\"mcp_session_id\")\n                if current and current != expected_session_id:\n                    # Another session already replaced it; do not clear\n                    return\n            entry.pop(\"session\", None)\n            state.discovered_servers[server_name] = entry\n            logger.debug(\n                f\"Cleared MCP session for server={server_name}, \"\n                f\"user={user_id}, session={session_id}\"\n            )\n</code></pre> <code></code> sk_agents.mcp_discovery.mcp_discovery_manager <p>MCP State Manager - Abstract Interface</p> <p>Provides abstract base class for managing MCP tool discovery and session state. Follows the same pattern as TaskPersistenceManager and SecureAuthStorageManager.</p> <code></code> sk_agents.mcp_discovery.mcp_discovery_manager.DiscoveryError <p>               Bases: <code>Exception</code></p> <p>Base exception for MCP state manager errors.</p> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>class DiscoveryError(Exception):\n    \"\"\"Base exception for MCP state manager errors.\"\"\"\n\n    pass\n</code></pre> <code></code> sk_agents.mcp_discovery.mcp_discovery_manager.DiscoveryCreateError <p>               Bases: <code>DiscoveryError</code></p> <p>Raised when state creation fails.</p> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>class DiscoveryCreateError(DiscoveryError):\n    \"\"\"Raised when state creation fails.\"\"\"\n\n    pass\n</code></pre> <code></code> sk_agents.mcp_discovery.mcp_discovery_manager.DiscoveryUpdateError <p>               Bases: <code>DiscoveryError</code></p> <p>Raised when state update fails.</p> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>class DiscoveryUpdateError(DiscoveryError):\n    \"\"\"Raised when state update fails.\"\"\"\n\n    pass\n</code></pre> <code></code> sk_agents.mcp_discovery.mcp_discovery_manager.McpState <p>MCP state for a specific user session.</p> <p>Stores the results of MCP server discovery and session management including: - Which servers have been discovered - Serialized plugin data for each server - MCP session IDs for stateful servers - Completion status</p> <p>Scoped to (user_id, session_id) for session-level isolation.</p> <p>Structure of discovered_servers: {     \"server_name\": {         \"tools\": [...],  # Plugin metadata         \"mcp_session_id\": \"session-abc123\",  # Optional, for stateful servers         \"last_used_at\": \"2025-01-15T10:30:00Z\",  # Optional, session activity timestamp         \"created_at\": \"2025-01-15T10:00:00Z\"  # Optional, session creation timestamp     } }</p> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>class McpState:\n    \"\"\"\n    MCP state for a specific user session.\n\n    Stores the results of MCP server discovery and session management including:\n    - Which servers have been discovered\n    - Serialized plugin data for each server\n    - MCP session IDs for stateful servers\n    - Completion status\n\n    Scoped to (user_id, session_id) for session-level isolation.\n\n    Structure of discovered_servers:\n    {\n        \"server_name\": {\n            \"tools\": [...],  # Plugin metadata\n            \"mcp_session_id\": \"session-abc123\",  # Optional, for stateful servers\n            \"last_used_at\": \"2025-01-15T10:30:00Z\",  # Optional, session activity timestamp\n            \"created_at\": \"2025-01-15T10:00:00Z\"  # Optional, session creation timestamp\n        }\n    }\n    \"\"\"\n\n    def __init__(\n        self,\n        user_id: str,\n        session_id: str,\n        discovered_servers: dict[str, dict],\n        discovery_completed: bool,\n        created_at: datetime | None = None,\n        failed_servers: dict[str, str] | None = None,\n    ):\n        \"\"\"\n        Initialize MCP state.\n\n        Args:\n            user_id: User ID for authentication and scoping\n            session_id: Session ID for conversation grouping\n            discovered_servers: Mapping of server_name to plugin data and session info\n            discovery_completed: Whether discovery has finished successfully\n            created_at: Timestamp of state creation (defaults to now)\n            failed_servers: Dictionary of failed servers and their error messages\n        \"\"\"\n        self.user_id = user_id\n        self.session_id = session_id\n        self.discovered_servers = discovered_servers\n        self.discovery_completed = discovery_completed\n        self.created_at = created_at or datetime.now(UTC)\n        self.failed_servers = failed_servers or {}\n</code></pre> <code></code> sk_agents.mcp_discovery.mcp_discovery_manager.McpState.__init__ <pre><code>__init__(\n    user_id: str,\n    session_id: str,\n    discovered_servers: dict[str, dict],\n    discovery_completed: bool,\n    created_at: datetime | None = None,\n    failed_servers: dict[str, str] | None = None,\n)\n</code></pre> <p>Initialize MCP state.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID for authentication and scoping</p> required <code>session_id</code> <code>str</code> <p>Session ID for conversation grouping</p> required <code>discovered_servers</code> <code>dict[str, dict]</code> <p>Mapping of server_name to plugin data and session info</p> required <code>discovery_completed</code> <code>bool</code> <p>Whether discovery has finished successfully</p> required <code>created_at</code> <code>datetime | None</code> <p>Timestamp of state creation (defaults to now)</p> <code>None</code> <code>failed_servers</code> <code>dict[str, str] | None</code> <p>Dictionary of failed servers and their error messages</p> <code>None</code> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>def __init__(\n    self,\n    user_id: str,\n    session_id: str,\n    discovered_servers: dict[str, dict],\n    discovery_completed: bool,\n    created_at: datetime | None = None,\n    failed_servers: dict[str, str] | None = None,\n):\n    \"\"\"\n    Initialize MCP state.\n\n    Args:\n        user_id: User ID for authentication and scoping\n        session_id: Session ID for conversation grouping\n        discovered_servers: Mapping of server_name to plugin data and session info\n        discovery_completed: Whether discovery has finished successfully\n        created_at: Timestamp of state creation (defaults to now)\n        failed_servers: Dictionary of failed servers and their error messages\n    \"\"\"\n    self.user_id = user_id\n    self.session_id = session_id\n    self.discovered_servers = discovered_servers\n    self.discovery_completed = discovery_completed\n    self.created_at = created_at or datetime.now(UTC)\n    self.failed_servers = failed_servers or {}\n</code></pre> <code></code> sk_agents.mcp_discovery.mcp_discovery_manager.McpStateManager <p>               Bases: <code>ABC</code></p> <p>Abstract interface for MCP state management (discovery + sessions).</p> <p>Implementations must provide storage for MCP state scoped to (user_id, session_id) combinations. This enables: - Session-level tool isolation - Shared discovery across tasks in the same session - MCP session persistence for stateful servers - External state storage (Redis, in-memory, etc.)</p> <p>Pattern matches: - TaskPersistenceManager (for task state) - SecureAuthStorageManager (for OAuth tokens)</p> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>class McpStateManager(ABC):\n    \"\"\"\n    Abstract interface for MCP state management (discovery + sessions).\n\n    Implementations must provide storage for MCP state scoped to\n    (user_id, session_id) combinations. This enables:\n    - Session-level tool isolation\n    - Shared discovery across tasks in the same session\n    - MCP session persistence for stateful servers\n    - External state storage (Redis, in-memory, etc.)\n\n    Pattern matches:\n    - TaskPersistenceManager (for task state)\n    - SecureAuthStorageManager (for OAuth tokens)\n    \"\"\"\n\n    @abstractmethod\n    async def create_discovery(self, state: McpState) -&gt; None:\n        \"\"\"\n        Create initial state for (user_id, session_id).\n\n        Args:\n            state: MCP state to create\n\n        Raises:\n            DiscoveryCreateError: If state already exists for this (user_id, session_id)\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def load_discovery(self, user_id: str, session_id: str) -&gt; McpState | None:\n        \"\"\"\n        Load MCP state for (user_id, session_id).\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n\n        Returns:\n            MCP state if exists, None otherwise\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def update_discovery(self, state: McpState) -&gt; None:\n        \"\"\"\n        Update existing MCP state.\n\n        Args:\n            state: Updated MCP state\n\n        Raises:\n            DiscoveryUpdateError: If state does not exist\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def delete_discovery(self, user_id: str, session_id: str) -&gt; None:\n        \"\"\"\n        Delete MCP state for (user_id, session_id).\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def mark_completed(self, user_id: str, session_id: str) -&gt; None:\n        \"\"\"\n        Mark discovery as completed for (user_id, session_id).\n\n        If the state does not exist, it will be created automatically\n        with an empty discovered_servers dict and discovery_completed=True.\n        A warning will be logged when auto-creating.\n\n        This operation is idempotent - calling it multiple times has the same\n        effect as calling it once.\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def is_completed(self, user_id: str, session_id: str) -&gt; bool:\n        \"\"\"\n        Check if discovery is completed for (user_id, session_id).\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n\n        Returns:\n            True if discovery completed, False otherwise\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def store_mcp_session(\n        self, user_id: str, session_id: str, server_name: str, mcp_session_id: str\n    ) -&gt; None:\n        \"\"\"\n        Store MCP session ID for a server.\n\n        If state doesn't exist, it will be created. If server doesn't exist\n        in discovered_servers, it will be added.\n\n        Args:\n            user_id: User ID\n            session_id: Teal agent session ID\n            server_name: Name of the MCP server\n            mcp_session_id: MCP session ID from server\n\n        Raises:\n            DiscoveryUpdateError: If state update fails\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def get_mcp_session(self, user_id: str, session_id: str, server_name: str) -&gt; str | None:\n        \"\"\"\n        Get MCP session ID for a server.\n\n        Args:\n            user_id: User ID\n            session_id: Teal agent session ID\n            server_name: Name of the MCP server\n\n        Returns:\n            MCP session ID if exists, None otherwise\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def update_session_last_used(\n        self, user_id: str, session_id: str, server_name: str\n    ) -&gt; None:\n        \"\"\"\n        Update last_used timestamp for an MCP session.\n\n        Args:\n            user_id: User ID\n            session_id: Teal agent session ID\n            server_name: Name of the MCP server\n\n        Raises:\n            DiscoveryUpdateError: If state or server doesn't exist\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def clear_mcp_session(\n        self,\n        user_id: str,\n        session_id: str,\n        server_name: str,\n        expected_session_id: str | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Clear the stored MCP session for a given server (if present).\n\n        Args:\n            user_id: User ID\n            session_id: Teal agent session ID\n            server_name: Name of the MCP server\n            expected_session_id: Optional session id to match before clearing\n        \"\"\"\n        pass\n</code></pre> <code></code> sk_agents.mcp_discovery.mcp_discovery_manager.McpStateManager.create_discovery <code>abstractmethod</code> <code>async</code> <pre><code>create_discovery(state: McpState) -&gt; None\n</code></pre> <p>Create initial state for (user_id, session_id).</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>McpState</code> <p>MCP state to create</p> required <p>Raises:</p> Type Description <code>DiscoveryCreateError</code> <p>If state already exists for this (user_id, session_id)</p> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>@abstractmethod\nasync def create_discovery(self, state: McpState) -&gt; None:\n    \"\"\"\n    Create initial state for (user_id, session_id).\n\n    Args:\n        state: MCP state to create\n\n    Raises:\n        DiscoveryCreateError: If state already exists for this (user_id, session_id)\n    \"\"\"\n    pass\n</code></pre> <code></code> sk_agents.mcp_discovery.mcp_discovery_manager.McpStateManager.load_discovery <code>abstractmethod</code> <code>async</code> <pre><code>load_discovery(\n    user_id: str, session_id: str\n) -&gt; McpState | None\n</code></pre> <p>Load MCP state for (user_id, session_id).</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required <p>Returns:</p> Type Description <code>McpState | None</code> <p>MCP state if exists, None otherwise</p> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>@abstractmethod\nasync def load_discovery(self, user_id: str, session_id: str) -&gt; McpState | None:\n    \"\"\"\n    Load MCP state for (user_id, session_id).\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n\n    Returns:\n        MCP state if exists, None otherwise\n    \"\"\"\n    pass\n</code></pre> <code></code> sk_agents.mcp_discovery.mcp_discovery_manager.McpStateManager.update_discovery <code>abstractmethod</code> <code>async</code> <pre><code>update_discovery(state: McpState) -&gt; None\n</code></pre> <p>Update existing MCP state.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>McpState</code> <p>Updated MCP state</p> required <p>Raises:</p> Type Description <code>DiscoveryUpdateError</code> <p>If state does not exist</p> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>@abstractmethod\nasync def update_discovery(self, state: McpState) -&gt; None:\n    \"\"\"\n    Update existing MCP state.\n\n    Args:\n        state: Updated MCP state\n\n    Raises:\n        DiscoveryUpdateError: If state does not exist\n    \"\"\"\n    pass\n</code></pre> <code></code> sk_agents.mcp_discovery.mcp_discovery_manager.McpStateManager.delete_discovery <code>abstractmethod</code> <code>async</code> <pre><code>delete_discovery(user_id: str, session_id: str) -&gt; None\n</code></pre> <p>Delete MCP state for (user_id, session_id).</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>@abstractmethod\nasync def delete_discovery(self, user_id: str, session_id: str) -&gt; None:\n    \"\"\"\n    Delete MCP state for (user_id, session_id).\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n    \"\"\"\n    pass\n</code></pre> <code></code> sk_agents.mcp_discovery.mcp_discovery_manager.McpStateManager.mark_completed <code>abstractmethod</code> <code>async</code> <pre><code>mark_completed(user_id: str, session_id: str) -&gt; None\n</code></pre> <p>Mark discovery as completed for (user_id, session_id).</p> <p>If the state does not exist, it will be created automatically with an empty discovered_servers dict and discovery_completed=True. A warning will be logged when auto-creating.</p> <p>This operation is idempotent - calling it multiple times has the same effect as calling it once.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>@abstractmethod\nasync def mark_completed(self, user_id: str, session_id: str) -&gt; None:\n    \"\"\"\n    Mark discovery as completed for (user_id, session_id).\n\n    If the state does not exist, it will be created automatically\n    with an empty discovered_servers dict and discovery_completed=True.\n    A warning will be logged when auto-creating.\n\n    This operation is idempotent - calling it multiple times has the same\n    effect as calling it once.\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n    \"\"\"\n    pass\n</code></pre> <code></code> sk_agents.mcp_discovery.mcp_discovery_manager.McpStateManager.is_completed <code>abstractmethod</code> <code>async</code> <pre><code>is_completed(user_id: str, session_id: str) -&gt; bool\n</code></pre> <p>Check if discovery is completed for (user_id, session_id).</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if discovery completed, False otherwise</p> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>@abstractmethod\nasync def is_completed(self, user_id: str, session_id: str) -&gt; bool:\n    \"\"\"\n    Check if discovery is completed for (user_id, session_id).\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n\n    Returns:\n        True if discovery completed, False otherwise\n    \"\"\"\n    pass\n</code></pre> <code></code> sk_agents.mcp_discovery.mcp_discovery_manager.McpStateManager.store_mcp_session <code>abstractmethod</code> <code>async</code> <pre><code>store_mcp_session(\n    user_id: str,\n    session_id: str,\n    server_name: str,\n    mcp_session_id: str,\n) -&gt; None\n</code></pre> <p>Store MCP session ID for a server.</p> <p>If state doesn't exist, it will be created. If server doesn't exist in discovered_servers, it will be added.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Teal agent session ID</p> required <code>server_name</code> <code>str</code> <p>Name of the MCP server</p> required <code>mcp_session_id</code> <code>str</code> <p>MCP session ID from server</p> required <p>Raises:</p> Type Description <code>DiscoveryUpdateError</code> <p>If state update fails</p> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>@abstractmethod\nasync def store_mcp_session(\n    self, user_id: str, session_id: str, server_name: str, mcp_session_id: str\n) -&gt; None:\n    \"\"\"\n    Store MCP session ID for a server.\n\n    If state doesn't exist, it will be created. If server doesn't exist\n    in discovered_servers, it will be added.\n\n    Args:\n        user_id: User ID\n        session_id: Teal agent session ID\n        server_name: Name of the MCP server\n        mcp_session_id: MCP session ID from server\n\n    Raises:\n        DiscoveryUpdateError: If state update fails\n    \"\"\"\n    pass\n</code></pre> <code></code> sk_agents.mcp_discovery.mcp_discovery_manager.McpStateManager.get_mcp_session <code>abstractmethod</code> <code>async</code> <pre><code>get_mcp_session(\n    user_id: str, session_id: str, server_name: str\n) -&gt; str | None\n</code></pre> <p>Get MCP session ID for a server.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Teal agent session ID</p> required <code>server_name</code> <code>str</code> <p>Name of the MCP server</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>MCP session ID if exists, None otherwise</p> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>@abstractmethod\nasync def get_mcp_session(self, user_id: str, session_id: str, server_name: str) -&gt; str | None:\n    \"\"\"\n    Get MCP session ID for a server.\n\n    Args:\n        user_id: User ID\n        session_id: Teal agent session ID\n        server_name: Name of the MCP server\n\n    Returns:\n        MCP session ID if exists, None otherwise\n    \"\"\"\n    pass\n</code></pre> <code></code> sk_agents.mcp_discovery.mcp_discovery_manager.McpStateManager.update_session_last_used <code>abstractmethod</code> <code>async</code> <pre><code>update_session_last_used(\n    user_id: str, session_id: str, server_name: str\n) -&gt; None\n</code></pre> <p>Update last_used timestamp for an MCP session.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Teal agent session ID</p> required <code>server_name</code> <code>str</code> <p>Name of the MCP server</p> required <p>Raises:</p> Type Description <code>DiscoveryUpdateError</code> <p>If state or server doesn't exist</p> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>@abstractmethod\nasync def update_session_last_used(\n    self, user_id: str, session_id: str, server_name: str\n) -&gt; None:\n    \"\"\"\n    Update last_used timestamp for an MCP session.\n\n    Args:\n        user_id: User ID\n        session_id: Teal agent session ID\n        server_name: Name of the MCP server\n\n    Raises:\n        DiscoveryUpdateError: If state or server doesn't exist\n    \"\"\"\n    pass\n</code></pre> <code></code> sk_agents.mcp_discovery.mcp_discovery_manager.McpStateManager.clear_mcp_session <code>abstractmethod</code> <code>async</code> <pre><code>clear_mcp_session(\n    user_id: str,\n    session_id: str,\n    server_name: str,\n    expected_session_id: str | None = None,\n) -&gt; None\n</code></pre> <p>Clear the stored MCP session for a given server (if present).</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Teal agent session ID</p> required <code>server_name</code> <code>str</code> <p>Name of the MCP server</p> required <code>expected_session_id</code> <code>str | None</code> <p>Optional session id to match before clearing</p> <code>None</code> Source code in <code>src/sk_agents/mcp_discovery/mcp_discovery_manager.py</code> <pre><code>@abstractmethod\nasync def clear_mcp_session(\n    self,\n    user_id: str,\n    session_id: str,\n    server_name: str,\n    expected_session_id: str | None = None,\n) -&gt; None:\n    \"\"\"\n    Clear the stored MCP session for a given server (if present).\n\n    Args:\n        user_id: User ID\n        session_id: Teal agent session ID\n        server_name: Name of the MCP server\n        expected_session_id: Optional session id to match before clearing\n    \"\"\"\n    pass\n</code></pre> <code></code> sk_agents.mcp_discovery.redis_discovery_manager <p>Redis MCP State Manager</p> <p>Provides Redis-backed implementation for production deployments. Follows the same pattern as Redis persistence and auth storage.</p> <code></code> sk_agents.mcp_discovery.redis_discovery_manager.RedisStateManager <p>               Bases: <code>McpStateManager</code></p> <p>Redis-backed implementation of MCP state manager.</p> <p>Stores MCP state in Redis for: - Production deployments - Multi-instance horizontal scaling - Persistence across server restarts - Shared state across distributed systems</p> <p>Uses the same Redis configuration as other components (TA_REDIS_*).</p> Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>class RedisStateManager(McpStateManager):\n    \"\"\"\n    Redis-backed implementation of MCP state manager.\n\n    Stores MCP state in Redis for:\n    - Production deployments\n    - Multi-instance horizontal scaling\n    - Persistence across server restarts\n    - Shared state across distributed systems\n\n    Uses the same Redis configuration as other components (TA_REDIS_*).\n    \"\"\"\n\n    def __init__(self, app_config: AppConfig, redis_client: Redis | None = None):\n        \"\"\"\n        Initialize Redis state manager.\n\n        Args:\n            app_config: Application configuration for Redis connection\n            redis_client: Optional pre-configured Redis client (for testing)\n        \"\"\"\n        self.app_config = app_config\n        self.redis = redis_client or self._create_redis_client()\n        self.key_prefix = \"mcp_state\"\n\n        # TTL support: Default to 24 hours (86400 seconds)\n        from sk_agents.configs import TA_REDIS_TTL\n\n        ttl_str = self.app_config.get(TA_REDIS_TTL.env_name)\n        if ttl_str:\n            self.ttl = int(ttl_str)\n        else:\n            # Default to 24 hours for discovery state\n            self.ttl = 86400\n\n        logger.debug(f\"Redis state manager initialized with TTL={self.ttl}s\")\n\n    async def close(self) -&gt; None:\n        \"\"\"Close Redis connection and cleanup resources.\"\"\"\n        if self.redis:\n            await self.redis.close()\n            logger.debug(\"Redis state manager connection closed\")\n\n    async def __aenter__(self):\n        \"\"\"Async context manager entry.\"\"\"\n        return self\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Async context manager exit.\"\"\"\n        await self.close()\n\n    def _create_redis_client(self) -&gt; Redis:\n        \"\"\"\n        Create Redis client from app configuration.\n\n        Reuses existing TA_REDIS_* environment variables for consistency\n        with other persistence components.\n\n        Returns:\n            Configured Redis client\n\n        Raises:\n            ValueError: If required Redis config is missing\n        \"\"\"\n        from sk_agents.configs import (\n            TA_REDIS_DB,\n            TA_REDIS_HOST,\n            TA_REDIS_PORT,\n            TA_REDIS_PWD,\n            TA_REDIS_SSL,\n        )\n\n        host = self.app_config.get(TA_REDIS_HOST.env_name)\n        port_str = self.app_config.get(TA_REDIS_PORT.env_name)\n        db_str = self.app_config.get(TA_REDIS_DB.env_name, default=\"0\")\n        ssl_str = self.app_config.get(TA_REDIS_SSL.env_name, default=\"false\")\n        pwd = self.app_config.get(TA_REDIS_PWD.env_name, default=None)\n\n        if not host:\n            raise ValueError(\"TA_REDIS_HOST must be configured for Redis discovery manager\")\n        if not port_str:\n            raise ValueError(\"TA_REDIS_PORT must be configured for Redis discovery manager\")\n\n        port = int(port_str)\n        db = int(db_str)\n        ssl = strtobool(ssl_str)\n\n        logger.info(\n            f\"Creating Redis discovery client: host={host}, port={port}, db={db}, ssl={ssl}\"\n        )\n\n        return Redis(host=host, port=port, db=db, ssl=ssl, password=pwd)\n\n    def _make_key(self, user_id: str, session_id: str) -&gt; str:\n        \"\"\"\n        Create Redis key for storage.\n\n        Format: mcp_state:{user_id}:{session_id}\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n\n        Returns:\n            Redis key string\n        \"\"\"\n        return f\"{self.key_prefix}:{user_id}:{session_id}\"\n\n    async def create_discovery(self, state: McpState) -&gt; None:\n        \"\"\"\n        Create initial MCP state in Redis.\n\n        Args:\n            state: MCP state to create\n\n        Raises:\n            DiscoveryCreateError: If state already exists\n        \"\"\"\n        key = self._make_key(state.user_id, state.session_id)\n        exists = await self.redis.exists(key)\n        if exists:\n            raise DiscoveryCreateError(\n                f\"MCP state already exists for user={state.user_id}, session={state.session_id}\"\n            )\n\n        data = self._serialize(state)\n        # Set with TTL\n        await self.redis.set(key, data, ex=self.ttl)\n        logger.debug(\n            f\"Created Redis MCP state: user={state.user_id}, session={state.session_id}, \"\n            f\"TTL={self.ttl}s\"\n        )\n\n    async def load_discovery(self, user_id: str, session_id: str) -&gt; McpState | None:\n        \"\"\"\n        Load MCP state from Redis.\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n\n        Returns:\n            MCP state if exists, None otherwise\n        \"\"\"\n        key = self._make_key(user_id, session_id)\n        data = await self.redis.get(key)\n        if not data:\n            return None\n        return self._deserialize(data, user_id, session_id)\n\n    async def update_discovery(self, state: McpState) -&gt; None:\n        \"\"\"\n        Update existing MCP state in Redis.\n\n        Args:\n            state: Updated MCP state\n\n        Raises:\n            DiscoveryUpdateError: If state does not exist\n        \"\"\"\n        key = self._make_key(state.user_id, state.session_id)\n        # Check existence before updating\n        exists = await self.redis.exists(key)\n        if not exists:\n            raise DiscoveryUpdateError(\n                f\"MCP state not found for user={state.user_id}, session={state.session_id}\"\n            )\n\n        data = self._serialize(state)\n        # Update with TTL to extend expiration\n        await self.redis.set(key, data, ex=self.ttl)\n        logger.debug(f\"Updated Redis MCP state: user={state.user_id}, session={state.session_id}\")\n\n    async def delete_discovery(self, user_id: str, session_id: str) -&gt; None:\n        \"\"\"\n        Delete discovery state from Redis.\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n        \"\"\"\n        key = self._make_key(user_id, session_id)\n        await self.redis.delete(key)\n        logger.debug(f\"Deleted Redis discovery state: user={user_id}, session={session_id}\")\n\n    async def mark_completed(self, user_id: str, session_id: str) -&gt; None:\n        \"\"\"\n        Mark discovery as completed in Redis using atomic operation.\n\n        If state doesn't exist, auto-creates it with discovery_completed=True\n        and empty discovered_servers dict. A warning is logged when auto-creating.\n\n        Uses Lua script for atomic read-modify-write to prevent race conditions\n        in multi-worker deployments.\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n        \"\"\"\n        key = self._make_key(user_id, session_id)\n\n        # Lua script for atomic mark_completed operation\n        lua_script = \"\"\"\n        local key = KEYS[1]\n        local ttl = tonumber(ARGV[1])\n        local data = redis.call('GET', key)\n\n        if data then\n            -- State exists, update discovery_completed field\n            local obj = cjson.decode(data)\n            obj.discovery_completed = true\n            local updated_data = cjson.encode(obj)\n            redis.call('SET', key, updated_data, 'EX', ttl)\n            return 1\n        else\n            -- State doesn't exist, return 0 to signal auto-create\n            return 0\n        end\n        \"\"\"\n\n        result = await self.redis.eval(lua_script, 1, key, self.ttl)\n\n        if result == 1:\n            logger.debug(f\"Marked discovery completed: user={user_id}, session={session_id}\")\n        else:\n            # Auto-create state if it doesn't exist\n            logger.warning(\n                f\"MCP state not found for user={user_id}, session={session_id}. \"\n                f\"Auto-creating with discovery_completed=True.\"\n            )\n            state = McpState(\n                user_id=user_id,\n                session_id=session_id,\n                discovered_servers={},\n                discovery_completed=True,\n                created_at=datetime.now(UTC),\n            )\n            data = self._serialize(state)\n            await self.redis.set(key, data, ex=self.ttl)\n            logger.debug(f\"Auto-created discovery state: user={user_id}, session={session_id}\")\n\n    async def is_completed(self, user_id: str, session_id: str) -&gt; bool:\n        \"\"\"\n        Check if discovery is completed in Redis.\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n\n        Returns:\n            True if discovery completed, False otherwise\n        \"\"\"\n        state = await self.load_discovery(user_id, session_id)\n        return state.discovery_completed if state else False\n\n    async def store_mcp_session(\n        self, user_id: str, session_id: str, server_name: str, mcp_session_id: str\n    ) -&gt; None:\n        \"\"\"\n        Store MCP session ID for a server using atomic Lua script.\n\n        Args:\n            user_id: User ID\n            session_id: Teal agent session ID\n            server_name: Name of the MCP server\n            mcp_session_id: MCP session ID from server\n        \"\"\"\n        key = self._make_key(user_id, session_id)\n\n        # Lua script for atomic store operation\n        lua_script = \"\"\"\n        local key = KEYS[1]\n        local ttl = tonumber(ARGV[1])\n        local server_name = ARGV[2]\n        local mcp_session_id = ARGV[3]\n        local timestamp = ARGV[4]\n\n        local data = redis.call('GET', key)\n        local obj\n\n        if data then\n            -- State exists, update it\n            obj = cjson.decode(data)\n        else\n            -- State doesn't exist, create minimal state\n            obj = {\n                user_id = ARGV[5],\n                session_id = ARGV[6],\n                discovered_servers = {},\n                discovery_completed = false,\n                created_at = timestamp\n            }\n        end\n\n        -- Ensure server entry exists\n        if not obj.discovered_servers[server_name] then\n            obj.discovered_servers[server_name] = {}\n        end\n\n        -- Store session data\n        if not obj.discovered_servers[server_name].session then\n            obj.discovered_servers[server_name].session = {}\n        end\n\n        obj.discovered_servers[server_name].session.mcp_session_id = mcp_session_id\n        local sess = obj.discovered_servers[server_name].session\n        sess.created_at = sess.created_at or timestamp\n        sess.last_used_at = timestamp\n\n        local updated_data = cjson.encode(obj)\n        redis.call('SET', key, updated_data, 'EX', ttl)\n        return 1\n        \"\"\"\n\n        timestamp = datetime.now(UTC).isoformat()\n        await self.redis.eval(\n            lua_script,\n            1,\n            key,\n            self.ttl,\n            server_name,\n            mcp_session_id,\n            timestamp,\n            user_id,\n            session_id,\n        )\n\n        logger.debug(\n            f\"Stored MCP session {mcp_session_id} for server={server_name}, \"\n            f\"user={user_id}, session={session_id}\"\n        )\n\n    async def get_mcp_session(self, user_id: str, session_id: str, server_name: str) -&gt; str | None:\n        \"\"\"\n        Get MCP session ID for a server.\n\n        Args:\n            user_id: User ID\n            session_id: Teal agent session ID\n            server_name: Name of the MCP server\n\n        Returns:\n            MCP session ID if exists, None otherwise\n        \"\"\"\n        state = await self.load_discovery(user_id, session_id)\n\n        if not state:\n            return None\n\n        server_data = state.discovered_servers.get(server_name)\n        if not server_data:\n            return None\n\n        session_bucket = server_data.get(\"session\")\n        if not session_bucket:\n            return None\n\n        return session_bucket.get(\"mcp_session_id\")\n\n    async def update_session_last_used(\n        self, user_id: str, session_id: str, server_name: str\n    ) -&gt; None:\n        \"\"\"\n        Update last_used timestamp using atomic Lua script.\n\n        Args:\n            user_id: User ID\n            session_id: Teal agent session ID\n            server_name: Name of the MCP server\n\n        Raises:\n            DiscoveryUpdateError: If state or server doesn't exist\n        \"\"\"\n        key = self._make_key(user_id, session_id)\n\n        # Lua script for atomic update\n        lua_script = \"\"\"\n        local key = KEYS[1]\n        local ttl = tonumber(ARGV[1])\n        local server_name = ARGV[2]\n        local timestamp = ARGV[3]\n\n        local data = redis.call('GET', key)\n        if not data then\n            return 0  -- State not found\n        end\n\n        local obj = cjson.decode(data)\n\n        if not obj.discovered_servers[server_name] then\n            return -1  -- Server not found\n        end\n\n        if not obj.discovered_servers[server_name].session then\n            obj.discovered_servers[server_name].session = {}\n        end\n        obj.discovered_servers[server_name].session.last_used_at = timestamp\n\n        local updated_data = cjson.encode(obj)\n        redis.call('SET', key, updated_data, 'EX', ttl)\n        return 1\n        \"\"\"\n\n        timestamp = datetime.now(UTC).isoformat()\n        result = await self.redis.eval(lua_script, 1, key, self.ttl, server_name, timestamp)\n\n        if result == 0:\n            raise DiscoveryUpdateError(\n                f\"MCP state not found for user={user_id}, session={session_id}\"\n            )\n        elif result == -1:\n            raise DiscoveryUpdateError(\n                f\"Server {server_name} not found in state for user={user_id}, session={session_id}\"\n            )\n\n        logger.debug(\n            f\"Updated last_used for server={server_name}, user={user_id}, session={session_id}\"\n        )\n\n    async def clear_mcp_session(\n        self,\n        user_id: str,\n        session_id: str,\n        server_name: str,\n        expected_session_id: str | None = None,\n    ) -&gt; None:\n        \"\"\"Remove stored MCP session info for a server if present.\"\"\"\n        key = self._make_key(user_id, session_id)\n\n        lua_script = \"\"\"\n        local key = KEYS[1]\n        local server_name = ARGV[1]\n        local ttl = tonumber(ARGV[2])\n        local expected_session_id = ARGV[3]\n\n        local data = redis.call('GET', key)\n        if not data then\n            return 0 -- state missing\n        end\n\n        local obj = cjson.decode(data)\n        if not obj.discovered_servers[server_name] then\n            return -1 -- server missing\n        end\n\n        -- Only clear if expected matches or no expectation provided\n        if obj.discovered_servers[server_name].session then\n            local current = obj.discovered_servers[server_name].session.mcp_session_id\n            if expected_session_id ~= nil and expected_session_id ~= '' then\n                if current ~= expected_session_id then\n                    return -2  -- session changed, skip clear\n                end\n            end\n        end\n\n        obj.discovered_servers[server_name].session = nil\n\n        local updated_data = cjson.encode(obj)\n        redis.call('SET', key, updated_data, 'EX', ttl)\n        return 1\n        \"\"\"\n\n        expected_arg = expected_session_id or \"\"\n        result = await self.redis.eval(lua_script, 1, key, server_name, self.ttl, expected_arg)\n        if result == 0:\n            logger.debug(\n                f\"clear_mcp_session: state missing for user={user_id}, session={session_id}\"\n            )\n        elif result == -1:\n            logger.debug(\n                f\"clear_mcp_session: server missing for user={user_id}, \"\n                f\"session={session_id}, server={server_name}\"\n            )\n        elif result == -2:\n            logger.debug(\n                f\"clear_mcp_session: session changed for user={user_id}, \"\n                f\"session={session_id}, server={server_name}\"\n            )\n        else:\n            logger.debug(\n                f\"Cleared MCP session for server={server_name}, \"\n                f\"user={user_id}, session={session_id}\"\n            )\n\n    def _serialize(self, state: McpState) -&gt; str:\n        \"\"\"\n        Serialize MCP state to JSON.\n\n        Args:\n            state: MCP state to serialize\n\n        Returns:\n            JSON string representation\n        \"\"\"\n        return json.dumps(\n            {\n                \"user_id\": state.user_id,\n                \"session_id\": state.session_id,\n                \"discovered_servers\": state.discovered_servers,\n                \"discovery_completed\": state.discovery_completed,\n                \"created_at\": state.created_at.isoformat(),\n                \"failed_servers\": state.failed_servers,\n            }\n        )\n\n    def _deserialize(self, data: str | bytes, user_id: str, session_id: str) -&gt; McpState:\n        \"\"\"\n        Deserialize JSON to MCP state object.\n\n        Args:\n            data: JSON string or bytes from Redis\n            user_id: User ID (for validation)\n            session_id: Session ID (for validation)\n\n        Returns:\n            McpState object\n\n        Raises:\n            ValueError: If deserialized user_id/session_id don't match parameters\n        \"\"\"\n        # Handle bytes from Redis\n        if isinstance(data, bytes):\n            data = data.decode(\"utf-8\")\n\n        obj = json.loads(data)\n\n        # Validate that serialized data matches the key parameters\n        if obj[\"user_id\"] != user_id:\n            raise ValueError(\n                f\"Deserialized user_id '{obj['user_id']}' does not match \"\n                f\"expected user_id '{user_id}'\"\n            )\n        if obj[\"session_id\"] != session_id:\n            raise ValueError(\n                f\"Deserialized session_id '{obj['session_id']}' does not match \"\n                f\"expected session_id '{session_id}'\"\n            )\n\n        return McpState(\n            user_id=user_id,\n            session_id=session_id,\n            discovered_servers=obj[\"discovered_servers\"],\n            discovery_completed=obj[\"discovery_completed\"],\n            created_at=datetime.fromisoformat(obj[\"created_at\"]),\n            failed_servers=obj.get(\"failed_servers\", {}),\n        )\n</code></pre> <code></code> sk_agents.mcp_discovery.redis_discovery_manager.RedisStateManager.__init__ <pre><code>__init__(\n    app_config: AppConfig, redis_client: Redis | None = None\n)\n</code></pre> <p>Initialize Redis state manager.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>AppConfig</code> <p>Application configuration for Redis connection</p> required <code>redis_client</code> <code>Redis | None</code> <p>Optional pre-configured Redis client (for testing)</p> <code>None</code> Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>def __init__(self, app_config: AppConfig, redis_client: Redis | None = None):\n    \"\"\"\n    Initialize Redis state manager.\n\n    Args:\n        app_config: Application configuration for Redis connection\n        redis_client: Optional pre-configured Redis client (for testing)\n    \"\"\"\n    self.app_config = app_config\n    self.redis = redis_client or self._create_redis_client()\n    self.key_prefix = \"mcp_state\"\n\n    # TTL support: Default to 24 hours (86400 seconds)\n    from sk_agents.configs import TA_REDIS_TTL\n\n    ttl_str = self.app_config.get(TA_REDIS_TTL.env_name)\n    if ttl_str:\n        self.ttl = int(ttl_str)\n    else:\n        # Default to 24 hours for discovery state\n        self.ttl = 86400\n\n    logger.debug(f\"Redis state manager initialized with TTL={self.ttl}s\")\n</code></pre> <code></code> sk_agents.mcp_discovery.redis_discovery_manager.RedisStateManager.close <code>async</code> <pre><code>close() -&gt; None\n</code></pre> <p>Close Redis connection and cleanup resources.</p> Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"Close Redis connection and cleanup resources.\"\"\"\n    if self.redis:\n        await self.redis.close()\n        logger.debug(\"Redis state manager connection closed\")\n</code></pre> <code></code> sk_agents.mcp_discovery.redis_discovery_manager.RedisStateManager.__aenter__ <code>async</code> <pre><code>__aenter__()\n</code></pre> <p>Async context manager entry.</p> Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def __aenter__(self):\n    \"\"\"Async context manager entry.\"\"\"\n    return self\n</code></pre> <code></code> sk_agents.mcp_discovery.redis_discovery_manager.RedisStateManager.__aexit__ <code>async</code> <pre><code>__aexit__(exc_type, exc_val, exc_tb)\n</code></pre> <p>Async context manager exit.</p> Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def __aexit__(self, exc_type, exc_val, exc_tb):\n    \"\"\"Async context manager exit.\"\"\"\n    await self.close()\n</code></pre> <code></code> sk_agents.mcp_discovery.redis_discovery_manager.RedisStateManager.create_discovery <code>async</code> <pre><code>create_discovery(state: McpState) -&gt; None\n</code></pre> <p>Create initial MCP state in Redis.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>McpState</code> <p>MCP state to create</p> required <p>Raises:</p> Type Description <code>DiscoveryCreateError</code> <p>If state already exists</p> Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def create_discovery(self, state: McpState) -&gt; None:\n    \"\"\"\n    Create initial MCP state in Redis.\n\n    Args:\n        state: MCP state to create\n\n    Raises:\n        DiscoveryCreateError: If state already exists\n    \"\"\"\n    key = self._make_key(state.user_id, state.session_id)\n    exists = await self.redis.exists(key)\n    if exists:\n        raise DiscoveryCreateError(\n            f\"MCP state already exists for user={state.user_id}, session={state.session_id}\"\n        )\n\n    data = self._serialize(state)\n    # Set with TTL\n    await self.redis.set(key, data, ex=self.ttl)\n    logger.debug(\n        f\"Created Redis MCP state: user={state.user_id}, session={state.session_id}, \"\n        f\"TTL={self.ttl}s\"\n    )\n</code></pre> <code></code> sk_agents.mcp_discovery.redis_discovery_manager.RedisStateManager.load_discovery <code>async</code> <pre><code>load_discovery(\n    user_id: str, session_id: str\n) -&gt; McpState | None\n</code></pre> <p>Load MCP state from Redis.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required <p>Returns:</p> Type Description <code>McpState | None</code> <p>MCP state if exists, None otherwise</p> Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def load_discovery(self, user_id: str, session_id: str) -&gt; McpState | None:\n    \"\"\"\n    Load MCP state from Redis.\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n\n    Returns:\n        MCP state if exists, None otherwise\n    \"\"\"\n    key = self._make_key(user_id, session_id)\n    data = await self.redis.get(key)\n    if not data:\n        return None\n    return self._deserialize(data, user_id, session_id)\n</code></pre> <code></code> sk_agents.mcp_discovery.redis_discovery_manager.RedisStateManager.update_discovery <code>async</code> <pre><code>update_discovery(state: McpState) -&gt; None\n</code></pre> <p>Update existing MCP state in Redis.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>McpState</code> <p>Updated MCP state</p> required <p>Raises:</p> Type Description <code>DiscoveryUpdateError</code> <p>If state does not exist</p> Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def update_discovery(self, state: McpState) -&gt; None:\n    \"\"\"\n    Update existing MCP state in Redis.\n\n    Args:\n        state: Updated MCP state\n\n    Raises:\n        DiscoveryUpdateError: If state does not exist\n    \"\"\"\n    key = self._make_key(state.user_id, state.session_id)\n    # Check existence before updating\n    exists = await self.redis.exists(key)\n    if not exists:\n        raise DiscoveryUpdateError(\n            f\"MCP state not found for user={state.user_id}, session={state.session_id}\"\n        )\n\n    data = self._serialize(state)\n    # Update with TTL to extend expiration\n    await self.redis.set(key, data, ex=self.ttl)\n    logger.debug(f\"Updated Redis MCP state: user={state.user_id}, session={state.session_id}\")\n</code></pre> <code></code> sk_agents.mcp_discovery.redis_discovery_manager.RedisStateManager.delete_discovery <code>async</code> <pre><code>delete_discovery(user_id: str, session_id: str) -&gt; None\n</code></pre> <p>Delete discovery state from Redis.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def delete_discovery(self, user_id: str, session_id: str) -&gt; None:\n    \"\"\"\n    Delete discovery state from Redis.\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n    \"\"\"\n    key = self._make_key(user_id, session_id)\n    await self.redis.delete(key)\n    logger.debug(f\"Deleted Redis discovery state: user={user_id}, session={session_id}\")\n</code></pre> <code></code> sk_agents.mcp_discovery.redis_discovery_manager.RedisStateManager.mark_completed <code>async</code> <pre><code>mark_completed(user_id: str, session_id: str) -&gt; None\n</code></pre> <p>Mark discovery as completed in Redis using atomic operation.</p> <p>If state doesn't exist, auto-creates it with discovery_completed=True and empty discovered_servers dict. A warning is logged when auto-creating.</p> <p>Uses Lua script for atomic read-modify-write to prevent race conditions in multi-worker deployments.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def mark_completed(self, user_id: str, session_id: str) -&gt; None:\n    \"\"\"\n    Mark discovery as completed in Redis using atomic operation.\n\n    If state doesn't exist, auto-creates it with discovery_completed=True\n    and empty discovered_servers dict. A warning is logged when auto-creating.\n\n    Uses Lua script for atomic read-modify-write to prevent race conditions\n    in multi-worker deployments.\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n    \"\"\"\n    key = self._make_key(user_id, session_id)\n\n    # Lua script for atomic mark_completed operation\n    lua_script = \"\"\"\n    local key = KEYS[1]\n    local ttl = tonumber(ARGV[1])\n    local data = redis.call('GET', key)\n\n    if data then\n        -- State exists, update discovery_completed field\n        local obj = cjson.decode(data)\n        obj.discovery_completed = true\n        local updated_data = cjson.encode(obj)\n        redis.call('SET', key, updated_data, 'EX', ttl)\n        return 1\n    else\n        -- State doesn't exist, return 0 to signal auto-create\n        return 0\n    end\n    \"\"\"\n\n    result = await self.redis.eval(lua_script, 1, key, self.ttl)\n\n    if result == 1:\n        logger.debug(f\"Marked discovery completed: user={user_id}, session={session_id}\")\n    else:\n        # Auto-create state if it doesn't exist\n        logger.warning(\n            f\"MCP state not found for user={user_id}, session={session_id}. \"\n            f\"Auto-creating with discovery_completed=True.\"\n        )\n        state = McpState(\n            user_id=user_id,\n            session_id=session_id,\n            discovered_servers={},\n            discovery_completed=True,\n            created_at=datetime.now(UTC),\n        )\n        data = self._serialize(state)\n        await self.redis.set(key, data, ex=self.ttl)\n        logger.debug(f\"Auto-created discovery state: user={user_id}, session={session_id}\")\n</code></pre> <code></code> sk_agents.mcp_discovery.redis_discovery_manager.RedisStateManager.is_completed <code>async</code> <pre><code>is_completed(user_id: str, session_id: str) -&gt; bool\n</code></pre> <p>Check if discovery is completed in Redis.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if discovery completed, False otherwise</p> Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def is_completed(self, user_id: str, session_id: str) -&gt; bool:\n    \"\"\"\n    Check if discovery is completed in Redis.\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n\n    Returns:\n        True if discovery completed, False otherwise\n    \"\"\"\n    state = await self.load_discovery(user_id, session_id)\n    return state.discovery_completed if state else False\n</code></pre> <code></code> sk_agents.mcp_discovery.redis_discovery_manager.RedisStateManager.store_mcp_session <code>async</code> <pre><code>store_mcp_session(\n    user_id: str,\n    session_id: str,\n    server_name: str,\n    mcp_session_id: str,\n) -&gt; None\n</code></pre> <p>Store MCP session ID for a server using atomic Lua script.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Teal agent session ID</p> required <code>server_name</code> <code>str</code> <p>Name of the MCP server</p> required <code>mcp_session_id</code> <code>str</code> <p>MCP session ID from server</p> required Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def store_mcp_session(\n    self, user_id: str, session_id: str, server_name: str, mcp_session_id: str\n) -&gt; None:\n    \"\"\"\n    Store MCP session ID for a server using atomic Lua script.\n\n    Args:\n        user_id: User ID\n        session_id: Teal agent session ID\n        server_name: Name of the MCP server\n        mcp_session_id: MCP session ID from server\n    \"\"\"\n    key = self._make_key(user_id, session_id)\n\n    # Lua script for atomic store operation\n    lua_script = \"\"\"\n    local key = KEYS[1]\n    local ttl = tonumber(ARGV[1])\n    local server_name = ARGV[2]\n    local mcp_session_id = ARGV[3]\n    local timestamp = ARGV[4]\n\n    local data = redis.call('GET', key)\n    local obj\n\n    if data then\n        -- State exists, update it\n        obj = cjson.decode(data)\n    else\n        -- State doesn't exist, create minimal state\n        obj = {\n            user_id = ARGV[5],\n            session_id = ARGV[6],\n            discovered_servers = {},\n            discovery_completed = false,\n            created_at = timestamp\n        }\n    end\n\n    -- Ensure server entry exists\n    if not obj.discovered_servers[server_name] then\n        obj.discovered_servers[server_name] = {}\n    end\n\n    -- Store session data\n    if not obj.discovered_servers[server_name].session then\n        obj.discovered_servers[server_name].session = {}\n    end\n\n    obj.discovered_servers[server_name].session.mcp_session_id = mcp_session_id\n    local sess = obj.discovered_servers[server_name].session\n    sess.created_at = sess.created_at or timestamp\n    sess.last_used_at = timestamp\n\n    local updated_data = cjson.encode(obj)\n    redis.call('SET', key, updated_data, 'EX', ttl)\n    return 1\n    \"\"\"\n\n    timestamp = datetime.now(UTC).isoformat()\n    await self.redis.eval(\n        lua_script,\n        1,\n        key,\n        self.ttl,\n        server_name,\n        mcp_session_id,\n        timestamp,\n        user_id,\n        session_id,\n    )\n\n    logger.debug(\n        f\"Stored MCP session {mcp_session_id} for server={server_name}, \"\n        f\"user={user_id}, session={session_id}\"\n    )\n</code></pre> <code></code> sk_agents.mcp_discovery.redis_discovery_manager.RedisStateManager.get_mcp_session <code>async</code> <pre><code>get_mcp_session(\n    user_id: str, session_id: str, server_name: str\n) -&gt; str | None\n</code></pre> <p>Get MCP session ID for a server.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Teal agent session ID</p> required <code>server_name</code> <code>str</code> <p>Name of the MCP server</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>MCP session ID if exists, None otherwise</p> Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def get_mcp_session(self, user_id: str, session_id: str, server_name: str) -&gt; str | None:\n    \"\"\"\n    Get MCP session ID for a server.\n\n    Args:\n        user_id: User ID\n        session_id: Teal agent session ID\n        server_name: Name of the MCP server\n\n    Returns:\n        MCP session ID if exists, None otherwise\n    \"\"\"\n    state = await self.load_discovery(user_id, session_id)\n\n    if not state:\n        return None\n\n    server_data = state.discovered_servers.get(server_name)\n    if not server_data:\n        return None\n\n    session_bucket = server_data.get(\"session\")\n    if not session_bucket:\n        return None\n\n    return session_bucket.get(\"mcp_session_id\")\n</code></pre> <code></code> sk_agents.mcp_discovery.redis_discovery_manager.RedisStateManager.update_session_last_used <code>async</code> <pre><code>update_session_last_used(\n    user_id: str, session_id: str, server_name: str\n) -&gt; None\n</code></pre> <p>Update last_used timestamp using atomic Lua script.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Teal agent session ID</p> required <code>server_name</code> <code>str</code> <p>Name of the MCP server</p> required <p>Raises:</p> Type Description <code>DiscoveryUpdateError</code> <p>If state or server doesn't exist</p> Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def update_session_last_used(\n    self, user_id: str, session_id: str, server_name: str\n) -&gt; None:\n    \"\"\"\n    Update last_used timestamp using atomic Lua script.\n\n    Args:\n        user_id: User ID\n        session_id: Teal agent session ID\n        server_name: Name of the MCP server\n\n    Raises:\n        DiscoveryUpdateError: If state or server doesn't exist\n    \"\"\"\n    key = self._make_key(user_id, session_id)\n\n    # Lua script for atomic update\n    lua_script = \"\"\"\n    local key = KEYS[1]\n    local ttl = tonumber(ARGV[1])\n    local server_name = ARGV[2]\n    local timestamp = ARGV[3]\n\n    local data = redis.call('GET', key)\n    if not data then\n        return 0  -- State not found\n    end\n\n    local obj = cjson.decode(data)\n\n    if not obj.discovered_servers[server_name] then\n        return -1  -- Server not found\n    end\n\n    if not obj.discovered_servers[server_name].session then\n        obj.discovered_servers[server_name].session = {}\n    end\n    obj.discovered_servers[server_name].session.last_used_at = timestamp\n\n    local updated_data = cjson.encode(obj)\n    redis.call('SET', key, updated_data, 'EX', ttl)\n    return 1\n    \"\"\"\n\n    timestamp = datetime.now(UTC).isoformat()\n    result = await self.redis.eval(lua_script, 1, key, self.ttl, server_name, timestamp)\n\n    if result == 0:\n        raise DiscoveryUpdateError(\n            f\"MCP state not found for user={user_id}, session={session_id}\"\n        )\n    elif result == -1:\n        raise DiscoveryUpdateError(\n            f\"Server {server_name} not found in state for user={user_id}, session={session_id}\"\n        )\n\n    logger.debug(\n        f\"Updated last_used for server={server_name}, user={user_id}, session={session_id}\"\n    )\n</code></pre> <code></code> sk_agents.mcp_discovery.redis_discovery_manager.RedisStateManager.clear_mcp_session <code>async</code> <pre><code>clear_mcp_session(\n    user_id: str,\n    session_id: str,\n    server_name: str,\n    expected_session_id: str | None = None,\n) -&gt; None\n</code></pre> <p>Remove stored MCP session info for a server if present.</p> Source code in <code>src/sk_agents/mcp_discovery/redis_discovery_manager.py</code> <pre><code>async def clear_mcp_session(\n    self,\n    user_id: str,\n    session_id: str,\n    server_name: str,\n    expected_session_id: str | None = None,\n) -&gt; None:\n    \"\"\"Remove stored MCP session info for a server if present.\"\"\"\n    key = self._make_key(user_id, session_id)\n\n    lua_script = \"\"\"\n    local key = KEYS[1]\n    local server_name = ARGV[1]\n    local ttl = tonumber(ARGV[2])\n    local expected_session_id = ARGV[3]\n\n    local data = redis.call('GET', key)\n    if not data then\n        return 0 -- state missing\n    end\n\n    local obj = cjson.decode(data)\n    if not obj.discovered_servers[server_name] then\n        return -1 -- server missing\n    end\n\n    -- Only clear if expected matches or no expectation provided\n    if obj.discovered_servers[server_name].session then\n        local current = obj.discovered_servers[server_name].session.mcp_session_id\n        if expected_session_id ~= nil and expected_session_id ~= '' then\n            if current ~= expected_session_id then\n                return -2  -- session changed, skip clear\n            end\n        end\n    end\n\n    obj.discovered_servers[server_name].session = nil\n\n    local updated_data = cjson.encode(obj)\n    redis.call('SET', key, updated_data, 'EX', ttl)\n    return 1\n    \"\"\"\n\n    expected_arg = expected_session_id or \"\"\n    result = await self.redis.eval(lua_script, 1, key, server_name, self.ttl, expected_arg)\n    if result == 0:\n        logger.debug(\n            f\"clear_mcp_session: state missing for user={user_id}, session={session_id}\"\n        )\n    elif result == -1:\n        logger.debug(\n            f\"clear_mcp_session: server missing for user={user_id}, \"\n            f\"session={session_id}, server={server_name}\"\n        )\n    elif result == -2:\n        logger.debug(\n            f\"clear_mcp_session: session changed for user={user_id}, \"\n            f\"session={session_id}, server={server_name}\"\n        )\n    else:\n        logger.debug(\n            f\"Cleared MCP session for server={server_name}, \"\n            f\"user={user_id}, session={session_id}\"\n        )\n</code></pre>"},{"location":"reference/#sk_agents.mcp_plugin_registry","title":"sk_agents.mcp_plugin_registry","text":"<p>MCP Plugin Registry - Discovers and stores MCP tools at session start.</p> <p>This registry discovers MCP tools and stores them in external state. At request time, tools are loaded from state and used to instantiate McpPlugin directly in kernel_builder.</p> sk_agents.mcp_plugin_registry.McpPluginRegistry <p>Registry for MCP tools with per-session isolation.</p> <p>At session start, this registry: 1. Connects to MCP servers temporarily 2. Discovers available tools 3. Registers tools in catalog for governance/HITL 4. Serializes tool data to external storage (via McpStateManager)</p> <p>At request time: - Tools are loaded from storage via get_tools_for_session() - kernel_builder instantiates McpPlugin directly with these tools</p> <p>This ensures proper multi-tenant isolation and horizontal scalability. Tool state is stored externally (Redis/InMemory) instead of class variables.</p> Source code in <code>src/sk_agents/mcp_plugin_registry.py</code> <pre><code>class McpPluginRegistry:\n    \"\"\"\n    Registry for MCP tools with per-session isolation.\n\n    At session start, this registry:\n    1. Connects to MCP servers temporarily\n    2. Discovers available tools\n    3. Registers tools in catalog for governance/HITL\n    4. Serializes tool data to external storage (via McpStateManager)\n\n    At request time:\n    - Tools are loaded from storage via get_tools_for_session()\n    - kernel_builder instantiates McpPlugin directly with these tools\n\n    This ensures proper multi-tenant isolation and horizontal scalability.\n    Tool state is stored externally (Redis/InMemory) instead of class variables.\n    \"\"\"\n\n    @staticmethod\n    def _apply_governance_overrides(\n        base_governance: Governance, tool_name: str, overrides: dict[str, GovernanceOverride] | None\n    ) -&gt; Governance:\n        \"\"\"Apply manual governance overrides from config.\"\"\"\n        if not overrides or tool_name not in overrides:\n            return base_governance\n\n        override = overrides[tool_name]\n\n        return Governance(\n            requires_hitl=override.requires_hitl\n            if override.requires_hitl is not None\n            else base_governance.requires_hitl,\n            cost=override.cost if override.cost is not None else base_governance.cost,\n            data_sensitivity=override.data_sensitivity\n            if override.data_sensitivity is not None\n            else base_governance.data_sensitivity,\n        )\n\n    @staticmethod\n    def _create_auth_if_needed(server_config: McpServerConfig) -&gt; Oauth2PluginAuth | None:\n        \"\"\"Create auth config if server requires OAuth2.\"\"\"\n        if server_config.auth_server and server_config.scopes:\n            return Oauth2PluginAuth(\n                auth_server=server_config.auth_server, scopes=server_config.scopes\n            )\n        return None\n\n    @classmethod\n    async def discover_and_materialize(\n        cls,\n        mcp_servers: list[McpServerConfig],\n        user_id: str,\n        session_id: str,\n        discovery_manager,  # McpStateManager\n        app_config,\n    ) -&gt; None:\n        \"\"\"\n        Discover MCP tools and store in external state.\n\n        This is called once per session when first invoked.\n        Creates temporary connections to discover tools, then closes them.\n\n        Args:\n            mcp_servers: List of MCP server configurations\n            user_id: User ID for authentication\n            session_id: Session ID for scoping\n            discovery_manager: Manager for storing discovery state\n\n        Raises:\n            AuthRequiredError: If any server requires authentication that is missing\n        \"\"\"\n        from sk_agents.mcp_client import AuthRequiredError\n\n        logger.info(f\"Starting MCP discovery for session {session_id} ({len(mcp_servers)} servers)\")\n\n        # Load existing state\n        state = await discovery_manager.load_discovery(user_id, session_id)\n        if not state:\n            raise ValueError(f\"Discovery state not initialized for session: {session_id}\")\n\n        auth_errors = []  # Collect auth errors to surface to user\n\n        for server_config in mcp_servers:\n            try:\n                # Discover this server\n                plugin_data, discovered_session_id = await cls._discover_server(\n                    server_config, user_id, session_id, discovery_manager, app_config\n                )\n\n                # Preserve any existing session bucket\n                existing_entry = state.discovered_servers.get(server_config.name, {})\n                session_bucket = existing_entry.get(\"session\") or {}\n\n                # Always persist freshly discovered plugin data\n                state.discovered_servers[server_config.name] = {\n                    \"plugin_data\": plugin_data,\n                    **({\"session\": session_bucket} if session_bucket else {}),\n                }\n                await discovery_manager.update_discovery(state)\n\n                # If discovery yielded a session id, persist via state manager API\n                if discovered_session_id:\n                    try:\n                        await discovery_manager.store_mcp_session(\n                            user_id,\n                            session_id,\n                            server_config.name,\n                            discovered_session_id,\n                        )\n                        await discovery_manager.update_session_last_used(\n                            user_id, session_id, server_config.name\n                        )\n                    except Exception as err:\n                        logger.warning(\n                            f\"Failed to persist MCP session for {server_config.name}: {err}\"\n                        )\n\n            except AuthRequiredError as e:\n                # Auth error - collect and surface to user\n                logger.warning(\n                    f\"Auth required for MCP server {server_config.name} (session: {session_id})\"\n                )\n                auth_errors.append(e)\n            except Exception as e:\n                # Other errors - log and continue with remaining servers\n                # Extract underlying exception from TaskGroup if needed\n                import traceback\n\n                error_details = \"\".join(traceback.format_exception(type(e), e, e.__traceback__))\n\n                # If it's a TaskGroup exception, try to extract the underlying exception\n                underlying_error = str(e)\n                if hasattr(e, \"__cause__\") and e.__cause__:\n                    underlying_error = f\"{e} (caused by: {e.__cause__})\"\n                elif hasattr(e, \"exceptions\"):\n                    # ExceptionGroup-style\n                    underlying_error = f\"{e} (sub-exceptions: {e.exceptions})\"\n\n                logger.error(\n                    f\"Failed to discover MCP server {server_config.name} \"\n                    f\"for session {session_id}:\\n\"\n                    f\"Error: {underlying_error}\\n\"\n                    f\"Full traceback:\\n{error_details}\"\n                )\n\n                # Capture failure in state\n                state.failed_servers[server_config.name] = underlying_error\n                try:\n                    await discovery_manager.update_discovery(state)\n                except Exception as update_err:\n                    logger.error(\n                        f\"Failed to persist discovery error for {server_config.name}: {update_err}\"\n                    )\n\n                continue\n\n        # If any servers require auth, raise the first one to trigger auth challenge\n        if auth_errors:\n            logger.info(\n                f\"MCP discovery requires auth for {len(auth_errors)} server(s) \"\n                f\"(session: {session_id}): {[e.server_name for e in auth_errors]}\"\n            )\n            raise auth_errors[0]  # Raise first auth error to trigger challenge\n\n        logger.info(\n            f\"MCP discovery complete for session {session_id}. \"\n            f\"Discovered {len(state.discovered_servers)} servers\"\n        )\n\n    @classmethod\n    async def _discover_server(\n        cls,\n        server_config: McpServerConfig,\n        user_id: str,\n        session_id: str,\n        discovery_manager,\n        app_config,\n    ) -&gt; tuple[dict, str | None]:\n        \"\"\"\n        Discover tools from a single MCP server.\n\n        Returns:\n            Tuple: (Serialized plugin data, optional mcp_session_id)\n        \"\"\"\n        logger.info(f\"Discovering tools from MCP server: {server_config.name}\")\n\n        # Pre-flight auth validation using unified resolver (handles refresh/audience)\n        try:\n            await resolve_server_auth_headers(\n                server_config,\n                user_id=user_id,\n                app_config=app_config,\n            )\n            logger.info(f\"Auth verified for {server_config.name}, proceeding with discovery\")\n        except AuthRequiredError:\n            raise\n        except Exception as e:\n            logger.error(f\"Auth resolution failed for {server_config.name}: {e}\")\n            raise\n\n        # Temporary connection for discovery\n        async with AsyncExitStack() as stack:\n            stored_session_id = None\n            if discovery_manager:\n                try:\n                    stored_session_id = await discovery_manager.get_mcp_session(\n                        user_id, session_id, server_config.name\n                    )\n                except Exception:\n                    logger.debug(\"Unable to fetch stored MCP session id for discovery\")\n\n            # Create temp connection (reuse session id if available)\n            session, get_session_id = await create_mcp_session_with_retry(\n                server_config,\n                stack,\n                user_id,\n                mcp_session_id=stored_session_id,\n                on_stale_session=(\n                    lambda sid: (\n                        discovery_manager.clear_mcp_session(\n                            user_id, session_id, server_config.name, expected_session_id=sid\n                        )\n                        if discovery_manager\n                        else None\n                    )\n                ),\n            )\n\n            # List available tools\n            tools_result = await session.list_tools()\n            logger.info(f\"Found {len(tools_result.tools)} tools on {server_config.name}\")\n\n            # Create stateless McpTool objects\n            mcp_tools = []\n            for tool_info in tools_result.tools:\n                # Create stateless tool\n                mcp_tool = McpTool(\n                    tool_name=tool_info.name,\n                    description=tool_info.description,\n                    input_schema=tool_info.inputSchema,\n                    output_schema=getattr(tool_info, \"outputSchema\", None),\n                    server_config=server_config,\n                    server_name=server_config.name,\n                )\n                mcp_tools.append(mcp_tool)\n\n                # Register in catalog for governance/HITL\n                cls._register_tool_in_catalog(tool_info, server_config)\n\n            # Serialize plugin data for storage\n            plugin_data = cls._serialize_plugin_data(mcp_tools, server_config.name)\n\n            session_identifier = get_session_id() if get_session_id else None\n\n            logger.info(f\"Discovered {len(mcp_tools)} tools from {server_config.name}\")\n            # Connection auto-closes when exiting context\n\n            return plugin_data, session_identifier\n\n    @classmethod\n    def _register_tool_in_catalog(cls, tool_info: Any, server_config: McpServerConfig) -&gt; None:\n        \"\"\"Register tool in catalog for governance and HITL.\"\"\"\n        try:\n            catalog = PluginCatalogFactory().get_catalog()\n            if not catalog:\n                logger.warning(\"Plugin catalog not available, skipping catalog registration\")\n                return\n\n            # Create consistent tool_id format: mcp_{server_name}_{tool_name}\n            tool_id = f\"mcp_{server_config.name}_{tool_info.name}\"\n\n            # Map MCP annotations to governance.\n            # Newer MCP SDKs return a ToolAnnotations object without dict-like access.\n            annotations_obj = getattr(tool_info, \"annotations\", None)\n            if annotations_obj is None:\n                annotations = {}\n            elif hasattr(annotations_obj, \"model_dump\"):\n                annotations = annotations_obj.model_dump() or {}\n            elif isinstance(annotations_obj, dict):\n                annotations = annotations_obj\n            else:\n                # Best-effort fallback for unknown types\n                annotations = {}\n\n            base_governance = map_mcp_annotations_to_governance(annotations)\n            governance_with_trust = apply_trust_level_governance(\n                base_governance, server_config.trust_level, tool_info.description or \"\"\n            )\n\n            # Apply manual overrides from config\n            governance = cls._apply_governance_overrides(\n                governance_with_trust, tool_info.name, server_config.tool_governance_overrides\n            )\n\n            # Create auth config if needed\n            auth = cls._create_auth_if_needed(server_config)\n\n            # Create PluginTool for catalog\n            plugin_tool = PluginTool(\n                tool_id=tool_id,\n                name=tool_info.name,\n                description=tool_info.description,\n                governance=governance,\n                auth=auth,\n            )\n\n            # Register in catalog\n            plugin_id = f\"mcp_{server_config.name}\"\n            catalog.register_dynamic_tool(plugin_tool, plugin_id=plugin_id)\n\n            logger.debug(\n                f\"Registered tool in catalog: {tool_id} (requires_hitl={governance.requires_hitl})\"\n            )\n\n        except Exception as e:\n            logger.error(f\"Failed to register tool {tool_info.name} in catalog: {e}\")\n            # Don't fail the whole discovery if catalog registration fails\n\n    @classmethod\n    def _serialize_plugin_data(cls, tools: list[McpTool], server_name: str) -&gt; dict:\n        \"\"\"\n        Serialize plugin tools to storable format.\n\n        Args:\n            tools: List of McpTool objects\n            server_name: Name of the MCP server\n\n        Returns:\n            Dict: Serialized plugin data\n        \"\"\"\n\n        def _sanitize_server_config(server_config):\n            \"\"\"Drop secrets before persisting discovery state.\"\"\"\n            cfg = server_config.model_dump()\n\n            # Remove confidential OAuth client secret\n            cfg.pop(\"oauth_client_secret\", None)\n\n            # Strip Authorization headers to avoid token leakage\n            headers = cfg.get(\"headers\") or {}\n            cfg[\"headers\"] = {k: v for k, v in headers.items() if k.lower() != \"authorization\"}\n\n            # Drop env entries that look sensitive (best\u2011effort)\n            env = cfg.get(\"env\")\n            if isinstance(env, dict):\n                cfg[\"env\"] = {\n                    k: v\n                    for k, v in env.items()\n                    if not any(s in k.lower() for s in [\"secret\", \"token\", \"key\", \"password\"])\n                }\n\n            return cfg\n\n        tools_data = []\n        for tool in tools:\n            tools_data.append(\n                {\n                    \"tool_name\": tool.tool_name,\n                    \"description\": tool.description,\n                    \"input_schema\": tool.input_schema,\n                    \"output_schema\": tool.output_schema,\n                    \"server_name\": tool.server_name,\n                    \"server_config\": _sanitize_server_config(tool.server_config),\n                }\n            )\n        return {\"server_name\": server_name, \"tools\": tools_data}\n\n    @classmethod\n    def _deserialize_tools(cls, plugin_data: dict) -&gt; list[McpTool]:\n        \"\"\"\n        Deserialize plugin data to McpTool list.\n\n        Args:\n            plugin_data: Serialized plugin data from storage\n\n        Returns:\n            List of McpTool objects\n        \"\"\"\n        from sk_agents.tealagents.v1alpha1.config import McpServerConfig\n\n        tools = []\n        for tool_data in plugin_data[\"tools\"]:\n            server_config = McpServerConfig(**tool_data[\"server_config\"])\n            tool = McpTool(\n                tool_name=tool_data[\"tool_name\"],\n                description=tool_data[\"description\"],\n                input_schema=tool_data[\"input_schema\"],\n                output_schema=tool_data[\"output_schema\"],\n                server_config=server_config,\n                server_name=tool_data[\"server_name\"],\n            )\n            tools.append(tool)\n\n        return tools\n\n    @classmethod\n    async def get_tools_for_session(\n        cls,\n        user_id: str,\n        session_id: str,\n        discovery_manager,  # McpStateManager\n    ) -&gt; dict[str, list[McpTool]]:\n        \"\"\"\n        Load MCP tools from external storage for this session.\n\n        Args:\n            user_id: User ID\n            session_id: Session ID\n            discovery_manager: Manager for loading discovery state\n\n        Returns:\n            Dictionary mapping server_name to list of McpTool objects\n        \"\"\"\n        # Load state from external storage\n        state = await discovery_manager.load_discovery(user_id, session_id)\n        if not state or not state.discovery_completed:\n            return {}\n\n        # Deserialize tools for each server\n        server_tools = {}\n        for server_name, entry in state.discovered_servers.items():\n            plugin_blob = entry.get(\"plugin_data\") if isinstance(entry, dict) else None\n            plugin_data = plugin_blob if plugin_blob else entry  # fallback to legacy shape\n            tools = cls._deserialize_tools(plugin_data)\n            server_tools[server_name] = tools\n\n        logger.debug(f\"Loaded tools for {len(server_tools)} MCP servers for session {session_id}\")\n        return server_tools\n</code></pre> <code></code> sk_agents.mcp_plugin_registry.McpPluginRegistry.discover_and_materialize <code>async</code> <code>classmethod</code> <pre><code>discover_and_materialize(\n    mcp_servers: list[McpServerConfig],\n    user_id: str,\n    session_id: str,\n    discovery_manager,\n    app_config,\n) -&gt; None\n</code></pre> <p>Discover MCP tools and store in external state.</p> <p>This is called once per session when first invoked. Creates temporary connections to discover tools, then closes them.</p> <p>Parameters:</p> Name Type Description Default <code>mcp_servers</code> <code>list[McpServerConfig]</code> <p>List of MCP server configurations</p> required <code>user_id</code> <code>str</code> <p>User ID for authentication</p> required <code>session_id</code> <code>str</code> <p>Session ID for scoping</p> required <code>discovery_manager</code> <p>Manager for storing discovery state</p> required <p>Raises:</p> Type Description <code>AuthRequiredError</code> <p>If any server requires authentication that is missing</p> Source code in <code>src/sk_agents/mcp_plugin_registry.py</code> <pre><code>@classmethod\nasync def discover_and_materialize(\n    cls,\n    mcp_servers: list[McpServerConfig],\n    user_id: str,\n    session_id: str,\n    discovery_manager,  # McpStateManager\n    app_config,\n) -&gt; None:\n    \"\"\"\n    Discover MCP tools and store in external state.\n\n    This is called once per session when first invoked.\n    Creates temporary connections to discover tools, then closes them.\n\n    Args:\n        mcp_servers: List of MCP server configurations\n        user_id: User ID for authentication\n        session_id: Session ID for scoping\n        discovery_manager: Manager for storing discovery state\n\n    Raises:\n        AuthRequiredError: If any server requires authentication that is missing\n    \"\"\"\n    from sk_agents.mcp_client import AuthRequiredError\n\n    logger.info(f\"Starting MCP discovery for session {session_id} ({len(mcp_servers)} servers)\")\n\n    # Load existing state\n    state = await discovery_manager.load_discovery(user_id, session_id)\n    if not state:\n        raise ValueError(f\"Discovery state not initialized for session: {session_id}\")\n\n    auth_errors = []  # Collect auth errors to surface to user\n\n    for server_config in mcp_servers:\n        try:\n            # Discover this server\n            plugin_data, discovered_session_id = await cls._discover_server(\n                server_config, user_id, session_id, discovery_manager, app_config\n            )\n\n            # Preserve any existing session bucket\n            existing_entry = state.discovered_servers.get(server_config.name, {})\n            session_bucket = existing_entry.get(\"session\") or {}\n\n            # Always persist freshly discovered plugin data\n            state.discovered_servers[server_config.name] = {\n                \"plugin_data\": plugin_data,\n                **({\"session\": session_bucket} if session_bucket else {}),\n            }\n            await discovery_manager.update_discovery(state)\n\n            # If discovery yielded a session id, persist via state manager API\n            if discovered_session_id:\n                try:\n                    await discovery_manager.store_mcp_session(\n                        user_id,\n                        session_id,\n                        server_config.name,\n                        discovered_session_id,\n                    )\n                    await discovery_manager.update_session_last_used(\n                        user_id, session_id, server_config.name\n                    )\n                except Exception as err:\n                    logger.warning(\n                        f\"Failed to persist MCP session for {server_config.name}: {err}\"\n                    )\n\n        except AuthRequiredError as e:\n            # Auth error - collect and surface to user\n            logger.warning(\n                f\"Auth required for MCP server {server_config.name} (session: {session_id})\"\n            )\n            auth_errors.append(e)\n        except Exception as e:\n            # Other errors - log and continue with remaining servers\n            # Extract underlying exception from TaskGroup if needed\n            import traceback\n\n            error_details = \"\".join(traceback.format_exception(type(e), e, e.__traceback__))\n\n            # If it's a TaskGroup exception, try to extract the underlying exception\n            underlying_error = str(e)\n            if hasattr(e, \"__cause__\") and e.__cause__:\n                underlying_error = f\"{e} (caused by: {e.__cause__})\"\n            elif hasattr(e, \"exceptions\"):\n                # ExceptionGroup-style\n                underlying_error = f\"{e} (sub-exceptions: {e.exceptions})\"\n\n            logger.error(\n                f\"Failed to discover MCP server {server_config.name} \"\n                f\"for session {session_id}:\\n\"\n                f\"Error: {underlying_error}\\n\"\n                f\"Full traceback:\\n{error_details}\"\n            )\n\n            # Capture failure in state\n            state.failed_servers[server_config.name] = underlying_error\n            try:\n                await discovery_manager.update_discovery(state)\n            except Exception as update_err:\n                logger.error(\n                    f\"Failed to persist discovery error for {server_config.name}: {update_err}\"\n                )\n\n            continue\n\n    # If any servers require auth, raise the first one to trigger auth challenge\n    if auth_errors:\n        logger.info(\n            f\"MCP discovery requires auth for {len(auth_errors)} server(s) \"\n            f\"(session: {session_id}): {[e.server_name for e in auth_errors]}\"\n        )\n        raise auth_errors[0]  # Raise first auth error to trigger challenge\n\n    logger.info(\n        f\"MCP discovery complete for session {session_id}. \"\n        f\"Discovered {len(state.discovered_servers)} servers\"\n    )\n</code></pre> <code></code> sk_agents.mcp_plugin_registry.McpPluginRegistry.get_tools_for_session <code>async</code> <code>classmethod</code> <pre><code>get_tools_for_session(\n    user_id: str, session_id: str, discovery_manager\n) -&gt; dict[str, list[McpTool]]\n</code></pre> <p>Load MCP tools from external storage for this session.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>str</code> <p>User ID</p> required <code>session_id</code> <code>str</code> <p>Session ID</p> required <code>discovery_manager</code> <p>Manager for loading discovery state</p> required <p>Returns:</p> Type Description <code>dict[str, list[McpTool]]</code> <p>Dictionary mapping server_name to list of McpTool objects</p> Source code in <code>src/sk_agents/mcp_plugin_registry.py</code> <pre><code>@classmethod\nasync def get_tools_for_session(\n    cls,\n    user_id: str,\n    session_id: str,\n    discovery_manager,  # McpStateManager\n) -&gt; dict[str, list[McpTool]]:\n    \"\"\"\n    Load MCP tools from external storage for this session.\n\n    Args:\n        user_id: User ID\n        session_id: Session ID\n        discovery_manager: Manager for loading discovery state\n\n    Returns:\n        Dictionary mapping server_name to list of McpTool objects\n    \"\"\"\n    # Load state from external storage\n    state = await discovery_manager.load_discovery(user_id, session_id)\n    if not state or not state.discovery_completed:\n        return {}\n\n    # Deserialize tools for each server\n    server_tools = {}\n    for server_name, entry in state.discovered_servers.items():\n        plugin_blob = entry.get(\"plugin_data\") if isinstance(entry, dict) else None\n        plugin_data = plugin_blob if plugin_blob else entry  # fallback to legacy shape\n        tools = cls._deserialize_tools(plugin_data)\n        server_tools[server_name] = tools\n\n    logger.debug(f\"Loaded tools for {len(server_tools)} MCP servers for session {session_id}\")\n    return server_tools\n</code></pre>"},{"location":"reference/#sk_agents.persistence","title":"sk_agents.persistence","text":"sk_agents.persistence.custom sk_agents.persistence.custom.example_redis_persistence <p>Complete Redis Task Persistence Implementation</p> <p>This example demonstrates a full-featured, production-ready Redis-based task persistence implementation. It serves as a complete alternative to the default in-memory storage.</p> <p>To use this implementation, set the following environment variables:</p> <p>TA_PERSISTENCE_MODULE=src/sk_agents/persistence/custom/example_redis_persistence.py TA_PERSISTENCE_CLASS=RedisTaskPersistenceManager</p> <p>Required Redis configuration environment variables: - TA_REDIS_HOST (default: localhost) - TA_REDIS_PORT (default: 6379) - TA_REDIS_DB (default: 0) - TA_REDIS_TTL (default: 3600 seconds) - TA_REDIS_PWD (optional) - TA_REDIS_SSL (default: false)</p> sk_agents.persistence.custom.example_redis_persistence.RedisTaskPersistenceManager <p>               Bases: <code>TaskPersistenceManager</code></p> Source code in <code>src/sk_agents/persistence/custom/example_redis_persistence.py</code> <pre><code>class RedisTaskPersistenceManager(TaskPersistenceManager):\n    def __init__(self, app_config: AppConfig = None):\n        \"\"\"\n        Initialize the Redis-based task persistence manager.\n\n        Args:\n            app_config: Application configuration object. If None, creates a new one.\n        \"\"\"\n        if app_config is None:\n            app_config = AppConfig()\n\n        self.app_config = app_config\n        self._lock = threading.Lock()\n\n        # Get Redis configuration\n        redis_host = self.app_config.get(TA_REDIS_HOST.env_name) or \"localhost\"\n        redis_port = int(self.app_config.get(TA_REDIS_PORT.env_name) or 6379)\n        redis_db = int(self.app_config.get(TA_REDIS_DB.env_name) or 0)\n        redis_password = self.app_config.get(TA_REDIS_PWD.env_name)\n        redis_ssl = self.app_config.get(TA_REDIS_SSL.env_name) == \"false\"\n        self.ttl = int(self.app_config.get(TA_REDIS_TTL.env_name) or 3600)  # Default 1 hour\n\n        # Initialize Redis client\n        self.redis_client = redis.Redis(\n            host=redis_host,\n            port=redis_port,\n            db=redis_db,\n            password=redis_password,\n            ssl=redis_ssl,\n            decode_responses=True,  # Automatically decode responses to strings\n            socket_connect_timeout=5,\n            socket_timeout=5,\n            retry_on_timeout=True,\n        )\n\n        # Test connection\n        try:\n            self.redis_client.ping()\n        except redis.ConnectionError as e:\n            raise ConnectionError(f\"Failed to connect to Redis: {e}\") from e\n\n    def _get_task_key(self, task_id: str) -&gt; str:\n        \"\"\"Generate a Redis key for the given task_id.\"\"\"\n        return f\"task_persistence:task:{task_id}\"\n\n    def _get_request_index_key(self, request_id: str) -&gt; str:\n        \"\"\"Generate a Redis key for request_id index.\"\"\"\n        return f\"task_persistence:request_index:{request_id}\"\n\n    def _serialize_task(self, task: AgentTask) -&gt; str:\n        \"\"\"Serialize AgentTask to JSON string.\"\"\"\n        return task.model_dump_json()\n\n    def _deserialize_task(self, task_str: str) -&gt; AgentTask:\n        \"\"\"Deserialize JSON string to AgentTask.\"\"\"\n        task_dict = json.loads(task_str)\n        return AgentTask.model_validate(task_dict)\n\n    async def create(self, task: AgentTask) -&gt; None:\n        \"\"\"Create a new task in Redis.\"\"\"\n        try:\n            task_key = self._get_task_key(task.task_id)\n\n            # Check if task already exists\n            if self.redis_client.exists(task_key):\n                raise PersistenceCreateError(\n                    message=f\"Task with ID '{task.task_id}' already exists.\"\n                )\n\n            # Serialize and store the task\n            serialized_task = self._serialize_task(task)\n            self.redis_client.setex(task_key, self.ttl, serialized_task)\n\n            # Update request_id indexes\n            for item in task.items:\n                request_index_key = self._get_request_index_key(item.request_id)\n                self.redis_client.sadd(request_index_key, task.task_id)\n                self.redis_client.expire(request_index_key, self.ttl)\n\n        except redis.RedisError as e:\n            raise PersistenceCreateError(\n                message=f\"Failed to create task '{task.task_id}' in Redis: {e}\"\n            ) from e\n        except Exception as e:\n            raise PersistenceCreateError(\n                message=f\"Unexpected error creating task '{task.task_id}': {e}\"\n            ) from e\n\n    async def load(self, task_id: str) -&gt; AgentTask | None:\n        \"\"\"Load a task from Redis by task_id.\"\"\"\n        with self._lock:\n            try:\n                task_key = self._get_task_key(task_id)\n                task_str = self.redis_client.get(task_key)\n\n                if task_str is None:\n                    return None\n\n                return self._deserialize_task(task_str)\n\n            except redis.RedisError as e:\n                raise PersistenceLoadError(\n                    message=f\"Failed to load task '{task_id}' from Redis: {e}\"\n                ) from e\n            except (json.JSONDecodeError, ValueError) as e:\n                # If we can't deserialize the task, it's corrupted, so delete it\n                try:\n                    task_key = self._get_task_key(task_id)\n                    self.redis_client.delete(task_key)\n                except redis.RedisError:\n                    pass  # Ignore deletion errors\n                raise PersistenceLoadError(\n                    message=f\"Corrupted task data found for task_id {task_id}: {e}\"\n                ) from e\n\n    async def update(self, task: AgentTask) -&gt; None:\n        \"\"\"Update an existing task in Redis.\"\"\"\n        try:\n            task_key = self._get_task_key(task.task_id)\n\n            # Check if task exists\n            old_task_str = self.redis_client.get(task_key)\n            if old_task_str is None:\n                raise PersistenceUpdateError(\n                    f\"Task with ID '{task.task_id}' does not exist for update.\"\n                )\n\n            # Deserialize old task to clean up old request_id indexes\n            old_task = self._deserialize_task(old_task_str)\n\n            # Remove old request_id associations\n            for item in old_task.items:\n                request_index_key = self._get_request_index_key(item.request_id)\n                self.redis_client.srem(request_index_key, task.task_id)\n\n            # Update the task\n            serialized_task = self._serialize_task(task)\n            self.redis_client.setex(task_key, self.ttl, serialized_task)\n\n            # Add new request_id associations\n            for item in task.items:\n                request_index_key = self._get_request_index_key(item.request_id)\n                self.redis_client.sadd(request_index_key, task.task_id)\n                self.redis_client.expire(request_index_key, self.ttl)\n\n        except redis.RedisError as e:\n            raise PersistenceUpdateError(\n                message=f\"Failed to update task '{task.task_id}' in Redis: {e}\"\n            ) from e\n        except Exception as e:\n            raise PersistenceUpdateError(\n                message=f\"Unexpected error updating task '{task.task_id}': {e}\"\n            ) from e\n\n    async def delete(self, task_id: str) -&gt; None:\n        \"\"\"Delete a task from Redis.\"\"\"\n        try:\n            task_key = self._get_task_key(task_id)\n\n            # Get the task first to clean up request_id indexes\n            task_str = self.redis_client.get(task_key)\n            if task_str is None:\n                raise PersistenceDeleteError(\n                    message=f\"Task with ID '{task_id}' does not exist for deletion.\"\n                )\n\n            task = self._deserialize_task(task_str)\n\n            # Remove from request_id indexes\n            for item in task.items:\n                request_index_key = self._get_request_index_key(item.request_id)\n                self.redis_client.srem(request_index_key, task_id)\n\n            # Delete the task\n            self.redis_client.delete(task_key)\n\n        except redis.RedisError as e:\n            raise PersistenceDeleteError(\n                message=f\"Failed to delete task '{task_id}' from Redis: {e}\"\n            ) from e\n        except Exception as e:\n            raise PersistenceDeleteError(\n                message=f\"Unexpected error deleting task '{task_id}': {e}\"\n            ) from e\n\n    async def load_by_request_id(self, request_id: str) -&gt; AgentTask | None:\n        \"\"\"Load a task by request_id.\"\"\"\n        try:\n            request_index_key = self._get_request_index_key(request_id)\n            task_ids = self.redis_client.smembers(request_index_key)\n\n            if not task_ids:\n                return None\n\n            # If multiple tasks have the same request_id, return the first one\n            task_id = next(iter(task_ids))\n            return await self.load(task_id)\n\n        except redis.RedisError as e:\n            raise PersistenceLoadError(\n                message=f\"Failed to load task by request_id '{request_id}' from Redis: {e}\"\n            ) from e\n        except Exception as e:\n            raise PersistenceLoadError(\n                message=f\"Unexpected error loading task by request_id '{request_id}': {e}\"\n            ) from e\n\n    def health_check(self) -&gt; bool:\n        \"\"\"Check if Redis connection is healthy.\"\"\"\n        try:\n            self.redis_client.ping()\n            return True\n        except redis.RedisError:\n            return False\n\n    def clear_all_tasks(self) -&gt; int:\n        \"\"\"\n        Clear all task data (useful for testing).\n\n        Returns:\n            Number of keys deleted.\n        \"\"\"\n        try:\n            # Get all task keys\n            task_keys = self.redis_client.keys(\"task_persistence:task:*\")\n            request_index_keys = self.redis_client.keys(\"task_persistence:request_index:*\")\n\n            all_keys = task_keys + request_index_keys\n\n            if not all_keys:\n                return 0\n\n            return self.redis_client.delete(*all_keys)\n\n        except redis.RedisError as e:\n            raise RuntimeError(f\"Failed to clear all tasks from Redis: {e}\") from e\n</code></pre> <code></code> sk_agents.persistence.custom.example_redis_persistence.RedisTaskPersistenceManager.__init__ <pre><code>__init__(app_config: AppConfig = None)\n</code></pre> <p>Initialize the Redis-based task persistence manager.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>AppConfig</code> <p>Application configuration object. If None, creates a new one.</p> <code>None</code> Source code in <code>src/sk_agents/persistence/custom/example_redis_persistence.py</code> <pre><code>def __init__(self, app_config: AppConfig = None):\n    \"\"\"\n    Initialize the Redis-based task persistence manager.\n\n    Args:\n        app_config: Application configuration object. If None, creates a new one.\n    \"\"\"\n    if app_config is None:\n        app_config = AppConfig()\n\n    self.app_config = app_config\n    self._lock = threading.Lock()\n\n    # Get Redis configuration\n    redis_host = self.app_config.get(TA_REDIS_HOST.env_name) or \"localhost\"\n    redis_port = int(self.app_config.get(TA_REDIS_PORT.env_name) or 6379)\n    redis_db = int(self.app_config.get(TA_REDIS_DB.env_name) or 0)\n    redis_password = self.app_config.get(TA_REDIS_PWD.env_name)\n    redis_ssl = self.app_config.get(TA_REDIS_SSL.env_name) == \"false\"\n    self.ttl = int(self.app_config.get(TA_REDIS_TTL.env_name) or 3600)  # Default 1 hour\n\n    # Initialize Redis client\n    self.redis_client = redis.Redis(\n        host=redis_host,\n        port=redis_port,\n        db=redis_db,\n        password=redis_password,\n        ssl=redis_ssl,\n        decode_responses=True,  # Automatically decode responses to strings\n        socket_connect_timeout=5,\n        socket_timeout=5,\n        retry_on_timeout=True,\n    )\n\n    # Test connection\n    try:\n        self.redis_client.ping()\n    except redis.ConnectionError as e:\n        raise ConnectionError(f\"Failed to connect to Redis: {e}\") from e\n</code></pre> <code></code> sk_agents.persistence.custom.example_redis_persistence.RedisTaskPersistenceManager.create <code>async</code> <pre><code>create(task: AgentTask) -&gt; None\n</code></pre> <p>Create a new task in Redis.</p> Source code in <code>src/sk_agents/persistence/custom/example_redis_persistence.py</code> <pre><code>async def create(self, task: AgentTask) -&gt; None:\n    \"\"\"Create a new task in Redis.\"\"\"\n    try:\n        task_key = self._get_task_key(task.task_id)\n\n        # Check if task already exists\n        if self.redis_client.exists(task_key):\n            raise PersistenceCreateError(\n                message=f\"Task with ID '{task.task_id}' already exists.\"\n            )\n\n        # Serialize and store the task\n        serialized_task = self._serialize_task(task)\n        self.redis_client.setex(task_key, self.ttl, serialized_task)\n\n        # Update request_id indexes\n        for item in task.items:\n            request_index_key = self._get_request_index_key(item.request_id)\n            self.redis_client.sadd(request_index_key, task.task_id)\n            self.redis_client.expire(request_index_key, self.ttl)\n\n    except redis.RedisError as e:\n        raise PersistenceCreateError(\n            message=f\"Failed to create task '{task.task_id}' in Redis: {e}\"\n        ) from e\n    except Exception as e:\n        raise PersistenceCreateError(\n            message=f\"Unexpected error creating task '{task.task_id}': {e}\"\n        ) from e\n</code></pre> <code></code> sk_agents.persistence.custom.example_redis_persistence.RedisTaskPersistenceManager.load <code>async</code> <pre><code>load(task_id: str) -&gt; AgentTask | None\n</code></pre> <p>Load a task from Redis by task_id.</p> Source code in <code>src/sk_agents/persistence/custom/example_redis_persistence.py</code> <pre><code>async def load(self, task_id: str) -&gt; AgentTask | None:\n    \"\"\"Load a task from Redis by task_id.\"\"\"\n    with self._lock:\n        try:\n            task_key = self._get_task_key(task_id)\n            task_str = self.redis_client.get(task_key)\n\n            if task_str is None:\n                return None\n\n            return self._deserialize_task(task_str)\n\n        except redis.RedisError as e:\n            raise PersistenceLoadError(\n                message=f\"Failed to load task '{task_id}' from Redis: {e}\"\n            ) from e\n        except (json.JSONDecodeError, ValueError) as e:\n            # If we can't deserialize the task, it's corrupted, so delete it\n            try:\n                task_key = self._get_task_key(task_id)\n                self.redis_client.delete(task_key)\n            except redis.RedisError:\n                pass  # Ignore deletion errors\n            raise PersistenceLoadError(\n                message=f\"Corrupted task data found for task_id {task_id}: {e}\"\n            ) from e\n</code></pre> <code></code> sk_agents.persistence.custom.example_redis_persistence.RedisTaskPersistenceManager.update <code>async</code> <pre><code>update(task: AgentTask) -&gt; None\n</code></pre> <p>Update an existing task in Redis.</p> Source code in <code>src/sk_agents/persistence/custom/example_redis_persistence.py</code> <pre><code>async def update(self, task: AgentTask) -&gt; None:\n    \"\"\"Update an existing task in Redis.\"\"\"\n    try:\n        task_key = self._get_task_key(task.task_id)\n\n        # Check if task exists\n        old_task_str = self.redis_client.get(task_key)\n        if old_task_str is None:\n            raise PersistenceUpdateError(\n                f\"Task with ID '{task.task_id}' does not exist for update.\"\n            )\n\n        # Deserialize old task to clean up old request_id indexes\n        old_task = self._deserialize_task(old_task_str)\n\n        # Remove old request_id associations\n        for item in old_task.items:\n            request_index_key = self._get_request_index_key(item.request_id)\n            self.redis_client.srem(request_index_key, task.task_id)\n\n        # Update the task\n        serialized_task = self._serialize_task(task)\n        self.redis_client.setex(task_key, self.ttl, serialized_task)\n\n        # Add new request_id associations\n        for item in task.items:\n            request_index_key = self._get_request_index_key(item.request_id)\n            self.redis_client.sadd(request_index_key, task.task_id)\n            self.redis_client.expire(request_index_key, self.ttl)\n\n    except redis.RedisError as e:\n        raise PersistenceUpdateError(\n            message=f\"Failed to update task '{task.task_id}' in Redis: {e}\"\n        ) from e\n    except Exception as e:\n        raise PersistenceUpdateError(\n            message=f\"Unexpected error updating task '{task.task_id}': {e}\"\n        ) from e\n</code></pre> <code></code> sk_agents.persistence.custom.example_redis_persistence.RedisTaskPersistenceManager.delete <code>async</code> <pre><code>delete(task_id: str) -&gt; None\n</code></pre> <p>Delete a task from Redis.</p> Source code in <code>src/sk_agents/persistence/custom/example_redis_persistence.py</code> <pre><code>async def delete(self, task_id: str) -&gt; None:\n    \"\"\"Delete a task from Redis.\"\"\"\n    try:\n        task_key = self._get_task_key(task_id)\n\n        # Get the task first to clean up request_id indexes\n        task_str = self.redis_client.get(task_key)\n        if task_str is None:\n            raise PersistenceDeleteError(\n                message=f\"Task with ID '{task_id}' does not exist for deletion.\"\n            )\n\n        task = self._deserialize_task(task_str)\n\n        # Remove from request_id indexes\n        for item in task.items:\n            request_index_key = self._get_request_index_key(item.request_id)\n            self.redis_client.srem(request_index_key, task_id)\n\n        # Delete the task\n        self.redis_client.delete(task_key)\n\n    except redis.RedisError as e:\n        raise PersistenceDeleteError(\n            message=f\"Failed to delete task '{task_id}' from Redis: {e}\"\n        ) from e\n    except Exception as e:\n        raise PersistenceDeleteError(\n            message=f\"Unexpected error deleting task '{task_id}': {e}\"\n        ) from e\n</code></pre> <code></code> sk_agents.persistence.custom.example_redis_persistence.RedisTaskPersistenceManager.load_by_request_id <code>async</code> <pre><code>load_by_request_id(request_id: str) -&gt; AgentTask | None\n</code></pre> <p>Load a task by request_id.</p> Source code in <code>src/sk_agents/persistence/custom/example_redis_persistence.py</code> <pre><code>async def load_by_request_id(self, request_id: str) -&gt; AgentTask | None:\n    \"\"\"Load a task by request_id.\"\"\"\n    try:\n        request_index_key = self._get_request_index_key(request_id)\n        task_ids = self.redis_client.smembers(request_index_key)\n\n        if not task_ids:\n            return None\n\n        # If multiple tasks have the same request_id, return the first one\n        task_id = next(iter(task_ids))\n        return await self.load(task_id)\n\n    except redis.RedisError as e:\n        raise PersistenceLoadError(\n            message=f\"Failed to load task by request_id '{request_id}' from Redis: {e}\"\n        ) from e\n    except Exception as e:\n        raise PersistenceLoadError(\n            message=f\"Unexpected error loading task by request_id '{request_id}': {e}\"\n        ) from e\n</code></pre> <code></code> sk_agents.persistence.custom.example_redis_persistence.RedisTaskPersistenceManager.health_check <pre><code>health_check() -&gt; bool\n</code></pre> <p>Check if Redis connection is healthy.</p> Source code in <code>src/sk_agents/persistence/custom/example_redis_persistence.py</code> <pre><code>def health_check(self) -&gt; bool:\n    \"\"\"Check if Redis connection is healthy.\"\"\"\n    try:\n        self.redis_client.ping()\n        return True\n    except redis.RedisError:\n        return False\n</code></pre> <code></code> sk_agents.persistence.custom.example_redis_persistence.RedisTaskPersistenceManager.clear_all_tasks <pre><code>clear_all_tasks() -&gt; int\n</code></pre> <p>Clear all task data (useful for testing).</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of keys deleted.</p> Source code in <code>src/sk_agents/persistence/custom/example_redis_persistence.py</code> <pre><code>def clear_all_tasks(self) -&gt; int:\n    \"\"\"\n    Clear all task data (useful for testing).\n\n    Returns:\n        Number of keys deleted.\n    \"\"\"\n    try:\n        # Get all task keys\n        task_keys = self.redis_client.keys(\"task_persistence:task:*\")\n        request_index_keys = self.redis_client.keys(\"task_persistence:request_index:*\")\n\n        all_keys = task_keys + request_index_keys\n\n        if not all_keys:\n            return 0\n\n        return self.redis_client.delete(*all_keys)\n\n    except redis.RedisError as e:\n        raise RuntimeError(f\"Failed to clear all tasks from Redis: {e}\") from e\n</code></pre> <code></code> sk_agents.persistence.persistence_factory <code></code> sk_agents.persistence.persistence_factory.PersistenceFactory Source code in <code>src/sk_agents/persistence/persistence_factory.py</code> <pre><code>class PersistenceFactory(metaclass=Singleton):\n    def __init__(self, app_config: AppConfig):\n        self.app_config = app_config\n\n        # Try to load custom module, fallback to default if not configured\n        module_name, class_name = self._get_custom_persistence_config()\n        if module_name and class_name:\n            try:\n                self.module = ModuleLoader.load_module(module_name)\n            except Exception as e:\n                raise ImportError(f\"Failed to load module '{module_name}': {e}\") from e\n\n            self.class_name = class_name\n            self._validate_custom_class()\n        else:\n            self.module = None\n            self.class_name = None\n\n    def get_persistence_manager(self) -&gt; TaskPersistenceManager:\n        if self.module and self.class_name:\n            # Use custom implementation\n            custom_class = getattr(self.module, self.class_name)\n            try:\n                return custom_class(app_config=self.app_config)\n            except TypeError:\n                # Fallback if app_config not accepted\n                return custom_class()\n        else:\n            # Use default implementation\n            return InMemoryPersistenceManager()\n\n    def _get_custom_persistence_config(self) -&gt; tuple[str | None, str | None]:\n        \"\"\"Get custom persistence configuration, returning None values if using defaults.\"\"\"\n        module_name = self.app_config.get(TA_PERSISTENCE_MODULE.env_name)\n        class_name = self.app_config.get(TA_PERSISTENCE_CLASS.env_name)\n\n        # Check if we're using the default values (which means no custom config)\n        if (\n            module_name == TA_PERSISTENCE_MODULE.default_value\n            and class_name == TA_PERSISTENCE_CLASS.default_value\n        ):\n            return None, None\n\n        return module_name, class_name\n\n    def _validate_custom_class(self):\n        \"\"\"Validate that the custom class is a proper TaskPersistenceManager subclass.\"\"\"\n        if not hasattr(self.module, self.class_name):\n            module_name = getattr(self.module, \"__name__\", \"unknown module\")\n            raise ValueError(\n                f\"Custom Task Persistence Manager class: {self.class_name} \"\n                f\"Not found in module: {module_name}\"\n            )\n\n        custom_class = getattr(self.module, self.class_name)\n        if not issubclass(custom_class, TaskPersistenceManager):\n            raise TypeError(\n                f\"Class '{self.class_name}' is not a subclass of TaskPersistenceManager.\"\n            )\n</code></pre>"},{"location":"reference/#sk_agents.plugin_catalog","title":"sk_agents.plugin_catalog","text":"sk_agents.plugin_catalog.local_plugin_catalog sk_agents.plugin_catalog.local_plugin_catalog.FileBasedPluginCatalog <p>               Bases: <code>PluginCatalog</code></p> <p>File-based implementation that loads plugins from JSON files.</p> Source code in <code>src/sk_agents/plugin_catalog/local_plugin_catalog.py</code> <pre><code>class FileBasedPluginCatalog(PluginCatalog):\n    \"\"\"File-based implementation that loads plugins from JSON files.\"\"\"\n\n    def __init__(self, app_config: AppConfig):\n        self.app_config = app_config\n        self.catalog_path = Path(self.app_config.get(TA_PLUGIN_CATALOG_FILE.env_name))\n        self._plugins: dict[str, Plugin] = {}\n        self._tools: dict[str, PluginTool] = {}\n        self._load_plugins()\n\n    def get_plugin(self, plugin_id: str) -&gt; Plugin | None:\n        \"\"\"Get a plugin by its ID.\"\"\"\n        return self._plugins.get(plugin_id)\n\n    def get_tool(self, tool_id: str) -&gt; PluginTool | None:\n        \"\"\"Get a tool by its ID.\"\"\"\n        return self._tools.get(tool_id)\n\n    def register_dynamic_plugin(self, plugin: Plugin) -&gt; None:\n        \"\"\"Register a plugin discovered at runtime (e.g., from MCP servers).\"\"\"\n        self._plugins[plugin.plugin_id] = plugin\n\n        # Index all tools from this plugin for quick lookup\n        for tool in plugin.tools:\n            self._tools[tool.tool_id] = tool\n\n    def register_dynamic_tool(self, tool: PluginTool, plugin_id: str = None) -&gt; None:\n        \"\"\"Register a tool discovered at runtime.\"\"\"\n        # Add tool to tools index\n        self._tools[tool.tool_id] = tool\n\n        # If plugin_id is provided, ensure the plugin exists or create it\n        if plugin_id:\n            if plugin_id not in self._plugins:\n                # Create a minimal plugin for this tool\n                from sk_agents.plugin_catalog.models import McpPluginType\n\n                plugin = Plugin(\n                    plugin_id=plugin_id,\n                    name=f\"Dynamic Plugin: {plugin_id}\",\n                    description=\"Dynamically created plugin for runtime tools\",\n                    version=\"1.0.0\",\n                    owner=\"dynamic-registration\",\n                    plugin_type=McpPluginType(),\n                    tools=[tool],\n                )\n                self._plugins[plugin_id] = plugin\n            else:\n                # Add tool to existing plugin\n                existing_plugin = self._plugins[plugin_id]\n                if tool not in existing_plugin.tools:\n                    existing_plugin.tools.append(tool)\n\n    def unregister_dynamic_plugin(self, plugin_id: str) -&gt; bool:\n        \"\"\"Unregister a dynamically registered plugin.\"\"\"\n        if plugin_id in self._plugins:\n            plugin = self._plugins[plugin_id]\n\n            # Remove all tools from this plugin\n            for tool in plugin.tools:\n                if tool.tool_id in self._tools:\n                    del self._tools[tool.tool_id]\n\n            # Remove the plugin\n            del self._plugins[plugin_id]\n            return True\n        return False\n\n    def _load_plugins(self) -&gt; None:\n        \"\"\"Load plugins from a single JSON file.\"\"\"\n        if not self.catalog_path.exists():\n            return\n\n        try:\n            with open(self.catalog_path) as local_plugin_json:\n                catalog_data = json.load(local_plugin_json)\n\n            # Validate and convert to PluginCatalogDefinition\n            try:\n                catalog_definition = PluginCatalogDefinition.model_validate(catalog_data)\n            except Exception as validation_error:\n                raise PluginCatalogDefinitionException(\n                    message=\"Plugin catalog definition validation failed\"\n                ) from validation_error\n            # Process the validated plugins\n            for plugin_data in catalog_definition.plugins:\n                plugin = plugin_data\n                self._plugins[plugin.plugin_id] = plugin\n\n                # Index tools for quick lookup\n                for tool in plugin.tools:\n                    self._tools[tool.tool_id] = tool\n\n        except PluginCatalogDefinitionException:\n            # Re-raise our custom exception\n            raise\n        except Exception as e:\n            raise PluginFileReadException(\n                message=\"\"\"\n                Catalog encountered an error\n                when attempting to read file\n                \"\"\"\n            ) from e\n</code></pre> <code></code> sk_agents.plugin_catalog.local_plugin_catalog.FileBasedPluginCatalog.get_plugin <pre><code>get_plugin(plugin_id: str) -&gt; Plugin | None\n</code></pre> <p>Get a plugin by its ID.</p> Source code in <code>src/sk_agents/plugin_catalog/local_plugin_catalog.py</code> <pre><code>def get_plugin(self, plugin_id: str) -&gt; Plugin | None:\n    \"\"\"Get a plugin by its ID.\"\"\"\n    return self._plugins.get(plugin_id)\n</code></pre> <code></code> sk_agents.plugin_catalog.local_plugin_catalog.FileBasedPluginCatalog.get_tool <pre><code>get_tool(tool_id: str) -&gt; PluginTool | None\n</code></pre> <p>Get a tool by its ID.</p> Source code in <code>src/sk_agents/plugin_catalog/local_plugin_catalog.py</code> <pre><code>def get_tool(self, tool_id: str) -&gt; PluginTool | None:\n    \"\"\"Get a tool by its ID.\"\"\"\n    return self._tools.get(tool_id)\n</code></pre> <code></code> sk_agents.plugin_catalog.local_plugin_catalog.FileBasedPluginCatalog.register_dynamic_plugin <pre><code>register_dynamic_plugin(plugin: Plugin) -&gt; None\n</code></pre> <p>Register a plugin discovered at runtime (e.g., from MCP servers).</p> Source code in <code>src/sk_agents/plugin_catalog/local_plugin_catalog.py</code> <pre><code>def register_dynamic_plugin(self, plugin: Plugin) -&gt; None:\n    \"\"\"Register a plugin discovered at runtime (e.g., from MCP servers).\"\"\"\n    self._plugins[plugin.plugin_id] = plugin\n\n    # Index all tools from this plugin for quick lookup\n    for tool in plugin.tools:\n        self._tools[tool.tool_id] = tool\n</code></pre> <code></code> sk_agents.plugin_catalog.local_plugin_catalog.FileBasedPluginCatalog.register_dynamic_tool <pre><code>register_dynamic_tool(\n    tool: PluginTool, plugin_id: str = None\n) -&gt; None\n</code></pre> <p>Register a tool discovered at runtime.</p> Source code in <code>src/sk_agents/plugin_catalog/local_plugin_catalog.py</code> <pre><code>def register_dynamic_tool(self, tool: PluginTool, plugin_id: str = None) -&gt; None:\n    \"\"\"Register a tool discovered at runtime.\"\"\"\n    # Add tool to tools index\n    self._tools[tool.tool_id] = tool\n\n    # If plugin_id is provided, ensure the plugin exists or create it\n    if plugin_id:\n        if plugin_id not in self._plugins:\n            # Create a minimal plugin for this tool\n            from sk_agents.plugin_catalog.models import McpPluginType\n\n            plugin = Plugin(\n                plugin_id=plugin_id,\n                name=f\"Dynamic Plugin: {plugin_id}\",\n                description=\"Dynamically created plugin for runtime tools\",\n                version=\"1.0.0\",\n                owner=\"dynamic-registration\",\n                plugin_type=McpPluginType(),\n                tools=[tool],\n            )\n            self._plugins[plugin_id] = plugin\n        else:\n            # Add tool to existing plugin\n            existing_plugin = self._plugins[plugin_id]\n            if tool not in existing_plugin.tools:\n                existing_plugin.tools.append(tool)\n</code></pre> <code></code> sk_agents.plugin_catalog.local_plugin_catalog.FileBasedPluginCatalog.unregister_dynamic_plugin <pre><code>unregister_dynamic_plugin(plugin_id: str) -&gt; bool\n</code></pre> <p>Unregister a dynamically registered plugin.</p> Source code in <code>src/sk_agents/plugin_catalog/local_plugin_catalog.py</code> <pre><code>def unregister_dynamic_plugin(self, plugin_id: str) -&gt; bool:\n    \"\"\"Unregister a dynamically registered plugin.\"\"\"\n    if plugin_id in self._plugins:\n        plugin = self._plugins[plugin_id]\n\n        # Remove all tools from this plugin\n        for tool in plugin.tools:\n            if tool.tool_id in self._tools:\n                del self._tools[tool.tool_id]\n\n        # Remove the plugin\n        del self._plugins[plugin_id]\n        return True\n    return False\n</code></pre> <code></code> sk_agents.plugin_catalog.models <code></code> sk_agents.plugin_catalog.models.GovernanceOverride <p>               Bases: <code>BaseModel</code></p> <p>Optional governance overrides for MCP tools.</p> <p>Only specified fields will override auto-inferred values.</p> Source code in <code>src/sk_agents/plugin_catalog/models.py</code> <pre><code>class GovernanceOverride(BaseModel):\n    \"\"\"Optional governance overrides for MCP tools.\n\n    Only specified fields will override auto-inferred values.\n    \"\"\"\n\n    requires_hitl: bool | None = None\n    cost: Literal[\"low\", \"medium\", \"high\"] | None = None\n    data_sensitivity: Literal[\"public\", \"proprietary\", \"confidential\", \"sensitive\"] | None = None\n</code></pre> <code></code> sk_agents.plugin_catalog.plugin_catalog <code></code> sk_agents.plugin_catalog.plugin_catalog.PluginCatalog <p>               Bases: <code>ABC</code></p> Source code in <code>src/sk_agents/plugin_catalog/plugin_catalog.py</code> <pre><code>class PluginCatalog(ABC):\n    @abstractmethod\n    def get_plugin(self, plugin_id: str) -&gt; Plugin | None: ...\n\n    @abstractmethod\n    def get_tool(self, tool_id: str) -&gt; PluginTool | None: ...\n\n    # Dynamic registration methods for MCP and other runtime-discovered tools\n    def register_dynamic_plugin(self, plugin: Plugin) -&gt; None:\n        \"\"\"Register a plugin discovered at runtime (e.g., from MCP servers).\"\"\"\n        # Default no-op implementation; subclasses may override\n        _ = plugin\n\n    def register_dynamic_tool(self, tool: PluginTool, plugin_id: str | None = None) -&gt; None:\n        \"\"\"Register a tool discovered at runtime.\"\"\"\n        # Default no-op implementation; subclasses may override\n        _ = tool, plugin_id\n\n    def unregister_dynamic_plugin(self, plugin_id: str) -&gt; bool:\n        \"\"\"Unregister a dynamically registered plugin.\"\"\"\n        return False  # Default implementation does nothing\n</code></pre> <code></code> sk_agents.plugin_catalog.plugin_catalog.PluginCatalog.register_dynamic_plugin <pre><code>register_dynamic_plugin(plugin: Plugin) -&gt; None\n</code></pre> <p>Register a plugin discovered at runtime (e.g., from MCP servers).</p> Source code in <code>src/sk_agents/plugin_catalog/plugin_catalog.py</code> <pre><code>def register_dynamic_plugin(self, plugin: Plugin) -&gt; None:\n    \"\"\"Register a plugin discovered at runtime (e.g., from MCP servers).\"\"\"\n    # Default no-op implementation; subclasses may override\n    _ = plugin\n</code></pre> <code></code> sk_agents.plugin_catalog.plugin_catalog.PluginCatalog.register_dynamic_tool <pre><code>register_dynamic_tool(\n    tool: PluginTool, plugin_id: str | None = None\n) -&gt; None\n</code></pre> <p>Register a tool discovered at runtime.</p> Source code in <code>src/sk_agents/plugin_catalog/plugin_catalog.py</code> <pre><code>def register_dynamic_tool(self, tool: PluginTool, plugin_id: str | None = None) -&gt; None:\n    \"\"\"Register a tool discovered at runtime.\"\"\"\n    # Default no-op implementation; subclasses may override\n    _ = tool, plugin_id\n</code></pre> <code></code> sk_agents.plugin_catalog.plugin_catalog.PluginCatalog.unregister_dynamic_plugin <pre><code>unregister_dynamic_plugin(plugin_id: str) -&gt; bool\n</code></pre> <p>Unregister a dynamically registered plugin.</p> Source code in <code>src/sk_agents/plugin_catalog/plugin_catalog.py</code> <pre><code>def unregister_dynamic_plugin(self, plugin_id: str) -&gt; bool:\n    \"\"\"Unregister a dynamically registered plugin.\"\"\"\n    return False  # Default implementation does nothing\n</code></pre> <code></code> sk_agents.plugin_catalog.plugin_catalog_factory <code></code> sk_agents.plugin_catalog.plugin_catalog_factory.PluginCatalogFactory <p>Singleton factory for creating PluginCatalog instances based on environment variables.</p> Source code in <code>src/sk_agents/plugin_catalog/plugin_catalog_factory.py</code> <pre><code>class PluginCatalogFactory(metaclass=Singleton):\n    \"\"\"\n    Singleton factory for creating PluginCatalog\n    instances based on environment variables.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n        AppConfig.add_configs(configs)\n        app_config = AppConfig()\n        self.app_config = app_config\n        self._catalog_instance: PluginCatalog | None = None\n\n    def get_catalog(self) -&gt; PluginCatalog:\n        \"\"\"\n        Get the plugin catalog instance,\n        creating it if it doesn't exist.\n        \"\"\"\n        if self._catalog_instance is None:\n            self._catalog_instance = self._create_catalog()\n        return self._catalog_instance\n\n    def _create_catalog(self) -&gt; PluginCatalog:\n        \"\"\"\n        Create a new plugin catalog instance\n        based on environment variables.\n        \"\"\"\n        module_name = self.app_config.get(TA_PLUGIN_CATALOG_MODULE.env_name)\n        class_name = self.app_config.get(TA_PLUGIN_CATALOG_CLASS.env_name)\n\n        if not module_name or not class_name:\n            raise ValueError(\n                \"Both TA_PLUGIN_CATALOG_MODULE and TA_PLUGIN_CATALOG_CLASS \"\n                \"environment variables must be set\"\n            )\n\n        try:\n            # Dynamically import the module\n            module = ModuleLoader.load_module(module_name)\n\n            # Get the class from the module\n            catalog_class: type[PluginCatalog] = getattr(module, class_name)\n\n            # Verify it's a subclass of PluginCatalog\n            if not issubclass(catalog_class, PluginCatalog):\n                raise TypeError(\n                    f\"Class {class_name} in module {module_name} must inherit from PluginCatalog\"\n                )\n\n            # Instantiate and return the catalog\n            return catalog_class(self.app_config)\n\n        except ImportError as e:\n            raise ImportError(f\"Failed to import module '{module_name}': {e}\") from e\n        except AttributeError as e:\n            raise AttributeError(\n                f\"Class '{class_name}' not found in module '{module_name}': {e}\"\n            ) from e\n</code></pre> <code></code> sk_agents.plugin_catalog.plugin_catalog_factory.PluginCatalogFactory.get_catalog <pre><code>get_catalog() -&gt; PluginCatalog\n</code></pre> <p>Get the plugin catalog instance, creating it if it doesn't exist.</p> Source code in <code>src/sk_agents/plugin_catalog/plugin_catalog_factory.py</code> <pre><code>def get_catalog(self) -&gt; PluginCatalog:\n    \"\"\"\n    Get the plugin catalog instance,\n    creating it if it doesn't exist.\n    \"\"\"\n    if self._catalog_instance is None:\n        self._catalog_instance = self._create_catalog()\n    return self._catalog_instance\n</code></pre>"},{"location":"reference/#sk_agents.routes","title":"sk_agents.routes","text":"sk_agents.routes.Routes Source code in <code>src/sk_agents/routes.py</code> <pre><code>class Routes:\n    @staticmethod\n    def get_url(name: str, version: str, app_config: AppConfig) -&gt; str:\n        base_url = app_config.get(TA_AGENT_BASE_URL.env_name)\n        if not base_url:\n            logger.exception(\"Base URL is not provided in the app config.\")\n            raise ValueError(\"Base URL is not provided in the app config.\")\n        return f\"{base_url}/{name}/{version}/a2a\"\n\n    @staticmethod\n    def get_provider(app_config: AppConfig) -&gt; AgentProvider:\n        return AgentProvider(\n            organization=app_config.get(TA_PROVIDER_ORG.env_name),\n            url=app_config.get(TA_PROVIDER_URL.env_name),\n        )\n\n    @staticmethod\n    def get_agent_card(config: BaseConfig, app_config: AppConfig) -&gt; AgentCard:\n        if config.metadata is None:\n            logger.exception(\"Agent card metadata is not provided in the config.\")\n            raise ValueError(\"Agent card metadata is not provided in the config.\")\n\n        metadata = config.metadata\n        skills = [\n            AgentSkill(\n                id=skill.id,\n                name=skill.name,\n                description=skill.description,\n                tags=skill.tags,\n                examples=skill.examples,\n                inputModes=skill.input_modes,\n                outputModes=skill.output_modes,\n            )\n            for skill in metadata.skills\n        ]\n        return AgentCard(\n            name=config.name,\n            version=str(config.version),\n            description=metadata.description,\n            url=Routes.get_url(config.name, config.version, app_config),\n            provider=Routes.get_provider(app_config),\n            documentationUrl=config.metadata.documentation_url,\n            capabilities=AgentCapabilities(\n                streaming=True, pushNotifications=False, stateTransitionHistory=True\n            ),\n            defaultInputModes=[\"text\"],\n            defaultOutputModes=[\"text\"],\n            skills=skills,\n        )\n\n    @staticmethod\n    def _create_chat_completions_builder(app_config: AppConfig):\n        return ChatCompletionBuilder(app_config)\n\n    @staticmethod\n    def _create_remote_plugin_loader(app_config: AppConfig):\n        remote_plugin_catalog = RemotePluginCatalog(app_config)\n        return RemotePluginLoader(remote_plugin_catalog)\n\n    @staticmethod\n    def _create_kernel_builder(app_config: AppConfig, authorization: str):\n        chat_completions = Routes._create_chat_completions_builder(app_config)\n        remote_plugin_loader = Routes._create_remote_plugin_loader(app_config)\n        kernel_builder = KernelBuilder(\n            chat_completions, remote_plugin_loader, app_config, authorization\n        )\n        return kernel_builder\n\n    @staticmethod\n    def _create_agent_builder(app_config: AppConfig, authorization: str):\n        kernel_builder = Routes._create_kernel_builder(app_config, authorization)\n        agent_builder = AgentBuilder(kernel_builder, authorization)\n        return agent_builder\n\n    @staticmethod\n    def get_request_handler(\n        config: BaseConfig,\n        app_config: AppConfig,\n        chat_completion_builder: ChatCompletionBuilder,\n        state_manager: StateManager,\n        task_store: TaskStore,\n    ) -&gt; DefaultRequestHandler:\n        return DefaultRequestHandler(\n            agent_executor=A2AAgentExecutor(\n                config, app_config, chat_completion_builder, state_manager\n            ),\n            task_store=task_store,\n        )\n\n    @staticmethod\n    def get_task_handler(\n        config: BaseConfig,\n        app_config: AppConfig,\n        authorization: str,\n        state_manager: TaskPersistenceManager,\n        mcp_discovery_manager=None,  # McpStateManager - Optional\n    ) -&gt; TealAgentsV1Alpha1Handler:\n        agent_builder = Routes._create_agent_builder(app_config, authorization)\n        return TealAgentsV1Alpha1Handler(\n            config, app_config, agent_builder, state_manager, mcp_discovery_manager\n        )\n\n    @staticmethod\n    def get_a2a_routes(\n        name: str,\n        version: str,\n        description: str,\n        config: BaseConfig,\n        app_config: AppConfig,\n        chat_completion_builder: ChatCompletionBuilder,\n        task_store: TaskStore,\n        state_manager: StateManager,\n    ) -&gt; APIRouter:\n        \"\"\"\n        DEPRECATION NOTICE: A2A (Agent-to-Agent) routes are being deprecated\n        as part of the framework migration evaluation. This method is maintained for\n        backward compatibility only. New development should avoid using A2A functionality.\n        \"\"\"\n        a2a_app = A2AStarletteApplication(\n            agent_card=Routes.get_agent_card(config, app_config),\n            http_handler=Routes.get_request_handler(\n                config, app_config, chat_completion_builder, state_manager, task_store\n            ),\n        )\n        a2a_router = APIRouter()\n\n        @a2a_router.post(\"\")\n        @docstring_parameter(description)\n        async def handle_a2a(request: Request):\n            \"\"\"\n            {0}\n\n            Agent-to-Agent Invocation\n            \"\"\"\n            return await a2a_app._handle_requests(request)\n\n        @a2a_router.get(\"/.well-known/agent.json\")\n        @docstring_parameter(f\"{name}:{version} - {description}\")\n        async def handle_get_agent_card(request: Request):\n            \"\"\"\n            Retrieve agent card for {0}\n            \"\"\"\n            return await a2a_app._handle_get_agent_card(request)\n\n        return a2a_router\n\n    @staticmethod\n    def get_rest_routes(\n        name: str,\n        version: str,\n        description: str,\n        root_handler_name: str,\n        config: BaseConfig,\n        app_config: AppConfig,\n        input_class: type,\n        output_class: type,\n    ) -&gt; APIRouter:\n        router = APIRouter()\n\n        @router.post(\"\")\n        @docstring_parameter(description)\n        async def invoke(inputs: input_class, request: Request) -&gt; InvokeResponse[output_class]:  # type: ignore\n            \"\"\"\n            {0}\n            \"\"\"\n            st = get_telemetry()\n            context = extract(request.headers)\n\n            authorization = request.headers.get(\"authorization\", None)\n            with (\n                st.tracer.start_as_current_span(\n                    f\"{name}-{version}-invoke\",\n                    context=context,\n                )\n                if st.telemetry_enabled()\n                else nullcontext()\n            ):\n                match root_handler_name:\n                    case \"skagents\":\n                        handler: BaseHandler = skagents_handle(config, app_config, authorization)\n                    case _:\n                        raise ValueError(f\"Unknown apiVersion: {config.apiVersion}\")\n\n                inv_inputs = inputs.__dict__\n                output = await handler.invoke(inputs=inv_inputs)\n                return output\n\n        @router.post(\"/sse\")\n        @docstring_parameter(description)\n        async def invoke_sse(inputs: input_class, request: Request) -&gt; StreamingResponse:\n            \"\"\"\n            {0}\n            Initiate SSE call\n            \"\"\"\n            st = get_telemetry()\n            context = extract(request.headers)\n            authorization = request.headers.get(\"authorization\", None)\n            inv_inputs = inputs.__dict__\n\n            async def event_generator():\n                with (\n                    st.tracer.start_as_current_span(\n                        f\"{config.service_name}-{str(config.version)}-invoke_sse\",\n                        context=context,\n                    )\n                    if st.telemetry_enabled()\n                    else nullcontext()\n                ):\n                    match root_handler_name:\n                        case \"skagents\":\n                            handler: BaseHandler = skagents_handle(\n                                config, app_config, authorization\n                            )\n                            # noinspection PyTypeChecker\n                            async for content in handler.invoke_stream(inputs=inv_inputs):\n                                yield get_sse_event_for_response(content)\n                        case _:\n                            logger.exception(\n                                \"Unknown apiVersion: %s\", config.apiVersion, exc_info=True\n                            )\n                            raise ValueError(f\"Unknown apiVersion: {config.apiVersion}\")\n\n            return StreamingResponse(event_generator(), media_type=\"text/event-stream\")\n\n        return router\n\n    @staticmethod\n    def get_websocket_routes(\n        name: str,\n        version: str,\n        root_handler_name: str,\n        config: BaseConfig,\n        app_config: AppConfig,\n        input_class: type,\n    ) -&gt; APIRouter:\n        router = APIRouter()\n\n        @router.websocket(\"/stream\")\n        async def invoke_stream(websocket: WebSocket) -&gt; None:\n            await websocket.accept()\n            st = get_telemetry()\n            context = extract(websocket.headers)\n\n            authorization = websocket.headers.get(\"authorization\", None)\n            try:\n                data = await websocket.receive_json()\n                with (\n                    st.tracer.start_as_current_span(\n                        f\"{name}-{str(version)}-invoke_stream\",\n                        context=context,\n                    )\n                    if st.telemetry_enabled()\n                    else nullcontext()\n                ):\n                    inputs = input_class(**data)\n                    inv_inputs = inputs.__dict__\n                    match root_handler_name:\n                        case \"skagents\":\n                            handler: BaseHandler = skagents_handle(\n                                config, app_config, authorization\n                            )\n                            async for content in handler.invoke_stream(inputs=inv_inputs):\n                                if isinstance(content, PartialResponse):\n                                    await websocket.send_text(content.output_partial)\n                            await websocket.close()\n                        case _:\n                            logger.exception(\n                                \"Unknown apiVersion: %s\", config.apiVersion, exc_info=True\n                            )\n                            raise ValueError(f\"Unknown apiVersion %s: {config.apiVersion}\")\n            except WebSocketDisconnect:\n                logger.exception(\"websocket disconnected\")\n                print(\"websocket disconnected\")\n\n        return router\n\n    @staticmethod\n    def get_stateful_routes(\n        name: str,\n        version: str,\n        description: str,\n        config: BaseConfig,\n        app_config: AppConfig,\n        state_manager: TaskPersistenceManager,\n        authorizer: RequestAuthorizer,\n        auth_storage_manager: SecureAuthStorageManager,\n        mcp_discovery_manager=None,  # McpStateManager - Optional\n        input_class: type[UserMessage] = UserMessage,\n    ) -&gt; APIRouter:\n        \"\"\"\n        Get the stateful API routes for the given configuration.\n        \"\"\"\n        router = APIRouter()\n\n        async def get_user_id(authorization: str = Header(None)):\n            user_id = await authorizer.authorize_request(authorization)\n            if not user_id:\n                raise HTTPException(\n                    status_code=status.HTTP_401_UNAUTHORIZED, detail=\"Authentication required\"\n                )\n            return user_id\n\n        @router.post(\n            \"\",\n            response_model=StateResponse,\n            summary=\"Send a message to the agent\",\n            response_description=\"Agent response with state identifiers\",\n            tags=[\"Agent\"],\n        )\n        async def chat(message: input_class, user_id: str = Depends(get_user_id)) -&gt; StateResponse:\n            # Handle new task creation or task retrieval\n            teal_handler = Routes.get_task_handler(\n                config, app_config, user_id, state_manager, mcp_discovery_manager\n            )\n            response_content = await teal_handler.invoke(user_id, message)\n            # Return response with state identifiers\n            status = TaskStatus.COMPLETED.value\n            if type(response_content) is HitlResponse:\n                status = TaskStatus.PAUSED.value\n            return StateResponse(\n                session_id=response_content.session_id,\n                task_id=response_content.task_id,\n                request_id=response_content.request_id,\n                status=status,\n                content=response_content,  # Replace with actual response\n            )\n\n        return router\n\n    @staticmethod\n    def get_resume_routes(\n        config: BaseConfig,\n        app_config: AppConfig,\n        state_manager: TaskPersistenceManager,\n        mcp_discovery_manager=None,\n    ) -&gt; APIRouter:\n        router = APIRouter()\n\n        @router.post(\"/tealagents/v1alpha1/resume/{request_id}\")\n        async def resume(request_id: str, request: Request, body: ResumeRequest):\n            authorization = request.headers.get(\"authorization\", None)\n            teal_handler = Routes.get_task_handler(\n                config, app_config, authorization, state_manager, mcp_discovery_manager\n            )\n            try:\n                return await teal_handler.resume_task(authorization, request_id, body, stream=False)\n            except Exception as e:\n                logger.exception(f\"Error in resume: {e}\")\n                raise HTTPException(status_code=500, detail=\"Internal Server Error\") from e\n\n        @router.post(\"/tealagents/v1alpha1/resume/{request_id}/sse\")\n        async def resume_sse(request_id: str, request: Request, body: ResumeRequest):\n            authorization = request.headers.get(\"authorization\", None)\n            teal_handler = Routes.get_task_handler(\n                config, app_config, authorization, state_manager, mcp_discovery_manager\n            )\n\n            async def event_generator():\n                try:\n                    async for content in teal_handler.resume_task(\n                        authorization, request_id, body, stream=True\n                    ):\n                        yield get_sse_event_for_response(content)\n                except Exception as e:\n                    logger.exception(f\"Error in resume_sse: {e}\")\n                    raise HTTPException(status_code=500, detail=\"Internal Server Error\") from e\n\n            return StreamingResponse(event_generator(), media_type=\"text/event-stream\")\n\n        return router\n\n    @staticmethod\n    def get_oauth_callback_routes(\n        config: BaseConfig,\n        app_config: AppConfig,\n    ) -&gt; APIRouter:\n        \"\"\"\n        Get OAuth 2.1 callback routes for MCP server authentication.\n\n        This route handles the OAuth redirect callback after user authorization.\n        \"\"\"\n        router = APIRouter()\n\n        @router.get(\"/oauth/callback\")\n        async def oauth_callback(\n            code: str,\n            state: str,\n        ):\n            \"\"\"\n            Handle OAuth 2.1 callback from authorization server.\n\n            Validates state, exchanges code for tokens, and stores in AuthStorage.\n\n            Args:\n                code: Authorization code from auth server\n                state: CSRF state parameter\n\n            Returns:\n                Success response with server name and token metadata\n            \"\"\"\n            from sk_agents.auth.oauth_client import OAuthClient\n            from sk_agents.auth.oauth_state_manager import OAuthStateManager\n\n            try:\n                # Initialize OAuth components\n                oauth_client = OAuthClient()\n                state_manager = OAuthStateManager()\n\n                # Retrieve flow state using state parameter only\n                # This extracts user_id without requiring it upfront\n                try:\n                    flow_state = state_manager.retrieve_flow_state_by_state_only(state)\n                except ValueError as e:\n                    logger.warning(f\"Invalid OAuth state in callback: {e}\")\n                    raise HTTPException(\n                        status_code=status.HTTP_400_BAD_REQUEST,\n                        detail=\"Invalid or expired state parameter\",\n                    ) from e\n\n                user_id = flow_state.user_id\n                server_name = flow_state.server_name\n\n                # Look up server config from agent configuration\n                mcp_servers = (\n                    getattr(config.spec.agent, \"mcp_servers\", None)\n                    if hasattr(config, \"spec\")\n                    else None\n                )\n                if not mcp_servers:\n                    raise HTTPException(\n                        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n                        detail=\"No MCP servers configured\",\n                    )\n\n                server_config = None\n                for server in mcp_servers:\n                    if server.name == server_name:\n                        server_config = server\n                        break\n\n                if not server_config:\n                    raise HTTPException(\n                        status_code=status.HTTP_404_NOT_FOUND,\n                        detail=f\"MCP server '{server_name}' not found in configuration\",\n                    )\n\n                # Handle callback (validate state, exchange code, store tokens)\n                oauth_data = await oauth_client.handle_callback(\n                    code=code, state=state, user_id=user_id, server_config=server_config\n                )\n\n                logger.info(f\"OAuth callback successful for user={user_id}, server={server_name}\")\n\n                # Return success response\n                return {\n                    \"status\": \"success\",\n                    \"message\": f\"Successfully authenticated to {server_name}\",\n                    \"server_name\": server_name,\n                    \"scopes\": oauth_data.scopes,\n                    \"expires_at\": oauth_data.expires_at.isoformat(),\n                }\n\n            except HTTPException:\n                raise\n            except Exception as e:\n                logger.exception(f\"Error in OAuth callback: {e}\")\n                raise HTTPException(\n                    status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n                    detail=f\"OAuth callback failed: {str(e)}\",\n                ) from e\n\n        return router\n</code></pre> <code></code> sk_agents.routes.Routes.get_a2a_routes <code>staticmethod</code> <pre><code>get_a2a_routes(\n    name: str,\n    version: str,\n    description: str,\n    config: BaseConfig,\n    app_config: AppConfig,\n    chat_completion_builder: ChatCompletionBuilder,\n    task_store: TaskStore,\n    state_manager: StateManager,\n) -&gt; APIRouter\n</code></pre> <p>DEPRECATION NOTICE: A2A (Agent-to-Agent) routes are being deprecated as part of the framework migration evaluation. This method is maintained for backward compatibility only. New development should avoid using A2A functionality.</p> Source code in <code>src/sk_agents/routes.py</code> <pre><code>@staticmethod\ndef get_a2a_routes(\n    name: str,\n    version: str,\n    description: str,\n    config: BaseConfig,\n    app_config: AppConfig,\n    chat_completion_builder: ChatCompletionBuilder,\n    task_store: TaskStore,\n    state_manager: StateManager,\n) -&gt; APIRouter:\n    \"\"\"\n    DEPRECATION NOTICE: A2A (Agent-to-Agent) routes are being deprecated\n    as part of the framework migration evaluation. This method is maintained for\n    backward compatibility only. New development should avoid using A2A functionality.\n    \"\"\"\n    a2a_app = A2AStarletteApplication(\n        agent_card=Routes.get_agent_card(config, app_config),\n        http_handler=Routes.get_request_handler(\n            config, app_config, chat_completion_builder, state_manager, task_store\n        ),\n    )\n    a2a_router = APIRouter()\n\n    @a2a_router.post(\"\")\n    @docstring_parameter(description)\n    async def handle_a2a(request: Request):\n        \"\"\"\n        {0}\n\n        Agent-to-Agent Invocation\n        \"\"\"\n        return await a2a_app._handle_requests(request)\n\n    @a2a_router.get(\"/.well-known/agent.json\")\n    @docstring_parameter(f\"{name}:{version} - {description}\")\n    async def handle_get_agent_card(request: Request):\n        \"\"\"\n        Retrieve agent card for {0}\n        \"\"\"\n        return await a2a_app._handle_get_agent_card(request)\n\n    return a2a_router\n</code></pre> <code></code> sk_agents.routes.Routes.get_stateful_routes <code>staticmethod</code> <pre><code>get_stateful_routes(\n    name: str,\n    version: str,\n    description: str,\n    config: BaseConfig,\n    app_config: AppConfig,\n    state_manager: TaskPersistenceManager,\n    authorizer: RequestAuthorizer,\n    auth_storage_manager: SecureAuthStorageManager,\n    mcp_discovery_manager=None,\n    input_class: type[UserMessage] = UserMessage,\n) -&gt; APIRouter\n</code></pre> <p>Get the stateful API routes for the given configuration.</p> Source code in <code>src/sk_agents/routes.py</code> <pre><code>@staticmethod\ndef get_stateful_routes(\n    name: str,\n    version: str,\n    description: str,\n    config: BaseConfig,\n    app_config: AppConfig,\n    state_manager: TaskPersistenceManager,\n    authorizer: RequestAuthorizer,\n    auth_storage_manager: SecureAuthStorageManager,\n    mcp_discovery_manager=None,  # McpStateManager - Optional\n    input_class: type[UserMessage] = UserMessage,\n) -&gt; APIRouter:\n    \"\"\"\n    Get the stateful API routes for the given configuration.\n    \"\"\"\n    router = APIRouter()\n\n    async def get_user_id(authorization: str = Header(None)):\n        user_id = await authorizer.authorize_request(authorization)\n        if not user_id:\n            raise HTTPException(\n                status_code=status.HTTP_401_UNAUTHORIZED, detail=\"Authentication required\"\n            )\n        return user_id\n\n    @router.post(\n        \"\",\n        response_model=StateResponse,\n        summary=\"Send a message to the agent\",\n        response_description=\"Agent response with state identifiers\",\n        tags=[\"Agent\"],\n    )\n    async def chat(message: input_class, user_id: str = Depends(get_user_id)) -&gt; StateResponse:\n        # Handle new task creation or task retrieval\n        teal_handler = Routes.get_task_handler(\n            config, app_config, user_id, state_manager, mcp_discovery_manager\n        )\n        response_content = await teal_handler.invoke(user_id, message)\n        # Return response with state identifiers\n        status = TaskStatus.COMPLETED.value\n        if type(response_content) is HitlResponse:\n            status = TaskStatus.PAUSED.value\n        return StateResponse(\n            session_id=response_content.session_id,\n            task_id=response_content.task_id,\n            request_id=response_content.request_id,\n            status=status,\n            content=response_content,  # Replace with actual response\n        )\n\n    return router\n</code></pre> <code></code> sk_agents.routes.Routes.get_oauth_callback_routes <code>staticmethod</code> <pre><code>get_oauth_callback_routes(\n    config: BaseConfig, app_config: AppConfig\n) -&gt; APIRouter\n</code></pre> <p>Get OAuth 2.1 callback routes for MCP server authentication.</p> <p>This route handles the OAuth redirect callback after user authorization.</p> Source code in <code>src/sk_agents/routes.py</code> <pre><code>@staticmethod\ndef get_oauth_callback_routes(\n    config: BaseConfig,\n    app_config: AppConfig,\n) -&gt; APIRouter:\n    \"\"\"\n    Get OAuth 2.1 callback routes for MCP server authentication.\n\n    This route handles the OAuth redirect callback after user authorization.\n    \"\"\"\n    router = APIRouter()\n\n    @router.get(\"/oauth/callback\")\n    async def oauth_callback(\n        code: str,\n        state: str,\n    ):\n        \"\"\"\n        Handle OAuth 2.1 callback from authorization server.\n\n        Validates state, exchanges code for tokens, and stores in AuthStorage.\n\n        Args:\n            code: Authorization code from auth server\n            state: CSRF state parameter\n\n        Returns:\n            Success response with server name and token metadata\n        \"\"\"\n        from sk_agents.auth.oauth_client import OAuthClient\n        from sk_agents.auth.oauth_state_manager import OAuthStateManager\n\n        try:\n            # Initialize OAuth components\n            oauth_client = OAuthClient()\n            state_manager = OAuthStateManager()\n\n            # Retrieve flow state using state parameter only\n            # This extracts user_id without requiring it upfront\n            try:\n                flow_state = state_manager.retrieve_flow_state_by_state_only(state)\n            except ValueError as e:\n                logger.warning(f\"Invalid OAuth state in callback: {e}\")\n                raise HTTPException(\n                    status_code=status.HTTP_400_BAD_REQUEST,\n                    detail=\"Invalid or expired state parameter\",\n                ) from e\n\n            user_id = flow_state.user_id\n            server_name = flow_state.server_name\n\n            # Look up server config from agent configuration\n            mcp_servers = (\n                getattr(config.spec.agent, \"mcp_servers\", None)\n                if hasattr(config, \"spec\")\n                else None\n            )\n            if not mcp_servers:\n                raise HTTPException(\n                    status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n                    detail=\"No MCP servers configured\",\n                )\n\n            server_config = None\n            for server in mcp_servers:\n                if server.name == server_name:\n                    server_config = server\n                    break\n\n            if not server_config:\n                raise HTTPException(\n                    status_code=status.HTTP_404_NOT_FOUND,\n                    detail=f\"MCP server '{server_name}' not found in configuration\",\n                )\n\n            # Handle callback (validate state, exchange code, store tokens)\n            oauth_data = await oauth_client.handle_callback(\n                code=code, state=state, user_id=user_id, server_config=server_config\n            )\n\n            logger.info(f\"OAuth callback successful for user={user_id}, server={server_name}\")\n\n            # Return success response\n            return {\n                \"status\": \"success\",\n                \"message\": f\"Successfully authenticated to {server_name}\",\n                \"server_name\": server_name,\n                \"scopes\": oauth_data.scopes,\n                \"expires_at\": oauth_data.expires_at.isoformat(),\n            }\n\n        except HTTPException:\n            raise\n        except Exception as e:\n            logger.exception(f\"Error in OAuth callback: {e}\")\n            raise HTTPException(\n                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n                detail=f\"OAuth callback failed: {str(e)}\",\n            ) from e\n\n    return router\n</code></pre>"},{"location":"reference/#sk_agents.ska_types","title":"sk_agents.ska_types","text":"sk_agents.ska_types.HistoryMultiModalMessage <p>               Bases: <code>BaseModel</code></p> Source code in <code>src/sk_agents/ska_types.py</code> <pre><code>class HistoryMultiModalMessage(BaseModel):\n    role: Literal[\"user\", \"assistant\"]\n    items: list[MultiModalItem]\n\n    @model_validator(mode=\"before\")\n    @classmethod\n    def convert_content_to_items(cls, data: Any) -&gt; Any:\n        \"\"\"Auto-convert plain HistoryMessage format (content: str)\n        to MultiModal format (items: list).\"\"\"\n        if isinstance(data, dict) and \"content\" in data and \"items\" not in data:\n            content = data.pop(\"content\")\n            data[\"items\"] = [{\"content_type\": \"text\", \"content\": content}]\n        return data\n</code></pre> <code></code> sk_agents.ska_types.HistoryMultiModalMessage.convert_content_to_items <code>classmethod</code> <pre><code>convert_content_to_items(data: Any) -&gt; Any\n</code></pre> <p>Auto-convert plain HistoryMessage format (content: str) to MultiModal format (items: list).</p> Source code in <code>src/sk_agents/ska_types.py</code> <pre><code>@model_validator(mode=\"before\")\n@classmethod\ndef convert_content_to_items(cls, data: Any) -&gt; Any:\n    \"\"\"Auto-convert plain HistoryMessage format (content: str)\n    to MultiModal format (items: list).\"\"\"\n    if isinstance(data, dict) and \"content\" in data and \"items\" not in data:\n        content = data.pop(\"content\")\n        data[\"items\"] = [{\"content_type\": \"text\", \"content\": content}]\n    return data\n</code></pre> <code></code> sk_agents.ska_types.BaseMultiModalInputWithUserContext <p>               Bases: <code>KernelBaseModel</code></p> <p>The history of a chat interaction between an automated assistant and a human with multimodal input (text and images), along with context about the user.</p> Source code in <code>src/sk_agents/ska_types.py</code> <pre><code>class BaseMultiModalInputWithUserContext(KernelBaseModel):\n    \"\"\"The history of a chat interaction between an automated assistant and a\n    human with multimodal input (text and images),\n    along with context about the user.\"\"\"\n\n    session_id: str | None = None\n    chat_history: list[HistoryMultiModalMessage] | None = None\n    user_context: dict[str, str] | None = None\n</code></pre> <code></code> sk_agents.ska_types.HistoryMessage <p>               Bases: <code>BaseModel</code></p> <p>A single interaction in a chat history. 'role' - Either 'user' (requestor) or 'assistant' (responder) indicating who sent the message. 'content' - The content of the message</p> Source code in <code>src/sk_agents/ska_types.py</code> <pre><code>class HistoryMessage(BaseModel):\n    \"\"\"A single interaction in a chat history.&lt;br/&gt;\n    'role' - Either 'user' (requestor) or 'assistant' (responder) indicating\n    who sent the message.&lt;br/&gt;\n    'content' - The content of the message\"\"\"\n\n    role: Literal[\"user\", \"assistant\"]\n    content: str\n</code></pre> <code></code> sk_agents.ska_types.BaseInput <p>               Bases: <code>KernelBaseModel</code></p> <p>The history of a chat interaction between an automated assistant and a human.</p> Source code in <code>src/sk_agents/ska_types.py</code> <pre><code>class BaseInput(KernelBaseModel):\n    \"\"\"The history of a chat interaction between an automated assistant and a\n    human.\"\"\"\n\n    chat_history: list[HistoryMessage] | None = None\n</code></pre> <code></code> sk_agents.ska_types.BaseInputWithUserContext <p>               Bases: <code>KernelBaseModel</code></p> <p>The history of a chat interaction between an automated assistant and a human, along with context about the user.</p> Source code in <code>src/sk_agents/ska_types.py</code> <pre><code>class BaseInputWithUserContext(KernelBaseModel):\n    \"\"\"The history of a chat interaction between an automated assistant and a\n    human, along with context about the user.\"\"\"\n\n    chat_history: list[HistoryMessage] | None = None\n    user_context: dict[str, str] | None = None\n</code></pre>"},{"location":"reference/#sk_agents.state","title":"sk_agents.state","text":"sk_agents.state.redis_state_manager <p>Redis implementation of the StateManager interface. This implementation uses Redis as the persistent store for task state management.</p> sk_agents.state.redis_state_manager.RedisStateManager <p>               Bases: <code>StateManager</code></p> <p>Redis implementation of the StateManager interface.</p> <p>This class provides Redis-based persistence for task state management.</p> Source code in <code>src/sk_agents/state/redis_state_manager.py</code> <pre><code>class RedisStateManager(StateManager):\n    \"\"\"Redis implementation of the StateManager interface.\n\n    This class provides Redis-based persistence for task state management.\n    \"\"\"\n\n    def __init__(\n        self,\n        redis_client: Redis,\n        ttl: int | None = None,\n        key_prefix: str = \"task_state:\",\n    ):\n        \"\"\"Initialize the RedisStateManager with a Redis client.\n\n        Args:\n            redis_client: An instance of Redis client\n            key_prefix: Prefix used for Redis keys (default: \"task_state:\")\n        \"\"\"\n        self._redis = redis_client\n        self._key_prefix = key_prefix\n        self._ttl = ttl\n\n    def _get_message_key(self, task_id: str) -&gt; str:\n        \"\"\"Generate a Redis key for a task's messages.\n\n        Args:\n            task_id: The ID of the task\n\n        Returns:\n            A Redis key string for the task's messages\n        \"\"\"\n        return f\"{self._key_prefix}{task_id}:messages\"\n\n    def _get_canceled_key(self, task_id: str) -&gt; str:\n        \"\"\"Generate a Redis key for a task's canceled status.\n\n        Args:\n            task_id: The ID of the task\n\n        Returns:\n            A Redis key string for the task's canceled status\n        \"\"\"\n        return f\"{self._key_prefix}{task_id}:canceled\"\n\n    async def update_task_messages(\n        self, task_id: str, new_message: HistoryMultiModalMessage\n    ) -&gt; list[HistoryMultiModalMessage]:\n        \"\"\"Updates the messages for a specific task.\n\n        Appends a new message to the task's message history and returns\n        the complete list of messages.\n\n        Args:\n            task_id: The ID of the task\n            new_message: The new message to add to the task's history\n\n        Returns:\n            The complete list of messages for the task\n        \"\"\"\n        # Get the Redis key for this task's messages\n        message_key = self._get_message_key(task_id)\n\n        # Serialize the new message to JSON with mode='json' to ensure enums are properly serialized\n        message_json = json.dumps(new_message.model_dump(mode=\"json\"))\n\n        # Add the new message to the list in Redis\n        await self._redis.rpush(message_key, message_json)\n        if self._ttl:\n            await self._redis.expire(message_key, int(self._ttl))\n\n        # Retrieve all messages for the task\n        message_jsons = await self._redis.lrange(message_key, 0, -1)\n\n        # Deserialize each message from JSON\n        messages = [\n            HistoryMultiModalMessage.model_validate(json.loads(msg)) for msg in message_jsons\n        ]\n\n        return messages\n\n    async def set_canceled(self, task_id: str) -&gt; None:\n        \"\"\"Marks a task as canceled.\n\n        Args:\n            task_id: The ID of the task to mark as canceled\n        \"\"\"\n        # Set the canceled flag for the task\n        await self._redis.set(self._get_canceled_key(task_id), \"1\", ex=self._ttl)\n\n    async def is_canceled(self, task_id: str) -&gt; bool:\n        \"\"\"Checks if a task is marked as canceled.\n\n        Args:\n            task_id: The ID of the task to check\n\n        Returns:\n            True if the task is canceled, False otherwise\n        \"\"\"\n        # Check if the canceled flag is set\n        canceled = await self._redis.get(self._get_canceled_key(task_id))\n        return canceled == \"1\"\n</code></pre> <code></code> sk_agents.state.redis_state_manager.RedisStateManager.__init__ <pre><code>__init__(\n    redis_client: Redis,\n    ttl: int | None = None,\n    key_prefix: str = \"task_state:\",\n)\n</code></pre> <p>Initialize the RedisStateManager with a Redis client.</p> <p>Parameters:</p> Name Type Description Default <code>redis_client</code> <code>Redis</code> <p>An instance of Redis client</p> required <code>key_prefix</code> <code>str</code> <p>Prefix used for Redis keys (default: \"task_state:\")</p> <code>'task_state:'</code> Source code in <code>src/sk_agents/state/redis_state_manager.py</code> <pre><code>def __init__(\n    self,\n    redis_client: Redis,\n    ttl: int | None = None,\n    key_prefix: str = \"task_state:\",\n):\n    \"\"\"Initialize the RedisStateManager with a Redis client.\n\n    Args:\n        redis_client: An instance of Redis client\n        key_prefix: Prefix used for Redis keys (default: \"task_state:\")\n    \"\"\"\n    self._redis = redis_client\n    self._key_prefix = key_prefix\n    self._ttl = ttl\n</code></pre> <code></code> sk_agents.state.redis_state_manager.RedisStateManager.update_task_messages <code>async</code> <pre><code>update_task_messages(\n    task_id: str, new_message: HistoryMultiModalMessage\n) -&gt; list[HistoryMultiModalMessage]\n</code></pre> <p>Updates the messages for a specific task.</p> <p>Appends a new message to the task's message history and returns the complete list of messages.</p> <p>Parameters:</p> Name Type Description Default <code>task_id</code> <code>str</code> <p>The ID of the task</p> required <code>new_message</code> <code>HistoryMultiModalMessage</code> <p>The new message to add to the task's history</p> required <p>Returns:</p> Type Description <code>list[HistoryMultiModalMessage]</code> <p>The complete list of messages for the task</p> Source code in <code>src/sk_agents/state/redis_state_manager.py</code> <pre><code>async def update_task_messages(\n    self, task_id: str, new_message: HistoryMultiModalMessage\n) -&gt; list[HistoryMultiModalMessage]:\n    \"\"\"Updates the messages for a specific task.\n\n    Appends a new message to the task's message history and returns\n    the complete list of messages.\n\n    Args:\n        task_id: The ID of the task\n        new_message: The new message to add to the task's history\n\n    Returns:\n        The complete list of messages for the task\n    \"\"\"\n    # Get the Redis key for this task's messages\n    message_key = self._get_message_key(task_id)\n\n    # Serialize the new message to JSON with mode='json' to ensure enums are properly serialized\n    message_json = json.dumps(new_message.model_dump(mode=\"json\"))\n\n    # Add the new message to the list in Redis\n    await self._redis.rpush(message_key, message_json)\n    if self._ttl:\n        await self._redis.expire(message_key, int(self._ttl))\n\n    # Retrieve all messages for the task\n    message_jsons = await self._redis.lrange(message_key, 0, -1)\n\n    # Deserialize each message from JSON\n    messages = [\n        HistoryMultiModalMessage.model_validate(json.loads(msg)) for msg in message_jsons\n    ]\n\n    return messages\n</code></pre> <code></code> sk_agents.state.redis_state_manager.RedisStateManager.set_canceled <code>async</code> <pre><code>set_canceled(task_id: str) -&gt; None\n</code></pre> <p>Marks a task as canceled.</p> <p>Parameters:</p> Name Type Description Default <code>task_id</code> <code>str</code> <p>The ID of the task to mark as canceled</p> required Source code in <code>src/sk_agents/state/redis_state_manager.py</code> <pre><code>async def set_canceled(self, task_id: str) -&gt; None:\n    \"\"\"Marks a task as canceled.\n\n    Args:\n        task_id: The ID of the task to mark as canceled\n    \"\"\"\n    # Set the canceled flag for the task\n    await self._redis.set(self._get_canceled_key(task_id), \"1\", ex=self._ttl)\n</code></pre> <code></code> sk_agents.state.redis_state_manager.RedisStateManager.is_canceled <code>async</code> <pre><code>is_canceled(task_id: str) -&gt; bool\n</code></pre> <p>Checks if a task is marked as canceled.</p> <p>Parameters:</p> Name Type Description Default <code>task_id</code> <code>str</code> <p>The ID of the task to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the task is canceled, False otherwise</p> Source code in <code>src/sk_agents/state/redis_state_manager.py</code> <pre><code>async def is_canceled(self, task_id: str) -&gt; bool:\n    \"\"\"Checks if a task is marked as canceled.\n\n    Args:\n        task_id: The ID of the task to check\n\n    Returns:\n        True if the task is canceled, False otherwise\n    \"\"\"\n    # Check if the canceled flag is set\n    canceled = await self._redis.get(self._get_canceled_key(task_id))\n    return canceled == \"1\"\n</code></pre>"},{"location":"reference/#sk_agents.stateful","title":"sk_agents.stateful","text":"sk_agents.stateful.UserMessage <p>               Bases: <code>BaseModel</code></p> <p>New input model for the tealagents/v1alpha1 API version. Unlike BaseMultiModalInput, chat history is maintained server-side.</p> Source code in <code>src/sk_agents/stateful.py</code> <pre><code>class UserMessage(BaseModel):\n    \"\"\"\n    New input model for the tealagents/v1alpha1 API version.\n    Unlike BaseMultiModalInput, chat history is maintained server-side.\n    \"\"\"\n\n    session_id: UUID4 | None = None\n    task_id: UUID4 | None = None\n    items: list[MultiModalItem]\n\n    @field_validator(\"session_id\", \"task_id\", mode=\"before\")\n    @classmethod\n    def validate_uuid(cls, v):\n        if v is not None and not isinstance(v, uuid.UUID):\n            try:\n                return uuid.UUID(v)\n            except (ValueError, AttributeError) as err:\n                raise ValueError(f\"Invalid UUID format: {v}\") from err\n        return v\n</code></pre> <code></code> sk_agents.stateful.TaskState <p>               Bases: <code>BaseModel</code></p> <p>Model for the state associated with a Task ID</p> Source code in <code>src/sk_agents/stateful.py</code> <pre><code>class TaskState(BaseModel):\n    \"\"\"Model for the state associated with a Task ID\"\"\"\n\n    task_id: UUID4\n    session_id: UUID4\n    user_id: str  # User identity for authorization\n    messages: list[dict[str, Any]]  # Chat history and execution trace\n    status: TaskStatus = TaskStatus.RUNNING\n    created_at: datetime = Field(default_factory=datetime.utcnow)\n    updated_at: datetime = Field(default_factory=datetime.utcnow)\n    metadata: dict[str, Any] = Field(default_factory=dict)\n</code></pre> <code></code> sk_agents.stateful.RequestState <p>               Bases: <code>BaseModel</code></p> <p>Model for the state associated with a Request ID</p> Source code in <code>src/sk_agents/stateful.py</code> <pre><code>class RequestState(BaseModel):\n    \"\"\"Model for the state associated with a Request ID\"\"\"\n\n    request_id: UUID4\n    task_id: UUID4\n    status: TaskStatus = TaskStatus.RUNNING\n    created_at: datetime = Field(default_factory=datetime.utcnow)\n    updated_at: datetime = Field(default_factory=datetime.utcnow)\n    metadata: dict[str, Any] = Field(default_factory=dict)\n</code></pre> <code></code> sk_agents.stateful.StateResponse <p>               Bases: <code>BaseModel</code></p> <p>Response model including state identifiers</p> Source code in <code>src/sk_agents/stateful.py</code> <pre><code>class StateResponse(BaseModel):\n    \"\"\"Response model including state identifiers\"\"\"\n\n    session_id: UUID4\n    task_id: UUID4\n    request_id: UUID4\n    status: TaskStatus\n    content: InvokeResponse | RejectedToolResponse | HitlResponse | TealAgentsResponse\n</code></pre> <code></code> sk_agents.stateful.StateManager <p>               Bases: <code>ABC</code></p> <p>Abstract base class for state management</p> Source code in <code>src/sk_agents/stateful.py</code> <pre><code>class StateManager(ABC):\n    \"\"\"Abstract base class for state management\"\"\"\n\n    @abstractmethod\n    async def create_task(self, session_id: UUID4 | None, user_id: str) -&gt; tuple[UUID4, UUID4]:\n        \"\"\"Create a new task and return session_id and task_id\"\"\"\n\n    @abstractmethod\n    async def get_task(self, task_id: UUID4) -&gt; TaskState:\n        \"\"\"Get a task by ID\"\"\"\n\n    @abstractmethod\n    async def update_task(self, task_state: TaskState) -&gt; None:\n        \"\"\"Update a task state\"\"\"\n\n    @abstractmethod\n    async def create_request(self, task_id: UUID4) -&gt; UUID4:\n        \"\"\"Create a new request and return request_id\"\"\"\n\n    @abstractmethod\n    async def get_request(self, request_id: UUID4) -&gt; RequestState:\n        \"\"\"Get a request by ID\"\"\"\n\n    @abstractmethod\n    async def update_request(self, request_state: RequestState) -&gt; None:\n        \"\"\"Update a request state\"\"\"\n</code></pre> <code></code> sk_agents.stateful.StateManager.create_task <code>abstractmethod</code> <code>async</code> <pre><code>create_task(\n    session_id: UUID4 | None, user_id: str\n) -&gt; tuple[UUID4, UUID4]\n</code></pre> <p>Create a new task and return session_id and task_id</p> Source code in <code>src/sk_agents/stateful.py</code> <pre><code>@abstractmethod\nasync def create_task(self, session_id: UUID4 | None, user_id: str) -&gt; tuple[UUID4, UUID4]:\n    \"\"\"Create a new task and return session_id and task_id\"\"\"\n</code></pre> <code></code> sk_agents.stateful.StateManager.get_task <code>abstractmethod</code> <code>async</code> <pre><code>get_task(task_id: UUID4) -&gt; TaskState\n</code></pre> <p>Get a task by ID</p> Source code in <code>src/sk_agents/stateful.py</code> <pre><code>@abstractmethod\nasync def get_task(self, task_id: UUID4) -&gt; TaskState:\n    \"\"\"Get a task by ID\"\"\"\n</code></pre> <code></code> sk_agents.stateful.StateManager.update_task <code>abstractmethod</code> <code>async</code> <pre><code>update_task(task_state: TaskState) -&gt; None\n</code></pre> <p>Update a task state</p> Source code in <code>src/sk_agents/stateful.py</code> <pre><code>@abstractmethod\nasync def update_task(self, task_state: TaskState) -&gt; None:\n    \"\"\"Update a task state\"\"\"\n</code></pre> <code></code> sk_agents.stateful.StateManager.create_request <code>abstractmethod</code> <code>async</code> <pre><code>create_request(task_id: UUID4) -&gt; UUID4\n</code></pre> <p>Create a new request and return request_id</p> Source code in <code>src/sk_agents/stateful.py</code> <pre><code>@abstractmethod\nasync def create_request(self, task_id: UUID4) -&gt; UUID4:\n    \"\"\"Create a new request and return request_id\"\"\"\n</code></pre> <code></code> sk_agents.stateful.StateManager.get_request <code>abstractmethod</code> <code>async</code> <pre><code>get_request(request_id: UUID4) -&gt; RequestState\n</code></pre> <p>Get a request by ID</p> Source code in <code>src/sk_agents/stateful.py</code> <pre><code>@abstractmethod\nasync def get_request(self, request_id: UUID4) -&gt; RequestState:\n    \"\"\"Get a request by ID\"\"\"\n</code></pre> <code></code> sk_agents.stateful.StateManager.update_request <code>abstractmethod</code> <code>async</code> <pre><code>update_request(request_state: RequestState) -&gt; None\n</code></pre> <p>Update a request state</p> Source code in <code>src/sk_agents/stateful.py</code> <pre><code>@abstractmethod\nasync def update_request(self, request_state: RequestState) -&gt; None:\n    \"\"\"Update a request state\"\"\"\n</code></pre> <code></code> sk_agents.stateful.InMemoryStateManager <p>               Bases: <code>StateManager</code></p> <p>In-memory implementation of state manager</p> Source code in <code>src/sk_agents/stateful.py</code> <pre><code>class InMemoryStateManager(StateManager):\n    \"\"\"In-memory implementation of state manager\"\"\"\n\n    def __init__(self):\n        self.tasks: dict[UUID4, TaskState] = {}\n        self.requests: dict[UUID4, RequestState] = {}\n\n    async def create_task(self, session_id: UUID4 | None, user_id: str) -&gt; tuple[UUID4, UUID4]:\n        session_id = session_id or uuid.uuid4()\n        task_id = uuid.uuid4()\n        self.tasks[task_id] = TaskState(\n            task_id=task_id, session_id=session_id, user_id=user_id, messages=[]\n        )\n        return session_id, task_id\n\n    async def get_task(self, task_id: UUID4) -&gt; TaskState:\n        if task_id not in self.tasks:\n            raise ValueError(f\"Task not found: {task_id}\")\n        return self.tasks[task_id]\n\n    async def update_task(self, task_state: TaskState) -&gt; None:\n        task_state.updated_at = datetime.utcnow()\n        self.tasks[task_state.task_id] = task_state\n\n    async def create_request(self, task_id: UUID4) -&gt; UUID4:\n        request_id = uuid.uuid4()\n        self.requests[request_id] = RequestState(request_id=request_id, task_id=task_id)\n        return request_id\n\n    async def get_request(self, request_id: UUID4) -&gt; RequestState:\n        if request_id not in self.requests:\n            raise ValueError(f\"Request not found: {request_id}\")\n        return self.requests[request_id]\n\n    async def update_request(self, request_state: RequestState) -&gt; None:\n        request_state.updated_at = datetime.utcnow()\n        self.requests[request_state.request_id] = request_state\n</code></pre> <code></code> sk_agents.stateful.RedisStateManager <p>               Bases: <code>StateManager</code></p> <p>Redis implementation of state manager</p> Source code in <code>src/sk_agents/stateful.py</code> <pre><code>class RedisStateManager(StateManager):\n    \"\"\"Redis implementation of state manager\"\"\"\n\n    def __init__(self, redis_client: Redis, ttl: int | None = None):\n        self.redis = redis_client\n        self.ttl = ttl  # Time-to-live in seconds\n\n    async def create_task(self, session_id: UUID4 | None, user_id: str) -&gt; tuple[UUID4, UUID4]:\n        session_id = session_id or uuid.uuid4()\n        task_id = uuid.uuid4()\n        task_state = TaskState(task_id=task_id, session_id=session_id, user_id=user_id, messages=[])\n        await self._set_task(task_state)\n        return session_id, task_id\n\n    async def get_task(self, task_id: UUID4) -&gt; TaskState:\n        key = f\"task:{task_id}\"\n        data = await self.redis.get(key)\n        if not data:\n            raise ValueError(f\"Task not found: {task_id}\")\n        return TaskState.parse_raw(data)\n\n    async def update_task(self, task_state: TaskState) -&gt; None:\n        task_state.updated_at = datetime.utcnow()\n        await self._set_task(task_state)\n\n    async def _set_task(self, task_state: TaskState) -&gt; None:\n        key = f\"task:{task_state.task_id}\"\n        await self.redis.set(key, task_state.json(), ex=self.ttl)\n\n    async def create_request(self, task_id: UUID4) -&gt; UUID4:\n        request_id = uuid.uuid4()\n        request_state = RequestState(request_id=request_id, task_id=task_id)\n        await self._set_request(request_state)\n        return request_id\n\n    async def get_request(self, request_id: UUID4) -&gt; RequestState:\n        key = f\"request:{request_id}\"\n        data = await self.redis.get(key)\n        if not data:\n            raise ValueError(f\"Request not found: {request_id}\")\n        return RequestState.parse_raw(data)\n\n    async def update_request(self, request_state: RequestState) -&gt; None:\n        request_state.updated_at = datetime.utcnow()\n        await self._set_request(request_state)\n\n    async def _set_request(self, request_state: RequestState) -&gt; None:\n        key = f\"request:{request_state.request_id}\"\n        await self.redis.set(key, request_state.json(), ex=self.ttl)\n</code></pre> <code></code> sk_agents.stateful.AuthenticationManager <p>               Bases: <code>ABC</code></p> <p>Abstract base class for authentication management</p> Source code in <code>src/sk_agents/stateful.py</code> <pre><code>class AuthenticationManager(ABC):\n    \"\"\"Abstract base class for authentication management\"\"\"\n\n    @abstractmethod\n    async def authorize_request(self, token: str) -&gt; str:\n        \"\"\"Authenticate a token and return the user ID\"\"\"\n        pass\n\n    @abstractmethod\n    async def validate_task_access(self, task_id: UUID4, user_id: str) -&gt; bool:\n        \"\"\"Validate if a user has access to a task\"\"\"\n        pass\n</code></pre> <code></code> sk_agents.stateful.AuthenticationManager.authorize_request <code>abstractmethod</code> <code>async</code> <pre><code>authorize_request(token: str) -&gt; str\n</code></pre> <p>Authenticate a token and return the user ID</p> Source code in <code>src/sk_agents/stateful.py</code> <pre><code>@abstractmethod\nasync def authorize_request(self, token: str) -&gt; str:\n    \"\"\"Authenticate a token and return the user ID\"\"\"\n    pass\n</code></pre> <code></code> sk_agents.stateful.AuthenticationManager.validate_task_access <code>abstractmethod</code> <code>async</code> <pre><code>validate_task_access(task_id: UUID4, user_id: str) -&gt; bool\n</code></pre> <p>Validate if a user has access to a task</p> Source code in <code>src/sk_agents/stateful.py</code> <pre><code>@abstractmethod\nasync def validate_task_access(self, task_id: UUID4, user_id: str) -&gt; bool:\n    \"\"\"Validate if a user has access to a task\"\"\"\n    pass\n</code></pre> <code></code> sk_agents.stateful.MockAuthenticationManager <p>               Bases: <code>AuthenticationManager</code></p> <p>Mock implementation of authentication manager for development</p> Source code in <code>src/sk_agents/stateful.py</code> <pre><code>class MockAuthenticationManager(AuthenticationManager):\n    \"\"\"Mock implementation of authentication manager for development\"\"\"\n\n    async def authorize_request(self, token: str) -&gt; str:\n        # In mock implementation, just return the token as the user ID\n        # In real implementation, this would validate the token with Entra ID\n        return token or \"anonymous-user\"\n\n    async def validate_task_access(self, task_id: UUID4, user_id: str) -&gt; bool:\n        # In mock implementation, always return True\n        # In real implementation, this would check if the user owns the task\n        return True\n</code></pre>"},{"location":"reference/#sk_agents.tealagents","title":"sk_agents.tealagents","text":"sk_agents.tealagents.kernel_builder sk_agents.tealagents.kernel_builder.KernelBuilder Source code in <code>src/sk_agents/tealagents/kernel_builder.py</code> <pre><code>class KernelBuilder:\n    def __init__(\n        self,\n        chat_completion_builder: ChatCompletionBuilder,\n        remote_plugin_loader: RemotePluginLoader,\n        app_config: AppConfig,\n        authorization: str | None = None,\n    ):\n        self.chat_completion_builder: ChatCompletionBuilder = chat_completion_builder\n        self.remote_plugin_loader = remote_plugin_loader\n        self.app_config: AppConfig = app_config\n        self.authorization = authorization\n        self.logger = logging.getLogger(__name__)\n\n        # Initialize auth storage and authorizer for token cache functionality\n        self.auth_storage_manager: SecureAuthStorageManager = AuthStorageFactory(\n            app_config\n        ).get_auth_storage_manager()\n        self.authorizer: RequestAuthorizer = AuthorizerFactory(app_config).get_authorizer()\n\n    async def build_kernel(\n        self,\n        model_name: str,\n        service_id: str,\n        plugins: list[str],\n        remote_plugins: list[str],\n        mcp_servers: list[McpServerConfig] | None = None,\n        authorization: str | None = None,\n        extra_data_collector: ExtraDataCollector | None = None,\n        user_id: str | None = None,\n    ) -&gt; Kernel:\n        try:\n            kernel = self._create_base_kernel(model_name, service_id)\n            kernel = self._parse_plugins(plugins, kernel, authorization, extra_data_collector)\n            kernel = self._load_remote_plugins(remote_plugins, kernel)\n\n            # MCP plugins will be loaded separately in async context by handler\n            # Remove sync MCP loading to avoid event loop conflicts\n\n            return kernel\n        except Exception as e:\n            self.logger.exception(f\"Could build kernel with service ID {service_id}. - {e}\")\n            raise\n\n    def get_model_type_for_name(self, model_name: str) -&gt; ModelType:\n        try:\n            return self.chat_completion_builder.get_model_type_for_name(model_name)\n        except Exception as e:\n            self.logger.exception(f\"Could not get model type for {model_name}. - {e}\")\n            raise\n\n    def model_supports_structured_output(self, model_name: str) -&gt; bool:\n        return self.chat_completion_builder.model_supports_structured_output(model_name)\n\n    def _create_base_kernel(self, model_name: str, service_id: str) -&gt; Kernel:\n        try:\n            chat_completion = self.chat_completion_builder.get_chat_completion_for_model(\n                service_id=service_id,\n                model_name=model_name,\n            )\n\n            kernel = Kernel()\n            kernel.add_service(chat_completion)\n\n            return kernel\n        except Exception as e:\n            self.logger.exception(f\"Could not create base kernelwith service id {service_id}.-{e}\")\n            raise\n\n    def _load_remote_plugins(self, remote_plugins: list[str], kernel: Kernel) -&gt; Kernel:\n        if remote_plugins is None or len(remote_plugins) &lt; 1:\n            return kernel\n        try:\n            self.remote_plugin_loader.load_remote_plugins(kernel, remote_plugins)\n            return kernel\n        except Exception as e:\n            self.logger.exception(f\"Could not load remote plugings. -{e}\")\n            raise\n\n    async def load_mcp_plugins(\n        self,\n        kernel: Kernel,\n        user_id: str,\n        session_id: str,\n        mcp_discovery_manager,\n        connection_manager,\n    ) -&gt; Kernel:\n        \"\"\"\n        Load MCP plugins by instantiating McpPlugin directly with tools from storage.\n\n        This loads tools discovered at session start and creates McpPlugin instances\n        for each MCP server. Only tools that the user has authenticated to access\n        will be loaded, ensuring proper multi-tenant isolation at the session level.\n\n        Args:\n            kernel: The kernel to add plugins to\n            user_id: User ID to get plugins for (required)\n            session_id: Session ID for plugin isolation (required)\n            mcp_discovery_manager: Discovery manager for loading tool state (required)\n            connection_manager: Request-scoped connection manager for connection reuse (required)\n\n        Returns:\n            The kernel with session's MCP plugins loaded\n\n        Note: MCP tools must be discovered first via McpPluginRegistry.discover_and_materialize()\n        before calling this method.\n        \"\"\"\n        if not user_id:\n            raise ValueError(\"user_id is required when loading MCP plugins\")\n        if not session_id:\n            raise ValueError(\"session_id is required when loading MCP plugins\")\n        if not mcp_discovery_manager:\n            raise ValueError(\"mcp_discovery_manager is required when loading MCP plugins\")\n        if not connection_manager:\n            raise ValueError(\"connection_manager is required when loading MCP plugins\")\n\n        try:\n            from sk_agents.mcp_client import McpPlugin\n            from sk_agents.mcp_plugin_registry import McpPluginRegistry\n\n            # Get tools for THIS session (session-level isolation)\n            server_tools = await McpPluginRegistry.get_tools_for_session(\n                user_id, session_id, mcp_discovery_manager\n            )\n\n            if not server_tools:\n                self.logger.debug(f\"No MCP tools found for user {user_id}, session {session_id}\")\n                return kernel\n\n            # Instantiate McpPlugin directly for each server\n            for server_name, tools in server_tools.items():\n                plugin_instance = McpPlugin(\n                    tools=tools,\n                    server_name=server_name,\n                    user_id=user_id,\n                    connection_manager=connection_manager,\n                    authorization=self.authorization,\n                    extra_data_collector=None,\n                )\n\n                # Register with kernel\n                # Sanitize server name: SK requires plugin names to match ^[0-9A-Za-z_]+\n                sanitized_server_name = server_name.replace(\"-\", \"_\").replace(\".\", \"_\")\n                kernel.add_plugin(plugin_instance, f\"mcp_{sanitized_server_name}\")\n                self.logger.info(\n                    f\"Loaded MCP plugin for {server_name} as mcp_{sanitized_server_name} \"\n                    f\"(user: {user_id}, session: {session_id})\"\n                )\n\n            self.logger.info(\n                f\"Loaded {len(server_tools)} MCP plugins for user {user_id}, session {session_id}\"\n            )\n            return kernel\n\n        except Exception as e:\n            self.logger.exception(\n                f\"Could not load MCP plugins for user {user_id}, session {session_id}. - {e}\"\n            )\n            raise\n\n    def _parse_plugins(\n        self,\n        plugin_names: list[str],\n        kernel: Kernel,\n        authorization: str | None = None,\n        extra_data_collector: ExtraDataCollector | None = None,\n    ) -&gt; Kernel:\n        if plugin_names is None or len(plugin_names) &lt; 1:\n            return kernel\n\n        plugin_loader = get_plugin_loader()\n        plugins = plugin_loader.get_plugins(plugin_names)\n\n        for plugin_name, plugin_class in plugins.items():\n            # For non-MCP plugins, use original authorization directly\n            # (MCP plugins handle auth differently via user_id)\n            plugin_authorization = authorization\n\n            # Create and add the plugin to the kernel\n            kernel.add_plugin(plugin_class(plugin_authorization, extra_data_collector), plugin_name)\n\n        return kernel\n\n    async def _get_plugin_authorization(\n        self, plugin_name: str, original_authorization: str | None = None\n    ) -&gt; str | None:\n        \"\"\"\n        Get plugin-specific authorization, checking token cache for stored OAuth2 tokens.\n\n        Args:\n            plugin_name: Name of the plugin requesting authorization\n            original_authorization: Original authorization header from the request\n\n        Returns:\n            Authorization string to use for the plugin (either cached token or original)\n        \"\"\"\n        if not original_authorization:\n            return None\n\n        try:\n            # Extract user ID from the authorization header\n            user_id = await self.authorizer.authorize_request(original_authorization)\n            if not user_id:\n                self.logger.warning(\n                    f\"Could not extract user ID from authorization for plugin {plugin_name}\"\n                )\n                return original_authorization\n\n            # Try to retrieve cached OAuth2 tokens for this user and plugin\n            cached_auth_data = self.auth_storage_manager.retrieve(user_id, plugin_name)\n\n            if cached_auth_data and hasattr(cached_auth_data, \"access_token\"):\n                self.logger.info(f\"Using cached token for plugin {plugin_name}, user {user_id}\")\n                # Return the cached access token in Bearer format\n                return f\"Bearer {cached_auth_data.access_token}\"\n            else:\n                self.logger.debug(\n                    f\"No cached tokens found for plugin {plugin_name}, user {user_id} - \"\n                    f\"returning None\"\n                )\n                return None\n\n        except Exception as e:\n            self.logger.warning(\n                f\"Error retrieving cached tokens for plugin {plugin_name}: {e} - returning None\"\n            )\n            return None\n</code></pre> <code></code> sk_agents.tealagents.kernel_builder.KernelBuilder.load_mcp_plugins <code>async</code> <pre><code>load_mcp_plugins(\n    kernel: Kernel,\n    user_id: str,\n    session_id: str,\n    mcp_discovery_manager,\n    connection_manager,\n) -&gt; Kernel\n</code></pre> <p>Load MCP plugins by instantiating McpPlugin directly with tools from storage.</p> <p>This loads tools discovered at session start and creates McpPlugin instances for each MCP server. Only tools that the user has authenticated to access will be loaded, ensuring proper multi-tenant isolation at the session level.</p> <p>Parameters:</p> Name Type Description Default <code>kernel</code> <code>Kernel</code> <p>The kernel to add plugins to</p> required <code>user_id</code> <code>str</code> <p>User ID to get plugins for (required)</p> required <code>session_id</code> <code>str</code> <p>Session ID for plugin isolation (required)</p> required <code>mcp_discovery_manager</code> <p>Discovery manager for loading tool state (required)</p> required <code>connection_manager</code> <p>Request-scoped connection manager for connection reuse (required)</p> required <p>Returns:</p> Type Description <code>Kernel</code> <p>The kernel with session's MCP plugins loaded</p> <p>Note: MCP tools must be discovered first via McpPluginRegistry.discover_and_materialize() before calling this method.</p> Source code in <code>src/sk_agents/tealagents/kernel_builder.py</code> <pre><code>async def load_mcp_plugins(\n    self,\n    kernel: Kernel,\n    user_id: str,\n    session_id: str,\n    mcp_discovery_manager,\n    connection_manager,\n) -&gt; Kernel:\n    \"\"\"\n    Load MCP plugins by instantiating McpPlugin directly with tools from storage.\n\n    This loads tools discovered at session start and creates McpPlugin instances\n    for each MCP server. Only tools that the user has authenticated to access\n    will be loaded, ensuring proper multi-tenant isolation at the session level.\n\n    Args:\n        kernel: The kernel to add plugins to\n        user_id: User ID to get plugins for (required)\n        session_id: Session ID for plugin isolation (required)\n        mcp_discovery_manager: Discovery manager for loading tool state (required)\n        connection_manager: Request-scoped connection manager for connection reuse (required)\n\n    Returns:\n        The kernel with session's MCP plugins loaded\n\n    Note: MCP tools must be discovered first via McpPluginRegistry.discover_and_materialize()\n    before calling this method.\n    \"\"\"\n    if not user_id:\n        raise ValueError(\"user_id is required when loading MCP plugins\")\n    if not session_id:\n        raise ValueError(\"session_id is required when loading MCP plugins\")\n    if not mcp_discovery_manager:\n        raise ValueError(\"mcp_discovery_manager is required when loading MCP plugins\")\n    if not connection_manager:\n        raise ValueError(\"connection_manager is required when loading MCP plugins\")\n\n    try:\n        from sk_agents.mcp_client import McpPlugin\n        from sk_agents.mcp_plugin_registry import McpPluginRegistry\n\n        # Get tools for THIS session (session-level isolation)\n        server_tools = await McpPluginRegistry.get_tools_for_session(\n            user_id, session_id, mcp_discovery_manager\n        )\n\n        if not server_tools:\n            self.logger.debug(f\"No MCP tools found for user {user_id}, session {session_id}\")\n            return kernel\n\n        # Instantiate McpPlugin directly for each server\n        for server_name, tools in server_tools.items():\n            plugin_instance = McpPlugin(\n                tools=tools,\n                server_name=server_name,\n                user_id=user_id,\n                connection_manager=connection_manager,\n                authorization=self.authorization,\n                extra_data_collector=None,\n            )\n\n            # Register with kernel\n            # Sanitize server name: SK requires plugin names to match ^[0-9A-Za-z_]+\n            sanitized_server_name = server_name.replace(\"-\", \"_\").replace(\".\", \"_\")\n            kernel.add_plugin(plugin_instance, f\"mcp_{sanitized_server_name}\")\n            self.logger.info(\n                f\"Loaded MCP plugin for {server_name} as mcp_{sanitized_server_name} \"\n                f\"(user: {user_id}, session: {session_id})\"\n            )\n\n        self.logger.info(\n            f\"Loaded {len(server_tools)} MCP plugins for user {user_id}, session {session_id}\"\n        )\n        return kernel\n\n    except Exception as e:\n        self.logger.exception(\n            f\"Could not load MCP plugins for user {user_id}, session {session_id}. - {e}\"\n        )\n        raise\n</code></pre> <code></code> sk_agents.tealagents.models <code></code> sk_agents.tealagents.models.AuthChallengeResponse <p>               Bases: <code>BaseModel</code></p> <p>Response when MCP server authentication is required before agent construction.</p> Source code in <code>src/sk_agents/tealagents/models.py</code> <pre><code>class AuthChallengeResponse(BaseModel):\n    \"\"\"Response when MCP server authentication is required before agent construction.\"\"\"\n\n    task_id: str\n    session_id: str\n    request_id: str\n    message: str = \"Authentication required for MCP servers.\"\n    auth_challenges: list[dict]  # List of auth challenge details per server\n    resume_url: str  # URL to resume agent flow after auth completion\n</code></pre> <code></code> sk_agents.tealagents.models.TaskStatus <p>               Bases: <code>Enum</code></p> <p>Enum representing the status of a task</p> Source code in <code>src/sk_agents/tealagents/models.py</code> <pre><code>class TaskStatus(Enum):\n    \"\"\"Enum representing the status of a task\"\"\"\n\n    RUNNING = \"Running\"\n    PAUSED = \"Paused\"\n    COMPLETED = \"Completed\"\n    FAILED = \"Failed\"\n</code></pre> <code></code> sk_agents.tealagents.v1alpha1 <code></code> sk_agents.tealagents.v1alpha1.agent <code></code> sk_agents.tealagents.v1alpha1.agent.handler <code></code> sk_agents.tealagents.v1alpha1.agent.handler.TealAgentsV1Alpha1Handler <p>               Bases: <code>BaseHandler</code></p> Source code in <code>src/sk_agents/tealagents/v1alpha1/agent/handler.py</code> <pre><code>class TealAgentsV1Alpha1Handler(BaseHandler):\n    def __init__(\n        self,\n        config: BaseConfig,\n        app_config: AppConfig,\n        agent_builder: AgentBuilder,\n        state_manager: TaskPersistenceManager,\n        discovery_manager=None,  # McpStateManager - Optional, only needed for MCP\n    ):\n        self.version = config.version\n        self.name = config.name\n        self.app_config = app_config\n        if hasattr(config, \"spec\"):\n            self.config = Config(config=config)\n        else:\n            raise ValueError(\"Invalid config\")\n        self.agent_builder = agent_builder\n        self.state = state_manager\n        self.authorizer = DummyAuthorizer()\n        self.discovery_manager = discovery_manager  # Store discovery manager (optional)\n\n        # Track which sessions have seen MCP auth status messages (to show only once per session)\n        self._mcp_status_shown_per_session: set[str] = set()\n\n    async def _create_mcp_connection_manager(self, user_id: str, session_id: str):\n        \"\"\"\n        Create a request-scoped MCP connection manager if MCP servers are configured.\n\n        The connection manager provides:\n        - Lazy connection establishment (connect on first tool call per server)\n        - Connection reuse within the request (all tools share connections)\n        - Automatic cleanup at request end\n        - Session ID persistence for cross-request continuity\n\n        Args:\n            user_id: User ID for authentication\n            session_id: Session ID for session-level scoping\n\n        Returns:\n            McpConnectionManager if MCP servers configured, None otherwise\n        \"\"\"\n        mcp_servers = self.config.get_agent().mcp_servers\n        if not mcp_servers or not self.discovery_manager:\n            return None\n\n        try:\n            from sk_agents.mcp_client import McpConnectionManager\n\n            # Build server configs dict keyed by server name\n            server_configs = {server.name: server for server in mcp_servers}\n\n            return McpConnectionManager(\n                server_configs=server_configs,\n                user_id=user_id,\n                session_id=session_id,\n                state_manager=self.discovery_manager,\n                app_config=self.app_config,\n            )\n        except Exception as e:\n            logger.warning(\n                f\"Failed to create MCP connection manager: {e}. \"\n                \"Falling back to per-tool connections.\"\n            )\n            return None\n\n    async def _ensure_session_discovery(\n        self, user_id: str, session_id: str, task_id: str, request_id: str\n    ) -&gt; AuthChallengeResponse | None:\n        \"\"\"\n        Ensure MCP tool discovery has been performed for this session.\n\n        Discovery happens once per (user_id, session_id) when first detected.\n        All tasks in the session share the discovered tools.\n\n        Args:\n            user_id: User ID for authentication\n            session_id: Session ID for session-level scoping\n            task_id: Task ID for auth challenge response\n            request_id: Request ID for auth challenge response\n\n        Returns:\n            AuthChallengeResponse if authentication is required, None if discovery complete\n        \"\"\"\n        # Early return if no discovery manager (no MCP servers configured)\n        if not self.discovery_manager:\n            return None\n\n        # Check if discovery already completed for this session\n        is_completed = await self.discovery_manager.is_completed(user_id, session_id)\n        if is_completed:\n            logger.debug(f\"MCP discovery already completed for session: {session_id}\")\n            return None\n\n        # Load or create discovery state\n        discovery_state = await self.discovery_manager.load_discovery(user_id, session_id)\n        if not discovery_state:\n            from sk_agents.mcp_discovery.mcp_discovery_manager import McpState\n\n            discovery_state = McpState(\n                user_id=user_id,\n                session_id=session_id,\n                discovered_servers={},\n                discovery_completed=False,\n            )\n            await self.discovery_manager.create_discovery(discovery_state)\n            logger.info(f\"Created discovery state for session: {session_id}\")\n\n        # Check if MCP servers configured\n        mcp_servers = self.config.get_agent().mcp_servers\n        if not mcp_servers or len(mcp_servers) == 0:\n            await self.discovery_manager.mark_completed(user_id, session_id)\n            return None\n\n        try:\n            from sk_agents.mcp_client import AuthRequiredError\n            from sk_agents.mcp_plugin_registry import McpPluginRegistry\n\n            logger.info(\n                f\"Starting MCP discovery for session {session_id} ({len(mcp_servers)} servers)\"\n            )\n\n            await McpPluginRegistry.discover_and_materialize(\n                mcp_servers, user_id, session_id, self.discovery_manager, self.app_config\n            )\n\n            await self.discovery_manager.mark_completed(user_id, session_id)\n            logger.info(f\"MCP discovery completed for session {session_id}\")\n            return None\n\n        except AuthRequiredError as e:\n            # Auth required - return challenge\n            logger.info(\n                f\"MCP discovery requires authentication for '{e.server_name}' \"\n                f\"(session: {session_id})\"\n            )\n\n            try:\n                # Find server config\n                server_config = next((s for s in mcp_servers if s.name == e.server_name), None)\n                if not server_config:\n                    raise ValueError(f\"Server config not found for '{e.server_name}'\")\n\n                # Initiate OAuth 2.1 authorization flow with PKCE\n                from sk_agents.auth.oauth_client import OAuthClient\n\n                oauth_client = OAuthClient()\n\n                # Generate authorization URL with PKCE\n                auth_url = await oauth_client.initiate_authorization_flow(\n                    server_config=server_config, user_id=user_id\n                )\n\n                logger.info(f\"Generated OAuth authorization URL for {e.server_name}\")\n\n                return AuthChallengeResponse(\n                    task_id=task_id,\n                    session_id=session_id,\n                    request_id=request_id,\n                    message=f\"Authentication required for MCP server '{e.server_name}'.\",\n                    auth_challenges=[\n                        {\n                            \"server_name\": e.server_name,\n                            \"auth_server\": e.auth_server,\n                            \"scopes\": e.scopes,\n                            \"auth_url\": auth_url,\n                        }\n                    ],\n                    resume_url=\"/tealagents/v1alpha1/invoke\",\n                )\n\n            except Exception as oauth_error:\n                logger.error(f\"Failed to initiate OAuth flow: {oauth_error}\")\n                return AuthChallengeResponse(\n                    task_id=task_id,\n                    session_id=session_id,\n                    request_id=request_id,\n                    message=f\"Authentication required for MCP server '{e.server_name}'.\",\n                    auth_challenges=[\n                        {\n                            \"server_name\": e.server_name,\n                            \"auth_server\": e.auth_server,\n                            \"scopes\": e.scopes,\n                            \"auth_url\": f\"{e.auth_server}/authorize?error=oauth_client_failed\",\n                        }\n                    ],\n                    resume_url=\"/tealagents/v1alpha1/invoke\",\n                )\n\n        except Exception as e:\n            logger.error(f\"MCP discovery failed for session {session_id}: {e}\")\n            raise\n\n    @staticmethod\n    async def _invoke_function(\n        kernel: Kernel, fc_content: FunctionCallContent\n    ) -&gt; FunctionResultContent:\n        \"\"\"Helper to execute a single tool function call.\"\"\"\n        function = kernel.get_function(\n            fc_content.plugin_name,\n            fc_content.function_name,\n        )\n        kernel_argument = fc_content.to_kernel_arguments()\n        function_result = await function.invoke(kernel, kernel_argument)\n        return FunctionResultContent.from_function_call_content_and_result(\n            fc_content, function_result\n        )\n\n    @staticmethod\n    def _augment_with_user_context(inputs: UserMessage, chat_history: ChatHistory) -&gt; None:\n        if inputs.user_context:\n            content = \"The following user context was provided:\\n\"\n            for key, value in inputs.user_context.items():\n                content += f\"  {key}: {value}\\n\"\n            chat_history.add_message(\n                ChatMessageContent(role=AuthorRole.USER, items=[TextContent(text=content)])\n            )\n\n    @staticmethod\n    def _configure_agent_task(\n        session_id: str,\n        user_id: str,\n        task_id: str,\n        role: Literal[\"user\", \"assistant\"],\n        request_id: str,\n        inputs: UserMessage,\n        status: Literal[\"Running\", \"Paused\", \"Completed\", \"Failed\", \"Canceled\"],\n    ) -&gt; AgentTask:\n        agent_items = []\n        for item in inputs.items:\n            task_item = AgentTaskItem(\n                task_id=task_id, role=role, item=item, request_id=request_id, updated=datetime.now()\n            )\n            agent_items.append(task_item)\n\n        agent_task = AgentTask(\n            task_id=task_id,\n            session_id=session_id,\n            user_id=user_id,\n            items=agent_items,\n            created_at=datetime.now(),\n            last_updated=datetime.now(),\n            status=status,\n        )\n        return agent_task\n\n    async def authenticate_user(self, token: str) -&gt; str:\n        try:\n            user_id = await self.authorizer.authorize_request(auth_header=token)\n            return user_id\n        except Exception as e:\n            raise AuthenticationException(\n                message=(f\"Unable to authenticate user, exception message: {e}\")\n            ) from e\n\n    async def authenticate_mcp_servers(\n        self, user_id: str, session_id: str, task_id: str, request_id: str\n    ) -&gt; AuthChallengeResponse | None:\n        \"\"\"\n        Authenticate MCP servers before agent construction.\n\n        Returns AuthChallengeResponse if authentication is needed,\n        None if all servers are authenticated.\n        \"\"\"\n        mcp_servers = self.config.get_agent().mcp_servers\n        if not mcp_servers:\n            return None\n\n        try:\n            from sk_agents.auth_storage.auth_storage_factory import AuthStorageFactory\n            from sk_agents.mcp_client import build_auth_storage_key\n\n            auth_storage_factory = AuthStorageFactory(self.app_config)\n            auth_storage = auth_storage_factory.get_auth_storage_manager()\n\n            missing_auth_servers = []\n\n            for server_config in mcp_servers:\n                if server_config.auth_server and server_config.scopes:\n                    # Check if we have valid auth for this server\n                    composite_key = build_auth_storage_key(\n                        server_config.auth_server, server_config.scopes\n                    )\n                    auth_data = auth_storage.retrieve(user_id, composite_key)\n\n                    if not auth_data:\n                        # Missing authentication for this server\n                        scope_param = \"%20\".join(server_config.scopes)\n                        auth_challenge = {\n                            \"server_name\": server_config.name,\n                            \"auth_server\": server_config.auth_server,\n                            \"scopes\": server_config.scopes,\n                            \"auth_url\": (\n                                f\"{server_config.auth_server}/authorize?\"\n                                f\"client_id=teal_agents&amp;scope={scope_param}&amp;response_type=code\"\n                            ),\n                        }\n                        missing_auth_servers.append(auth_challenge)\n\n            if missing_auth_servers:\n                num_servers = len(missing_auth_servers)\n                return AuthChallengeResponse(\n                    task_id=task_id,\n                    session_id=session_id,\n                    request_id=request_id,\n                    message=f\"Authentication required for {num_servers} MCP server(s).\",\n                    auth_challenges=missing_auth_servers,\n                    resume_url=f\"/tealagents/v1alpha1/resume/{request_id}\",\n                )\n\n            return None\n\n        except Exception as e:\n            logger.warning(f\"Error during MCP server authentication check: {e}\")\n            # Continue without MCP auth if there are issues with auth storage\n            return None\n\n    @staticmethod\n    def handle_state_id(inputs: UserMessage) -&gt; tuple[str, str, str]:\n        if inputs.session_id:\n            session_id = inputs.session_id\n        else:\n            session_id = str(uuid.uuid4())\n\n        if inputs.task_id:\n            task_id = inputs.task_id\n        else:\n            task_id = str(uuid.uuid4())\n\n        request_id = str(uuid.uuid4())\n\n        return session_id, task_id, request_id\n\n    async def _manage_incoming_task(\n        self, task_id: str, session_id: str, user_id: str, request_id: str, inputs: UserMessage\n    ) -&gt; AgentTask | None:\n        try:\n            agent_task = await self.state.load(task_id)\n            if not agent_task:\n                agent_task = TealAgentsV1Alpha1Handler._configure_agent_task(\n                    session_id=session_id,\n                    user_id=user_id,\n                    task_id=task_id,\n                    role=\"user\",\n                    request_id=request_id,\n                    inputs=inputs,\n                    status=\"Running\",\n                )\n                await self.state.create(agent_task)\n                return agent_task\n        except (PersistenceLoadError, PersistenceCreateError) as e:\n            raise AgentInvokeException(\n                f\"Failed to load or create task {task_id}: {e.message}\"\n            ) from e\n        except Exception as e:\n            raise AgentInvokeException(\n                f\"Unexpected error occurred while managing incoming task {task_id}: {str(e)}\"\n            ) from e\n\n    async def _manage_agent_response_task(\n        self, agent_task: AgentTask, agent_response: TealAgentsResponse\n    ) -&gt; None:\n        new_item = AgentTaskItem(\n            task_id=agent_response.task_id,\n            role=\"assistant\",\n            item=MultiModalItem(content_type=ContentType.TEXT, content=agent_response.output),\n            request_id=agent_response.request_id,\n            updated=datetime.now(),\n        )\n        agent_task.items.append(new_item)\n        agent_task.last_updated = datetime.now()\n        await self.state.update(agent_task)\n\n    @staticmethod\n    def _validate_user_id(user_id: str, task_id: str, agent_task: AgentTask) -&gt; None:\n        try:\n            assert user_id == agent_task.user_id\n        except AssertionError as e:\n            raise AgentInvokeException(\n                message=(f\"Invalid user ID {user_id}and task ID {task_id} provided. {e}\")\n            ) from e\n\n    @staticmethod\n    def _build_chat_history(agent_task: AgentTask, chat_history: ChatHistory) -&gt; ChatHistory:\n        chat_message_items: list[TextContent | ImageContent] = []\n        for task_item in agent_task.items:\n            chat_message_items.append(item_to_content(task_item.item))\n            message_content = ChatMessageContent(role=task_item.role, items=chat_message_items)\n            chat_history.add_message(message_content)\n        return chat_history\n\n    @staticmethod\n    def _rejected_task_item(task_id: str, request_id: str) -&gt; AgentTaskItem:\n        return AgentTaskItem(\n            task_id=task_id,\n            role=\"user\",\n            item=MultiModalItem(content_type=ContentType.TEXT, content=\"tool execution rejected\"),\n            request_id=request_id,\n            updated=datetime.now(),\n        )\n\n    @staticmethod\n    def _approved_task_item(task_id: str, request_id: str) -&gt; AgentTaskItem:\n        return AgentTaskItem(\n            task_id=task_id,\n            role=\"user\",\n            item=MultiModalItem(content_type=ContentType.TEXT, content=\"tool execution approved\"),\n            request_id=request_id,\n            updated=datetime.now(),\n        )\n\n    async def _manage_hitl_exception(\n        self,\n        agent_task: AgentTask,\n        session_id: str,\n        task_id: str,\n        request_id: str,\n        function_calls: list,\n        chat_history: ChatHistory,\n    ):\n        agent_task.status = \"Paused\"\n        assistant_item = AgentTaskItem(\n            task_id=task_id,\n            role=\"assistant\",\n            item=MultiModalItem(\n                content_type=ContentType.TEXT, content=\"HITL intervention required.\"\n            ),\n            request_id=request_id,\n            updated=datetime.now(),\n            pending_tool_calls=[fc.model_dump() for fc in function_calls],\n            chat_history=chat_history,\n        )\n        agent_task.items.append(assistant_item)\n        agent_task.last_updated = datetime.now()\n        await self.state.update(agent_task)\n\n        base_url = \"/tealagents/v1alpha1/resume\"\n        approval_url = f\"{base_url}/{request_id}?action=approve\"\n        rejection_url = f\"{base_url}/{request_id}?action=reject\"\n\n        hitl_response = HitlResponse(\n            session_id=session_id,\n            task_id=task_id,\n            request_id=request_id,\n            tool_calls=[fc.model_dump() for fc in function_calls],\n            approval_url=approval_url,\n            rejection_url=rejection_url,\n        )\n        return hitl_response\n\n    @staticmethod\n    async def _manage_function_calls(\n        function_calls: list[FunctionCallContent], chat_history: ChatHistory, kernel: Kernel\n    ) -&gt; None:\n        intervention_calls = []\n        non_intervention_calls = []\n\n        # Separate function calls into intervention and non-intervention\n        for fc in function_calls:\n            if hitl_manager.check_for_intervention(fc):\n                intervention_calls.append(fc)\n            else:\n                non_intervention_calls.append(fc)\n\n        # Process non-intervention function calls first\n        if non_intervention_calls:\n            results = await asyncio.gather(\n                *[\n                    TealAgentsV1Alpha1Handler._invoke_function(kernel, fc)\n                    for fc in non_intervention_calls\n                ]\n            )\n\n            # Add results to history\n            for result in results:\n                chat_history.add_message(result.to_chat_message_content())\n\n        # Handle intervention function calls\n        if intervention_calls:\n            logger.info(f\"Intervention required for{len(intervention_calls)} function calls.\")\n            raise hitl_manager.HitlInterventionRequired(intervention_calls)\n\n    async def prepare_agent_response(\n        self,\n        agent_task: AgentTask,\n        request_id: str,\n        response: ChatMessageContent | list[str],\n        token_usage: TokenUsage,\n        extra_data_collector: ExtraDataCollector,\n    ):\n        if isinstance(response, list):\n            agent_output = \"\".join(response)\n        else:\n            agent_output = response.content\n\n        total_tokens = token_usage.total_tokens\n        session_id = agent_task.session_id\n        task_id = agent_task.task_id\n        request_id = request_id\n\n        agent_response = TealAgentsResponse(\n            session_id=session_id,\n            task_id=task_id,\n            request_id=request_id,\n            output=agent_output,\n            source=f\"{self.name}:{self.version}\",\n            token_usage=token_usage,\n            extra_data=extra_data_collector.get_extra_data(),\n        )\n        await self._manage_agent_response_task(agent_task, agent_response)\n        logger.info(\n            f\"{self.name}:{self.version}\"\n            f\"successful invocation with {total_tokens} tokens. \"\n            f\"Session ID: {session_id}, Task ID: {task_id},\"\n            f\"Request ID {request_id}\"\n        )\n        return agent_response\n\n    async def resume_task(\n        self, auth_token: str, request_id: str, action_status: ResumeRequest, stream: bool\n    ) -&gt; (\n        TealAgentsResponse\n        | RejectedToolResponse\n        | HitlResponse\n        | AsyncIterable[TealAgentsResponse | TealAgentsPartialResponse | HitlResponse]\n    ):\n        user_id = await self.authenticate_user(token=auth_token)\n        agent_task = await self.state.load_by_request_id(request_id)\n        if agent_task is None:\n            raise AgentInvokeException(f\"No agent task found for request ID: {request_id}\")\n\n        # Validate task has items\n        if not agent_task.items:\n            raise AgentInvokeException(\n                f\"Cannot resume task {request_id}: task has no items. \"\n                f\"Task may be corrupted or improperly initialized.\"\n            )\n\n        session_id = agent_task.session_id\n        task_id = agent_task.task_id\n\n        # Retrieve chat history from last item with validation\n        last_item = agent_task.items[-1]\n        if last_item.chat_history is None:\n            raise AgentInvokeException(\n                f\"Cannot resume task {request_id}: chat history not preserved in paused state. \"\n                f\"This indicates a persistence layer issue during HITL pause.\"\n            )\n        chat_history = last_item.chat_history\n\n        TealAgentsV1Alpha1Handler._validate_user_id(user_id, task_id, agent_task)\n\n        # Validate task is in correct state for resumption\n        if agent_task.status != \"Paused\":\n            raise AgentInvokeException(\n                f\"Cannot resume task {task_id}: task is in '{agent_task.status}' state, \"\n                f\"expected 'Paused'. Task may have already been processed or cancelled.\"\n            )\n\n        if action_status.action != \"approve\":\n            agent_task.status = \"Canceled\"\n            agent_task.items.append(\n                TealAgentsV1Alpha1Handler._rejected_task_item(\n                    task_id=task_id, request_id=request_id\n                )\n            )\n            agent_task.last_updated = datetime.now()\n            await self.state.update(agent_task)\n\n            return RejectedToolResponse(\n                task_id=task_id, session_id=agent_task.session_id, request_id=request_id\n            )\n        # Record Approval state\n        agent_task.status = \"Running\"\n        agent_task.items.append(\n            TealAgentsV1Alpha1Handler._approved_task_item(\n                task_id=agent_task.task_id, request_id=request_id\n            )\n        )\n        agent_task.last_updated = datetime.now()\n        await self.state.update(agent_task)\n\n        # Retrieve the pending_tool_calls from the last AgentTaskItem before approval/rejection item\n        # Validate sufficient items exist\n        if len(agent_task.items) &lt; 2:\n            raise AgentInvokeException(\n                f\"Invalid task state for request ID {request_id}: \"\n                f\"expected at least 2 task items for HITL resume, found {len(agent_task.items)}\"\n            )\n\n        pending_tools_item = agent_task.items[-2]\n        if not pending_tools_item.pending_tool_calls:\n            raise AgentInvokeException(\n                f\"Pending tool calls not found for request ID: {request_id}. \"\n                f\"Task item at index -2 has no pending tool calls.\"\n            )\n\n        _pending_tools = list(pending_tools_item.pending_tool_calls)\n        pending_tools = [FunctionCallContent(**function_call) for function_call in _pending_tools]\n\n        # Create request-scoped connection manager for MCP connection reuse\n        connection_manager = await self._create_mcp_connection_manager(user_id, session_id)\n\n        async def _execute_resume(conn_mgr=None):\n            # Execute the tool calls using asyncio.gather(),\n            # just as the agent would have.\n            extra_data_collector = ExtraDataCollector()\n            agent = await self.agent_builder.build_agent(\n                self.config.get_agent(), extra_data_collector, user_id=user_id\n            )\n\n            # Load MCP plugins after agent construction (per-session isolation)\n            # connection_manager is required for MCP plugin loading\n            if self.config.get_agent().mcp_servers and self.discovery_manager and conn_mgr:\n                await self.agent_builder.kernel_builder.load_mcp_plugins(\n                    agent.agent.kernel, user_id, session_id, self.discovery_manager, conn_mgr\n                )\n\n            kernel = agent.agent.kernel\n\n            # Create ToolContent objects from the results\n            results = await asyncio.gather(\n                *[TealAgentsV1Alpha1Handler._invoke_function(kernel, fc) for fc in pending_tools]\n            )\n            # Add results to chat history\n            for result in results:\n                chat_history.add_message(result.to_chat_message_content())\n\n            if stream:\n                final_response_stream = self.recursion_invoke_stream(\n                    chat_history, session_id, task_id, request_id, connection_manager=conn_mgr\n                )\n                return final_response_stream\n            else:\n                final_response_invoke = await self.recursion_invoke(\n                    inputs=chat_history,\n                    session_id=session_id,\n                    request_id=request_id,\n                    task_id=task_id,\n                    connection_manager=conn_mgr,\n                )\n                return final_response_invoke\n\n        if connection_manager:\n            async with connection_manager:\n                return await _execute_resume(connection_manager)\n        else:\n            return await _execute_resume()\n\n    async def invoke(\n        self, auth_token: str, inputs: UserMessage\n    ) -&gt; TealAgentsResponse | HitlResponse | AuthChallengeResponse:\n        # Initial setup\n        logger.info(\"Beginning processing invoke\")\n\n        user_id = await self.authenticate_user(token=auth_token)\n\n        # Generate state IDs first (needed for auth challenges)\n        state_ids = TealAgentsV1Alpha1Handler.handle_state_id(inputs)\n        session_id, task_id, request_id = state_ids\n        inputs.session_id = session_id\n        inputs.task_id = task_id\n\n        # Ensure MCP discovery has been performed for this session\n        # May return AuthChallengeResponse if auth required during discovery\n        discovery_auth_challenge = await self._ensure_session_discovery(\n            user_id, session_id, task_id, request_id\n        )\n        if discovery_auth_challenge:\n            logger.info(\"Returning auth challenge from MCP discovery\")\n            return discovery_auth_challenge\n\n        agent_task = await self._manage_incoming_task(\n            task_id, session_id, user_id, request_id, inputs\n        )\n        if agent_task is None:\n            raise AgentInvokeException(\"Agent task not created\")\n        # Check user_id match request and state\n        TealAgentsV1Alpha1Handler._validate_user_id(user_id, task_id, agent_task)\n\n        # Check MCP server authentication before agent construction\n        auth_challenge = await self.authenticate_mcp_servers(\n            user_id, session_id, task_id, request_id\n        )\n        if auth_challenge:\n            logger.info(\n                f\"MCP authentication required for {len(auth_challenge.auth_challenges)} server(s)\"\n            )\n            return auth_challenge\n\n        chat_history = ChatHistory()\n        TealAgentsV1Alpha1Handler._augment_with_user_context(\n            inputs=inputs, chat_history=chat_history\n        )\n        TealAgentsV1Alpha1Handler._build_chat_history(agent_task, chat_history)\n        logger.info(\"Building the final response\")\n\n        # Create request-scoped connection manager for MCP connection reuse\n        connection_manager = await self._create_mcp_connection_manager(user_id, session_id)\n        if connection_manager:\n            async with connection_manager:\n                final_response_invoke = await self.recursion_invoke(\n                    inputs=chat_history,\n                    session_id=session_id,\n                    request_id=request_id,\n                    task_id=task_id,\n                    connection_manager=connection_manager,\n                )\n        else:\n            final_response_invoke = await self.recursion_invoke(\n                inputs=chat_history, session_id=session_id, request_id=request_id, task_id=task_id\n            )\n        logger.info(\"Final response complete\")\n\n        return final_response_invoke\n\n    async def invoke_stream(\n        self, auth_token: str, inputs: UserMessage\n    ) -&gt; AsyncIterable[\n        TealAgentsResponse | TealAgentsPartialResponse | HitlResponse | AuthChallengeResponse\n    ]:\n        # Initial setup\n        logger.info(\"Beginning processing invoke\")\n        user_id = await self.authenticate_user(token=auth_token)\n\n        # Generate state IDs first (needed for auth challenges)\n        state_ids = TealAgentsV1Alpha1Handler.handle_state_id(inputs)\n        session_id, task_id, request_id = state_ids\n\n        # Ensure MCP discovery has been performed for this session\n        # May return AuthChallengeResponse if auth required during discovery\n        discovery_auth_challenge = await self._ensure_session_discovery(\n            user_id, session_id, task_id, request_id\n        )\n        if discovery_auth_challenge:\n            logger.info(\"Returning auth challenge from MCP discovery\")\n            yield discovery_auth_challenge\n            return\n\n        # Notify user that MCP is ready (only once per session, after discovery)\n        mcp_servers = self.config.get_agent().mcp_servers\n        show_status = session_id not in self._mcp_status_shown_per_session\n\n        if show_status and mcp_servers and len(mcp_servers) &gt; 0:\n            # Load state to check for failures\n            failed_servers = {}\n            if self.discovery_manager:\n                try:\n                    state = await self.discovery_manager.load_discovery(user_id, session_id)\n                    if state:\n                        failed_servers = state.failed_servers\n                except Exception:\n                    logger.debug(\"Failed to load discovery state for status message\")\n\n            all_server_names = [server.name for server in mcp_servers]\n            successful_servers = [s for s in all_server_names if s not in failed_servers]\n\n            messages = []\n            if successful_servers:\n                messages.append(f\"\u2705 MCP connected: {', '.join(successful_servers)}\")\n\n            if failed_servers:\n                failed_list = []\n                for name, error in failed_servers.items():\n                    # Truncate error if too long\n                    short_error = (error[:50] + \"...\") if len(error) &gt; 50 else error\n                    failed_list.append(f\"{name} ({short_error})\")\n                messages.append(f\"\u26a0\ufe0f MCP connection failed: {', '.join(failed_list)}\")\n\n            status_msg = \"\\n\".join(messages) + \"\\n\\n\"\n\n            yield TealAgentsPartialResponse(\n                task_id=task_id,\n                session_id=session_id,\n                request_id=request_id,\n                output_partial=status_msg,\n            )\n            # Mark this session as having seen the status message\n            self._mcp_status_shown_per_session.add(session_id)\n\n        agent_task = await self._manage_incoming_task(\n            task_id, session_id, user_id, request_id, inputs\n        )\n        if agent_task is None:\n            raise AgentInvokeException(\"Agent task not created\")\n        # Check user_id match request and state\n        TealAgentsV1Alpha1Handler._validate_user_id(user_id, task_id, agent_task)\n\n        # Check MCP server authentication before agent construction\n        auth_challenge = await self.authenticate_mcp_servers(\n            user_id, session_id, task_id, request_id\n        )\n        if auth_challenge:\n            logger.info(\n                f\"MCP authentication required for {len(auth_challenge.auth_challenges)} server(s)\"\n            )\n            yield auth_challenge\n            return\n\n        chat_history = ChatHistory()\n        TealAgentsV1Alpha1Handler._augment_with_user_context(\n            inputs=inputs, chat_history=chat_history\n        )\n        logger.info(\"Building the final response\")\n        TealAgentsV1Alpha1Handler._build_chat_history(agent_task, chat_history)\n\n        # Create request-scoped connection manager for MCP connection reuse\n        connection_manager = await self._create_mcp_connection_manager(user_id, session_id)\n        if connection_manager:\n            async with connection_manager:\n                async for response_chunk in self.recursion_invoke_stream(\n                    chat_history,\n                    session_id,\n                    task_id,\n                    request_id,\n                    connection_manager=connection_manager,\n                ):\n                    yield response_chunk\n        else:\n            async for response_chunk in self.recursion_invoke_stream(\n                chat_history, session_id, task_id, request_id\n            ):\n                yield response_chunk\n\n        logger.info(\"Final response complete\")\n\n    async def recursion_invoke(\n        self,\n        inputs: ChatHistory,\n        session_id: str,\n        task_id: str,\n        request_id: str,\n        connection_manager=None,\n    ) -&gt; TealAgentsResponse | HitlResponse:\n        # Initial setup\n\n        chat_history = inputs\n        agent_task = await self.state.load_by_request_id(request_id)\n        if not agent_task:\n            raise PersistenceLoadError(f\"Agent task with ID {task_id} not found in state.\")\n\n        user_id = agent_task.user_id\n        extra_data_collector = ExtraDataCollector()\n        agent = await self.agent_builder.build_agent(\n            self.config.get_agent(), extra_data_collector, user_id=user_id\n        )\n\n        # Load MCP plugins after agent construction (per-session isolation)\n        # connection_manager is required for MCP plugin loading\n        if self.config.get_agent().mcp_servers and self.discovery_manager and connection_manager:\n            await self.agent_builder.kernel_builder.load_mcp_plugins(\n                agent.agent.kernel, user_id, session_id, self.discovery_manager, connection_manager\n            )\n\n        # Prepare metadata\n        completion_tokens: int = 0\n        prompt_tokens: int = 0\n        total_tokens: int = 0\n\n        try:\n            # Manual tool calling implementation (existing logic)\n            kernel = agent.agent.kernel\n            arguments = agent.agent.arguments\n            chat_completion_service, settings = kernel.select_ai_service(\n                arguments=arguments, type=ChatCompletionClientBase\n            )\n\n            assert isinstance(chat_completion_service, ChatCompletionClientBase)\n\n            # Initial call to the LLM\n            response_list = []\n            responses = await chat_completion_service.get_chat_message_contents(\n                chat_history=chat_history,\n                settings=settings,\n                kernel=kernel,\n                arguments=arguments,\n            )\n            for response_chunk in responses:\n                # response_list.extend(response_chunk)\n                chat_history.add_message(response_chunk)\n                response_list.append(response_chunk)\n\n            function_calls = []\n            final_response = None\n\n            # Separate content and tool calls\n            for response in response_list:\n                # Update token usage\n                call_usage = get_token_usage_for_response(agent.get_model_type(), response)\n                completion_tokens += call_usage.completion_tokens\n                prompt_tokens += call_usage.prompt_tokens\n                total_tokens += call_usage.total_tokens\n\n                # A response may have multiple items, e.g., multiple tool calls\n                fc_in_response = [\n                    item for item in response.items if isinstance(item, FunctionCallContent)\n                ]\n\n                if fc_in_response:\n                    # chat_history.add_message(response)\n                    # Add assistant's message to history\n                    function_calls.extend(fc_in_response)\n                else:\n                    # If no function calls, it's a direct answer\n                    final_response = response\n            token_usage = TokenUsage(\n                completion_tokens=completion_tokens,\n                prompt_tokens=prompt_tokens,\n                total_tokens=total_tokens,\n            )\n            # If tool calls were returned, execute them\n            if function_calls:\n                await self._manage_function_calls(function_calls, chat_history, kernel)\n\n                # Make a recursive call to get the final response from the LLM\n                recursive_response = await self.recursion_invoke(\n                    inputs=chat_history,\n                    session_id=session_id,\n                    task_id=task_id,\n                    request_id=request_id,\n                    connection_manager=connection_manager,\n                )\n                return recursive_response\n\n            # No tool calls, return the direct response\n            if final_response is None:\n                error_msg = (\n                    f\"No response received from LLM for Session ID {session_id}, \"\n                    f\"Task ID {task_id}, Request ID {request_id}. \"\n                    f\"Function calls processed: {len(function_calls)}\"\n                )\n                logger.error(error_msg)\n                raise AgentInvokeException(error_msg)\n        except hitl_manager.HitlInterventionRequired as hitl_exc:\n            return await self._manage_hitl_exception(\n                agent_task, session_id, task_id, request_id, hitl_exc.function_calls, chat_history\n            )\n\n        except Exception as e:\n            logger.exception(\n                f\"Error invoking {self.name}:{self.version}\"\n                f\"for Session ID {session_id}, Task ID {task_id},\"\n                f\"Request ID {request_id}, Error message: {str(e)}\",\n                exc_info=True,\n            )\n            raise AgentInvokeException(\n                f\"Error invoking {self.name}:{self.version}\"\n                f\"for Session ID {session_id}, Task ID {task_id},\"\n                f\" Request ID {request_id}, Error message: {str(e)}\"\n            ) from e\n\n        # Persist and return response\n        return await self.prepare_agent_response(\n            agent_task, request_id, final_response, token_usage, extra_data_collector\n        )\n\n    async def recursion_invoke_stream(\n        self,\n        inputs: ChatHistory,\n        session_id: str,\n        task_id: str,\n        request_id: str,\n        connection_manager=None,\n    ) -&gt; AsyncIterable[TealAgentsResponse | TealAgentsPartialResponse | HitlResponse]:\n        chat_history = inputs\n        agent_task = await self.state.load_by_request_id(request_id)\n        if not agent_task:\n            raise PersistenceLoadError(f\"Agent task with ID {task_id} not found in state.\")\n\n        user_id = agent_task.user_id\n        extra_data_collector = ExtraDataCollector()\n        agent = await self.agent_builder.build_agent(\n            self.config.get_agent(), extra_data_collector, user_id=user_id\n        )\n\n        # Load MCP plugins after agent construction (per-session isolation)\n        # connection_manager is required for MCP plugin loading\n        if self.config.get_agent().mcp_servers and self.discovery_manager and connection_manager:\n            await self.agent_builder.kernel_builder.load_mcp_plugins(\n                agent.agent.kernel, user_id, session_id, self.discovery_manager, connection_manager\n            )\n\n        # Prepare metadata\n        final_response = []\n        completion_tokens: int = 0\n        prompt_tokens: int = 0\n        total_tokens: int = 0\n\n        try:\n            kernel = agent.agent.kernel\n            arguments = agent.agent.arguments\n            kernel_configs = kernel.select_ai_service(\n                arguments=arguments, type=ChatCompletionClientBase\n            )\n            chat_completion_service, settings = kernel_configs\n            assert isinstance(chat_completion_service, ChatCompletionClientBase)\n\n            all_responses = []\n            # Stream the initial response from the LLM\n            response_list = []\n            responses = await chat_completion_service.get_chat_message_contents(\n                chat_history=chat_history,\n                settings=settings,\n                kernel=kernel,\n                arguments=arguments,\n            )\n            for response_chunk in responses:\n                chat_history.add_message(response_chunk)\n                response_list.append(response_chunk)\n\n            for response in response_list:\n                all_responses.append(response)\n                # Calculate usage metrics\n                call_usage = get_token_usage_for_response(agent.get_model_type(), response)\n                completion_tokens += call_usage.completion_tokens\n                prompt_tokens += call_usage.prompt_tokens\n                total_tokens += call_usage.total_tokens\n\n                if response.content:\n                    try:\n                        # Attempt to parse as ExtraDataPartial\n                        extra_data_partial: ExtraDataPartial = ExtraDataPartial.new_from_json(\n                            response.content\n                        )\n                        extra_data_collector.add_extra_data_items(extra_data_partial.extra_data)\n                    except Exception:\n                        if len(response.content) &gt; 0:\n                            # Handle and return partial response\n                            final_response.append(response.content)\n                            yield TealAgentsPartialResponse(\n                                session_id=session_id,\n                                task_id=task_id,\n                                request_id=request_id,\n                                output_partial=response.content,\n                                source=f\"{self.name}:{self.version}\",\n                            )\n\n            token_usage = TokenUsage(\n                completion_tokens=completion_tokens,\n                prompt_tokens=prompt_tokens,\n                total_tokens=total_tokens,\n            )\n            # Aggregate the full response to check for tool calls\n            if not all_responses:\n                return\n\n            full_completion: StreamingChatMessageContent = reduce(lambda x, y: x + y, all_responses)\n            function_calls = [\n                item for item in full_completion.items if isinstance(item, FunctionCallContent)\n            ]\n\n            # If tool calls are present, execute them\n            if function_calls:\n                await self._manage_function_calls(function_calls, chat_history, kernel)\n                # Make a recursive call to get the final streamed response\n                async for final_response_chunk in self.recursion_invoke_stream(\n                    chat_history,\n                    session_id,\n                    task_id,\n                    request_id,\n                    connection_manager=connection_manager,\n                ):\n                    yield final_response_chunk\n                return\n        except hitl_manager.HitlInterventionRequired as hitl_exc:\n            yield await self._manage_hitl_exception(\n                agent_task, session_id, task_id, request_id, hitl_exc.function_calls, chat_history\n            )\n            return\n\n        except Exception as e:\n            logger.exception(\n                f\"Error invoking stream for {self.name}:{self.version} \"\n                f\"for Session ID {session_id}, Task ID {task_id},\"\n                f\" Request ID {request_id}, Error message: {str(e)}\",\n                exc_info=True,\n            )\n            raise AgentInvokeException(\n                f\"Error invoking stream for {self.name}:{self.version}\"\n                f\"for Session ID {session_id}, Task ID {task_id},\"\n                f\"Request ID {request_id}, Error message: {str(e)}\"\n            ) from e\n\n        # # Persist and return response\n        yield await self.prepare_agent_response(\n            agent_task, request_id, final_response, token_usage, extra_data_collector\n        )\n</code></pre> <code></code> sk_agents.tealagents.v1alpha1.agent.handler.TealAgentsV1Alpha1Handler.authenticate_mcp_servers <code>async</code> <pre><code>authenticate_mcp_servers(\n    user_id: str,\n    session_id: str,\n    task_id: str,\n    request_id: str,\n) -&gt; AuthChallengeResponse | None\n</code></pre> <p>Authenticate MCP servers before agent construction.</p> <p>Returns AuthChallengeResponse if authentication is needed, None if all servers are authenticated.</p> Source code in <code>src/sk_agents/tealagents/v1alpha1/agent/handler.py</code> <pre><code>async def authenticate_mcp_servers(\n    self, user_id: str, session_id: str, task_id: str, request_id: str\n) -&gt; AuthChallengeResponse | None:\n    \"\"\"\n    Authenticate MCP servers before agent construction.\n\n    Returns AuthChallengeResponse if authentication is needed,\n    None if all servers are authenticated.\n    \"\"\"\n    mcp_servers = self.config.get_agent().mcp_servers\n    if not mcp_servers:\n        return None\n\n    try:\n        from sk_agents.auth_storage.auth_storage_factory import AuthStorageFactory\n        from sk_agents.mcp_client import build_auth_storage_key\n\n        auth_storage_factory = AuthStorageFactory(self.app_config)\n        auth_storage = auth_storage_factory.get_auth_storage_manager()\n\n        missing_auth_servers = []\n\n        for server_config in mcp_servers:\n            if server_config.auth_server and server_config.scopes:\n                # Check if we have valid auth for this server\n                composite_key = build_auth_storage_key(\n                    server_config.auth_server, server_config.scopes\n                )\n                auth_data = auth_storage.retrieve(user_id, composite_key)\n\n                if not auth_data:\n                    # Missing authentication for this server\n                    scope_param = \"%20\".join(server_config.scopes)\n                    auth_challenge = {\n                        \"server_name\": server_config.name,\n                        \"auth_server\": server_config.auth_server,\n                        \"scopes\": server_config.scopes,\n                        \"auth_url\": (\n                            f\"{server_config.auth_server}/authorize?\"\n                            f\"client_id=teal_agents&amp;scope={scope_param}&amp;response_type=code\"\n                        ),\n                    }\n                    missing_auth_servers.append(auth_challenge)\n\n        if missing_auth_servers:\n            num_servers = len(missing_auth_servers)\n            return AuthChallengeResponse(\n                task_id=task_id,\n                session_id=session_id,\n                request_id=request_id,\n                message=f\"Authentication required for {num_servers} MCP server(s).\",\n                auth_challenges=missing_auth_servers,\n                resume_url=f\"/tealagents/v1alpha1/resume/{request_id}\",\n            )\n\n        return None\n\n    except Exception as e:\n        logger.warning(f\"Error during MCP server authentication check: {e}\")\n        # Continue without MCP auth if there are issues with auth storage\n        return None\n</code></pre> <code></code> sk_agents.tealagents.v1alpha1.config <code></code> sk_agents.tealagents.v1alpha1.config.McpServerConfig <p>               Bases: <code>BaseModel</code></p> <p>Configuration for an MCP server connection supporting multiple transports.</p> Source code in <code>src/sk_agents/tealagents/v1alpha1/config.py</code> <pre><code>class McpServerConfig(BaseModel):\n    \"\"\"Configuration for an MCP server connection supporting multiple transports.\"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n\n    name: str\n    # Supported transports: stdio for local servers, http for remote servers\n    transport: Literal[\"stdio\", \"http\"] = \"stdio\"\n\n    # Stdio transport fields\n    command: str | None = None\n    args: list[str] = []\n    env: dict[str, str] | None = None\n\n    # HTTP transport fields\n    url: str | None = None\n    headers: dict[str, str] | None = None  # Non-sensitive headers only\n    timeout: float | None = None  # Will be set automatically if not provided\n    sse_read_timeout: float | None = None  # Will be set automatically if not provided\n    verify_ssl: bool = True  # Allow opt-out for dev; defaults to verified SSL\n\n    # Server-level authentication for tool catalog integration\n    auth_server: str | None = None  # OAuth2 authorization server URL\n    scopes: list[str] = []  # Required OAuth2 scopes for this server's tools\n\n    # Tool-specific governance overrides (optional)\n    tool_governance_overrides: dict[str, GovernanceOverride] | None = None\n\n    # Server trust level for additional governance controls\n    trust_level: Literal[\"trusted\", \"sandboxed\", \"untrusted\"] = \"untrusted\"\n\n    # Request-level timeout for individual MCP operations (seconds)\n    request_timeout: float | None = 30.0\n\n    # Optional per-server user header injection (opt-in)\n    user_id_header: str | None = None  # e.g., \"Arcade-User-Id\"\n    user_id_source: Literal[\"auth\", \"env\"] | None = None  # where to read the value\n    user_id_env_var: str | None = None  # env var name when source == \"env\"\n\n    # OAuth 2.1 Configuration (MCP Compliance)\n    oauth_client_id: str | None = None  # Pre-registered OAuth client ID\n    oauth_client_secret: str | None = None  # Client secret (confidential clients only)\n    canonical_uri: str | None = None  # Explicit canonical URI override\n    enable_dynamic_registration: bool = True  # Try RFC7591 dynamic registration\n\n    # MCP Protocol Version (for conditional OAuth parameter inclusion)\n    protocol_version: str | None = None  # MCP protocol version (e.g., \"2025-06-18\")\n\n    # Server Metadata Discovery Configuration (RFC 8414/9728)\n    enable_metadata_discovery: bool = True  # Enable RFC 8414/9728 discovery\n    metadata_cache_ttl: int = 3600  # Metadata cache TTL in seconds (default: 1 hour)\n\n    @property\n    def effective_canonical_uri(self) -&gt; str:\n        \"\"\"\n        Get canonical MCP server URI for resource parameter binding.\n\n        Per MCP spec, canonical URI must be:\n        - Absolute HTTPS URI\n        - Lowercase scheme and host\n        - Optional port and path\n\n        Returns:\n            str: Canonical URI (either explicit or computed from url)\n\n        Raises:\n            ValueError: If cannot determine canonical URI\n        \"\"\"\n        from sk_agents.mcp_client import normalize_canonical_uri\n\n        # Use explicit canonical_uri if provided\n        if self.canonical_uri:\n            return normalize_canonical_uri(self.canonical_uri)\n\n        # Compute from url for HTTP transport\n        if self.transport == \"http\" and self.url:\n            return normalize_canonical_uri(self.url)\n\n        # Stdio transport doesn't need canonical URI (no OAuth)\n        if self.transport == \"stdio\":\n            raise ValueError(\n                f\"Canonical URI not applicable for stdio transport (server: {self.name})\"\n            )\n\n        raise ValueError(\n            f\"Cannot determine canonical URI for server '{self.name}'. \"\n            f\"Provide 'canonical_uri' or ensure 'url' is set for HTTP transport.\"\n        )\n\n    @property\n    def oauth_redirect_uri(self) -&gt; str:\n        \"\"\"Get platform OAuth redirect URI from config.\"\"\"\n        from ska_utils import AppConfig\n\n        from sk_agents.configs import TA_OAUTH_REDIRECT_URI\n\n        app_config = AppConfig()\n        return app_config.get(TA_OAUTH_REDIRECT_URI.env_name)\n\n    @model_validator(mode=\"after\")\n    def validate_transport_fields(self):\n        \"\"\"Validate that required fields are provided for the selected transport.\"\"\"\n        if self.transport == \"stdio\":\n            if not self.command:\n                raise ValueError(\"'command' is required for stdio transport\")\n            # Basic security validation\n            if any(char in (self.command or \"\") for char in [\";\", \"&amp;\", \"|\", \"`\", \"$\"]):\n                raise ValueError(\"Command contains potentially unsafe characters\")\n        elif self.transport == \"http\":\n            if not self.url:\n                raise ValueError(\"'url' is required for http transport\")\n            # Validate URL format\n            if not (self.url.startswith(\"http://\") or self.url.startswith(\"https://\")):\n                raise ValueError(\"HTTP transport URL must start with 'http://' or 'https://'\")\n\n            # Set smart defaults for timeouts if not provided\n            if self.timeout is None:\n                self.timeout = 30.0  # Default timeout\n            if self.sse_read_timeout is None:\n                self.sse_read_timeout = 300.0  # Default SSE read timeout\n\n            # Warn if no authentication configured for HTTP server\n            has_oauth = self.auth_server and self.scopes\n            has_auth_header = self.headers and any(\n                k.lower() == \"authorization\" for k in self.headers.keys()\n            )\n\n            if not has_oauth and not has_auth_header:\n                import warnings\n\n                warnings.warn(\n                    f\"MCP server '{self.name}' is configured without authentication. \"\n                    f\"This should only be used for:\\n\"\n                    f\"  - Public/read-only MCP servers\\n\"\n                    f\"  - Development/testing environments\\n\"\n                    f\"  - Internal networks with network-level security\\n\"\n                    f\"For production use with sensitive data, configure OAuth \"\n                    f\"(auth_server + scopes) or provide Authorization header.\",\n                    UserWarning,\n                    stacklevel=2,\n                )\n\n            # OAuth validation - only if using OAuth\n            # If one OAuth field is provided, both must be provided\n            if self.auth_server or self.scopes:\n                if not (self.auth_server and self.scopes):\n                    raise ValueError(\n                        \"Both auth_server and scopes are required when using OAuth authentication. \"\n                        \"Provide both or neither for simple header-based authentication.\"\n                    )\n\n        # OAuth-specific validation (only when OAuth is configured)\n        if self.auth_server and self.scopes:\n            # Validate auth_server URL format\n            if not self.auth_server.startswith((\"http://\", \"https://\")):\n                raise ValueError(\"auth_server must be a valid HTTP/HTTPS URL\")\n\n            # HTTPS enforcement (per OAuth 2.1 and MCP spec)\n            from ska_utils import AppConfig\n\n            from sk_agents.configs import TA_MCP_OAUTH_STRICT_HTTPS_VALIDATION\n            from sk_agents.mcp_client import validate_https_url\n\n            app_config = AppConfig()\n            strict_https = (\n                app_config.get(TA_MCP_OAUTH_STRICT_HTTPS_VALIDATION.env_name).lower() == \"true\"\n            )\n\n            if strict_https:\n                # Validate auth_server uses HTTPS (or localhost)\n                if not validate_https_url(self.auth_server, allow_localhost=True):\n                    raise ValueError(\n                        f\"auth_server must use HTTPS (or http://localhost for dev): \"\n                        f\"{self.auth_server}. \"\n                        f\"Disable with TA_MCP_OAUTH_STRICT_HTTPS_VALIDATION=false\"\n                    )\n\n                # Validate redirect_uri uses HTTPS (or localhost)\n                redirect_uri = self.oauth_redirect_uri\n                if redirect_uri and not validate_https_url(redirect_uri, allow_localhost=True):\n                    raise ValueError(\n                        f\"OAuth redirect_uri must use HTTPS (or http://localhost for dev): \"\n                        f\"{redirect_uri}. \"\n                        f\"Disable with TA_MCP_OAUTH_STRICT_HTTPS_VALIDATION=false\"\n                    )\n\n        return self\n</code></pre> <code></code> sk_agents.tealagents.v1alpha1.config.McpServerConfig.effective_canonical_uri <code>property</code> <pre><code>effective_canonical_uri: str\n</code></pre> <p>Get canonical MCP server URI for resource parameter binding.</p> <p>Per MCP spec, canonical URI must be: - Absolute HTTPS URI - Lowercase scheme and host - Optional port and path</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Canonical URI (either explicit or computed from url)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If cannot determine canonical URI</p> <code></code> sk_agents.tealagents.v1alpha1.config.McpServerConfig.oauth_redirect_uri <code>property</code> <pre><code>oauth_redirect_uri: str\n</code></pre> <p>Get platform OAuth redirect URI from config.</p> <code></code> sk_agents.tealagents.v1alpha1.config.McpServerConfig.validate_transport_fields <pre><code>validate_transport_fields()\n</code></pre> <p>Validate that required fields are provided for the selected transport.</p> Source code in <code>src/sk_agents/tealagents/v1alpha1/config.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_transport_fields(self):\n    \"\"\"Validate that required fields are provided for the selected transport.\"\"\"\n    if self.transport == \"stdio\":\n        if not self.command:\n            raise ValueError(\"'command' is required for stdio transport\")\n        # Basic security validation\n        if any(char in (self.command or \"\") for char in [\";\", \"&amp;\", \"|\", \"`\", \"$\"]):\n            raise ValueError(\"Command contains potentially unsafe characters\")\n    elif self.transport == \"http\":\n        if not self.url:\n            raise ValueError(\"'url' is required for http transport\")\n        # Validate URL format\n        if not (self.url.startswith(\"http://\") or self.url.startswith(\"https://\")):\n            raise ValueError(\"HTTP transport URL must start with 'http://' or 'https://'\")\n\n        # Set smart defaults for timeouts if not provided\n        if self.timeout is None:\n            self.timeout = 30.0  # Default timeout\n        if self.sse_read_timeout is None:\n            self.sse_read_timeout = 300.0  # Default SSE read timeout\n\n        # Warn if no authentication configured for HTTP server\n        has_oauth = self.auth_server and self.scopes\n        has_auth_header = self.headers and any(\n            k.lower() == \"authorization\" for k in self.headers.keys()\n        )\n\n        if not has_oauth and not has_auth_header:\n            import warnings\n\n            warnings.warn(\n                f\"MCP server '{self.name}' is configured without authentication. \"\n                f\"This should only be used for:\\n\"\n                f\"  - Public/read-only MCP servers\\n\"\n                f\"  - Development/testing environments\\n\"\n                f\"  - Internal networks with network-level security\\n\"\n                f\"For production use with sensitive data, configure OAuth \"\n                f\"(auth_server + scopes) or provide Authorization header.\",\n                UserWarning,\n                stacklevel=2,\n            )\n\n        # OAuth validation - only if using OAuth\n        # If one OAuth field is provided, both must be provided\n        if self.auth_server or self.scopes:\n            if not (self.auth_server and self.scopes):\n                raise ValueError(\n                    \"Both auth_server and scopes are required when using OAuth authentication. \"\n                    \"Provide both or neither for simple header-based authentication.\"\n                )\n\n    # OAuth-specific validation (only when OAuth is configured)\n    if self.auth_server and self.scopes:\n        # Validate auth_server URL format\n        if not self.auth_server.startswith((\"http://\", \"https://\")):\n            raise ValueError(\"auth_server must be a valid HTTP/HTTPS URL\")\n\n        # HTTPS enforcement (per OAuth 2.1 and MCP spec)\n        from ska_utils import AppConfig\n\n        from sk_agents.configs import TA_MCP_OAUTH_STRICT_HTTPS_VALIDATION\n        from sk_agents.mcp_client import validate_https_url\n\n        app_config = AppConfig()\n        strict_https = (\n            app_config.get(TA_MCP_OAUTH_STRICT_HTTPS_VALIDATION.env_name).lower() == \"true\"\n        )\n\n        if strict_https:\n            # Validate auth_server uses HTTPS (or localhost)\n            if not validate_https_url(self.auth_server, allow_localhost=True):\n                raise ValueError(\n                    f\"auth_server must use HTTPS (or http://localhost for dev): \"\n                    f\"{self.auth_server}. \"\n                    f\"Disable with TA_MCP_OAUTH_STRICT_HTTPS_VALIDATION=false\"\n                )\n\n            # Validate redirect_uri uses HTTPS (or localhost)\n            redirect_uri = self.oauth_redirect_uri\n            if redirect_uri and not validate_https_url(redirect_uri, allow_localhost=True):\n                raise ValueError(\n                    f\"OAuth redirect_uri must use HTTPS (or http://localhost for dev): \"\n                    f\"{redirect_uri}. \"\n                    f\"Disable with TA_MCP_OAUTH_STRICT_HTTPS_VALIDATION=false\"\n                )\n\n    return self\n</code></pre>"},{"location":"reference/#sk_agents.utility_routes","title":"sk_agents.utility_routes","text":"sk_agents.utility_routes.HealthStatus <p>               Bases: <code>BaseModel</code></p> <p>Health check response model.</p> Source code in <code>src/sk_agents/utility_routes.py</code> <pre><code>class HealthStatus(BaseModel):\n    \"\"\"Health check response model.\"\"\"\n\n    status: str\n    timestamp: str\n    version: str | None = None\n    uptime: float | None = None\n    dependencies: dict[str, Any] | None = None\n</code></pre> <code></code> sk_agents.utility_routes.ReadinessStatus <p>               Bases: <code>BaseModel</code></p> <p>Readiness check response model.</p> Source code in <code>src/sk_agents/utility_routes.py</code> <pre><code>class ReadinessStatus(BaseModel):\n    \"\"\"Readiness check response model.\"\"\"\n\n    ready: bool\n    timestamp: str\n    checks: dict[str, Any]\n</code></pre> <code></code> sk_agents.utility_routes.LivenessStatus <p>               Bases: <code>BaseModel</code></p> <p>Liveness check response model.</p> Source code in <code>src/sk_agents/utility_routes.py</code> <pre><code>class LivenessStatus(BaseModel):\n    \"\"\"Liveness check response model.\"\"\"\n\n    alive: bool\n    timestamp: str\n</code></pre> <code></code> sk_agents.utility_routes.UtilityRoutes <p>Utility routes for health checks and system monitoring.</p> Source code in <code>src/sk_agents/utility_routes.py</code> <pre><code>class UtilityRoutes:\n    \"\"\"Utility routes for health checks and system monitoring.\"\"\"\n\n    def __init__(self, start_time: datetime | None = None):\n        self.start_time = start_time or datetime.now()\n\n    def get_health_routes(\n        self,\n        config: BaseConfig,\n        app_config: AppConfig,\n    ) -&gt; APIRouter:\n        \"\"\"\n        Get health check routes for the application.\n\n        Args:\n            config: Base configuration\n            app_config: Application configuration\n\n        Returns:\n            APIRouter: Router with health check endpoints\n        \"\"\"\n        router = APIRouter()\n\n        @router.get(\n            \"/health\",\n            response_model=HealthStatus,\n            summary=\"Health check endpoint\",\n            description=\"Returns the health status of the application\",\n            tags=[\"Health\"],\n        )\n        async def health_check() -&gt; HealthStatus:\n            \"\"\"\n            Basic health check endpoint that returns the application status.\n            \"\"\"\n            try:\n                current_time = datetime.now()\n                uptime = (current_time - self.start_time).total_seconds()\n\n                return HealthStatus(\n                    status=\"healthy\",\n                    timestamp=current_time.isoformat(),\n                    version=str(config.version) if config.version else None,\n                    uptime=uptime,\n                )\n            except Exception as e:\n                logger.exception(f\"Health check failed: {e}\")\n                raise HTTPException(\n                    status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Service unhealthy\"\n                ) from e\n\n        @router.get(\n            \"/health/live\",\n            response_model=LivenessStatus,\n            summary=\"Liveness probe\",\n            description=\"Kubernetes liveness probe endpoint\",\n            tags=[\"Health\"],\n        )\n        async def liveness_check() -&gt; LivenessStatus:\n            \"\"\"\n            Liveness probe for Kubernetes deployments.\n            This endpoint should return 200 if the application is running.\n            \"\"\"\n            try:\n                return LivenessStatus(alive=True, timestamp=datetime.now().isoformat())\n            except Exception as e:\n                logger.exception(f\"Liveness check failed: {e}\")\n                raise HTTPException(\n                    status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Service not alive\"\n                ) from e\n\n        return router\n</code></pre> <code></code> sk_agents.utility_routes.UtilityRoutes.get_health_routes <pre><code>get_health_routes(\n    config: BaseConfig, app_config: AppConfig\n) -&gt; APIRouter\n</code></pre> <p>Get health check routes for the application.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>BaseConfig</code> <p>Base configuration</p> required <code>app_config</code> <code>AppConfig</code> <p>Application configuration</p> required <p>Returns:</p> Name Type Description <code>APIRouter</code> <code>APIRouter</code> <p>Router with health check endpoints</p> Source code in <code>src/sk_agents/utility_routes.py</code> <pre><code>def get_health_routes(\n    self,\n    config: BaseConfig,\n    app_config: AppConfig,\n) -&gt; APIRouter:\n    \"\"\"\n    Get health check routes for the application.\n\n    Args:\n        config: Base configuration\n        app_config: Application configuration\n\n    Returns:\n        APIRouter: Router with health check endpoints\n    \"\"\"\n    router = APIRouter()\n\n    @router.get(\n        \"/health\",\n        response_model=HealthStatus,\n        summary=\"Health check endpoint\",\n        description=\"Returns the health status of the application\",\n        tags=[\"Health\"],\n    )\n    async def health_check() -&gt; HealthStatus:\n        \"\"\"\n        Basic health check endpoint that returns the application status.\n        \"\"\"\n        try:\n            current_time = datetime.now()\n            uptime = (current_time - self.start_time).total_seconds()\n\n            return HealthStatus(\n                status=\"healthy\",\n                timestamp=current_time.isoformat(),\n                version=str(config.version) if config.version else None,\n                uptime=uptime,\n            )\n        except Exception as e:\n            logger.exception(f\"Health check failed: {e}\")\n            raise HTTPException(\n                status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Service unhealthy\"\n            ) from e\n\n    @router.get(\n        \"/health/live\",\n        response_model=LivenessStatus,\n        summary=\"Liveness probe\",\n        description=\"Kubernetes liveness probe endpoint\",\n        tags=[\"Health\"],\n    )\n    async def liveness_check() -&gt; LivenessStatus:\n        \"\"\"\n        Liveness probe for Kubernetes deployments.\n        This endpoint should return 200 if the application is running.\n        \"\"\"\n        try:\n            return LivenessStatus(alive=True, timestamp=datetime.now().isoformat())\n        except Exception as e:\n            logger.exception(f\"Liveness check failed: {e}\")\n            raise HTTPException(\n                status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Service not alive\"\n            ) from e\n\n    return router\n</code></pre>"},{"location":"demos/01_getting_started/","title":"Configuring an Agent","text":"<p>All agents are configured using a YAML configuration file. For a very simple agent that simply interacts with the user using a specified LLM, your agent config file might look something like:</p> <pre><code>apiVersion: skagents/v1\nkind: Sequential\ndescription: &gt;\n  A simple chat agent\nservice_name: ChatBot\nversion: 0.1\ninput_type: BaseInput\nspec:\n  agents:\n    - name: default\n      role: Default Agent\n      model: gpt-4o\n      system_prompt: &gt;\n        You are a helpful assistant.\n  tasks:\n    - name: action_task\n      task_no: 1\n      description: Chat with user\n      instructions: &gt;\n        Work with the user to assist them in whatever they need.\n      agent: default\n</code></pre> <p>An agent configuration file can contain the following elements:</p> <ul> <li>apiVersion - At present, this should always be <code>skagents/v1</code></li> <li>kind - The way in which an agent will execute its tasks. Currently only the   value <code>Sequential</code> is supported, which means, for each invocation, the agent   will execute all tasks in the defined order.</li> <li>description (optional) - A description of the agent</li> <li>service_name - The name of the agent (and thus its service). This, in   combination with the version will make up the agent's REST and streaming   endpoints. In this example, said endpoints would be<ul> <li><code>/ChatBot/0.1</code></li> <li><code>/ChatBot/0.1/stream</code></li> </ul> </li> <li>version - The version of the agent (see above)</li> <li>input_type - The payload format for requests to this agent (more on this   later)</li> <li>output_type (optional - not shown) - The payload format for responses from   this agent (more on this later)</li> <li>spec - Agent and task configuration</li> <li>agents - A list of agents that can be used by tasks<ul> <li>name - The name of the agent</li> <li>role - The role/description of the agent</li> <li>model - The LLM model to use</li> <li>system_prompt - A system prompt for the agent</li> </ul> </li> <li>tasks - A list of tasks to be executed by the agent<ul> <li>name - The name of the task</li> <li>task_no - The order in which the task should be executed</li> <li>description - A description of the task</li> <li>instructions - Instructions for the task</li> <li>agent - The agent to use for the task (must match agent defined in the agents section)</li> </ul> </li> </ul>"},{"location":"demos/01_getting_started/#currently-available-models","title":"Currently available models","text":"<p>The models currently available for agent configuration include:</p> <ul> <li>gpt-4o (Not for MSD usage)</li> <li>gpt-4o-mini (Not for MSD usage)</li> </ul>"},{"location":"demos/02_input_output/","title":"Working with custom input and output types","text":"<p>When building an agent, you must specify what types of input it should receive. This input can be either one of the standard types included with the SK Agents Framework or a type you define yourself.</p>"},{"location":"demos/02_input_output/#available-standard-types","title":"Available Standard Types","text":"<ul> <li>BaseInput - A base input type containing chat history for   chat-like interactions</li> </ul> <p>You also have the option to specify a custom output type which will be used in REST calls as the output format for the response from the agent.</p> <p>To define either a custom input or output type, simply create a new Python file and create classes which inherit from <code>KernelBaseModel</code> in the <code>semantic_kernel.kernel_pydantic</code> package. Once defined, you can specify the types in your agent's configuration file.</p>"},{"location":"demos/02_input_output/#sk_agents.ska_types.BaseInput","title":"sk_agents.ska_types.BaseInput","text":"<p>               Bases: <code>KernelBaseModel</code></p> <p>The history of a chat interaction between an automated assistant and a human.</p> Source code in <code>src/sk_agents/ska_types.py</code> <pre><code>class BaseInput(KernelBaseModel):\n    \"\"\"The history of a chat interaction between an automated assistant and a\n    human.\"\"\"\n\n    chat_history: list[HistoryMessage] | None = None\n</code></pre>"},{"location":"demos/02_input_output/#rest-output","title":"REST Output","text":"<p>When invoking an agent using the REST endpoint, your output will always follow the below format: <pre><code>{\n  \"token_usage\": {\n    \"completion_tokens\": 0,\n    \"prompt_tokens\": 0,\n    \"total_tokens\": 0\n  },\n  \"extra_data\": {},\n  \"output_raw\": \"string\",\n  \"output_pydantic\": \"null or user-defined output type\"\n}\n</code></pre> <code>extra_data</code> provides a mechanism by which plugins can return additional data along with the output.</p> <p><code>output_raw</code> will contain the raw output from the agent, as a string.</p> <p>If you have defined a custom output type, the <code>output_pydantic</code> field will contain the output in the format of your defined class.</p> <p>Note: It is likely that future versions of the Framework will do away with the redundant output fields and your output will be either the raw string (if no custom output type was defined) or the output in the format of your defined class.</p>"},{"location":"demos/02_input_output/#streaming-output","title":"Streaming Output","text":"<p>When invoking an agent using the streaming endpoint, the output will always be the raw text output as structured output would not make sense in the streaming context.</p> <p><code>extra_data</code>, if populated, will be sent as a final message after all other text has been sent. The message will be in the format of: <pre><code>{\n  \"extra_data\": {\n    \"key\": \"value\",\n    ...\n  }\n}\n</code></pre></p> <p>Note: Currently, token usage metrics are not available via the streaming endpoint as it is not currently supported for any models by Semantic Kernel. There is planned support for this, however, so it will likely be included in a future version.</p>"},{"location":"demos/02_input_output/#number-adder-example","title":"Number Adder Example","text":"<p>For example, if we wanted to create an agent which adds two numbers together, and returns the result, we could define input and output types which looked like the following:</p> <pre><code># custom_types.py\nfrom semantic_kernel.kernel_pydantic import KernelBaseModel\n\nclass NumbersInput(KernelBaseModel):\n    number_1: int\n    number_2: int\n\nclass AddOutput(KernelBaseModel):\n    result: int\n</code></pre> <p>In the agent's configuration file, we would specify the input and output types by setting the <code>input_type</code> and <code>output_type</code> fields. <pre><code>apiVersion: skagents/v1\nkind: Sequential\ndescription: &gt;\n  A number adder\nservice_name: AdderAgent\nversion: 0.1\ninput_type: NumbersInput\noutput_type: AddOutput\nspec:\n  agents:\n    - name: default\n      role: Default Agent\n      model: gpt-4o\n      system_prompt: &gt;\n        You are a helpful assistant.\n  tasks:\n    - name: action_task\n      task_no: 1\n      description: Add two number\n      instructions: &gt;\n        Add the following two numbers together\n        {{number_1}} {{number_2}}\n      agent: default\n</code></pre></p> <p>Finally, to let the Framework know where our custom types have been defined, we'll need to set an environment variable defining the location of our custom types file:</p> <pre><code>TA_API_KEY=&lt;your-API-key&gt;\nTA_SERVICE_CONFIG=demos/02_input_output/config.yaml\nTA_TYPES_MODULE=demos/02_input_output/custom_types.py\n</code></pre> <p>Now, when we run the agent with the above environment file:</p> <pre><code>$ fastapi run src/sk_agents/app.py\n</code></pre> <p>We'll see that the request payload now matches our defined input type: </p> <p>Additionally, we'll see that the response payload contains a key called <code>output_pydantic</code> which matches the format of our defined output class.</p> <p></p>"},{"location":"demos/03_plugins/","title":"Plugins","text":"<p>Plugins are a concept unique to Semantic Kernel, in the agent framework space. Rather than giving agents access to individual tools, SK introduces the concept of plugins, which can be bundles of similar tools, thus more closely aligning with traditional concepts in software development around the creation of APIs.</p> <p>In the SK Agent Framework, plugins can be included in two ways: 1. Local/Custom Plugins 2. OpenAPI API Plugins</p>"},{"location":"demos/03_plugins/#localcustom-plugins","title":"Local/Custom Plugins","text":"<p>Local plugins are plugins that are created by the user and are specific to this agent. To create one, simply create a new Python file which will be included with your agent. The file should contain one or more plugin classes which are derived from <code>BasePlugin</code> in the <code>ska_types</code> module and which contain methods annotated with the <code>kernel_function</code> annotation from Semantic Kernel (<code>semantic_kernel.functions.kernel_function_decorator</code>).</p>"},{"location":"demos/03_plugins/#authorization-extra-data","title":"Authorization &amp; Extra Data","text":"<p>Your custom plugin classes MUST inherit from BasePlugin. This base class has an <code>__init__</code> method which accepts two arguments:</p> <ul> <li><code>authorization</code> which contains the value contained in the <code>Authorization</code>    header received from the client, if one is present. You can access the    authorization token (if present) via <code>self.authorization</code>.</li> <li><code>extra_data_collector</code> which contains an instance of <code>ExtraDataCollector</code>    which can be used to add extra data to the response. Extra data comes in the    format of key/value pairs. Use the <code>add_extra_data</code> method within the plugin    to include extra data.</li> </ul> <p>If you're overriding the <code>__init__</code> method in your custom plugin, make sure to call the base class's <code>__init__</code> method with the <code>authorization</code> and <code>extra_data</code> arguments.</p>"},{"location":"demos/03_plugins/#example","title":"Example","text":"<p>In this example, we've defined a <code>WeatherPlugin</code> which contains two annotated methods <code>gat_lat_lng_for_location</code> and <code>get_temperature</code>. The first method takes as input a location search string and returns the latitude, longitude, and timezone of the location. The second method takes as input the latitude, longitude, and timezone of a location and returns the low and high temperatures.</p> <pre><code>...\nclass WeatherPlugin(BasePlugin):\n   @staticmethod\n   def _get_temp_url_for_location(lat: float, lng: float, timezone: str) -&gt; str:\n      return f\"https://api.open-meteo.com/v1/forecast?latitude={str(lat)}&amp;longitude={str(lng)}&amp;daily=temperature_2m_max,temperature_2m_min&amp;temperature_unit=fahrenheit&amp;wind_speed_unit=mph&amp;precipitation_unit=inch&amp;timezone={timezone}&amp;forecast_days=1\"\n\n   @staticmethod\n   def _get_loc_url_for_location(self, location_string: str) -&gt; str:\n      return f\"http://api.geonames.org/searchJSON?formatted=true&amp;q={location_string}&amp;maxRows=1&amp;lang=en&amp;username=tealagents&amp;style=full\"\n\n   @kernel_function(\n      description=\"Retrieve low and high temperatures for the day for a given location\"\n   )\n   def get_temperature(\n           self, lat: float, lng: float, timezone: str\n   ) -&gt; TemperatureResponse:\n      url = WeatherPlugin._get_temp_url_for_location(lat, lng, timezone)\n\n      response = requests.get(url).json()\n      if response:\n         response_int: TemperatureResponseInt = TemperatureResponseInt(**response)\n         return TemperatureResponse(\n            low=response_int.daily.temperature_2m_min[0],\n            high=response_int.daily.temperature_2m_max[0],\n         )\n      else:\n         raise ValueError(f\"Error retrieving temperature\")\n\n   @kernel_function(\n      description=\"Retrieve the latitude, longitude, and timezone for a given location search string\"\n   )\n   def get_lat_lng_for_location(self, location_string: str) -&gt; LocationCoordinates:\n      url = WeatherPlugin._get_loc_url_for_location(self, location_string)\n\n      response = requests.get(url).json()\n      if response:\n         response_int: CoordsResponse = CoordsResponse(**response)\n         return LocationCoordinates(\n            latitude=response_int.geonames[0].lat,\n            longitude=response_int.geonames[0].lng,\n            timezone=response_int.geonames[0].timezone.timeZoneId,\n         )\n      else:\n         raise ValueError(f\"Error retrieving location coordinates\")\n</code></pre> <p>Once the custom plugin has been defined, you need to make it available to a configured agent in your agent configuration file. Do this by populating the plugins portion of the agent configuration, which takes a list of defined plugins.</p> <pre><code>...\n    spec:\n      agents:\n        - name: default\n          role: Default Agent\n          model: gpt-4o\n          system_prompt: &gt;\n            You are a helpful assistant.\n          plugins:\n          - WeatherPlugin\n...\n</code></pre> <p>Finally, we need to update our environment to specify the python file which contains the custom plugin.</p> <pre><code>TA_API_KEY=&lt;your-API-key&gt;\nTA_SERVICE_CONFIG=demos/03_plugins/config.yaml\nTA_PLUGIN_MODULE=demos/03_plugins/custom_plugins.py\n</code></pre> <p>And that's all you need to do. In this example, the agent is a chat agent, similar to example 1, but now it has the ability to retrieve the temperature for a specified location.</p> <p></p> <p></p>"},{"location":"demos/04_remote_plugins/","title":"Plugins","text":"<p>Plugins are a concept unique to Semantic Kernel, in the agent framework space. Rather than giving agents access to individual tools, SK introduces the concept of plugins, which can be bundles of similar tools, thus more closely aligning with traditional concepts in software development around the creation of APIs.</p> <p>In the Teal Agent Framework, plugins can be included in two ways:</p> <ol> <li>Local/Custom Plugins</li> <li>OpenAPI API Plugins</li> </ol>"},{"location":"demos/04_remote_plugins/#remote-plugins","title":"Remote Plugins","text":"<p>Remote plugins allow you to re-use existing, published APIs as plugins for your agent without having to write any code. To enable an API as a remote plugin for your agent, two conditions must be met:</p> <ol> <li>The API has a valid OpenAPI Swagger document</li> <li>The API is defined in the Remote Plugin Catalog</li> </ol> <p>Note: At present, the Remote Plugin Catalog is simply a YAML file you will define when creating an agent. In the future, there are plans to manage the available remote plugins via a centralized catalog.</p>"},{"location":"demos/04_remote_plugins/#example","title":"Example","text":"<p>In this example, we'll use two APIs.</p> <ol> <li>An API which, given a location search string, returns a number of    geographical details about the location, including its latitude, longitude,    and timezone.</li> <li>An API which, given a latitude and longitude, returns the high and low    temperatures for the location.</li> </ol> <p>To set up the remote plugin, we've provided the OpenAPI Swagger documents for both APIs in this directory (<code>openapi_weather.json</code> and <code>openapi_geonames.json</code>). Note, the Swagger document locations could also be URLs, rather than local files.</p> <p>Additionally, we've created a <code>remote-plugin-catalog.yaml</code> file which defines the details of the remote APIs.</p> <pre><code>remote_plugins:\n  - plugin_name: api_weather\n    openapi_json_path: ./demos/04_remote_plugins/openapi_weather.json\n    server_url: https://api.open-meteo.com\n  - plugin_name: api_geonames\n    openapi_json_path: ./demos/04_remote_plugins/openapi_geonames.json\n</code></pre> <p>In the configuration file, we reference the remote plugins in the agent section. Note that the remote plugin names are defined in the catalog file.</p> <pre><code>...\nspec:\n  agents:\n    - name: default\n      role: Default Agent\n      model: gpt-4o\n      system_prompt: &gt;\n        You are a helpful assistant.\n      remote_plugins:\n      - api_weather\n      - api_geonames\n...\n</code></pre> <p>Finally, in our environment variables, we provide the path to the local remote plugin catalog.</p> <pre><code>TA_API_KEY=&lt;your-API-key&gt;\nTA_SERVICE_CONFIG=demos/04_remote_plugins/config.yaml\nTA_REMOTE_PLUGIN_PATH=demos/04_remote_plugins/remote-plugin-catalog.yaml\n</code></pre> <p>Now when we run and execute the agent (still using the chat-style input from earlier examples), requesting the temperature for Rahway, we see that the agent leverages both of the remote plugins to satisfy the request, first searching for the location coordinates using the geonames API, and then retrieving temperature using the openmeteo API.</p> <p></p> <p></p>"},{"location":"demos/05_deployment/","title":"Deployment","text":"<p>Agents will be packaged and deployed as docker containers. While this capability is not fully developed, yet, this example will give you an idea of how it might eventually be realized.</p>"},{"location":"demos/05_deployment/#building-the-base-image","title":"Building the base image","text":"<p>Eventually, the base image would be available in Docker Hub, and to get started you'd need to simply pull that image down. Until then, you'll need to first build the base image, locally.  To do so, once you've cloned the repository, locally, build the base image by running the following command from the root.</p> <pre><code>$ git clone https://github.com/MSDLLCpapers/teal-agents.git\n$ cd teal-agents\n$ make teal-agents\n</code></pre> <p></p>"},{"location":"demos/05_deployment/#running-the-agent","title":"Running the agent","text":"<p>To run your agent with the base image, you'll need to make your configuration code files available to a running container and provide it with the appropriate environment variables referencing where you've mounted your files.</p> <p>Note: We'll be running the same example as shown in demo 4, but now we'll be running it within the container.</p> <p>First, set up your environment (.env) file as follows:</p> <pre><code>TA_API_KEY=&lt;your-API-key&gt;\nTA_SERVICE_CONFIG=agents/config.yaml\nTA_PLUGIN_MODULE=agents/custom_plugins.py\nTA_REMOTE_PLUGIN_PATH=agents/remote-plugin-catalog.yaml\n</code></pre> <p>We'll use this file to set the environment for our running container. Note that the path we're specifying to all of our configuration is in the <code>agents</code> folder. That means we'll have to mount all of these files to that location in the container.</p> <p>Also, since we're now moving everything inside the container, we'll need to update the remote plugin catalog (which references the local swagger file).</p> <pre><code>remote_plugins:\n  - plugin_name: api_weather\n    openapi_json_path: ./agents/openapi_weather.json\n    server_url: https://api.open-meteo.com\n</code></pre> <p>For this example, we'll use docker compose to start the agent using the base container. In our <code>compose.yaml</code> file, we expose port 8000, leverage the environment file we previously created, and tell it to mount all of our configuration files in the <code>/app/src/sk-agents/agents</code> directory in the container.</p> <pre><code>services:\n  teal-agents:\n    image: localhost/teal-agents:latest\n    ports:\n      - \"8000:8000\"\n    env_file: \".env\"\n    volumes:\n      - ./agents:/app/src/sk-agents/agents\n</code></pre> <p>Start the container</p> <pre><code>$ docker compose up -d\n</code></pre> <p>The agent will now be running and available on port 8000, just as in demo 4.</p> <p></p> <p></p>"},{"location":"demos/05_deployment/#adding-dependencies","title":"Adding Dependencies","text":"<p>If your agent plugins require additional pip dependencies, simply add a <code>requirements.txt</code> file to your agent directory. When you start the agent, the listed dependencies will be automatically installed in the container and available for your plugins. If your additional dependencies are listed in a file named something other than <code>requirements.txt</code>, you can specify the file name using the environment variable <code>TA_ADDL_REQUIREMENTS</code> (note that this variable must prefix the file name with /src/sk-agents/agents/ as this is where the files are available within the container).</p>"},{"location":"demos/06_deployment_github/","title":"Deployment from Github","text":"<p>For most common use cases, you will not need to work with this repo directly for anything other than debugging if you're writing custom code. Rather, you will store all of your agent configuration, custom_plugins/types.py, and requirements files in an agent-specific folder in a separate Github repository.</p> <p>When the agent starts up with your configuration, the Teal Agents framework will automatically download your agent configuration and start the agent from the existing framework container.</p>"},{"location":"demos/06_deployment_github/#testing-it-out-locally","title":"Testing it out locally","text":"<p>In this demonstration, we'll make use of an existing agent configuration from the shared repository, teal-agents-configs.</p> <p>For reference, the configuration in the shared repo is the same as that found in demo 03_plugins.</p> <p>In order to run this demonstration, you'll need to set up your environment file (<code>.env</code>) to contain the following: <pre><code>TA_API_KEY=&lt;Your API key&gt;\nTA_GITHUB=true\nTA_GH_ORG=teal-agents\nTA_GH_REPO=teal-agents-configs\nTA_GH_BRANCH=main\nTA_AGENT_NAME=ChatWeatherAgent\n</code></pre></p> <ul> <li>TA_API_KEY - Same as for other use cases, enter your appropriate API key</li> <li>TA_GITHUB - Set to true to indicate that your agent configuration resides   in a shared github repository</li> <li>TA_GH_ORG - The github organization that contains the shared agent   configurations</li> <li>TA_GH_REPO - The repository within the organization that contains the shared   agent configurations</li> <li>TA_GH_BRANCH - The branch within the repository that contains the shared   agent configurations</li> <li>TA_AGENT_NAME - The name of the agent configuration folder within the   repository</li> <li>TA_GH_TOKEN (not shown) - A github personal access token with read access to   the repository (if not public)</li> </ul> <p>To run this example, you'll need <code>docker compose</code> installed on your machine. After setting up your environment file, simply run <code>docker compose up -d</code>. The agent will start on port 8000 and can be accessed via http://localhost:8000/docs.</p>"},{"location":"demos/07_task_output/","title":"Multiple, Sequential Tasks","text":"<p>A Sequential Teal Agent allows you to perform multiple tasks, which should be performed in sequence. Each task can have its own agent, or the same agent can be shared by multiple tasks. Additionally, downstream tasks can leverage the output from previous tasks to complete their instructions.</p> <p>Similar to input variables, output from previous tasks can be injected in to the instructions of a given task using the <code>{{}}</code> curly brace syntax. Each task has unique variable name which is simply the name of the previously performed task preceded by a <code>_</code>.</p>"},{"location":"demos/07_task_output/#example","title":"Example","text":"<p>In the following configuration example, we define a single agent that will perform two tasks, in sequence, using the input provided by the consumer.</p> <pre><code>apiVersion: skagents/v1\nkind: Sequential\ndescription: &gt;\n  Add numbers 1 &amp; 2, then multiply the result by number 3 and add 10.\nservice_name: MathAgent\nversion: 0.1\ninput_type: NumbersInput\noutput_type: MathOutput\nspec:\n  agents:\n    - name: default\n      role: Default Agent\n      model: gpt-4o\n      system_prompt: &gt;\n        You are a helpful assistant.\n  tasks:\n    - name: action_task\n      task_no: 1\n      description: Add two numbers\n      instructions: &gt;\n        Add the following two numbers together\n        {{number_1}} {{number_2}}\n      agent: default\n    - name: follow_on_task\n      task_no: 2\n      description: Perform a final operation\n      instructions: &gt;\n        Multiply the result of the previous answer by {{number_3}} and then add\n        10 to it.\n\n        Previous operation:\n        {{_action_task}}\n      agent: default\n</code></pre> <p>NumbersInput is an object containing three fields: <pre><code>class NumbersInput(KernelBaseModel):\n    number_1: int\n    number_2: int\n    number_3: int\n</code></pre></p> <p>In the first task, we simply add <code>number_1</code> and <code>number_2</code> together to get the sum. In the second task, we multiply the result of the <code>action_task</code> by <code>number_3</code> and add 10 to it.</p> <p>Note: The <code>{{_action_task}}</code> variable is used to reference the output of the <code>action_task</code> task. This is a special variable that is automatically created by the Teal Agents Framework when a task is completed. The variable name is simply the name of the task, preceded by an underscore.</p> <p>Additional Note: The input to a downstream task that is a result from a previous task will be the agent's raw response. Take care to phrase the follow -on task's instructions in a way that the agent can understand the context.</p>"},{"location":"demos/08_multi_modal/","title":"Multi-Modal Input","text":"<p>In addition to text prompts, agents can work with multi-modal input (currently limited to images, but more are planned). There are two ways to leverage image input in an agent:</p>"},{"location":"demos/08_multi_modal/#basemultimodalinput","title":"BaseMultiModalInput","text":"<p>If you set the <code>input_type</code> to <code>BaseMultiModalInput</code>, the agent will expect a chat history that can include images as items in a user message.</p> <pre><code>apiVersion: skagents/v1\nkind: Sequential\ndescription: &gt;\n  A simple chat agent\nservice_name: ChatBot\nversion: 0.1\ninput_type: BaseMultiModalInput\nspec:\n  agents:\n    - name: default\n      role: Default Agent\n      model: gpt-4o\n      system_prompt: &gt;\n        You are a helpful assistant.\n  tasks:\n    - name: action_task\n      task_no: 1\n      description: Chat with user\n      instructions: &gt;\n        Work with the user to assist them in whatever they need.\n      agent: default\n</code></pre> <p>The <code>items</code> key within the request payload can now include both text and images. The <code>content_type</code> key specifies the type of item and <code>content</code> contains the actual content. <pre><code>{\n  \"chat_history\": [\n    {\n      \"role\": \"user\",\n      \"items\": [\n        {\n          \"content_type\": \"text or image\",\n          \"content\": \"content\"\n        }\n      ]\n    }\n  ]\n}\n</code></pre> When specifying an image, it must be base64-encoded, and prefixed with <code>data:image/jpeg;base64,</code> (substituting the appropriate format).  For example, to have the agent count the number of buttons, in this image:</p> <p></p> <p>Our request payload would look like: <pre><code>{\n  \"chat_history\": [\n    {\n      \"role\": \"user\",\n      \"items\": [\n        {\n          \"content_type\": \"text\",\n          \"content\": \"How many buttons are in this image\"\n        },\n        {\n          \"content_type\": \"image\",\n          \"content\": \"data:image/jpeg;base64,/9j/4QF...\"\n        }\n      ]\n    }\n  ]\n}\n</code></pre></p> <p>Note: To simplify testing of this demo, the example request payload is stored in request_payload.json.</p>"},{"location":"demos/08_multi_modal/#result","title":"Result","text":""},{"location":"demos/08_multi_modal/#embedded-image","title":"Embedded Image","text":"<p>An alternative method of including images for your agent to process would be to define a custom input type that includes a field called <code>embedded_image</code> whose structure matches:</p> <pre><code>{\n  ...\n  \"embedded_image\": {\n    \"format\": \"image/jpeg\",\n    \"content\": \"/9j/4QF...\"\n  }\n}\n</code></pre> <p>When including images in this way, the image will be sent along with your first task's instructions.</p>"},{"location":"demos/08_multi_modal/#example","title":"Example","text":"<p>Define a custom input type: <pre><code>from semantic_kernel.kernel_pydantic import KernelBaseModel\n\nfrom sk_agents.ska_types import EmbeddedImage\n\n\nclass ButtonGuess(KernelBaseModel):\n    guess: int\n    embedded_image: EmbeddedImage\n</code></pre></p> <p>And your agent configuration looked like this: <pre><code>apiVersion: skagents/v1\nkind: Sequential\ndescription: &gt;\n  A simple chat agent\nservice_name: ChatBot\nversion: 0.1\ninput_type: ButtonGuess\nspec:\n  agents:\n    - name: default\n      role: Default Agent\n      model: gpt-4o\n      system_prompt: &gt;\n        You are a helpful assistant.\n  tasks:\n    - name: action_task\n      task_no: 1\n      description: Chat with user\n      instructions: &gt;\n        Does the image contain {{guess}} buttons?\n      agent: default\n</code></pre></p> <p>You could send a payload that looked like this: <pre><code>{\n  \"guess\": 10,\n  \"embedded_image\": {\n    \"format\": \"image/jpeg\",\n    \"data\": \"/9j/4Q...\"\n  }\n}\n</code></pre></p> <p>The image in the payload would be detected and sent along with the user message \"Does the image contain 10 buttons?\". Your response would look something like: <pre><code>{\n  \"token_usage\": {\n    \"completion_tokens\": 9,\n    \"prompt_tokens\": 235,\n    \"total_tokens\": 244\n  },\n  \"extra_data\": null,\n  \"output_raw\": \"No, the image contains 12 buttons.\",\n  \"output_pydantic\": null\n}\n</code></pre></p>"},{"location":"demos/09_chat_simple/","title":"Chat-Only Agent","text":"<p>In addition to Sequential agents, there is also a chat-only type agent. The difference between the two is that, with chat-only, there are no tasks in which additional instructions can be provided. Rather, a chat-only agent expects input of one of the following types: * <code>BaseInput</code> - A simple text input * <code>BaseInputWithUserContext</code> - A text input with user context * <code>BaseMultiModalInput</code> - Input supporting both images and text</p> <p>A chat-only agent will use the chat history that's provided and attempt to perform any requested actions.</p>"},{"location":"demos/09_chat_simple/#example-configuration","title":"Example Configuration","text":"<pre><code>apiVersion: skagents/v1\nkind: Chat\ndescription: &gt;\n  A simple chat agent\nservice_name: ChatBot\nversion: 0.1\ninput_type: BaseInput\nspec:\n  agent:\n    name: default\n    role: Default Agent\n    model: gpt-4o-mini\n    system_prompt: &gt;\n      You are a helpful assistant.\n</code></pre>"},{"location":"demos/10_chat_plugins/","title":"Chat-Only Agents with PlugIns","text":"<p>Chat-only agents do support the same plug-in architecture as sequential agents.</p>"},{"location":"demos/10_chat_plugins/#example-configuration","title":"Example Configuration","text":"<pre><code>apiVersion: skagents/v1\nkind: Chat\ndescription: &gt;\n  A weather chat agent\nservice_name: WeatherBot\nversion: 0.1\ninput_type: BaseInputWithUserContext\nspec:\n  agent:\n    name: default\n    role: Default Agent\n    model: gpt-4o\n    system_prompt: &gt;\n      You are a helpful assistant.\n    plugins:\n    - WeatherPlugin\n</code></pre>"},{"location":"demos/10_chat_plugins/#example-custom-plugin","title":"Example Custom Plugin","text":"<pre><code>import requests\nfrom pydantic import BaseModel, ConfigDict\nfrom semantic_kernel.functions.kernel_function_decorator import kernel_function\n\nfrom sk_agents.ska_types import BasePlugin\n\n\nclass LocationCoordinates(BaseModel):\n    latitude: float\n    longitude: float\n    timezone: str\n\n\nclass DailyUnits(BaseModel):\n    time: str\n    temperature_2m_max: str\n    temperature_2m_min: str\n\n\nclass Daily(BaseModel):\n    time: list[str]\n    temperature_2m_max: list[float]\n    temperature_2m_min: list[float]\n\n\nclass TemperatureResponseInt(BaseModel):\n    latitude: float\n    longitude: float\n    generationtime_ms: float\n    utc_offset_seconds: int\n    timezone: str\n    timezone_abbreviation: str\n    elevation: int\n    daily_units: DailyUnits\n    daily: Daily\n\n\nclass TemperatureResponse(BaseModel):\n    low: float\n    high: float\n\n\nclass TimeZone(BaseModel):\n    model_config = ConfigDict(extra=\"allow\")\n    timeZoneId: str\n\n\nclass GeoName(BaseModel):\n    model_config = ConfigDict(extra=\"allow\")\n    timezone: TimeZone\n    lat: float\n    lng: float\n\n\nclass CoordsResponse(BaseModel):\n    model_config = ConfigDict(extra=\"allow\")\n    geonames: list[GeoName]\n\n\nclass WeatherPlugin(BasePlugin):\n    @staticmethod\n    def _get_temp_url_for_location(lat: float, lng: float, timezone: str) -&gt; str:\n        return f\"https://api.open-meteo.com/v1/forecast?latitude={str(lat)}&amp;longitude={str(lng)}&amp;daily=temperature_2m_max,temperature_2m_min&amp;temperature_unit=fahrenheit&amp;wind_speed_unit=mph&amp;precipitation_unit=inch&amp;timezone={timezone}&amp;forecast_days=1\"\n\n    @staticmethod\n    def _get_loc_url_for_location(self, location_string: str) -&gt; str:\n        return f\"http://api.geonames.org/searchJSON?formatted=true&amp;q={location_string}&amp;maxRows=1&amp;lang=en&amp;username=tealagents&amp;style=full\"\n\n    @kernel_function(\n        description=\"Retrieve low and high temperatures for the day for a given location\"\n    )\n    def get_temperature(self, lat: float, lng: float, timezone: str) -&gt; TemperatureResponse:\n        url = WeatherPlugin._get_temp_url_for_location(lat, lng, timezone)\n\n        response = requests.get(url).json()\n        if response:\n            response_int: TemperatureResponseInt = TemperatureResponseInt(**response)\n            return TemperatureResponse(\n                low=response_int.daily.temperature_2m_min[0],\n                high=response_int.daily.temperature_2m_max[0],\n            )\n        else:\n            raise ValueError(\"Error retrieving temperature\")\n\n    @kernel_function(\n        description=\"Retrieve the latitude, longitude, and timezone \\\n            for a given location search string\"\n    )\n    def get_lat_lng_for_location(self, location_string: str) -&gt; LocationCoordinates:\n        url = WeatherPlugin._get_loc_url_for_location(self, location_string)\n\n        response = requests.get(url).json()\n        if response:\n            response_int: CoordsResponse = CoordsResponse(**response)\n            return LocationCoordinates(\n                latitude=response_int.geonames[0].lat,\n                longitude=response_int.geonames[0].lng,\n                timezone=response_int.geonames[0].timezone.timeZoneId,\n            )\n        else:\n            raise ValueError(\"Error retrieving location coordinates\")\n</code></pre>"},{"location":"demos/11_hitl/","title":"Human-in-the-Loop (HITL) Agent Demo","text":"<p>This demo showcases how to configure an agent with Human-in-the-Loop (HITL) capabilities, which allows you to require human approval before sensitive or high-risk plugin functions are executed by the AI agent.</p>"},{"location":"demos/11_hitl/#overview","title":"Overview","text":"<p>Human-in-the-Loop is a critical security and governance feature that enables:</p> <ul> <li>Risk Mitigation: Prevent potentially dangerous operations from executing without human oversight</li> <li>Compliance: Meet regulatory requirements for human approval on sensitive data operations</li> <li>Security: Add a safety layer between AI decision-making and critical actions</li> <li>Auditability: Track and approve all high-risk operations with full traceability</li> </ul>"},{"location":"demos/11_hitl/#how-hitl-works","title":"How HITL Works","text":"<ol> <li>Agent Execution: The agent processes a user request and determines it needs to call a plugin function</li> <li>Governance Check: The framework checks the plugin catalog to see if the function requires HITL approval</li> <li>Execution Pause: If HITL is required, execution halts and returns an <code>HitlResponse</code> with approval URLs</li> <li>Human Review: A human reviewer examines the function call details and either approves or rejects it</li> <li>Execution Resume: If approved, the agent resumes and executes the function; if rejected, the agent is notified</li> </ol>"},{"location":"demos/11_hitl/#configuration-components","title":"Configuration Components","text":""},{"location":"demos/11_hitl/#1-agent-configuration-configyaml","title":"1. Agent Configuration (<code>config.yaml</code>)","text":"<p>The agent configuration defines the agent's behavior and which plugins it has access to:</p> <pre><code>apiVersion: tealagents/v1alpha1\nkind: Chat\ndescription: &gt;\n  A simple Hello World agent that greets users with their user ID from the user context\nname: MathAgent\nversion: 0.1\nspec:\n  agent:\n    name: default\n    role: MathAgent\n    model: gpt-4o-2024-05-13\n    system_prompt: &gt;\n        Your task is to provide a help with Math problems, and invoke the plugin\n        when you finish the math problem before responding\n    plugins:\n        - sensitive_plugin\n</code></pre> <p>Key Elements: - <code>apiVersion</code>: Uses <code>tealagents/v1alpha1</code> which supports HITL features - <code>kind</code>: Set to <code>Chat</code> for conversational agents - <code>plugins</code>: Lists the plugins available to the agent (in this case, <code>sensitive_plugin</code>) - <code>system_prompt</code>: Instructs the agent when to use the plugin</p>"},{"location":"demos/11_hitl/#2-custom-plugin-implementation-custom_pluginspy","title":"2. Custom Plugin Implementation (<code>custom_plugins.py</code>)","text":"<p>Define your plugin with functions that may require human oversight:</p> <pre><code>from semantic_kernel.functions.kernel_function_decorator import kernel_function\nfrom sk_agents.ska_types import BasePlugin\n\n\nclass sensitive_plugin(BasePlugin):\n    @kernel_function(description=\"invoke when a math problem is solved\")\n    def delete_user_data(self):\n        return \"you shouldnt see me\"\n</code></pre> <p>Key Elements: - Inherit from <code>BasePlugin</code>: Ensures proper integration with the framework - <code>@kernel_function</code> decorator: Marks methods as callable by the agent - Function description: Tells the agent when to invoke this function - Function logic: The actual operation that will execute after approval</p>"},{"location":"demos/11_hitl/#3-plugin-catalog-configuration-catalogjson","title":"3. Plugin Catalog Configuration (<code>catalog.json</code>)","text":"<p>The plugin catalog is where you define governance rules, including HITL requirements:</p> <pre><code>{\n  \"plugins\": [\n    {\n      \"plugin_id\": \"sensitive_plugin\",\n      \"name\": \"sensitive_plugin\",\n      \"description\": \"Executes shell commands.\",\n      \"version\": \"1.0\",\n      \"owner\": \"system\",\n      \"plugin_type\": { \"type_name\": \"code\" },\n      \"tools\": [\n        {\n          \"tool_id\": \"sensitive_plugin-delete_user_data\",\n          \"name\": \"delete_user_data\",\n          \"description\": \"Executes a command in the shell to delete user.\",\n          \"governance\": {\n            \"requires_hitl\": true,\n            \"cost\": \"high\",\n            \"data_sensitivity\": \"sensitive\"\n          },\n          \"auth\": null\n        }\n      ]\n    }\n  ]\n}\n</code></pre> <p>Key Elements: - <code>plugin_id</code>: Must match the plugin class name in your <code>custom_plugins.py</code> - <code>tool_id</code>: Format is <code>{plugin_id}-{function_name}</code> (e.g., <code>sensitive_plugin-delete_user_data</code>) - <code>governance</code>: Defines the governance controls for this tool   - <code>requires_hitl: true</code>: Enables human-in-the-loop for this function   - <code>cost</code>: Resource classification (<code>low</code>, <code>medium</code>, <code>high</code>)   - <code>data_sensitivity</code>: Sensitivity level (<code>public</code>, <code>proprietary</code>, <code>confidential</code>, <code>sensitive</code>) - <code>auth</code>: Optional authentication requirements (null in this example)</p>"},{"location":"demos/11_hitl/#environment-configuration","title":"Environment Configuration","text":"<p>To run this demo, you need to configure the following environment variables:</p> <pre><code># API Key for LLM access\nTA_API_KEY=&lt;your-API-key&gt;\n\n# Path to your agent configuration\nTA_SERVICE_CONFIG=demos/11_hitl/config.yaml\n\n# Path to your custom plugin implementation\nTA_PLUGIN_MODULE=demos/11_hitl/custom_plugins.py\n\n# Path to the plugin catalog (defines HITL governance)\nTA_PLUGIN_CATALOG_MODULE=src/sk_agents/plugin_catalog/local_plugin_catalog.py\nTA_PLUGIN_CATALOG_CLASS=FileBasedPluginCatalog\nTA_PLUGIN_CATALOG_PATH=src/sk_agents/plugin_catalog/catalog.json\n</code></pre> <p>Important Notes: - The <code>TA_PLUGIN_CATALOG_PATH</code> should point to your <code>catalog.json</code> file - You can create custom catalog implementations by extending the <code>PluginCatalog</code> abstract class - The catalog is loaded as a singleton, so all agents in the application share the same governance rules</p>"},{"location":"demos/11_hitl/#hitl-workflow-example","title":"HITL Workflow Example","text":""},{"location":"demos/11_hitl/#step-1-initial-request","title":"Step 1: Initial Request","text":"<p>User sends a request to the agent:</p> <pre><code>POST /MathAgent/0.1\n{\n  \"user_id\": \"user123\",\n  \"input\": \"What is 5 + 3? After you solve it, delete my data.\"\n}\n</code></pre>"},{"location":"demos/11_hitl/#step-2-agent-processing","title":"Step 2: Agent Processing","text":"<p>The agent: 1. Solves the math problem (5 + 3 = 8) 2. Determines it needs to call <code>delete_user_data</code> 3. Checks the plugin catalog and finds <code>requires_hitl: true</code> 4. Raises an <code>HitlInterventionRequired</code> exception</p>"},{"location":"demos/11_hitl/#step-3-hitl-response","title":"Step 3: HITL Response","text":"<p>The framework returns a <code>HitlResponse</code> instead of executing the function:</p> <pre><code>{\n  \"task_id\": \"task_abc123\",\n  \"session_id\": \"session_xyz789\",\n  \"request_id\": \"req_def456\",\n  \"human_message\": \"HITL intervention required for sensitive_plugin.delete_user_data\",\n  \"tool_calls\": [\n    {\n      \"plugin_name\": \"sensitive_plugin\",\n      \"function_name\": \"delete_user_data\",\n      \"arguments\": {}\n    }\n  ],\n  \"approval_url\": \"/approve/req_def456\",\n  \"rejection_url\": \"/reject/req_def456\"\n}\n</code></pre>"},{"location":"demos/11_hitl/#step-4-human-review","title":"Step 4: Human Review","text":"<p>A human reviewer examines the function call details and makes a decision.</p> <p>To Approve: <pre><code>POST /approve/req_def456\n{\n  \"action\": \"approved\",\n  \"reason\": \"User requested data deletion, verified identity\"\n}\n</code></pre></p> <p>To Reject: <pre><code>POST /reject/req_def456\n{\n  \"action\": \"rejected\",\n  \"reason\": \"Insufficient verification\"\n}\n</code></pre></p>"},{"location":"demos/11_hitl/#step-5-resume-execution","title":"Step 5: Resume Execution","text":"<p>After approval/rejection, use the resume endpoint:</p> <pre><code>POST /resume/req_def456\n{\n  \"action_status\": \"approved\"  # or \"rejected\"\n}\n</code></pre> <p>If approved, the agent executes <code>delete_user_data</code> and completes the response. If rejected, the agent is informed the action was not allowed and responds accordingly.</p>"},{"location":"demos/11_hitl/#governance-options","title":"Governance Options","text":"<p>The <code>governance</code> object in the plugin catalog supports multiple control mechanisms:</p>"},{"location":"demos/11_hitl/#hitl-requirement","title":"HITL Requirement","text":"<pre><code>\"governance\": {\n  \"requires_hitl\": true  // Set to false to allow automatic execution\n}\n</code></pre>"},{"location":"demos/11_hitl/#cost-classification","title":"Cost Classification","text":"<p>Used for resource tracking and budgeting: <pre><code>\"governance\": {\n  \"cost\": \"high\"  // Options: \"low\", \"medium\", \"high\"\n}\n</code></pre></p>"},{"location":"demos/11_hitl/#data-sensitivity","title":"Data Sensitivity","text":"<p>Used for data governance and compliance: <pre><code>\"governance\": {\n  \"data_sensitivity\": \"sensitive\"\n  // Options: \"public\", \"proprietary\", \"confidential\", \"sensitive\"\n}\n</code></pre></p>"},{"location":"demos/11_hitl/#common-use-cases","title":"Common Use Cases","text":""},{"location":"demos/11_hitl/#1-financial-transactions","title":"1. Financial Transactions","text":"<pre><code>{\n  \"tool_id\": \"finance_plugin-initiate_transfer\",\n  \"governance\": {\n    \"requires_hitl\": true,\n    \"cost\": \"high\",\n    \"data_sensitivity\": \"sensitive\"\n  }\n}\n</code></pre>"},{"location":"demos/11_hitl/#2-system-administration","title":"2. System Administration","text":"<pre><code>{\n  \"tool_id\": \"admin_tools-shutdown_service\",\n  \"governance\": {\n    \"requires_hitl\": true,\n    \"cost\": \"high\",\n    \"data_sensitivity\": \"confidential\"\n  }\n}\n</code></pre>"},{"location":"demos/11_hitl/#3-data-deletion","title":"3. Data Deletion","text":"<pre><code>{\n  \"tool_id\": \"sensitive_plugin-delete_user_data\",\n  \"governance\": {\n    \"requires_hitl\": true,\n    \"cost\": \"medium\",\n    \"data_sensitivity\": \"sensitive\"\n  }\n}\n</code></pre>"},{"location":"demos/11_hitl/#4-low-risk-operations","title":"4. Low-Risk Operations","text":"<pre><code>{\n  \"tool_id\": \"finance_plugin-get_balance\",\n  \"governance\": {\n    \"requires_hitl\": false,  // No human approval needed\n    \"cost\": \"low\",\n    \"data_sensitivity\": \"proprietary\"\n  }\n}\n</code></pre>"},{"location":"demos/11_hitl/#best-practices","title":"Best Practices","text":""},{"location":"demos/11_hitl/#1-plugin-naming-conventions","title":"1. Plugin Naming Conventions","text":"<ul> <li>Use descriptive plugin IDs that indicate their purpose</li> <li>Keep function names clear and action-oriented</li> <li>Tool IDs must follow the format: <code>{plugin_id}-{function_name}</code></li> </ul>"},{"location":"demos/11_hitl/#2-governance-configuration","title":"2. Governance Configuration","text":"<ul> <li>Mark all destructive operations as <code>requires_hitl: true</code></li> <li>Set appropriate cost and sensitivity levels</li> <li>Document governance decisions in plugin descriptions</li> </ul>"},{"location":"demos/11_hitl/#3-system-prompts","title":"3. System Prompts","text":"<ul> <li>Clearly instruct the agent when to use HITL-protected functions</li> <li>Provide context about why certain operations require approval</li> <li>Set expectations for users about approval workflows</li> </ul>"},{"location":"demos/11_hitl/#4-error-handling","title":"4. Error Handling","text":"<ul> <li>Always handle HITL responses in your client application</li> <li>Provide clear UI for approval/rejection workflows</li> <li>Implement timeout handling for pending approvals</li> </ul>"},{"location":"demos/11_hitl/#5-audit-trail","title":"5. Audit Trail","text":"<ul> <li>Log all HITL intervention requests</li> <li>Track approval/rejection decisions with timestamps and reasons</li> <li>Maintain records for compliance requirements</li> </ul>"},{"location":"demos/11_hitl/#architecture-integration","title":"Architecture Integration","text":"<p>The HITL system integrates with several framework components:</p> <ol> <li>Plugin Catalog (Singleton): Centralized governance rules</li> <li>HITL Manager: Checks for intervention requirements</li> <li>Agent Handler: Catches HITL exceptions and generates responses</li> <li>Persistence Layer: Tracks task state during approval workflows</li> <li>REST API: Provides approval/rejection endpoints</li> </ol>"},{"location":"demos/11_hitl/#troubleshooting","title":"Troubleshooting","text":""},{"location":"demos/11_hitl/#hitl-not-triggering","title":"HITL Not Triggering","text":"<p>Problem: Function executes without requiring approval</p> <p>Solutions: - Verify <code>requires_hitl: true</code> is set in <code>catalog.json</code> - Confirm <code>tool_id</code> matches the format: <code>{plugin_id}-{function_name}</code> - Check that <code>TA_PLUGIN_CATALOG_PATH</code> points to the correct catalog file - Ensure the plugin catalog is properly loaded (check logs)</p>"},{"location":"demos/11_hitl/#tool-not-found-in-catalog","title":"Tool Not Found in Catalog","text":"<p>Problem: Tool is not recognized by the catalog</p> <p>Solutions: - Verify the <code>plugin_id</code> matches your plugin class name - Check the <code>tool_id</code> format is correct - Ensure the catalog JSON is valid (use a JSON validator) - Restart the service after updating the catalog</p>"},{"location":"demos/11_hitl/#approval-urls-not-working","title":"Approval URLs Not Working","text":"<p>Problem: Approval/rejection endpoints return errors</p> <p>Solutions: - Confirm the request ID is valid and not expired - Check that persistence is configured correctly - Verify the resume endpoint is being called properly - Review service logs for detailed error messages</p>"},{"location":"demos/11_hitl/#further-reading","title":"Further Reading","text":"<ul> <li>HITL System Documentation</li> <li>Plugin Catalog Documentation</li> <li>Persistence Management</li> <li>Authorization &amp; Auth Storage</li> </ul>"},{"location":"hitl/auth_storage/","title":"Authentication Storage System","text":"<p>This document describes the authentication storage system for the Teal Agents framework.</p>"},{"location":"hitl/auth_storage/#overview","title":"Overview","text":"<p>The authentication storage system securely stores OAuth 2.0 and other authentication credentials. It provides:</p> <ul> <li>In-Memory Storage (default): Zero configuration, perfect for development</li> <li>Redis Storage (optional): Persistent, scalable, production-ready</li> <li>Custom Storage: Support for user-defined implementations</li> </ul>"},{"location":"hitl/auth_storage/#configuration","title":"Configuration","text":""},{"location":"hitl/auth_storage/#environment-variables","title":"Environment Variables","text":"<ul> <li><code>TA_AUTH_STORAGE_MANAGER_MODULE</code>: Path to custom auth storage module</li> <li><code>TA_AUTH_STORAGE_MANAGER_CLASS</code>: Class name for custom implementation</li> </ul>"},{"location":"hitl/auth_storage/#examples","title":"Examples","text":""},{"location":"hitl/auth_storage/#development-default","title":"Development (Default)","text":"<pre><code># No configuration needed - uses in-memory storage\n</code></pre>"},{"location":"hitl/auth_storage/#production-with-redis","title":"Production with Redis","text":"<pre><code>export TA_AUTH_STORAGE_MANAGER_MODULE=src/sk_agents/auth_storage/custom/example_redis_auth_storage.py\nexport TA_AUTH_STORAGE_MANAGER_CLASS=RedisSecureAuthStorageManager\nexport TA_REDIS_HOST=redis.production.com\nexport TA_REDIS_PORT=6379\nexport TA_REDIS_PWD=secure_password\n</code></pre>"},{"location":"hitl/auth_storage/#usage","title":"Usage","text":"<pre><code>from ska_utils import AppConfig\nfrom sk_agents.auth_storage.auth_storage_factory import AuthStorageFactory\nfrom sk_agents.auth_storage.models import OAuth2AuthData\n\n# Get auth storage manager\napp_config = AppConfig()\nfactory = AuthStorageFactory(app_config)\nauth_storage = factory.get_auth_storage_manager()\n\n# Store, retrieve, and delete auth data\nauth_storage.store(\"user123\", \"tool_a\", auth_data)\nretrieved_data = auth_storage.retrieve(\"user123\", \"tool_a\")\nauth_storage.delete(\"user123\", \"tool_a\")\n</code></pre>"},{"location":"hitl/auth_storage/#custom-implementation","title":"Custom Implementation","text":"<p>Create custom storage by extending <code>SecureAuthStorageManager</code>:</p> <pre><code>from sk_agents.auth_storage.secure_auth_storage_manager import SecureAuthStorageManager\n\nclass MyCustomAuthStorageManager(SecureAuthStorageManager):\n    def store(self, user_id: str, key: str, data: AuthData) -&gt; None:\n        # Your implementation\n        pass\n\n    def retrieve(self, user_id: str, key: str) -&gt; AuthData | None:\n        # Your implementation\n        return None\n\n    def delete(self, user_id: str, key: str) -&gt; None:\n        # Your implementation\n        pass\n</code></pre>"},{"location":"hitl/authorization/","title":"Authorization Module","text":"<p>This module provides a flexible authorization system for the SK Agents framework. It implements a factory pattern to dynamically load and manage request authorization mechanisms, with support for pluggable authorization strategies.</p>"},{"location":"hitl/authorization/#architecture-overview","title":"Architecture Overview","text":"<p>The authorization module follows a factory pattern with an abstract base class that defines the authorization interface. This design allows for easy extension and customization of authorization mechanisms while maintaining a consistent API.</p>"},{"location":"hitl/authorization/#files-and-classes","title":"Files and Classes","text":""},{"location":"hitl/authorization/#__init__py","title":"<code>__init__.py</code>","text":"<p>Empty initialization file that marks this directory as a Python package.</p>"},{"location":"hitl/authorization/#request_authorizerpy","title":"<code>request_authorizer.py</code>","text":""},{"location":"hitl/authorization/#requestauthorizer-abstract-base-class","title":"<code>RequestAuthorizer</code> (Abstract Base Class)","text":"<p>An abstract base class that defines the contract for all authorization implementations.</p> <p>Purpose: Provides a standardized interface for authorization mechanisms across the application.</p> <p>Key Method:</p> <ul> <li><code>authorize_request(auth_header: str) -&gt; str</code>: Abstract method that validates an authorization header and returns a unique user identifier.</li> </ul> <p>Parameters:</p> <ul> <li><code>auth_header</code>: The value of the 'Authorization' HTTP header (typically \"Bearer token\" format)</li> </ul> <p>Returns:</p> <ul> <li>A unique string identifier for the authenticated user (e.g., user ID, username, email)</li> </ul> <p>Raises:</p> <ul> <li><code>ValueError</code>: For missing, malformed, or invalid authorization headers</li> <li><code>AuthenticationError</code>: (Optional) For authentication failures in implementations</li> </ul> <p>Usage: All custom authorization implementations must inherit from this class and implement the <code>authorize_request</code> method.</p>"},{"location":"hitl/authorization/#dummy_authorizerpy","title":"<code>dummy_authorizer.py</code>","text":""},{"location":"hitl/authorization/#dummyauthorizer-concrete-implementation","title":"<code>DummyAuthorizer</code> (Concrete Implementation)","text":"<p>A simple test/development implementation of the <code>RequestAuthorizer</code> interface.</p> <p>Purpose: Provides a no-op authorization mechanism for development, testing, or scenarios where authentication is not required.</p> <p>Behavior:</p> <ul> <li>Always returns \"dummyuser\" regardless of the input authorization header</li> <li>Does not perform any actual validation or authentication</li> <li>Useful for development environments or testing scenarios</li> </ul> <p>Implementation:</p> <pre><code>async def authorize_request(self, auth_header: str) -&gt; str:\n    return \"dummyuser\"\n</code></pre> <p>Use Cases:</p> <ul> <li>Local development without authentication setup</li> <li>Testing environments</li> <li>Placeholder implementation during development</li> </ul>"},{"location":"hitl/authorization/#singletonpy","title":"<code>singleton.py</code>","text":""},{"location":"hitl/authorization/#singleton-metaclass","title":"<code>Singleton</code> (Metaclass)","text":"<p>A thread-safe implementation of the Singleton design pattern using a metaclass.</p> <p>Purpose: Ensures that only one instance of a class exists throughout the application lifecycle while being thread-safe.</p> <p>Features:</p> <ul> <li>Thread Safety: Uses <code>threading.Lock()</code> to prevent race conditions in multi-threaded environments</li> <li>Instance Management: Maintains a dictionary of class instances (<code>_instances</code>)</li> <li>Metaclass Implementation: Implemented as a metaclass (<code>ABCMeta</code> subclass) for clean integration</li> </ul> <p>Key Components:</p> <ul> <li><code>_instances</code>: Class-level dictionary storing singleton instances</li> <li><code>_lock</code>: Threading lock for thread-safe instance creation</li> <li><code>__call__</code>: Overridden method that controls instance creation</li> </ul> <p>Usage: Classes that need singleton behavior inherit this as their metaclass:</p> <pre><code>class MyClass(metaclass=Singleton):\n    pass\n</code></pre> <p>Thread Safety: The implementation ensures that even in multi-threaded environments, only one instance of each class is created.</p>"},{"location":"hitl/authorization/#authorizer_factorypy","title":"<code>authorizer_factory.py</code>","text":""},{"location":"hitl/authorization/#authorizerfactory-singleton-factory","title":"<code>AuthorizerFactory</code> (Singleton Factory)","text":"<p>A factory class that dynamically loads and creates authorization implementations based on configuration.</p> <p>Purpose: Provides a centralized way to create and manage authorization instances while supporting dynamic loading of custom authorization implementations.</p> <p>Design Pattern: Factory pattern combined with Singleton pattern for application-wide consistency.</p> <p>Key Features:</p> <ul> <li>Dynamic Loading: Loads authorization classes from modules specified by file paths in configuration</li> <li>Type Safety: Validates that loaded classes are proper <code>RequestAuthorizer</code> subclasses</li> <li>Configuration-Driven: Uses environment variables to determine which authorization implementation to use</li> <li>Singleton: Ensures consistent authorization behavior across the application</li> </ul> <p>Constructor Parameters:</p> <ul> <li><code>app_config</code>: An <code>AppConfig</code> instance containing application configuration</li> </ul> <p>Key Methods:</p>"},{"location":"hitl/authorization/#get_authorizer-requestauthorizer","title":"<code>get_authorizer() -&gt; RequestAuthorizer</code>","text":"<p>Returns an instance of the configured authorization class.</p> <p>Returns: A configured <code>RequestAuthorizer</code> implementation</p>"},{"location":"hitl/authorization/#_get_authorizer_config-tuplestr-str-private","title":"<code>_get_authorizer_config() -&gt; tuple[str, str]</code> (Private)","text":"<p>Retrieves the module and class names from configuration.</p> <p>Returns: Tuple containing (module_name, class_name)</p> <p>Raises:</p> <ul> <li><code>ValueError</code>: If required environment variables are not set</li> </ul> <p>Configuration Requirements:</p> <ul> <li><code>TA_AUTHORIZER_MODULE</code>: Environment variable specifying the file path to the module containing the authorization class (e.g., <code>src/sk_agents/authorization/dummy_authorizer.py</code>)</li> <li><code>TA_AUTHORIZER_CLASS</code>: Environment variable specifying the authorization class name</li> </ul> <p>Error Handling:</p> <ul> <li><code>ImportError</code>: Raised if the specified module cannot be loaded or the class is not found</li> <li><code>TypeError</code>: Raised if the loaded class is not a subclass of <code>RequestAuthorizer</code></li> <li><code>ValueError</code>: Raised if required configuration is missing</li> </ul> <p>Usage Example:</p> <pre><code># Configuration (environment variables)\nTA_AUTHORIZER_MODULE = \"src/sk_agents/authorization/dummy_authorizer.py\"\nTA_AUTHORIZER_CLASS = \"DummyAuthorizer\"\n\n# Usage\nfactory = AuthorizerFactory(app_config)\nauthorizer = factory.get_authorizer()\nuser_id = await authorizer.authorize_request(\"Bearer token123\")\n</code></pre>"},{"location":"hitl/authorization/#configuration","title":"Configuration","text":"<p>The authorization system is configured through environment variables:</p> <ul> <li><code>TA_AUTHORIZER_MODULE</code>: Specifies the file path to the Python module containing the authorization implementation (e.g., <code>src/sk_agents/authorization/dummy_authorizer.py</code>)</li> <li><code>TA_AUTHORIZER_CLASS</code>: Specifies the class name within the module that implements authorization</li> </ul>"},{"location":"hitl/authorization/#usage-patterns","title":"Usage Patterns","text":""},{"location":"hitl/authorization/#1-using-the-default-dummy-authorization","title":"1. Using the Default (Dummy) Authorization","text":"<pre><code># Set environment variables\nTA_AUTHORIZER_MODULE = \"src/sk_agents/authorization/dummy_authorizer.py\"\nTA_AUTHORIZER_CLASS = \"DummyAuthorizer\"\n\n# Create factory and get authorizer\nfactory = AuthorizerFactory(app_config)\nauthorizer = factory.get_authorizer()\n</code></pre>"},{"location":"hitl/authorization/#2-implementing-custom-authorization","title":"2. Implementing Custom Authorization","text":"<pre><code># Create custom authorizer\nclass MyCustomAuthorizer(RequestAuthorizer):\n    async def authorize_request(self, auth_header: str) -&gt; str:\n        # Custom validation logic\n        if not auth_header.startswith(\"Bearer \"):\n            raise ValueError(\"Invalid authorization header format\")\n\n        token = auth_header[7:]  # Remove \"Bearer \" prefix\n        # Validate token and return user ID\n        return validate_and_extract_user_id(token)\n\n# Configure to use custom authorizer\nTA_AUTHORIZER_MODULE = \"my_module/custom_auth.py\"\nTA_AUTHORIZER_CLASS = \"MyCustomAuthorizer\"\n</code></pre>"},{"location":"hitl/authorization/#3-integration-in-web-applications","title":"3. Integration in Web Applications","text":"<pre><code># In request handlers\nasync def protected_endpoint(request):\n    auth_header = request.headers.get(\"Authorization\")\n    if not auth_header:\n        raise ValueError(\"Authorization header required\")\n\n    factory = AuthorizerFactory(app_config)\n    authorizer = factory.get_authorizer()\n    user_id = await authorizer.authorize_request(auth_header)\n\n    # Proceed with authorized request\n    return handle_request_for_user(user_id)\n</code></pre>"},{"location":"hitl/authorization/#design-benefits","title":"Design Benefits","text":"<ol> <li>Flexibility: Easy to swap authorization mechanisms without code changes</li> <li>Extensibility: Simple to add new authorization strategies</li> <li>Testability: Dummy implementation available for testing</li> <li>Configuration-Driven: No hardcoded authorization logic</li> <li>Thread Safety: Singleton implementation ensures consistent behavior</li> <li>Type Safety: Factory validates loaded classes at runtime</li> </ol>"},{"location":"hitl/authorization/#dependencies","title":"Dependencies","text":"<ul> <li><code>ska_utils.AppConfig</code>: For configuration management</li> <li><code>ska_utils.ModuleLoader</code>: For dynamic module loading</li> <li><code>sk_agents.configs</code>: For configuration constants</li> <li><code>threading</code>: For thread-safe singleton implementation</li> <li><code>abc</code>: For abstract base class definition</li> </ul>"},{"location":"hitl/authorization/#thread-safety","title":"Thread Safety","text":"<p>The module is designed to be thread-safe:</p> <ul> <li>The <code>Singleton</code> metaclass uses threading locks to prevent race conditions</li> <li>The <code>AuthorizerFactory</code> is a singleton, ensuring consistent authorization across threads</li> <li>Authorization instances can be safely shared across multiple threads</li> </ul>"},{"location":"hitl/authorization/#error-handling","title":"Error Handling","text":"<p>The module provides comprehensive error handling:</p> <ul> <li>Configuration Errors: Clear messages for missing environment variables</li> <li>Import Errors: Detailed error messages for module loading failures</li> <li>Type Errors: Validation that loaded classes implement the correct interface</li> <li>Authorization Errors: Proper propagation of authentication failures</li> </ul>"},{"location":"hitl/hitl/","title":"Human-in-the-Loop (HITL) System","text":"<p>This document provides a comprehensive overview of the Human-in-the-Loop (HITL) system for the Teal Agents framework, including detailed documentation of all classes, functions, and implementation patterns.</p>"},{"location":"hitl/hitl/#overview","title":"Overview","text":"<p>The HITL system provides a security and governance layer that enables human oversight and approval for high-risk or sensitive tool calls before they are executed by AI agents. This system ensures that potentially dangerous operations require explicit human authorization, adding a critical safety layer to autonomous agent execution.</p>"},{"location":"hitl/hitl/#core-features","title":"Core Features","text":"<ul> <li>Tool Call Interception: Automatic detection and interception of high-risk function calls</li> <li>Policy-Based Governance: Integration with plugin catalog for configurable tool governance</li> <li>Exception-Based Flow Control: Clean exception handling for intervention requirements</li> <li>Request Tracking: Full traceability of intervention requests and responses</li> <li>URL-Based Approval: RESTful approval/rejection mechanism for human reviewers</li> </ul>"},{"location":"hitl/hitl/#folder-structure","title":"Folder Structure","text":"<pre><code>hitl/\n\u251c\u2500\u2500 __init__.py                    # Package initialization (empty)\n\u251c\u2500\u2500 README.md                      # This documentation file\n\u2514\u2500\u2500 hitl_manager.py               # Core HITL functionality and exception handling\n</code></pre>"},{"location":"hitl/hitl/#core-classes-and-functions-documentation","title":"Core Classes and Functions Documentation","text":""},{"location":"hitl/hitl/#1-check_for_intervention-function","title":"1. check_for_intervention() Function","text":"<p>File: <code>hitl_manager.py</code></p> <p>The primary function responsible for determining whether a tool call requires human intervention.</p>"},{"location":"hitl/hitl/#function-signature","title":"Function Signature","text":"<pre><code>def check_for_intervention(tool_call: FunctionCallContent) -&gt; bool\n</code></pre>"},{"location":"hitl/hitl/#parameters","title":"Parameters","text":"<ul> <li><code>tool_call: FunctionCallContent</code>: A Semantic Kernel function call object containing:</li> <li><code>plugin_name</code>: The name of the plugin containing the function</li> <li><code>function_name</code>: The specific function being called</li> <li>Additional metadata about the function call</li> </ul>"},{"location":"hitl/hitl/#returns","title":"Returns","text":"<ul> <li><code>bool</code>: <code>True</code> if the tool call requires human intervention, <code>False</code> otherwise</li> </ul>"},{"location":"hitl/hitl/#implementation-details","title":"Implementation Details","text":"<p>The function performs the following operations:</p> <ol> <li>Plugin Catalog Integration: Creates a <code>PluginCatalogFactory</code> instance to access the tool governance catalog</li> <li>Tool Identification: Constructs a unique tool ID using the format <code>{plugin_name}-{function_name}</code></li> <li>Governance Check: Queries the catalog for the tool's governance settings</li> <li>Policy Evaluation: Returns the value of <code>tool.governance.requires_hitl</code> if the tool is found in the catalog</li> <li>Fallback Behavior: Returns <code>False</code> (no intervention required) if:</li> <li>The catalog is not configured</li> <li>The tool is not found in the catalog</li> </ol>"},{"location":"hitl/hitl/#sk_agents.hitl.hitl_manager.check_for_intervention","title":"sk_agents.hitl.hitl_manager.check_for_intervention","text":"<pre><code>check_for_intervention(\n    tool_call: FunctionCallContent,\n) -&gt; bool\n</code></pre> <p>Checks the plugin catalog to determine if a tool call requires Human-in-the-Loop intervention.</p> Source code in <code>src/sk_agents/hitl/hitl_manager.py</code> <pre><code>def check_for_intervention(tool_call: FunctionCallContent) -&gt; bool:\n    \"\"\"\n    Checks the plugin catalog to determine if a tool call requires\n    Human-in-the-Loop intervention.\n    \"\"\"\n    plugin_factory = PluginCatalogFactory()\n    catalog = plugin_factory.get_catalog()\n    if not catalog:\n        # Fallback if catalog is not configured\n        return False\n\n    tool_id = f\"{tool_call.plugin_name}-{tool_call.function_name}\"\n    tool = catalog.get_tool(tool_id)\n\n    if tool:\n        logger.debug(\n            f\"HITL Check: Intercepted call to {tool_id}. \"\n            f\"Requires HITL: {tool.governance.requires_hitl}\"\n        )\n        return tool.governance.requires_hitl\n    # Default to no intervention if tool is not in the catalog\n    return False\n</code></pre>"},{"location":"hitl/hitl/#usage-in-agent-workflow","title":"Usage in Agent Workflow","text":"<p>This function is called by the agent handler during tool call processing:</p> <pre><code># In agent handler\nfor fc in function_calls:\n    if hitl_manager.check_for_intervention(fc):\n        intervention_calls.append(fc)\n\nif intervention_calls:\n    raise hitl_manager.HitlInterventionRequired(intervention_calls)\n</code></pre>"},{"location":"hitl/hitl/#debug-output","title":"Debug Output","text":"<p>The function includes diagnostic logging that outputs:</p> <ul> <li>The tool ID being checked</li> <li>Whether HITL intervention is required for that tool</li> </ul>"},{"location":"hitl/hitl/#2-hitlinterventionrequired-exception","title":"2. HitlInterventionRequired Exception","text":"<p>File: <code>hitl_manager.py</code></p> <p>A custom exception class that signals when tool calls require human intervention and halts agent execution until approval is received.</p>"},{"location":"hitl/hitl/#class-definition","title":"Class Definition","text":"<pre><code>class HitlInterventionRequired(Exception):\n    def __init__(self, function_calls: list[FunctionCallContent])\n</code></pre>"},{"location":"hitl/hitl/#attributes","title":"Attributes","text":"<ul> <li><code>function_calls: list[FunctionCallContent]</code>: List of all function calls that require intervention</li> <li><code>plugin_name: str</code>: Name of the plugin from the first function call (for convenience)</li> <li><code>function_name: str</code>: Name of the function from the first function call (for convenience)</li> </ul>"},{"location":"hitl/hitl/#constructor-behavior","title":"Constructor Behavior","text":"<ol> <li>Stores Function Calls: Preserves the complete list of function calls requiring intervention</li> <li>Extracts Metadata: Sets <code>plugin_name</code> and <code>function_name</code> from the first function call for easy access</li> <li>Generates Message: Creates a descriptive error message indicating which plugin and function requires intervention</li> <li>Handles Empty Lists: Provides a fallback message if no function calls are provided</li> </ol>"},{"location":"hitl/hitl/#exception-message-format","title":"Exception Message Format","text":"<ul> <li>With function calls: <code>\"HITL intervention required for {plugin_name}.{function_name}\"</code></li> <li>Without function calls: <code>\"HITL intervention required\"</code></li> </ul>"},{"location":"hitl/hitl/#usage-in-error-handling","title":"Usage in Error Handling","text":"<p>The exception is caught by agent handlers to generate <code>HitlResponse</code> objects:</p> <pre><code>try:\n    # Agent execution code\n    pass\nexcept hitl_manager.HitlInterventionRequired as hitl_exc:\n    # Generate HITL response with approval/rejection URLs\n    return HitlResponse(\n        task_id=task_id,\n        session_id=session_id,\n        request_id=request_id,\n        tool_calls=[fc.model_dump() for fc in hitl_exc.function_calls],\n        approval_url=f\"/approve/{request_id}\",\n        rejection_url=f\"/reject/{request_id}\"\n    )\n</code></pre>"},{"location":"hitl/hitl/#sk_agents.hitl.hitl_manager.HitlInterventionRequired","title":"sk_agents.hitl.hitl_manager.HitlInterventionRequired","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised when a tool call requires human-in-the-loop intervention.</p> Source code in <code>src/sk_agents/hitl/hitl_manager.py</code> <pre><code>class HitlInterventionRequired(Exception):\n    \"\"\"\n    Exception raised when a tool call\n    requires human-in-the-loop intervention.\n    \"\"\"\n\n    def __init__(self, function_calls: list[FunctionCallContent]):\n        self.function_calls = function_calls\n        if function_calls:\n            self.plugin_name = function_calls[0].plugin_name\n            self.function_name = function_calls[0].function_name\n            message = f\"HITL intervention required for {self.plugin_name}.{self.function_name}\"\n\n        else:\n            message = \"HITL intervention required but no function calls provided (internal error)\"\n        super().__init__(message)\n</code></pre>"},{"location":"hitl/hitl/#integration-with-teal-agents-framework","title":"Integration with Teal Agents Framework","text":""},{"location":"hitl/hitl/#agent-handler-integration","title":"Agent Handler Integration","text":"<p>The HITL system is integrated into the main agent execution flow at multiple points:</p> <ol> <li>Import: <code>from sk_agents.hitl import hitl_manager</code></li> <li>Tool Call Screening: Each function call is checked before execution</li> <li>Exception Handling: HITL exceptions are caught and converted to HTTP responses</li> <li>State Management: HITL requests are tracked through the agent's state system</li> </ol>"},{"location":"hitl/hitl/#plugin-catalog-dependency","title":"Plugin Catalog Dependency","text":"<p>The HITL system relies on the plugin catalog for governance policies:</p> <ul> <li>Tool Registration: Tools must be registered in the catalog with governance metadata</li> <li>Policy Configuration: The <code>requires_hitl</code> flag in tool governance determines intervention requirements</li> <li>Dynamic Updates: Governance policies can be updated without code changes</li> </ul>"},{"location":"hitl/hitl/#response-model-integration","title":"Response Model Integration","text":"<p>The system generates <code>HitlResponse</code> objects (defined in <code>sk_agents.tealagents.models</code>) containing:</p> <ul> <li>Task Metadata: <code>task_id</code>, <code>session_id</code>, <code>request_id</code></li> <li>Human Message: Descriptive message about the intervention requirement</li> <li>Approval URLs: RESTful endpoints for human approval/rejection</li> <li>Tool Call Data: Serialized function calls awaiting approval</li> </ul>"},{"location":"hitl/hitl/#security-considerations","title":"Security Considerations","text":""},{"location":"hitl/hitl/#fail-safe-design","title":"Fail-Safe Design","text":"<ul> <li>Default Deny: Unknown tools default to no intervention (configurable)</li> <li>Catalog Dependency: Missing catalog configuration falls back to permissive behavior</li> <li>Exception Isolation: HITL exceptions don't crash the agent, they pause execution</li> </ul>"},{"location":"hitl/hitl/#governance-integration","title":"Governance Integration","text":"<ul> <li>Centralized Policy: All governance rules are managed through the plugin catalog</li> <li>Audit Trail: All intervention requests are tracked and logged</li> <li>Configurable Risk Levels: Tools can be classified with different risk levels and policies</li> </ul>"},{"location":"hitl/hitl/#future-enhancements","title":"Future Enhancements","text":""},{"location":"hitl/hitl/#planned-features","title":"Planned Features","text":"<ul> <li>Risk Level Classification: Support for different intervention policies based on risk levels</li> <li>Batch Approval: Ability to approve/reject multiple tool calls simultaneously</li> <li>Timeout Handling: Automatic rejection of approval requests after timeout</li> <li>User Context: Integration with user authentication for personalized approval flows</li> </ul>"},{"location":"hitl/hitl/#extension-points","title":"Extension Points","text":"<ul> <li>Custom Policies: Support for custom intervention logic beyond simple boolean flags</li> <li>Approval Workflows: Integration with enterprise approval systems</li> <li>Notification Systems: Email/Slack notifications for pending approvals</li> <li>Analytics: Metrics on intervention frequency and approval rates</li> </ul>"},{"location":"hitl/hitl/#error-handling","title":"Error Handling","text":""},{"location":"hitl/hitl/#exception-hierarchy","title":"Exception Hierarchy","text":"<pre><code>Exception\n\u2514\u2500\u2500 HitlInterventionRequired\n    \u251c\u2500\u2500 function_calls: list[FunctionCallContent]\n    \u251c\u2500\u2500 plugin_name: str\n    \u2514\u2500\u2500 function_name: str\n</code></pre>"},{"location":"hitl/hitl/#error-recovery","title":"Error Recovery","text":"<ul> <li>Graceful Degradation: System continues operation even if HITL components fail</li> <li>Logging: All intervention decisions are logged for audit purposes</li> <li>Fallback Behavior: Clear fallback policies when governance data is unavailable</li> </ul>"},{"location":"hitl/hitl/#testing-considerations","title":"Testing Considerations","text":""},{"location":"hitl/hitl/#unit-testing","title":"Unit Testing","text":"<ul> <li>Mock Plugin Catalog: Test with various catalog configurations</li> <li>Exception Flow: Verify exception handling and response generation</li> <li>Edge Cases: Test with empty function call lists and missing catalog data</li> </ul>"},{"location":"hitl/hitl/#integration-testing","title":"Integration Testing","text":"<ul> <li>End-to-End Flow: Test complete approval/rejection workflows</li> <li>State Persistence: Verify that HITL requests are properly tracked</li> <li>URL Generation: Validate approval/rejection URL correctness</li> </ul>"},{"location":"hitl/hitl/#development-guidelines","title":"Development Guidelines","text":""},{"location":"hitl/hitl/#adding-new-hitl-policies","title":"Adding New HITL Policies","text":"<ol> <li>Register Tools: Add tools to the plugin catalog with appropriate governance flags</li> <li>Test Integration: Verify that <code>check_for_intervention</code> correctly identifies the tools</li> <li>Update Documentation: Document new governance policies and their implications</li> </ol>"},{"location":"hitl/hitl/#debugging-hitl-issues","title":"Debugging HITL Issues","text":"<ol> <li>Check Logs: Look for \"HITL Check: Intercepted call\" messages</li> <li>Verify Catalog: Ensure the plugin catalog is properly configured</li> <li>Test Isolation: Use unit tests to isolate HITL logic from agent execution</li> </ol>"},{"location":"hitl/persistence/","title":"Task Persistence System","text":"<p>This document provides a comprehensive overview of the task persistence system for the Teal Agents framework, including detailed documentation of all classes, interfaces, and implementation patterns.</p>"},{"location":"hitl/persistence/#overview","title":"Overview","text":"<p>The task persistence system provides a flexible, pluggable architecture for storing and retrieving agent tasks and their state. The system supports multiple storage backends through a factory pattern with dependency injection.</p>"},{"location":"hitl/persistence/#core-features","title":"Core Features","text":"<ul> <li>Pluggable Architecture: Factory pattern with configurable implementations</li> <li>Thread-Safe Operations: Async-safe with proper locking mechanisms</li> <li>In-Memory Storage (default): Zero configuration, perfect for development</li> <li>Redis Storage (optional): Persistent, scalable, production-ready</li> <li>Custom Storage: Support for user-defined implementations</li> <li>Request ID Indexing: Fast lookups by request ID across all implementations</li> </ul>"},{"location":"hitl/persistence/#folder-structure","title":"Folder Structure","text":"<pre><code>persistence/\n\u251c\u2500\u2500 __init__.py                           # Package initialization (empty)\n\u251c\u2500\u2500 README.md                            # This documentation file\n\u251c\u2500\u2500 singleton.py                         # Thread-safe singleton metaclass\n\u251c\u2500\u2500 task_persistence_manager.py         # Abstract base class interface\n\u251c\u2500\u2500 in_memory_persistence_manager.py    # Default in-memory implementation\n\u251c\u2500\u2500 persistence_factory.py              # Factory pattern with dependency injection\n\u2514\u2500\u2500 custom/                              # Custom implementations directory\n    \u2514\u2500\u2500 example_redis_persistence.py    # Production-ready Redis implementation\n</code></pre>"},{"location":"hitl/persistence/#core-classes-documentation","title":"Core Classes Documentation","text":""},{"location":"hitl/persistence/#1-taskpersistencemanager-abstract-base-class","title":"1. TaskPersistenceManager (Abstract Base Class)","text":"<p>File: <code>task_persistence_manager.py</code></p> <p>The abstract base class that defines the interface for all persistence implementations.</p>"},{"location":"hitl/persistence/#methods","title":"Methods","text":"<ul> <li><code>async create(task: AgentTask) -&gt; None</code></li> <li>Creates a new task in the persistence layer</li> <li> <p>Should raise <code>PersistenceCreateError</code> if task already exists or on failure</p> </li> <li> <p><code>async load(task_id: str) -&gt; AgentTask | None</code></p> </li> <li>Loads a task by its unique task ID</li> <li>Returns <code>None</code> if task not found</li> <li> <p>Should raise <code>PersistenceLoadError</code> on failure</p> </li> <li> <p><code>async update(task: AgentTask) -&gt; None</code></p> </li> <li>Updates an existing task in the persistence layer</li> <li> <p>Should raise <code>PersistenceUpdateError</code> if task doesn't exist or on failure</p> </li> <li> <p><code>async delete(task_id: str) -&gt; None</code></p> </li> <li>Deletes a task by its unique task ID</li> <li> <p>Should raise <code>PersistenceDeleteError</code> if task doesn't exist or on failure</p> </li> <li> <p><code>async load_by_request_id(request_id: str) -&gt; AgentTask | None</code></p> </li> <li>Loads a task by request ID (for tasks containing items with specific request IDs)</li> <li>Returns the first matching task if multiple exist</li> <li>Returns <code>None</code> if no task found</li> </ul>"},{"location":"hitl/persistence/#2-inmemorypersistencemanager-default-implementation","title":"2. InMemoryPersistenceManager (Default Implementation)","text":"<p>File: <code>in_memory_persistence_manager.py</code></p> <p>Production-ready in-memory implementation with thread safety and request ID indexing.</p>"},{"location":"hitl/persistence/#implementation-features","title":"Implementation Features","text":"<ul> <li>Thread Safety: Uses <code>asyncio.Lock()</code> for concurrent access protection</li> <li>Dual Indexing: Primary storage by task_id + secondary index by request_id</li> <li>Memory Efficient: Automatic cleanup of empty index entries</li> <li>Error Handling: Comprehensive exception handling with custom error types</li> </ul>"},{"location":"hitl/persistence/#internal-data-structures","title":"Internal Data Structures","text":"<ul> <li><code>in_memory: dict[str, AgentTask]</code>: Primary storage mapping task_id to AgentTask</li> <li><code>item_request_id_index: dict[str, set[str]]</code>: Secondary index mapping request_id to set of task_ids</li> </ul>"},{"location":"hitl/persistence/#thread-safety-implementation","title":"Thread Safety Implementation","text":"<pre><code>async with self._lock:\n    # All operations are protected by asyncio.Lock\n</code></pre>"},{"location":"hitl/persistence/#3-persistencefactory-factory-pattern","title":"3. PersistenceFactory (Factory Pattern)","text":"<p>File: <code>persistence_factory.py</code></p> <p>Singleton factory responsible for creating and managing persistence manager instances with dependency injection support.</p>"},{"location":"hitl/persistence/#key-features","title":"Key Features","text":"<ul> <li>Singleton Pattern: Ensures single instance per application lifecycle</li> <li>Dynamic Module Loading: Loads custom implementations via <code>ModuleLoader</code></li> <li>Configuration-Driven: Uses environment variables for custom implementations</li> <li>Validation: Ensures custom classes inherit from <code>TaskPersistenceManager</code></li> <li>Graceful Fallback: Falls back to in-memory implementation if custom module fails</li> </ul>"},{"location":"hitl/persistence/#configuration-methods","title":"Configuration Methods","text":"<ul> <li><code>_get_custom_persistence_config() -&gt; tuple[str | None, str | None]</code></li> <li>Retrieves module and class names from environment variables</li> <li> <p>Returns <code>(None, None)</code> if using default configuration</p> </li> <li> <p><code>_validate_custom_class()</code></p> </li> <li>Validates that custom class exists and inherits from <code>TaskPersistenceManager</code></li> <li>Raises appropriate exceptions for missing or invalid classes</li> </ul>"},{"location":"hitl/persistence/#dependency-injection","title":"Dependency Injection","text":"<p>The factory attempts to pass <code>app_config</code> to custom implementations:</p> <pre><code>try:\n    return custom_class(app_config=self.app_config)\nexcept TypeError:\n    # Fallback if app_config not accepted\n    return custom_class()\n</code></pre>"},{"location":"hitl/persistence/#4-singleton-metaclass","title":"4. Singleton (Metaclass)","text":"<p>File: <code>singleton.py</code></p> <p>Thread-safe singleton metaclass implementation using Python's <code>threading.Lock</code>.</p>"},{"location":"hitl/persistence/#features","title":"Features","text":"<ul> <li>Thread Safety: Uses <code>threading.Lock()</code> to prevent race conditions</li> <li>Metaclass Pattern: Implements singleton at the class level</li> <li>Instance Caching: Maintains <code>_instances</code> dictionary for created instances</li> </ul>"},{"location":"hitl/persistence/#usage-pattern","title":"Usage Pattern","text":"<pre><code>class MyClass(metaclass=Singleton):\n    def __init__(self):\n        # Initialization code\n        pass\n</code></pre>"},{"location":"hitl/persistence/#custom-implementations-directory","title":"Custom Implementations Directory","text":""},{"location":"hitl/persistence/#redistaskpersistencemanager-production-example","title":"RedisTaskPersistenceManager (Production Example)","text":"<p>File: <code>custom/example_redis_persistence.py</code></p> <p>A complete, production-ready Redis-based persistence implementation demonstrating advanced patterns.</p>"},{"location":"hitl/persistence/#architecture-features","title":"Architecture Features","text":"<ul> <li>Connection Management: Robust Redis connection with retry logic</li> <li>Serialization: JSON-based task serialization using Pydantic models</li> <li>TTL Support: Configurable time-to-live for all stored data</li> <li>Index Management: Maintains request_id to task_id mapping in Redis sets</li> <li>Error Recovery: Handles corrupted data with automatic cleanup</li> <li>Health Monitoring: Built-in health check capabilities</li> </ul>"},{"location":"hitl/persistence/#configuration-environment-variables","title":"Configuration Environment Variables","text":"<pre><code>TA_REDIS_HOST        # Redis server hostname (default: localhost)\nTA_REDIS_PORT        # Redis server port (default: 6379)\nTA_REDIS_DB          # Redis database number (default: 0)\nTA_REDIS_TTL         # Time-to-live in seconds (default: 3600)\nTA_REDIS_PWD         # Redis password (optional)\nTA_REDIS_SSL         # Enable SSL connection (default: false)\n</code></pre>"},{"location":"hitl/persistence/#redis-key-patterns","title":"Redis Key Patterns","text":"<ul> <li>Task Storage: <code>task_persistence:task:{task_id}</code></li> <li>Request Index: <code>task_persistence:request_index:{request_id}</code></li> </ul>"},{"location":"hitl/persistence/#advanced-methods","title":"Advanced Methods","text":"<ul> <li><code>health_check() -&gt; bool</code>: Tests Redis connectivity</li> <li><code>clear_all_tasks() -&gt; int</code>: Utility method for testing/cleanup</li> <li><code>_serialize_task(task: AgentTask) -&gt; str</code>: JSON serialization</li> <li><code>_deserialize_task(task_str: str) -&gt; AgentTask</code>: JSON deserialization</li> </ul>"},{"location":"hitl/persistence/#error-handling-strategy","title":"Error Handling Strategy","text":"<pre><code>try:\n    # Redis operation\nexcept redis.RedisError as e:\n    raise PersistenceCreateError(f\"Redis error: {e}\") from e\nexcept json.JSONDecodeError as e:\n    # Handle corrupted data with cleanup\n    self.redis_client.delete(task_key)\n    raise PersistenceLoadError(f\"Corrupted data: {e}\") from e\n</code></pre>"},{"location":"hitl/persistence/#configuration-system","title":"Configuration System","text":""},{"location":"hitl/persistence/#environment-variables","title":"Environment Variables","text":"<p>The persistence system uses the following environment variables:</p> <ul> <li><code>TA_PERSISTENCE_MODULE</code>: Path to custom task persistence module</li> <li><code>TA_PERSISTENCE_CLASS</code>: Class name for custom implementation</li> </ul>"},{"location":"hitl/persistence/#configuration-examples","title":"Configuration Examples","text":""},{"location":"hitl/persistence/#development-default-in-memory","title":"Development (Default - In-Memory)","text":"<pre><code># No configuration needed - uses in-memory storage\n</code></pre>"},{"location":"hitl/persistence/#production-with-redis","title":"Production with Redis","text":"<pre><code>export TA_PERSISTENCE_MODULE=src/sk_agents/persistence/custom/example_redis_persistence.py\nexport TA_PERSISTENCE_CLASS=RedisTaskPersistenceManager\nexport TA_REDIS_HOST=redis.production.com\nexport TA_REDIS_PORT=6379\nexport TA_REDIS_PWD=secure_password\nexport TA_REDIS_SSL=true\nexport TA_REDIS_TTL=7200\n</code></pre>"},{"location":"hitl/persistence/#custom-implementation","title":"Custom Implementation","text":"<pre><code>export TA_PERSISTENCE_MODULE=my_custom_module.py\nexport TA_PERSISTENCE_CLASS=MyCustomPersistenceManager\n</code></pre>"},{"location":"hitl/persistence/#usage-patterns","title":"Usage Patterns","text":""},{"location":"hitl/persistence/#basic-usage","title":"Basic Usage","text":"<pre><code>from ska_utils import AppConfig\nfrom sk_agents.persistence.persistence_factory import PersistenceFactory\nfrom sk_agents.tealagents.models import AgentTask\n\n# Get task persistence manager\napp_config = AppConfig()\nfactory = PersistenceFactory(app_config)\npersistence_manager = factory.get_persistence_manager()\n\n# Store, retrieve, and manage task data\nawait persistence_manager.create(agent_task)\nretrieved_task = await persistence_manager.load(\"task_id_123\")\nawait persistence_manager.update(agent_task)\nawait persistence_manager.delete(\"task_id_123\")\n\n# Load by request ID (useful for resuming workflows)\ntask = await persistence_manager.load_by_request_id(\"request_123\")\n</code></pre>"},{"location":"hitl/persistence/#advanced-usage-with-error-handling","title":"Advanced Usage with Error Handling","text":"<pre><code>from sk_agents.exceptions import PersistenceCreateError, PersistenceLoadError\n\ntry:\n    await persistence_manager.create(task)\nexcept PersistenceCreateError as e:\n    logger.error(f\"Failed to create task: {e.message}\")\n    # Handle creation failure\n\ntry:\n    task = await persistence_manager.load(task_id)\n    if task is None:\n        logger.info(f\"Task {task_id} not found\")\n    else:\n        # Process loaded task\n        pass\nexcept PersistenceLoadError as e:\n    logger.error(f\"Failed to load task: {e.message}\")\n</code></pre>"},{"location":"hitl/persistence/#creating-custom-implementations","title":"Creating Custom Implementations","text":""},{"location":"hitl/persistence/#step-1-implement-the-interface","title":"Step 1: Implement the Interface","text":"<p>Create a new class that inherits from <code>TaskPersistenceManager</code>:</p> <pre><code>from sk_agents.persistence.task_persistence_manager import TaskPersistenceManager\nfrom sk_agents.tealagents.models import AgentTask\nfrom sk_agents.exceptions import (\n    PersistenceCreateError,\n    PersistenceDeleteError,\n    PersistenceLoadError,\n    PersistenceUpdateError,\n)\n\nclass MyCustomTaskPersistenceManager(TaskPersistenceManager):\n    def __init__(self, app_config=None):\n        # Initialize your storage backend\n        self.storage = self._initialize_storage(app_config)\n\n    async def create(self, task: AgentTask) -&gt; None:\n        try:\n            # Your implementation\n            if await self._task_exists(task.task_id):\n                raise PersistenceCreateError(\n                    f\"Task {task.task_id} already exists\"\n                )\n            await self._store_task(task)\n        except Exception as e:\n            raise PersistenceCreateError(f\"Create failed: {e}\") from e\n\n    async def load(self, task_id: str) -&gt; AgentTask | None:\n        try:\n            return await self._retrieve_task(task_id)\n        except Exception as e:\n            raise PersistenceLoadError(f\"Load failed: {e}\") from e\n\n    async def update(self, task: AgentTask) -&gt; None:\n        try:\n            if not await self._task_exists(task.task_id):\n                raise PersistenceUpdateError(\n                    f\"Task {task.task_id} does not exist\"\n                )\n            await self._update_task(task)\n        except Exception as e:\n            raise PersistenceUpdateError(f\"Update failed: {e}\") from e\n\n    async def delete(self, task_id: str) -&gt; None:\n        try:\n            if not await self._task_exists(task_id):\n                raise PersistenceDeleteError(\n                    f\"Task {task_id} does not exist\"\n                )\n            await self._remove_task(task_id)\n        except Exception as e:\n            raise PersistenceDeleteError(f\"Delete failed: {e}\") from e\n\n    async def load_by_request_id(self, request_id: str) -&gt; AgentTask | None:\n        try:\n            task_ids = await self._find_tasks_by_request_id(request_id)\n            if not task_ids:\n                return None\n            return await self.load(task_ids[0])\n        except Exception as e:\n            raise PersistenceLoadError(f\"Load by request_id failed: {e}\") from e\n</code></pre>"},{"location":"hitl/persistence/#step-2-configuration","title":"Step 2: Configuration","text":"<p>Set the environment variables to use your custom implementation:</p> <pre><code>export TA_PERSISTENCE_MODULE=path/to/your/custom_module.py\nexport TA_PERSISTENCE_CLASS=MyCustomTaskPersistenceManager\n</code></pre>"},{"location":"hitl/persistence/#step-3-integration","title":"Step 3: Integration","text":"<p>The factory will automatically load and validate your implementation when the application starts.</p>"},{"location":"hitl/persistence/#error-handling","title":"Error Handling","text":"<p>The persistence system uses custom exception types for different failure scenarios:</p> <ul> <li><code>PersistenceCreateError</code>: Task creation failures</li> <li><code>PersistenceLoadError</code>: Task retrieval failures</li> <li><code>PersistenceUpdateError</code>: Task update failures</li> <li><code>PersistenceDeleteError</code>: Task deletion failures</li> </ul> <p>All implementations should raise these specific exceptions to maintain consistent error handling across the system.</p>"},{"location":"hitl/persistence/#testing-considerations","title":"Testing Considerations","text":"<p>When implementing custom persistence managers:</p> <ol> <li>Unit Tests: Test all CRUD operations with various edge cases</li> <li>Concurrency Tests: Verify thread safety with concurrent operations</li> <li>Error Scenarios: Test network failures, corrupted data, etc.</li> <li>Performance Tests: Measure latency and throughput under load</li> <li>Integration Tests: Test with actual AgentTask objects</li> </ol> <p>Example test pattern:</p> <pre><code>import pytest\nfrom sk_agents.tealagents.models import AgentTask\n\n@pytest.mark.asyncio\nasync def test_create_and_load():\n    persistence_manager = MyCustomPersistenceManager()\n\n    # Create test task\n    task = AgentTask(task_id=\"test_123\", ...)\n    await persistence_manager.create(task)\n\n    # Verify retrieval\n    loaded_task = await persistence_manager.load(\"test_123\")\n    assert loaded_task is not None\n    assert loaded_task.task_id == \"test_123\"\n</code></pre>"},{"location":"hitl/persistence/#best-practices","title":"Best Practices","text":"<ol> <li>Thread Safety: Always implement proper locking for concurrent access</li> <li>Error Handling: Use the standard exception types for consistency</li> <li>Resource Management: Properly close connections and clean up resources</li> <li>Configuration: Support dependency injection via <code>app_config</code> parameter</li> <li>Logging: Include comprehensive logging for debugging and monitoring</li> <li>Validation: Validate input parameters and handle edge cases</li> <li>Documentation: Document configuration requirements and usage patterns</li> </ol>"},{"location":"hitl/plugin_catalog/","title":"Plugin Catalog Module","text":"<p>The Plugin Catalog module provides a comprehensive system for managing, cataloging, and accessing plugins and their associated tools within the Teal Agents framework. This module implements a flexible architecture that supports different plugin types, governance controls, authentication mechanisms, and data loading strategies.</p>"},{"location":"hitl/plugin_catalog/#module-overview","title":"Module Overview","text":"<p>The plugin catalog system is designed to:</p> <ul> <li>Provide a standardized way to define and catalog plugins</li> <li>Implement governance controls for plugin tools (cost, data sensitivity, human-in-the-loop requirements)</li> <li>Support different plugin types (code-based, MCP-based)</li> <li>Enable dynamic loading and configuration of plugin catalogs</li> <li>Maintain a registry of available tools with their metadata</li> </ul>"},{"location":"hitl/plugin_catalog/#file-structure-and-components","title":"File Structure and Components","text":""},{"location":"hitl/plugin_catalog/#1-modelspy-data-models-and-schema-definitions","title":"1. <code>models.py</code> - Data Models and Schema Definitions","text":"<p>This file contains all Pydantic data models that define the structure and validation rules for the plugin catalog system.</p>"},{"location":"hitl/plugin_catalog/#core-classes","title":"Core Classes","text":"<p>Plugin Type Models:</p> <ul> <li><code>CodePluginType</code>: Represents plugins that contain executable code</li> <li> <p><code>type_name</code>: Literal[\"code\"] - Identifies this as a code-based plugin</p> </li> <li> <p><code>McpPluginType</code>: Represents Model Context Protocol (MCP) plugins</p> </li> <li><code>type_name</code>: Literal[\"mcp\"] - Identifies this as an MCP plugin</li> <li> <p>Future-proofed for additional MCP-specific metadata</p> </li> <li> <p><code>PluginType</code>: Union type that can be either CodePluginType or McpPluginType</p> </li> </ul> <p>Governance Model:</p> <ul> <li><code>Governance</code>: Defines security and operational controls for plugin tools</li> <li><code>requires_hitl</code>: Boolean flag indicating if human-in-the-loop approval is required</li> <li><code>cost</code>: Enum [\"low\", \"medium\", \"high\"] - Resource cost classification</li> <li><code>data_sensitivity</code>: Enum [\"public\", \"proprietary\", \"confidential\", \"sensitive\"] - Data sensitivity level</li> </ul> <p>Authentication Models:</p> <ul> <li><code>Oauth2PluginAuth</code>: OAuth2 authentication configuration</li> <li><code>auth_type</code>: Literal[\"oauth2\"] - Authentication method identifier</li> <li><code>auth_server</code>: Server URL for OAuth2 authentication</li> <li> <p><code>scopes</code>: List of OAuth2 scopes required</p> </li> <li> <p><code>PluginAuth</code>: Union type for authentication methods (currently only OAuth2)</p> </li> </ul> <p>Core Plugin Models:</p> <ul> <li><code>PluginTool</code>: Represents an individual tool within a plugin</li> <li><code>tool_id</code>: Unique identifier (e.g., \"Shell-execute\")</li> <li><code>name</code>: Human-readable tool name</li> <li><code>description</code>: Tool functionality description</li> <li><code>governance</code>: Governance controls for the tool</li> <li> <p><code>auth</code>: Optional authentication requirements</p> </li> <li> <p><code>Plugin</code>: Represents a complete plugin with its tools</p> </li> <li><code>plugin_id</code>: Unique plugin identifier</li> <li><code>name</code>: Human-readable plugin name</li> <li><code>description</code>: Plugin functionality description</li> <li><code>version</code>: Plugin version string</li> <li><code>owner</code>: Plugin owner/maintainer</li> <li><code>plugin_type</code>: Type of plugin (code or MCP)</li> <li> <p><code>tools</code>: List of tools provided by the plugin</p> </li> <li> <p><code>PluginCatalogDefinition</code>: Top-level container for plugin catalog data</p> </li> <li><code>plugins</code>: List of all plugins in the catalog</li> </ul>"},{"location":"hitl/plugin_catalog/#2-plugin_catalogpy-abstract-base-class","title":"2. <code>plugin_catalog.py</code> - Abstract Base Class","text":"<p>This file defines the abstract interface that all plugin catalog implementations must follow.</p>"},{"location":"hitl/plugin_catalog/#interface-definition","title":"Interface Definition","text":"<p>PluginCatalog (ABC):</p> <ul> <li>Abstract base class defining the contract for plugin catalog implementations</li> <li>Methods:</li> <li><code>get_plugin(plugin_id: str) -&gt; Plugin | None</code>: Retrieve a plugin by its ID</li> <li><code>get_tool(tool_id: str) -&gt; PluginTool | None</code>: Retrieve a tool by its ID</li> </ul> <p>This abstraction allows for different storage backends (file-based, database, remote API, etc.) while maintaining a consistent interface.</p>"},{"location":"hitl/plugin_catalog/#3-local_plugin_catalogpy-file-based-implementation","title":"3. <code>local_plugin_catalog.py</code> - File-Based Implementation","text":"<p>This file contains the concrete implementation of the plugin catalog that loads plugins from local JSON files.</p>"},{"location":"hitl/plugin_catalog/#implementation-details","title":"Implementation Details","text":"<p>FileBasedPluginCatalog:</p> <ul> <li>Concrete implementation of PluginCatalog that loads from JSON files</li> <li>Constructor Parameters:</li> <li> <p><code>app_config</code>: AppConfig instance for configuration management</p> </li> <li> <p>Instance Variables:</p> </li> <li><code>app_config</code>: Configuration manager</li> <li><code>catalog_path</code>: Path to the JSON catalog file</li> <li><code>_plugins</code>: Dictionary mapping plugin IDs to Plugin objects</li> <li> <p><code>_tools</code>: Dictionary mapping tool IDs to PluginTool objects</p> </li> <li> <p>Methods:</p> </li> <li><code>get_plugin(plugin_id: str) -&gt; Plugin | None</code>: Retrieves plugin from internal cache</li> <li><code>get_tool(tool_id: str) -&gt; PluginTool | None</code>: Retrieves tool from internal cache</li> <li> <p><code>_load_plugins()</code>: Private method that loads and validates plugins from JSON file</p> </li> <li> <p>Error Handling:</p> </li> <li>Validates JSON structure against Pydantic models</li> <li>Raises <code>PluginCatalogDefinitionException</code> for validation errors</li> <li>Raises <code>PluginFileReadException</code> for file I/O errors</li> </ul>"},{"location":"hitl/plugin_catalog/#4-plugin_catalog_factorypy-singleton-factory","title":"4. <code>plugin_catalog_factory.py</code> - Singleton Factory","text":"<p>This file implements a factory pattern with singleton behavior for creating plugin catalog instances.</p>"},{"location":"hitl/plugin_catalog/#factory-implementation","title":"Factory Implementation","text":"<p>PluginCatalogFactory:</p> <ul> <li>Singleton factory that creates and manages plugin catalog instances</li> <li>Uses environment variables to determine which catalog implementation to load</li> <li> <p>Singleton Behavior: Ensures only one factory instance exists per application</p> </li> <li> <p>Instance Variables:</p> </li> <li><code>app_config</code>: Configuration manager</li> <li> <p><code>_catalog_instance</code>: Cached catalog instance</p> </li> <li> <p>Methods:</p> </li> <li><code>get_catalog() -&gt; PluginCatalog</code>: Returns the catalog instance, creating it if needed</li> <li> <p><code>_create_catalog() -&gt; PluginCatalog</code>: Creates new catalog instance based on environment configuration</p> </li> <li> <p>Configuration:</p> </li> <li>Uses <code>TA_PLUGIN_CATALOG_MODULE</code> environment variable to specify the module</li> <li>Uses <code>TA_PLUGIN_CATALOG_CLASS</code> environment variable to specify the class name</li> <li> <p>Dynamically loads and instantiates the specified catalog class</p> </li> <li> <p>Error Handling:</p> </li> <li>Validates that environment variables are set</li> <li>Ensures the specified class inherits from PluginCatalog</li> <li>Handles import and instantiation errors gracefully</li> </ul>"},{"location":"hitl/plugin_catalog/#5-catalogjson-plugin-definitions","title":"5. <code>catalog.json</code> - Plugin Definitions","text":"<p>This JSON file contains the actual plugin and tool definitions used by the file-based catalog implementation.</p>"},{"location":"hitl/plugin_catalog/#plugin-structure","title":"Plugin Structure","text":"<p>The file contains a <code>plugins</code> array with the following sample plugins:</p> <p>sensitive_plugin:</p> <ul> <li>Plugin for executing sensitive shell commands</li> <li>Tools: <code>delete_user_data</code> - requires human approval due to high sensitivity</li> </ul> <p>finance_plugin:</p> <ul> <li>Plugin for financial operations</li> <li>Tools:</li> <li><code>initiate_transfer</code> - requires human approval for financial transactions</li> <li><code>get_balance</code> - low-cost balance inquiry operation</li> </ul> <p>admin_tools:</p> <ul> <li>Administrative system tools</li> <li>Tools: <code>shutdown_service</code> - requires human approval for service management</li> </ul> <p>utility_plugin:</p> <ul> <li>General utility operations</li> <li>Tools: <code>ShellCommand</code> - general shell command execution with approval requirements</li> </ul> <p>Each plugin includes:</p> <ul> <li>Unique identification and metadata</li> <li>Version and ownership information</li> <li>Plugin type classification</li> <li>List of available tools with their governance requirements</li> </ul>"},{"location":"hitl/plugin_catalog/#usage-patterns","title":"Usage Patterns","text":""},{"location":"hitl/plugin_catalog/#1-basic-usage","title":"1. Basic Usage","text":"<pre><code>from sk_agents.plugin_catalog.plugin_catalog_factory import PluginCatalogFactory\n\n# Get the catalog instance\nfactory = PluginCatalogFactory()\ncatalog = factory.get_catalog()\n\n# Retrieve a specific plugin\nplugin = catalog.get_plugin(\"finance_plugin\")\n\n# Retrieve a specific tool\ntool = catalog.get_tool(\"finance_plugin-get_balance\")\n</code></pre>"},{"location":"hitl/plugin_catalog/#2-governance-checks","title":"2. Governance Checks","text":"<pre><code>tool = catalog.get_tool(\"sensitive_plugin-delete_user_data\")\nif tool and tool.governance.requires_hitl:\n    # Request human approval before execution\n    await request_human_approval(tool)\n</code></pre>"},{"location":"hitl/plugin_catalog/#3-custom-catalog-implementation","title":"3. Custom Catalog Implementation","text":"<pre><code>from sk_agents.plugin_catalog.plugin_catalog import PluginCatalog\n\nclass DatabasePluginCatalog(PluginCatalog):\n    def get_plugin(self, plugin_id: str) -&gt; Plugin | None:\n        # Custom implementation using database\n        pass\n\n    def get_tool(self, tool_id: str) -&gt; PluginTool | None:\n        # Custom implementation using database\n        pass\n</code></pre>"},{"location":"hitl/plugin_catalog/#configuration","title":"Configuration","text":"<p>The module uses environment variables for configuration:</p> <ul> <li><code>TA_PLUGIN_CATALOG_MODULE</code>: Python module containing the catalog class</li> <li><code>TA_PLUGIN_CATALOG_CLASS</code>: Class name within the module</li> <li><code>TA_PLUGIN_CATALOG_FILE</code>: Path to the JSON catalog file (for file-based implementation)</li> </ul>"},{"location":"hitl/plugin_catalog/#security-considerations","title":"Security Considerations","text":"<p>The plugin catalog system includes several security features:</p> <ol> <li>Governance Controls: Each tool specifies its risk level and requirements</li> <li>Human-in-the-Loop: Critical operations can require human approval</li> <li>Data Sensitivity Classification: Tools are classified by data sensitivity</li> <li>Authentication Support: OAuth2 and other auth methods can be specified</li> <li>Validation: All plugin definitions are validated against strict schemas</li> </ol>"},{"location":"hitl/plugin_catalog/#extensibility","title":"Extensibility","text":"<p>The modular design allows for easy extension:</p> <ol> <li>New Plugin Types: Add new plugin type models to support additional architectures</li> <li>Additional Auth Methods: Extend the PluginAuth union with new authentication types</li> <li>Custom Catalogs: Implement the PluginCatalog interface for different storage backends</li> <li>Enhanced Governance: Add new governance controls and validation rules</li> </ol>"},{"location":"hitl/plugin_catalog/#dependencies","title":"Dependencies","text":"<ul> <li><code>pydantic</code>: For data validation and serialization</li> <li><code>ska_utils</code>: For configuration management and module loading</li> <li><code>pathlib</code>: For file system operations</li> <li><code>json</code>: For JSON file parsing</li> <li><code>typing</code>: For type hints and annotations</li> </ul> <p>This plugin catalog system provides a robust foundation for managing plugins in the Teal Agents framework, with strong typing, validation, and governance controls to ensure secure and reliable plugin execution.</p>"},{"location":"planning/2507-state-hitl-auth/00-teal-agents-overview/","title":"Overview of Teal Agents - Agent component","text":"<p>This project is one component of a larger, Agent Platform, known as Teal Agents. Its purpose is to enable the simplified creation of AI Agents using a low-code approach consisting of a YAML configuration file and optional Python Plug-in definitions (tools).</p> <p>The application is built using FastAPI as the primary hosting framework and Semantic Kernel for LLM integration. The source code can be found in the <code>src/sk_agents</code> subdirectory of this workspace.</p> <p>Currently, there are two versions of the YAML configuration API:</p> <ul> <li>skagents/v1 - The original version which, while still supported, is     deprecated (although we currently lack a stable successor).</li> <li>skagents/v2alpha1 - An prototype version which was never stabilized but     which does provide a base from which we'll build during this refactoring     initiative. An example of the <code>v2alpha1</code> configuration can be found in the     <code>demos/ZZ_wikipedia_demo</code> directory.</li> </ul> <p>The main entrypoint of the application is the <code>app.py</code> file which performs some basic setup and then, depending on the API version specified in the configuration file, branches to either AppV1 or AppV2 (found in <code>appv1.py</code> and <code>appv2.py</code>, respectively). For the purposes of this refactoring, we will use only <code>appv2.py</code> as a reference.</p> <p><code>appv2.py</code> sets up the pulls in the applicable routes and handlers from the <code>routes.py</code> file which specifies the following endpoints:</p> <ul> <li>POST // - Direct REST invocation <li>POST ///sse - SSE streaming invocation <p>NOTE: There is an additional <code>streaming</code> endpoint which handles websocket connections, but this should be considered deprecated and will not need to considered for future development.</p> <p>The route handlers parse the provided configuration file and then, based on the defined API version, call the appropriate handlers provided in the <code>__init__.py</code> files in the like-named directories (e.g. <code>skagents/v1</code> first invokes the handler in the <code>__init__.py</code> file in the <code>skagents</code> subdirectory which then invokes the handler in the <code>__init__.py</code> file in the <code>skagents/v1</code> subdirectory).  Because <code>v2alpha1</code> was able to leverage the exising <code>v1</code> logic for the <code>Chat</code> <code>kind</code>, no additional subdirectory was introduced, but that will change for this refactor.  The <code>__init__.py</code> file in <code>skagents/v1</code> directory then parses the <code>kind</code> from the configuration file and instantiates the appropriate handler (an implementation of the <code>BaseHandler</code> class) and then passes the request on to that handler for processing.</p> <p>NOTES:</p> <ul> <li>There's a lot that goes in to instantiating the appropriate handler class   including leveraging kernel and agent builders which define the intersection of   this application with Semantic Kernel.</li> <li>Teal Agents is an Open Source project and, as such, it is   implemented to generally support the publicly available LLM endpoints (e.g.   OpenAI).  However, since we're running it inside of our corporate network and we   have a custom LLM gateway, it can be extended with custom implementations of the   <code>ChatCompletionFactory</code> class available in <code>src/sk_agents/ska_types</code> directory.   For us, this has been done and the custom implementation can be found in the   <code>customization/teal-agents/merck_custom_chat_completion_factory.py</code> file.</li> <li>This application is designed in a very extendable manner and its   runtime behavior is heavily dependent on both the provided configuration file as   well as a number of environment variables. Every attempt should be made to   continue developing this in the same, open and extendable manner.</li> <li>This application strives to maintain backwards compatibility with currently   available API versions (e.g. <code>skagents/v1</code>) and, as such, whenever performing   any refactoring, you should ensure that the new functionality is isolated and   does not change anything about existing functionality.</li> <li>The Agent component of Teal Agents is one piece of a much larger overall   platform.  That said, it is also a standalone component.  Since it exposes   agents as APIs, it can run by itself and can be invoked directly, but it's also   common for it to be invoked by \"Orchestrators\" which are different components   which provide multi-agent orchestration capabilities. It's important to keep   this in mind when designing any new feature.</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-01-state-refactor/","title":"Phase 1 - State Refactoring of Teal Agents - Agent component","text":""},{"location":"planning/2507-state-hitl-auth/01-01-state-refactor/#objective","title":"Objective","text":"<p>The Agent component of Teal Agents was originally designed to be completely stateless.  Each invocation accepted a list of \"Chat History\" messages which were to contain the entirety of the conversation, thus far. While this would be ideal to maintain, we have reached a point in its evolution where we will have to pivot and begin maintaining state in order to support more complex use cases (e.g. HITL and Authorization for tool use). The purpose of this document is to provide an overview and required context which should be considered while designing the implementation of state for this Agent component.</p> <p>When refactoring, the API version which should act as the base pattern for the new capability should be <code>skagents/v2alpha1</code>. The configuration file structure should remain the same, but the new API version should be called <code>tealagents/v1alpha1</code>.</p>"},{"location":"planning/2507-state-hitl-auth/01-01-state-refactor/#core-concepts","title":"Core Concepts","text":"<p>To enable stateful agent invocation, we will need to introduce three new concepts in to the agent invocation flow: Session, Task, and Request.</p>"},{"location":"planning/2507-state-hitl-auth/01-01-state-refactor/#1-session-id-s","title":"1. Session ID (S)","text":"<ul> <li>Purpose: Represents the highest-level grouping, corresponding to a continuous interaction or \"conversation\" with a client.</li> <li>Scope: It logically groups together multiple related tasks initiated by a user. For example, a user's entire interaction with a chatbot for a specific purpose would be one session.</li> <li>Relevance: While not directly used for the internal mechanics of agent/orchestrator state, it provides the essential client-facing context and allows clients to manage and reference logical units of work.</li> <li>Lifecycle: Sessions persist across multiple tasks and can span extended periods of user interaction.</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-01-state-refactor/#2-task-id-t","title":"2. Task ID (T)","text":"<ul> <li>Purpose: Represents a single, stateful \"job\" or goal that the system is asked to accomplish. A task can be simple (a single agent invocation) or complex (an orchestration involving multiple agents and sub-orchestrators).</li> <li>State: This is the lynchpin of the stateful architecture. The state associated with a Task ID must include:<ul> <li>Interaction History: A \"chat history\" or log of all invocations and responses related to the task. This is critical for providing context in follow-on invocations.</li> <li>Execution Trace: A record of the steps taken, tools used, and intermediate results generated.</li> <li>Status: The current state of the task (e.g., <code>Running</code>, <code>Paused</code>, <code>Completed</code>, <code>Failed</code>).</li> <li>User Identity: The unique identifier of the user who created the task for authorization purposes.</li> <li>Timestamps: Creation time, last updated time, and optional expiration time.</li> <li>Metadata: Additional context and configuration data specific to the task.</li> </ul> </li> <li>Lifecycle: A task is created upon the initial invocation and persists until it is fully completed. Follow-on invocations from the client reference the same Task ID to leverage its history and state.</li> <li>Concurrency: Multiple concurrent access attempts to the same task must be handled safely to prevent data corruption.</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-01-state-refactor/#3-request-id-r","title":"3. Request ID (R)","text":"<ul> <li>Purpose: Represents a single, atomic attempt or invocation within a task. It provides the finest level of granularity for tracking and control.</li> <li>Scope: A unique Request ID is generated for each invocation of an agent or orchestrator. All actions performed within that invocation, including tool calls, belong to that single Request ID.</li> <li>Criticality for HITL: The Request ID is the key to enabling HITL. It allows the system to pause not just a general task, but the specific agent invocation that requires human approval. This prevents ambiguity and allows for precise control. When a <code>Resume Handler</code> approves an action, it targets the specific Request ID.</li> <li>Benefits:<ul> <li>Idempotency: If a resume signal is received multiple times, the system can check the status of the Request ID and prevent duplicate execution.</li> <li>Auditing: Provides a detailed, auditable log of every single action taken by the system.</li> <li>Traceability: Links all telemetry and logging data to specific request instances.</li> </ul> </li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-01-state-refactor/#example-flow","title":"Example Flow","text":""},{"location":"planning/2507-state-hitl-auth/01-01-state-refactor/#new-request","title":"New Request","text":"<ol> <li>An agent receives a request from either a client or an orchestrator that    may or may not include a \"Session ID\" but which DOES NOT contain a \"Task ID\"</li> <li>If not provided, the agent generates a new \"Session ID\"</li> <li>The agent generates a new \"Task ID\" and a new \"Request ID\"</li> <li>The agent persists the request in its state store with the associated \"Task ID\"</li> <li>The agent builds the appropriate chat history and invokes the LLM</li> <li>The agent receives the response from the LLM and persists this, associated    with the same \"Task ID\". For now we'll focus on getting state implemented    ignore future HITL or authorization requirements.</li> <li>The agent returns the response along with the \"Session ID\", \"Task ID\",    and \"Request ID\" to the client or orchestrator</li> </ol>"},{"location":"planning/2507-state-hitl-auth/01-01-state-refactor/#follow-on-request","title":"Follow-on Request","text":"<ol> <li>An agent receives a follow-on request from either a client or an orchestrator    that includes a \"Task ID\".</li> <li>The agent generates a new \"Request ID\"</li> <li>The agent verifies that the requesting identity (user) was the same    as the one who initiated the task in the first place (if not, 401).</li> <li>The agent retrieves all associated messages with the provided \"Task ID\",    builds the chat history (including the newly received message), and invokes    the LLM.\"</li> <li>The agent receives the response from the LLM and persists this, associated    with the same \"Task ID\".</li> <li>The agent returns the response along with the \"Session ID\", \"Task ID\",    and \"Request ID\" to the client or orchestrator</li> </ol>"},{"location":"planning/2507-state-hitl-auth/01-01-state-refactor/#implementation-requirements","title":"Implementation Requirements","text":""},{"location":"planning/2507-state-hitl-auth/01-01-state-refactor/#application-integration","title":"Application Integration","text":"<ul> <li>The new <code>tealagents/v1alpha1</code> API version should follow the same pattern as existing versions:</li> <li>Create an <code>AppV3</code> class similar to <code>AppV1</code> and <code>AppV2</code></li> <li>Attempt to reuse the existing <code>routes.py</code> <code>get_rest_routes</code> function if possible by passing appropriate configuration values</li> <li>If reuse is not feasible due to authentication requirements and scope of changes, create new route handling logic that maintains existing capabilities (especially telemetry)</li> <li>Exclude websocket routes (<code>get_websocket_routes</code>) from the new version as they are deprecated</li> <li>The main <code>app.py</code> should detect the new API version and route to <code>AppV3</code> accordingly</li> <li>Complete isolation from existing API versions to maintain 100% backward compatibility</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-01-state-refactor/#data-models","title":"Data Models","text":"<ul> <li>Define a new input type called <code>UserMessage</code> which:</li> <li>Does NOT inherit from <code>BaseMultiModalInput</code> but has a similar structure</li> <li>Contains a list of <code>MultiModalItem</code> objects for the current message (text, images, etc.)</li> <li>Removes the <code>chat_history</code> field since history is now managed server-side</li> <li>Optionally accepts \"Session ID\" and \"Task ID\" parameters</li> <li>Includes proper validation for UUID formats and required fields</li> <li>Should look like: <code>{ session_id?, task_id?, items: MultiModalItem[] }</code></li> <li>Implement comprehensive response models that include all state identifiers</li> <li>Define state data models for Session, Task, and Request entities with proper relationships and constraints</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-01-state-refactor/#authentication-and-authorization","title":"Authentication and Authorization","text":"<ul> <li>Implement a robust authentication system using Entra ID app registration:</li> <li>Clients must send authorization tokens with appropriate scopes to access the platform</li> <li>Implement middleware or route-level logic to verify tokens and extract unique user identifiers (OID)</li> <li>Store user identity with persistent tasks for ownership verification</li> <li>Verify user identity on follow-on requests (return 401 if user doesn't match task owner)</li> <li>For initial implementation, abstract this logic and provide mock implementations</li> <li>This authentication requirement may preclude reusing the existing <code>routes.py</code> file</li> <li>Plan follow-up tasks for actual Entra ID integration and token validation</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-01-state-refactor/#configuration-system","title":"Configuration System","text":"<ul> <li>The new API version is indicated by <code>apiVersion: tealagents/v1alpha1</code> in the configuration file</li> <li>Configuration file structure remains the same as existing versions (see <code>demos/ZZ_wikipedia_demo/config.yaml</code>)</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-01-state-refactor/#state-management","title":"State Management","text":"<ul> <li>Abstract out the persistence management to support multiple providers</li> <li>Implement an in-memory persistence provider for initial testing (no need for actual persistent implementation initially)</li> <li>Design for future Redis or DynamoDB implementations</li> <li>Include \"last updated\" timestamps for future cleanup capabilities</li> <li>Do not implement automatic cleanup initially - preserve all task data</li> <li>Handle concurrent access to the same task safely to prevent data corruption</li> <li>State should include sufficient information to rebuild chat history and context</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-01-state-refactor/#error-handling","title":"Error Handling","text":"<ul> <li>Persistence failures should result in 5xx response codes</li> <li>Corrupted or inconsistent state data should cause invocation failures with 5xx responses</li> <li>Implement appropriate timeout handling for long-running operations</li> <li>Consider implementing keepalive mechanisms for SSE streams (similar to previous 30-second dummy events for long LLM calls)</li> <li>Provide comprehensive error messages for debugging and troubleshooting</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-01-state-refactor/#implementation-details","title":"Implementation Details","text":""},{"location":"planning/2507-state-hitl-auth/01-01-state-refactor/#api-version-detection-and-routing","title":"API Version Detection and Routing","text":"<ul> <li>Define a new logic path for API version <code>tealagents/v1alpha1</code> following the same pattern as earlier API versions</li> <li>The main <code>app.py</code> should detect the new <code>tealagents/v1alpha1</code> API version and route to the appropriate <code>AppV3</code> class</li> <li>Complete isolation ensures this new capability doesn't affect existing functionality</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-01-state-refactor/#usermessage-input-model","title":"UserMessage Input Model","text":"<ul> <li>Create a new <code>UserMessage</code> class that looks similar to <code>BaseMultiModalInput</code> but simplified for single-message input</li> <li>Structure: Contains a list of <code>MultiModalItem</code> objects (content_type and content) for the current message</li> <li>Optional parameters: \"Session ID\" and \"Task ID\" for state management</li> <li>Validation: Proper UUID format validation and required field checks</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-01-state-refactor/#state-aware-handler-implementation","title":"State-Aware Handler Implementation","text":"<ul> <li>Implement a new handler for the new API version that performs state management tasks:</li> <li>Save new state for initial requests</li> <li>Load existing state for follow-on requests</li> <li>Save responses and update state after processing</li> <li>Handle authentication and user identity verification</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-01-state-refactor/#persistence-abstraction","title":"Persistence Abstraction","text":"<ul> <li>Abstract out the persistence management to support multiple persistence providers</li> <li>Implement an in-memory persistence provider for testing and initial development</li> <li>Design interfaces to support future Redis or DynamoDB implementations</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-02-state-refactor-implementation-plan/","title":"Refined State Management Implementation Plan","text":"<p>This plan is based on the practical implementation approach outlined in <code>my-list.md</code> with necessary additions for completeness.</p>"},{"location":"planning/2507-state-hitl-auth/01-02-state-refactor-implementation-plan/#phase-1-core-infrastructure-week-1","title":"Phase 1: Core Infrastructure (Week 1)","text":""},{"location":"planning/2507-state-hitl-auth/01-02-state-refactor-implementation-plan/#1-authorization-infrastructure","title":"1. Authorization Infrastructure","text":"<p>Files to create: - <code>src/sk_agents/authorization/request_authorizer.py</code> - Abstract base class - <code>src/sk_agents/authorization/dummy_authorizer.py</code> - Mock implementation - <code>src/sk_agents/authorization/authorizer_factory.py</code> - Factory implementation</p> <p>Tasks:</p> <ul> <li> Create abstract <code>RequestAuthorizer</code> class:   <pre><code>@abstractmethod\ndef authorize_request(self, auth_header: str) -&gt; str:\n    \"\"\"Returns authorized unique user identifier\"\"\"\n    pass\n</code></pre></li> <li> Implement <code>DummyAuthorizer</code> that always returns 'dummyuser'</li> <li> Create <code>AuthorizerFactory</code> with environment variable configuration:<ul> <li><code>TA_AUTHORIZER_MODULE</code> - Module path for authorizer implementation</li> <li><code>TA_AUTHORIZER_CLASS</code> - Class name for authorizer implementation</li> </ul> </li> <li> Add thread-safe singleton pattern to factory for performance</li> <li> Include comprehensive error handling for import failures and misconfigurations</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-02-state-refactor-implementation-plan/#2-persistence-infrastructure","title":"2. Persistence Infrastructure","text":"<p>Files to create:</p> <ul> <li><code>src/sk_agents/persistence/task_persistence_manager.py</code> - Abstract base class</li> <li><code>src/sk_agents/persistence/in_memory_persistence_manager.py</code> - In-memory implementation</li> <li><code>src/sk_agents/persistence/persistence_factory.py</code> - Factory implementation</li> </ul> <p>Tasks:</p> <ul> <li> Create abstract <code>TaskPersistenceManager</code> class with methods:<ul> <li><code>create(task: AgentTask) -&gt; None</code></li> <li><code>load(task_id: str) -&gt; AgentTask | None</code></li> <li><code>update(task: AgentTask) -&gt; None</code></li> <li><code>delete(task_id: str) -&gt; None</code></li> </ul> </li> <li> Implement <code>InMemoryPersistenceManager</code> with thread-safe concurrent access using proper locking mechanisms</li> <li> Create <code>PersistenceFactory</code> with environment variable configuration:<ul> <li><code>TA_PERSISTENCE_MODULE</code> - Module path for persistence implementation</li> <li><code>TA_PERSISTENCE_CLASS</code> - Class name for persistence implementation</li> </ul> </li> <li> Add proper error handling for persistence failures (should result in 5xx responses)</li> <li> Include memory management and monitoring for in-memory implementation</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-02-state-refactor-implementation-plan/#3-data-models","title":"3. Data Models","text":"<p>Files to create: - <code>src/sk_agents/tealagents/models.py</code> - All data models for tealagents</p> <p>Tasks:</p> <ul> <li> Create <code>UserMessage</code> model (does NOT inherit from <code>BaseMultiModalInput</code>):   <pre><code>class UserMessage(BaseModel):\n    session_id: str | None = None\n    task_id: str | None = None\n    items: list[MultiModalItem]\n</code></pre></li> <li> Create <code>AgentTaskItem</code> model:   <pre><code>class AgentTaskItem(BaseModel):\n    task_id: str\n    role: Literal[\"user\", \"assistant\"]\n    item: MultiModalItem\n    request_id: str\n    updated: datetime\n</code></pre></li> <li> Create <code>AgentTask</code> model:   <pre><code>class AgentTask(BaseModel):\n    task_id: str\n    session_id: str\n    user_id: str  # Added based on feedback\n    items: list[AgentTaskItem]\n    created_at: datetime\n    last_updated_at: datetime\n    status: Literal[\"Running\", \"Paused\", \"Completed\", \"Failed\"] = \"Running\"\n</code></pre></li> <li> Create new response models that collapse <code>output_raw</code> and <code>output_pydantic</code> to single <code>output</code> field:   <pre><code>class TealAgentsResponse(BaseModel):\n    session_id: str\n    task_id: str\n    request_id: str\n    output: str  # Collapsed from output_raw/output_pydantic\n    # ... all other existing InvokeResponse fields remain\n\nclass TealAgentsPartialResponse(BaseModel):\n    session_id: str\n    task_id: str\n    request_id: str\n    output_partial: str\n    # ... all other existing PartialResponse fields remain\n</code></pre></li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-02-state-refactor-implementation-plan/#phase-2-new-api-version-structure-week-2","title":"Phase 2: New API Version Structure (Week 2)","text":""},{"location":"planning/2507-state-hitl-auth/01-02-state-refactor-implementation-plan/#4-module-structure","title":"4. Module Structure","text":"<p>Directories to create:</p> <ul> <li><code>src/sk_agents/tealagents/</code></li> <li><code>src/sk_agents/tealagents/v1alpha1/</code></li> </ul> <p>Files to create:</p> <ul> <li><code>src/sk_agents/tealagents/__init__.py</code> - Top-level handler factory</li> <li><code>src/sk_agents/tealagents/v1alpha1/__init__.py</code> - Version-specific entry point</li> <li><code>src/sk_agents/tealagents/v1alpha1/agent.py</code> - State-aware BaseHandler implementation</li> </ul> <p>Specific isolation requirements:</p> <ul> <li> No imports from <code>skagents</code> modules in <code>tealagents</code> modules</li> <li> No shared mutable state between API versions</li> <li> Separate error handling paths to prevent cross-contamination</li> <li> Independent configuration validation logic</li> <li> Unit tests to verify complete isolation (test that changes to tealagents don't affect skagents behavior)</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-02-state-refactor-implementation-plan/#5-handler-implementation","title":"5. Handler Implementation","text":"<p>File: <code>src/sk_agents/tealagents/v1alpha1/agent.py</code></p> <p>Tasks:</p> <ul> <li> Create <code>TealAgentsV1Alpha1Handler</code> class implementing <code>BaseHandler</code></li> <li> Implement <code>invoke</code> method with complete state management flow:<ul> <li>Authorize request using factory-provided authorizer</li> <li>Generate session_id if not provided</li> <li>Generate request_id for this invocation</li> <li>Handle task_id logic (load existing vs create new)</li> <li>Verify user ownership for existing tasks (return 401 if mismatch)</li> <li>Build chat history from stored AgentTaskItem objects</li> <li>Invoke LLM and save response</li> <li>Return TealAgentsResponse with all state identifiers</li> </ul> </li> <li> Implement <code>invoke_stream</code> method with state management:<ul> <li>Same authorization and state loading logic as invoke</li> <li>Stream TealAgentsPartialResponse objects with state identifiers</li> <li>Save final response to task state</li> <li>Include keepalive mechanisms for long-running operations (30-second dummy events)</li> </ul> </li> <li> Add comprehensive error handling with appropriate HTTP status codes</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-02-state-refactor-implementation-plan/#phase-3-application-integration-week-3","title":"Phase 3: Application Integration (Week 3)","text":""},{"location":"planning/2507-state-hitl-auth/01-02-state-refactor-implementation-plan/#6-route-integration","title":"6. Route Integration","text":"<p>Files to modify:</p> <ul> <li><code>src/sk_agents/routes.py</code> - Minor updates to support tealagents routing</li> <li><code>src/sk_agents/appv3.py</code> - New application class</li> </ul> <p>Tasks:</p> <ul> <li> Update <code>routes.py</code> to route to tealagents handlers when <code>tealagents</code> is detected as first token in apiVersion</li> <li> Preserve all existing telemetry functionality in route updates</li> <li> Create <code>AppV3</code> class following same pattern as <code>AppV1</code> and <code>AppV2</code>:<ul> <li>Extract configuration information</li> <li>Set up routes using updated <code>routes.py</code> functionality</li> <li>Initialize any tealagents-specific middleware or configuration</li> </ul> </li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-02-state-refactor-implementation-plan/#7-main-application-updates","title":"7. Main Application Updates","text":"<p>Files to modify: - <code>src/sk_agents/app.py</code> - Add AppV3 routing logic</p> <p>Tasks:</p> <ul> <li> Update main application to detect <code>tealagents/v1alpha1</code> apiVersion in configuration:<ul> <li>Split apiVersion on <code>/</code> and check if first token is <code>tealagents</code></li> <li>Route to <code>AppV3</code> when tealagents API version is detected</li> <li>Maintain complete backward compatibility with existing routing logic</li> </ul> </li> <li> Ensure configuration file structure remains identical (reference: <code>demos/ZZ_wikipedia_demo/config.yaml</code>)</li> <li> Add proper error handling for unsupported tealagents versions</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-02-state-refactor-implementation-plan/#phase-4-testing-and-validation-week-4","title":"Phase 4: Testing and Validation (Week 4)","text":""},{"location":"planning/2507-state-hitl-auth/01-02-state-refactor-implementation-plan/#8-comprehensive-testing","title":"8. Comprehensive Testing","text":"<p>Test files to create:</p> <ul> <li><code>tests/test_tealagents_handler.py</code></li> <li><code>tests/test_authorization.py</code></li> <li><code>tests/test_persistence.py</code></li> <li><code>tests/test_isolation.py</code></li> </ul> <p>Test scenarios:</p> <ul> <li> Unit tests for all new components with &gt;80% coverage</li> <li> Concurrency tests for thread-safe state access (multiple simultaneous requests to same task)</li> <li> Authorization tests (valid user, invalid user, missing auth header)</li> <li> Persistence failure scenarios (should return 5xx responses)</li> <li> State corruption scenarios (should return 5xx responses)</li> <li> Complete isolation tests (verify tealagents changes don't affect skagents)</li> <li> End-to-end integration tests for complete state flow scenarios</li> <li> SSE streaming tests with state management</li> <li> Performance benchmarks for state operations</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-02-state-refactor-implementation-plan/#9-configuration-and-error-handling","title":"9. Configuration and Error Handling","text":"<p>Tasks:</p> <ul> <li> Validate that existing API versions continue to work unchanged:</li> <li><code>skagents/v1</code> (test with <code>demos/03_plugins/config.yaml</code>)</li> <li><code>skagents/v2alpha1</code> (test with <code>demos/10_chat_plugins/config.yaml</code>)</li> <li> Test new API version with <code>tealagents/v1alpha1</code> configuration</li> <li> Verify proper error messages for:<ul> <li>Invalid authorization</li> <li>Persistence failures</li> <li>Task not found</li> <li>User ownership mismatches</li> <li>Configuration errors</li> </ul> </li> <li> Test timeout handling for long-running operations</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-02-state-refactor-implementation-plan/#implementation-notes","title":"Implementation Notes","text":""},{"location":"planning/2507-state-hitl-auth/01-02-state-refactor-implementation-plan/#concurrency-safety","title":"Concurrency Safety","text":"<ul> <li>Use proper locking mechanisms in <code>InMemoryPersistenceManager</code></li> <li>Handle race conditions for concurrent access to same task</li> <li>Ensure thread-safe access to shared state throughout the application</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-02-state-refactor-implementation-plan/#error-handling-strategy","title":"Error Handling Strategy","text":"<ul> <li>Persistence failures \u2192 5xx responses</li> <li>Authorization failures \u2192 401 responses</li> <li>Task ownership violations \u2192 401 responses</li> <li>Configuration errors \u2192 500 responses with clear messages</li> <li>Invalid task_id \u2192 404 responses</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-02-state-refactor-implementation-plan/#sse-streaming-considerations","title":"SSE Streaming Considerations","text":"<ul> <li>Include state identifiers (session_id, task_id, request_id) in each streamed event</li> <li>Update task state during streaming operations</li> <li>Implement keepalive events for long LLM calls (30-second intervals)</li> <li>Handle streaming errors and state recovery gracefully</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-02-state-refactor-implementation-plan/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Lazy initialization of factories to minimize startup overhead</li> <li>Efficient chat history reconstruction from AgentTaskItem objects</li> <li>Monitor memory usage in InMemoryPersistenceManager</li> <li>Consider connection pooling for future persistent storage implementations</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-02-state-refactor-implementation-plan/#future-extensibility","title":"Future Extensibility","text":"<ul> <li>Abstract interfaces support future Redis/DynamoDB implementations</li> <li>Authorization abstraction allows for real Entra ID integration</li> <li>State models include timestamps for future cleanup implementations</li> <li>Response models designed to support future HITL requirements</li> </ul>"},{"location":"planning/2507-state-hitl-auth/01-02-state-refactor-implementation-plan/#environment-variables","title":"Environment Variables","text":"<p>New environment variables introduced:</p> <ul> <li><code>TA_AUTHORIZER_MODULE</code> - Module path for authorization implementation</li> <li><code>TA_AUTHORIZER_CLASS</code> - Class name for authorization implementation</li> <li><code>TA_PERSISTENCE_MODULE</code> - Module path for persistence implementation</li> <li><code>TA_PERSISTENCE_CLASS</code> - Class name for persistence implementation</li> </ul> <p>Default values for development:</p> <ul> <li>Authorizer: <code>sk_agents.authorization.dummy_authorizer.DummyAuthorizer</code></li> <li>Persistence: <code>sk_agents.persistence.in_memory_persistence_manager.InMemoryPersistenceManager</code></li> </ul>"},{"location":"planning/2507-state-hitl-auth/02-01-manual-tool-call/","title":"Phase 2 - Refactor for Manual Tool Call","text":"<p>Teal Agents currently leverages Semantic Kernel's in-built functionality to automatically perform agent tool calls. Unfortunately, the library does not include required capability to allow for our code to intercept the tool call message response from the LLM and perform any pre-requisite tasks prior to calling the tool.</p>"},{"location":"planning/2507-state-hitl-auth/02-01-manual-tool-call/#preparation-for-hitl","title":"Preparation for HITL","text":"<p>We need to introduce human-in-the-loop (HITL) functionality wherein, for certain \"high risk\" tool calls, we will pause the current interaction and respond to the calling application with a specially crafted message which will instruct client to prompt the user for explicit consent prior to proceeding with the tool call. To achieve this, we will have to refactor some of the code, \"de-abstracting\" the portion of the Semantic Kernel library where an agent performs tool calls.</p>"},{"location":"planning/2507-state-hitl-auth/02-01-manual-tool-call/#reference-documentation","title":"Reference Documentation","text":"<ul> <li><code>context/teal-agents-overview.md</code> - A reference of the overall structure and   background of the Teal Agents project</li> <li><code>context/state-refactor.md</code> - An overview of work that needs to be done to enable   stateful agent interactions. This work is currently ongoing and as such, this branch   of the code does not reflect any of this capability.</li> <li><code>context/refinde-implementation-plan.md</code> - A detailed plan of how state will be   implemented in the Teal Agents project (the actual work to-be-done based on the   <code>state-refactor.md</code> document).</li> <li><code>context/my-list.md</code> - This was my original plan for the refactoring to include state.   it, along with the <code>state-refactor.md</code> document provided the basis for the work   defined in <code>refined-implementation-plan.md</code>.</li> <li><code>src/sk_agents/skagents/v1/sk_agent.py</code> - This is the specific file in the current   implementation where agents are invoked. Within the file, in the <code>invoke</code> and   <code>invoke_stream</code> methods, the Semantic Kernel library's agent methods are called and   it is within these methods that tool calls are actually performed.</li> <li><code>src/sk_agents/skagents/v1/sk_agent_v2.py</code> - A version of the <code>sk_agent.py</code> file that   I directly refactored, using the Semantic Kernel library as a reference, to move the   tool calling functionality up a level to where Teal Agents would be responsible for   performing the tool calls. This file is not used in the current implementation, it   was just an example of how the refactoring could be done.</li> <li><code>chat_completion_agent.py</code> within the virtual environment - This is the Semantic   Kernel file that contains the tool calling logic.  It was the basis for   <code>sk_agent_v2.py</code></li> </ul>"},{"location":"planning/2507-state-hitl-auth/02-02-manual-tool-call-implementation-plan/","title":"Implementation Plan for Manual Tool Calling (with Code)","text":"<p>This document outlines the plan to refactor the agent invocation process to allow for manual interception of tool calls, as described in <code>context/manual-tool-call.md</code>. This change is a prerequisite for implementing Human-in-the-Loop (HITL) functionality.</p> <p>The implementation will follow the \"de-abstracted\" pattern prototyped in <code>src/sk_agents/skagents/v1/sk_agent_v2.py</code> and will be integrated into the new stateful API version <code>tealagents/v1alpha1</code>.</p>"},{"location":"planning/2507-state-hitl-auth/02-02-manual-tool-call-implementation-plan/#1-high-level-strategy","title":"1. High-Level Strategy","text":"<p>We will replace the high-level <code>agent.invoke()</code> and <code>agent.invoke_stream()</code> calls with a manual orchestration of the LLM interaction within our <code>Agent</code>. This provides a clear interception point to inspect tool calls before they are executed.</p>"},{"location":"planning/2507-state-hitl-auth/02-02-manual-tool-call-implementation-plan/#2-new-hitl-placeholder-module","title":"2. New HITL Placeholder Module","text":"<p>A new placeholder module will be created to establish a clean interception point for future HITL logic.</p> <p>File to Create: <code>src/sk_agents/tealagents/v1alpha1/hitl_manager.py</code></p> <pre><code># src/sk_agents/tealagents/v1alpha1/hitl_manager.py\nfrom semantic_kernel.contents.function_call_content import FunctionCallContent\n\ndef check_for_intervention(tool_call: FunctionCallContent) -&gt; bool:\n    \"\"\"\n    Placeholder for HITL logic. In the future, this will check\n    if the tool call requires user consent based on configured policies.\n\n    Returns False for now, allowing all calls to proceed without interruption.\n    \"\"\"\n    # TODO: Implement actual policy checks for high-risk tools.\n    print(f\"HITL Check: Intercepted call to {tool_call.plugin_name}.{tool_call.function_name}. Allowing to proceed.\")\n    return False\n</code></pre>"},{"location":"planning/2507-state-hitl-auth/02-02-manual-tool-call-implementation-plan/#3-refactoring-the-agent-handler","title":"3. Refactoring the Agent Handler","text":"<p>The core changes will be in the <code>Agent</code>.</p> <p>File to Modify: <code>src/sk_agents/tealagents/v1alpha1/agent.py</code></p>"},{"location":"planning/2507-state-hitl-auth/02-02-manual-tool-call-implementation-plan/#31-add-imports-and-helper-method","title":"3.1. Add Imports and Helper Method","text":"<p>We will add necessary imports and the <code>_invoke_function</code> helper method, adapted directly from <code>sk_agent_v2.py</code>.</p> <pre><code># Add to imports at the top of src/sk_agents/tealagents/v1alpha1/agent.py\nimport asyncio\nfrom functools import reduce\n\nfrom semantic_kernel.connectors.ai.chat_completion_client_base import ChatCompletionClientBase\nfrom semantic_kernel.contents.function_call_content import FunctionCallContent\nfrom semantic_kernel.contents.function_result_content import FunctionResultContent\nfrom semantic_kernel.contents.streaming_chat_message_content import StreamingChatMessageContent\n\n# Import the new HITL placeholder\nfrom sk_agents.hitl import hitl_manager\n\n# ... existing class definition for Agent ...\n\n    # Add this helper method inside the TealAgentsV1Alpha1Handler class\n    async def _invoke_function(self, kernel: \"Kernel\", fc_content: FunctionCallContent) -&gt; FunctionResultContent:\n        \"\"\"Helper to execute a single tool function call.\"\"\"\n        function = kernel.get_function(\n            fc_content.plugin_name,\n            fc_content.function_name,\n        )\n        function_result = await function(kernel, fc_content.to_kernel_arguments())\n        return FunctionResultContent.from_function_call_content_and_result(\n            fc_content, function_result\n        )\n</code></pre>"},{"location":"planning/2507-state-hitl-auth/02-02-manual-tool-call-implementation-plan/#32-updated-invoke-method-non-streaming","title":"3.2. Updated <code>invoke</code> Method (Non-Streaming)","text":"<p>The <code>invoke</code> method will be replaced with the following code to manually handle the tool-calling loop.</p> <pre><code># Replace the existing 'invoke' method in TealAgentsV1Alpha1Handler\nasync def invoke(self, history: ChatHistory) -&gt; AsyncIterable[ChatMessageContent]:\n    kernel = self.agent.kernel\n    arguments = self.agent.arguments\n    chat_completion_service, settings = kernel.select_ai_service(\n        arguments=arguments, type=ChatCompletionClientBase\n    )\n    assert isinstance(chat_completion_service, ChatCompletionClientBase)\n\n    # Initial call to the LLM\n    response_list = await chat_completion_service.get_chat_message_contents(\n        chat_history=history,\n        settings=settings,\n        kernel=kernel,\n        arguments=arguments,\n    )\n\n    function_calls = []\n    # Separate content and tool calls\n    for response in response_list:\n        # A response may have multiple items, e.g., multiple tool calls\n        fc_in_response = [item for item in response.items if isinstance(item, FunctionCallContent)]\n\n        if fc_in_response:\n            history.add_message(response) # Add assistant's message to history\n            function_calls.extend(fc_in_response)\n        else:\n            # If no function calls, it's a direct answer\n            yield response\n\n    # If tool calls were returned, execute them\n    if function_calls:\n        # --- INTERCEPTION POINT ---\n        for fc in function_calls:\n            hitl_manager.check_for_intervention(fc)\n            # In the future, a `True` return would trigger a pause flow.\n\n        # Execute all functions in parallel\n        results = await asyncio.gather(\n            *[self._invoke_function(kernel, fc) for fc in function_calls]\n        )\n\n        # Add results to history\n        for result in results:\n            history.add_message(result.to_chat_message_content())\n\n        # Make a recursive call to get the final response from the LLM\n        async for final_response in self.invoke(history):\n            yield final_response\n</code></pre>"},{"location":"planning/2507-state-hitl-auth/02-02-manual-tool-call-implementation-plan/#33-updated-invoke_stream-method-streaming","title":"3.3. Updated <code>invoke_stream</code> Method (Streaming)","text":"<p>The <code>invoke_stream</code> method will be replaced to handle streaming and tool calls correctly.</p> <pre><code># Replace the existing 'invoke_stream' method in TealAgentsV1Alpha1Handler\nasync def invoke_stream(self, history: ChatHistory) -&gt; AsyncIterable[StreamingChatMessageContent]:\n    kernel = self.agent.kernel\n    arguments = self.agent.arguments\n    chat_completion_service, settings = kernel.select_ai_service(\n        arguments=arguments, type=ChatCompletionClientBase\n    )\n    assert isinstance(chat_completion_service, ChatCompletionClientBase)\n\n    all_responses = []\n    # Stream the initial response from the LLM\n    async for response_list in chat_completion_service.get_streaming_chat_message_contents(\n        chat_history=history,\n        settings=settings,\n        kernel=kernel,\n        arguments=arguments,\n    ):\n        for response in response_list:\n            all_responses.append(response)\n            if response.content:\n                yield response # Yield content chunks to the client immediately\n\n    # Aggregate the full response to check for tool calls\n    if not all_responses:\n        return\n\n    full_completion: StreamingChatMessageContent = reduce(lambda x, y: x + y, all_responses)\n    function_calls = [\n        item\n        for item in full_completion.items\n        if isinstance(item, FunctionCallContent)\n    ]\n\n    # If tool calls are present, execute them\n    if function_calls:\n        history.add_message(message=full_completion.to_chat_message_content())\n\n        # --- INTERCEPTION POINT ---\n        for fc in function_calls:\n            hitl_manager.check_for_intervention(fc)\n\n        # Execute functions in parallel\n        results = await asyncio.gather(\n            *[self._invoke_function(kernel, fc) for fc in function_calls]\n        )\n\n        # Add results to history\n        for result in results:\n            history.add_message(result.to_chat_message_content())\n\n        # Make a recursive call to get the final streamed response\n        async for final_response_chunk in self.invoke_stream(history):\n            yield final_response_chunk\n</code></pre>"},{"location":"planning/2507-state-hitl-auth/02-02-manual-tool-call-implementation-plan/#4-testing-strategy","title":"4. Testing Strategy","text":"<p>The testing strategy remains the same as the previous plan, but the tests in <code>tests/test_tealagents_handler.py</code> will now be written against this specific implementation, verifying:</p> <ol> <li>Simple chat works without regression.</li> <li>Tool calls are correctly identified and executed.</li> <li>The <code>hitl_manager.check_for_intervention</code> function is called for each tool invocation.</li> <li>The final response after tool execution is correct for both streaming and non-streaming modes.</li> </ol>"},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/","title":"Application State After Phases 1 &amp; 2: Foundation for Human-in-the-Loop Implementation","text":"<p>This document provides a comprehensive overview of the application state after completing Phases 1 and 2, as described in <code>01-02-state-refactor-implementation-plan.md</code> and <code>02-02-manual-tool-call-implementation-plan.md</code>. This overview is intended to support Phase 3 planning, which will introduce Human-in-the-Loop (HITL) functionality for selected tool calls.</p>"},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#new-infrastructure-components","title":"New Infrastructure Components","text":""},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#authorization-system","title":"Authorization System","text":"<p>The application now includes a pluggable authorization system:</p> <ul> <li><code>src/sk_agents/authorization/</code> module - Complete authorization infrastructure</li> <li><code>RequestAuthorizer</code> - Abstract base class requiring <code>authorize_request(auth_header: str) -&gt; str</code></li> <li><code>DummyAuthorizer</code> - Development implementation returning 'dummyuser' for all requests</li> <li><code>AuthorizerFactory</code> - Thread-safe singleton factory with environment variable configuration<ul> <li><code>TA_AUTHORIZER_MODULE</code> - Module path for authorization implementation</li> <li><code>TA_AUTHORIZER_CLASS</code> - Class name for authorization implementation</li> </ul> </li> <li>Error handling - Comprehensive handling for import failures and misconfigurations</li> </ul>"},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#persistence-system","title":"Persistence System","text":"<p>A pluggable state storage system is now available:</p> <ul> <li><code>src/sk_agents/persistence/</code> module - Complete persistence infrastructure</li> <li><code>TaskPersistenceManager</code> - Abstract base class with CRUD operations for <code>AgentTask</code> objects<ul> <li><code>create(task: AgentTask) -&gt; None</code></li> <li><code>load(task_id: str) -&gt; AgentTask | None</code></li> <li><code>update(task: AgentTask) -&gt; None</code></li> <li><code>delete(task_id: str) -&gt; None</code></li> </ul> </li> <li><code>InMemoryPersistenceManager</code> - Thread-safe in-memory implementation with proper locking</li> <li><code>PersistenceFactory</code> - Environment variable configuration<ul> <li><code>TA_PERSISTENCE_MODULE</code> - Module path for persistence implementation</li> <li><code>TA_PERSISTENCE_CLASS</code> - Class name for persistence implementation</li> </ul> </li> <li>Error handling - Persistence failures result in 5xx responses</li> </ul>"},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#state-models","title":"State Models","text":"<p>New data models support complete conversation state management:</p> <ul> <li><code>AgentTask</code> - Core state container with:<ul> <li><code>task_id</code>, <code>session_id</code>, <code>user_id</code> for identification</li> <li><code>items: list[AgentTaskItem]</code> for conversation history</li> <li><code>created_at</code>, <code>last_updated_at</code> timestamps</li> <li><code>status: Literal[\"Running\", \"Paused\", \"Completed\", \"Failed\"]</code> for state tracking</li> </ul> </li> <li><code>AgentTaskItem</code> - Individual conversation entries with:<ul> <li><code>role: Literal[\"user\", \"assistant\"]</code> for message attribution</li> <li><code>item: MultiModalItem</code> for content</li> <li><code>request_id: str</code> for tracking individual requests</li> <li><code>updated: datetime</code> for chronological ordering</li> </ul> </li> <li><code>UserMessage</code> - Input model with optional state identifiers:<ul> <li><code>session_id: str | None</code> for session continuity</li> <li><code>task_id: str | None</code> for task resumption</li> <li><code>items: list[MultiModalItem]</code> for multimodal content</li> </ul> </li> <li><code>TealAgentsResponse</code>/<code>TealAgentsPartialResponse</code> - Response models with:<ul> <li><code>session_id</code>, <code>task_id</code>, <code>request_id</code> for complete state tracking</li> <li><code>output</code> field (collapsed from previous <code>output_raw</code>/<code>output_pydantic</code>)</li> <li>All existing response fields preserved</li> </ul> </li> </ul>"},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#new-api-architecture","title":"New API Architecture","text":""},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#module-structure","title":"Module Structure","text":"<p>A completely isolated API version has been created:</p> <ul> <li><code>src/sk_agents/tealagents/</code> - Top-level module, completely isolated from <code>skagents</code></li> <li><code>src/sk_agents/tealagents/v1alpha1/</code> - Version-specific implementation</li> <li><code>src/sk_agents/tealagents/v1alpha1/handler.py</code> - Core handler implementation</li> <li><code>src/sk_agents/tealagents/v1alpha1/agent.py</code> - LLM interaction and tool call</li> <li>Isolation requirements:<ul> <li>No imports from <code>skagents</code> modules in <code>tealagents</code> modules</li> <li>No shared mutable state between API versions</li> <li>Separate error handling paths to prevent cross-contamination</li> <li>Independent configuration validation logic</li> </ul> </li> </ul>"},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#routing-integration","title":"Routing Integration","text":"<p>The application routing has been extended to support the new API:</p> <ul> <li>Updated <code>routes.py</code> - Detects <code>tealagents</code> as first token in <code>apiVersion</code></li> <li>New <code>AppV3</code> class - Follows existing <code>AppV1</code>/<code>AppV2</code> patterns</li> <li>Main <code>app.py</code> - Routes <code>tealagents/v1alpha1</code> configurations to <code>AppV3</code></li> <li>Backward compatibility - All existing API versions continue to work unchanged</li> </ul>"},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#tool-call-interception-architecture","title":"Tool Call Interception Architecture","text":""},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#hitl-foundation","title":"HITL Foundation","text":"<p>The groundwork for Human-in-the-Loop functionality has been established:</p> <ul> <li><code>src/sk_agents/hitl/hitl_manager.py</code> - Placeholder module with interception point</li> <li><code>check_for_intervention(tool_call: FunctionCallContent) -&gt; bool</code> - Core interception function<ul> <li>Currently returns <code>False</code> (no intervention) for all tool calls</li> <li>Establishes the exact point where HITL logic will be implemented</li> <li>Receives complete <code>FunctionCallContent</code> objects for inspection</li> </ul> </li> </ul>"},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#manual-tool-orchestration","title":"Manual Tool Orchestration","text":"<p>The <code>Agent</code> (<code>src/sk_agents/tealagents/v1alpha1/agent.py</code>) implements the tool invocation loop:</p> <ul> <li>Direct LLM interaction - Uses <code>ChatCompletionClientBase</code> instead of high-level agent methods</li> <li>Manual tool extraction - Extracts <code>FunctionCallContent</code> objects from LLM responses</li> <li>Clear interception point - Each tool call is individually passed to <code>hitl_manager.check_for_intervention()</code></li> <li>Parallel execution - Approved tool calls are executed via <code>asyncio.gather()</code></li> <li>Recursive handling - Supports multi-turn tool calling scenarios</li> <li>Streaming support - Both <code>invoke()</code> and <code>invoke_stream()</code> methods have identical interception logic</li> </ul>"},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#state-management-flow","title":"State Management Flow","text":""},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#request-processing-pipeline","title":"Request Processing Pipeline","text":"<p>The <code>TealAgentsV1Alpha1Handler</code> (<code>src/sk_agents/tealagents/v1alpha1/handler.py</code>) processes requests with a clear state management flow:</p> <ol> <li>Authorization - Via pluggable authorizer (extracts <code>user_id</code>)</li> <li>Session/Task ID handling - Generation or validation of state identifiers</li> <li>User ownership verification - Existing tasks checked for user ownership</li> <li>Chat history reconstruction - Built from persisted <code>AgentTaskItem</code> objects</li> <li>Agent invocation - Invoke agent with appropriate chat history</li> <li>State persistence - After each interaction</li> <li>Response generation - With complete state identifiers</li> </ol>"},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#concurrency-error-handling","title":"Concurrency &amp; Error Handling","text":"<p>Robust error handling and concurrency support:</p> <ul> <li>Thread-safe state access - Proper locking mechanisms in persistence layer</li> <li>Comprehensive error responses:<ul> <li>401 for authorization failures</li> <li>404 for missing tasks</li> <li>5xx for persistence failures</li> </ul> </li> <li>Streaming support - State management with keepalive mechanisms</li> <li>Race condition handling - Concurrent access to same task properly managed</li> </ul>"},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#key-architectural-decisions-for-phase-3","title":"Key Architectural Decisions for Phase 3","text":""},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#tool-call-interception-points","title":"Tool Call Interception Points","text":"<p>The architecture provides clear interception capabilities:</p> <ul> <li>Identical interception logic - Both <code>invoke()</code> and <code>invoke_stream()</code> methods have the same interception flow</li> <li>Pre-execution inspection - Tool calls are extracted and inspected before execution</li> <li>Individual tool processing - Each <code>FunctionCallContent</code> object is individually passed to the interception function</li> <li>Execution control - The interception point can prevent tool execution (currently always allows)</li> </ul>"},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#state-persistence-capabilities","title":"State Persistence Capabilities","text":"<p>Complete state management for paused/resumed operations:</p> <ul> <li>Full conversation history - Maintained in <code>AgentTask.items</code> with chronological ordering</li> <li>Unique request tracking - Each interaction has a unique <code>request_id</code></li> <li>Pause support - Task status field supports \"Paused\" state (designed for HITL)</li> <li>Timestamp tracking - All state objects include timestamps for timeout/cleanup logic</li> <li>User association - All tasks are associated with specific users for authorization</li> </ul>"},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#response-model-design","title":"Response Model Design","text":"<p>Response models are designed to support HITL workflows:</p> <ul> <li>State identifier inclusion - All responses include <code>session_id</code>, <code>task_id</code>, <code>request_id</code></li> <li>Streaming consistency - State identifiers maintained throughout streaming responses</li> <li>Extensibility - Response models designed to support future HITL-specific fields</li> <li>Client tracking - State identifiers allow clients to track and respond to approval requests</li> </ul>"},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#hitl-implementation-ready-points","title":"HITL Implementation Ready Points","text":"<p>The architecture establishes the following foundation for Phase 3 HITL implementation:</p>"},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#1-tool-call-interception","title":"1. Tool Call Interception","text":"<ul> <li><code>hitl_manager.check_for_intervention()</code> - Ready to implement policy-based tool approval</li> <li>Complete tool context - <code>FunctionCallContent</code> objects provide full tool information</li> <li>Execution control - Return <code>True</code> to block tool execution</li> </ul>"},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#2-state-persistence-for-paused-tasks","title":"2. State Persistence for Paused Tasks","text":"<ul> <li>Task pausing - Change <code>AgentTask.status</code> to \"Paused\"</li> <li>Conversation state - Complete chat history preserved for resumption</li> <li>User context - User authorization preserved for approval requests</li> </ul>"},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#3-response-mechanisms","title":"3. Response Mechanisms","text":"<ul> <li>State tracking - Response models include all necessary identifiers</li> <li>Client communication - Mechanisms exist to inform clients of approval requirements</li> <li>Resumption support - Task can be resumed with <code>request_id</code> in subsequent requests</li> </ul>"},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#4-authorization-integration","title":"4. Authorization Integration","text":"<ul> <li>User identification - Every request tied to specific user</li> <li>Approval tracking - Tool approval requests can be associated with users</li> <li>Security - User ownership verification prevents unauthorized task access</li> </ul>"},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#environment-variables","title":"Environment Variables","text":"<p>New environment variables introduced:</p> <ul> <li><code>TA_AUTHORIZER_MODULE</code> - Module path for authorization implementation</li> <li><code>TA_AUTHORIZER_CLASS</code> - Class name for authorization implementation</li> <li><code>TA_PERSISTENCE_MODULE</code> - Module path for persistence implementation</li> <li><code>TA_PERSISTENCE_CLASS</code> - Class name for persistence implementation</li> </ul> <p>Default values for development:</p> <ul> <li>Authorizer: <code>sk_agents.authorization.dummy_authorizer.DummyAuthorizer</code></li> <li>Persistence: <code>sk_agents.persistence.in_memory_persistence_manager.InMemoryPersistenceManager</code></li> </ul>"},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#backward-compatibility","title":"Backward Compatibility","text":"<p>The application maintains complete backward compatibility:</p> <ul> <li>Existing APIs unchanged - <code>skagents/v1</code> and <code>skagents/v2alpha1</code> continue to work</li> <li>No shared state - New <code>tealagents</code> API is completely isolated</li> <li>Configuration compatibility - Existing configuration files continue to work</li> <li>Telemetry preservation - All existing telemetry functionality maintained</li> </ul>"},{"location":"planning/2507-state-hitl-auth/03-01-hitl-baseline/#summary","title":"Summary","text":"<p>After Phases 1 and 2, the application provides a complete foundation for Human-in-the-Loop implementation with:</p> <ol> <li>Authorization infrastructure - User identification and request authorization</li> <li>State persistence - Complete conversation state management with pause/resume capability</li> <li>Tool call interception - Clear points for inspecting and controlling tool execution</li> <li>Response mechanisms - State tracking and client communication capabilities</li> <li>Isolation - New functionality completely isolated from existing APIs</li> </ol> <p>The <code>tealagents/v1alpha1</code> API path now provides stateful, interceptable agent interactions while maintaining complete backward compatibility with existing functionality. Phase 3 can build upon this foundation to implement Human-in-the-Loop approval workflows for selected tool calls.</p>"},{"location":"planning/2507-state-hitl-auth/03-02-hitl/","title":"Phase 3 - Humaan-in-the-Loop (HITL)","text":""},{"location":"planning/2507-state-hitl-auth/03-02-hitl/#overview","title":"Overview","text":"<p>In phase 3, we will introduce the capability to pause the execution of an agent task, when certain \"high risk\" tools are identified for use, and require human intervention prior to proceeding. Achieving this relies on changes made in phases 1 and 2.</p>"},{"location":"planning/2507-state-hitl-auth/03-02-hitl/#phase-3-resulting-flow","title":"Phase 3 Resulting Flow","text":"<p>For tool calls identified as \"high risk\", instead of directly executing these calls, the application will need to:</p> <ol> <li>Save the relevant tool call details such that they can be resumed after human    intervention (this should probably be in the task item which might require extension    of its structure).</li> <li>Place the task in to a paused state</li> <li>Respond with a payload indicating the call or calls which triggered the HITL    requirement as well as a URL, referencing the appropriate request ID(s), which can    be invoked to \"Approve\" or \"Reject\" the call(s).</li> </ol> <p>Upon receipt of this new response, the client (not considered here) will be responsible for prompting the user for approval or rejection of the tool call(s).</p> <p>If the tool call(s) is/are approved, the application will need to resume immediately, from the point of the tool call(s) and proceed as normal (this might require an alternate logic path to reach the handler and/or agent invocation).</p> <p>If the tool call(s) is/are rejected, the application should place the task in to a canceled state and respond with a payload indicating as such.</p> <p>Approvals and rejections should be recorded somewhere in a persistence layer.</p>"},{"location":"planning/2507-state-hitl-auth/03-02-hitl/#additional-non-functional-requirements","title":"Additional Non-Functional Requirements","text":"<ul> <li>Keep the definition of the approval/rejection endpoint flexible. We will be   introducing additional functionality in subsequent phases which will allow tasks to be   paused in cases where the user need to perform authentication or grant consent in   order for tool calls to proceed. It would be ideal if this single \"resume\" endpoint   could be used for these cases, as well.</li> <li>The \"resume\" endpoint should leverage the <code>request_id</code> in the URL to identify which   tool call(s) task is being resumed/canceled. There is no need to include <code>session_id</code>   or <code>task_id</code> as the request ID, alone, would uniquely identify the task/invocation   which requires HITL.</li> <li>User authorization will need to be included in the resume endpoint, and it should be   validated that the user calling the endpoint is the same user who initiated the task.</li> <li>The determination of a tool's \"risk level\" can be left out of scope for this planning.   Just assume the <code>check_for_intervention</code> placeholder will determine handle this logic.</li> <li>The payload to-be-sent indicating that tool use approvals are required can be a   completely new model object. The existing response objects should not be extended to   support this new functionality.</li> <li>I believe we'll have to know the exact structure of the tool call responses from the   LLMs in order to determine exactly how we'll need to extend <code>AgentTaskItem</code> to   accommodate the persistence of the tool call details. For this reason, don't be   specific about exactly how to persist this, just indicate that it will need to be   persisted in <code>AgentTaskItem</code>.</li> <li>The \"resume\" endpoint will either approve or reject ALL tool calls for a given   <code>request_id</code>. We will not support partial approvals or rejections.</li> </ul>"},{"location":"planning/2507-state-hitl-auth/03-03-hitl-implementation-plan/","title":"Phase 3 Implementation Plan: Human-in-the-Loop (HITL)","text":"<p>This document outlines the development tasks required to implement the Human-in-the-Loop (HITL) functionality as described in <code>03-02-hitl.md</code>, building upon the foundational architecture established in Phases 1 and 2.</p>"},{"location":"planning/2507-state-hitl-auth/03-03-hitl-implementation-plan/#task-1-extend-state-models-for-hitl","title":"Task 1: Extend State Models for HITL","text":"<p>Objective: Update the core data models to support paused states, pending tool calls, and a new response type for HITL interventions.</p> <ul> <li>File: <code>src/sk_agents/ska_types.py</code></li> <li> <p>Changes:</p> <p>1.Modify <code>AgentTaskItem</code>: Add an optional field to store tool calls that are pending approval.     <pre><code># In AgentTaskItem class\npending_tool_calls: list[dict] | None = None # Store serialized FunctionCallContent\n</code></pre> 2.Modify <code>AgentTask</code>: Add a \"Canceled\" status to the <code>status</code> literal to handle rejections.     <pre><code># In AgentTask class\nstatus: Literal[\"Running\", \"Paused\", \"Completed\", \"Failed\", \"Canceled\"]\n</code></pre> 3.Create <code>HitlResponse</code> Model: Define a new Pydantic model for the response sent to the client when an intervention is required.     <code>python     class HitlResponse(BaseModel):         task_id: str         session_id: str         request_id: str         message: str = \"Human intervention required.\"         approval_url: str         rejection_url: str         tool_calls: list[dict] # Serialized FunctionCallContent</code></p> </li> </ul>"},{"location":"planning/2507-state-hitl-auth/03-03-hitl-implementation-plan/#task-2-implement-persistence-layer-extension","title":"Task 2: Implement Persistence Layer Extension","text":"<p>Objective: Enable the retrieval of tasks using a <code>request_id</code> to support the resume endpoint.</p> <ul> <li>Files:<ul> <li><code>src/sk_agents/persistence/task_persistence_manager.py</code></li> <li><code>src/sk_agents/persistence/in_memory_persistence_manager.py</code></li> </ul> </li> <li>Changes:<ol> <li>Update <code>TaskPersistenceManager</code> ABC: Add a new abstract method to find a task by <code>request_id</code>.     <pre><code>@abstractmethod\ndef load_by_request_id(self, request_id: str) -&gt; AgentTask | None:\n    ...\n</code></pre></li> <li>Implement in <code>InMemoryPersistenceManager</code>: Implement the new method. This will likely require creating a new index (dictionary) to map <code>request_id</code> to <code>task_id</code>. Ensure this index is properly maintained with thread-safe locks.</li> </ol> </li> </ul>"},{"location":"planning/2507-state-hitl-auth/03-03-hitl-implementation-plan/#task-3-implement-hitl-trigger-and-pause-logic","title":"Task 3: Implement HITL Trigger and Pause Logic","text":"<p>Objective: Modify the agent and handler to detect when an intervention is needed, pause the task, and persist the state.</p> <ul> <li>Files:<ul> <li><code>src/sk_agents/hitl/hitl_manager.py</code></li> <li><code>src/sk_agents/tealagents/v1alpha1/agent.py</code></li> <li><code>src/sk_agents/tealagents/v1alpha1/handler.py</code></li> </ul> </li> <li>Changes:<ol> <li>Update <code>hitl_manager.py</code>: For now, hardcode <code>check_for_intervention</code> to return <code>True</code> if a tool call's name matches a predefined \"high-risk\" tool (e.g., <code>ShellCommand</code>).</li> <li>Create Custom Exception: Define a custom exception, e.g., <code>HitlInterventionRequired(Exception)</code>, to signal the need for HITL from the agent to the handler.</li> <li>Modify <code>agent.py</code>: In <code>invoke()</code> and <code>invoke_stream()</code>, after extracting tool calls, iterate through them. If <code>check_for_intervention()</code> returns <code>True</code> for any of them, raise <code>HitlInterventionRequired</code> with the list of all tool calls from the LLM's response.</li> <li>Modify <code>handler.py</code>:         - Wrap the <code>agent.invoke()</code> call in a <code>try...except HitlInterventionRequired</code> block.         - In the <code>except</code> block:             - Set <code>AgentTask.status</code> to <code>\"Paused\"</code>.             - Create a new <code>AgentTaskItem</code> for the assistant's turn, storing the pending tool calls from the exception into the new <code>pending_tool_calls</code> field.             - Persist the updated <code>AgentTask</code> using the <code>persistence_manager</code>.             - Construct and return the <code>HitlResponse</code>, generating the appropriate approval and rejection URLs (e.g., <code>/tealagents/v1alpha1/resume/{request_id}</code>).</li> </ol> </li> </ul>"},{"location":"planning/2507-state-hitl-auth/03-03-hitl-implementation-plan/#task-4-create-the-hitl-resume-endpoint","title":"Task 4: Create the HITL Resume Endpoint","text":"<p>Objective: Create a new API endpoint that the client can call to approve or reject a paused tool call.</p> <ul> <li>Files:<ul> <li><code>src/sk_agents/routes.py</code></li> <li><code>src/sk_agents/app.py</code></li> <li><code>src/sk_agents/tealagents/v1alpha1/handler.py</code> (or a new <code>resume_handler.py</code>)</li> </ul> </li> <li>Changes:<ol> <li>Define Route in <code>routes.py</code>: Add a new <code>POST</code> route, e.g., <code>/tealagents/v1alpha1/resume/{request_id}</code>.</li> <li>Create Resume Handler: Implement a new handler function for this route. This function will accept the <code>request_id</code> from the URL and a simple JSON body like <code>{\"action\": \"approve\"}</code> or <code>{\"action\": \"reject\"}</code>.</li> <li>Integrate in <code>app.py</code>: Wire the new route to the new handler function in the <code>AppV3</code> class.</li> </ol> </li> </ul>"},{"location":"planning/2507-state-hitl-auth/03-03-hitl-implementation-plan/#task-5-implement-resume-and-rejection-logic","title":"Task 5: Implement Resume and Rejection Logic","text":"<p>Objective: Implement the core logic within the resume handler to either continue execution or cancel the task.</p> <ul> <li>File: <code>src/sk_agents/tealagents/v1alpha1/handler.py</code> (or the new resume handler file)</li> <li>Changes:<ol> <li>Authorization: The request must go through the <code>RequestAuthorizer</code> to get the <code>user_id</code>.</li> <li>Load Task: Use the new <code>persistence_manager.load_by_request_id()</code> method to fetch the <code>AgentTask</code>.</li> <li>Validation:<ul> <li>If the task is not found, return 404.</li> <li>Verify the <code>user_id</code> from the authorizer matches the <code>task.user_id</code>. If not, return 403 Forbidden.</li> <li>Verify the task status is \"Paused\". If not, return 409 Conflict.</li> </ul> </li> <li>Handle Rejection (<code>action == \"reject\"</code>):<ul> <li>Update the <code>AgentTask.status</code> to <code>\"Canceled\"</code>.</li> <li>Add an <code>AgentTaskItem</code> to the history logging the rejection.</li> <li>Persist the task.</li> <li>Return a confirmation response to the client.</li> </ul> </li> <li>Handle Approval (<code>action == \"approve\"</code>):<ul> <li>This is the most complex part, creating a new execution path.</li> <li>Retrieve the <code>pending_tool_calls</code> from the last <code>AgentTaskItem</code>.</li> <li>Execute the tool calls using <code>asyncio.gather()</code>, just as the agent would have.</li> <li>Create <code>ToolContent</code> objects from the results.</li> <li>Add the <code>AgentTaskItem</code> with the <code>pending_tool_calls</code> and a new <code>AgentTaskItem</code> with the <code>ToolContent</code> results to the chat history.</li> <li>Update the <code>AgentTask.status</code> to <code>\"Running\"</code>.</li> <li>Invoke the agent again with the updated chat history to get the final response from the LLM.</li> <li>Persist the final state (<code>AgentTask</code> and new <code>AgentTaskItem</code>s).</li> <li>Return the final <code>TealAgentsResponse</code> to the client.</li> </ul> </li> </ol> </li> </ul>"},{"location":"planning/2507-state-hitl-auth/03-03-hitl-implementation-plan/#task-6-record-approvalrejection","title":"Task 6: Record Approval/Rejection","text":"<p>Objective: Ensure that the approval or rejection action is explicitly recorded in the task's history.</p> <ul> <li>File: <code>src/sk_agents/tealagents/v1alpha1/handler.py</code> (or the new resume handler file)</li> <li>Changes:<ol> <li>When handling an approval or rejection, create a new <code>AgentTaskItem</code> that explicitly records the action.</li> <li>For approvals, this could be an item with <code>role: \"user\"</code> and content like <code>{\"action\": \"approve\", \"request_id\": \"...\"}</code>.</li> <li>For rejections, a similar item should be added before setting the state to \"Canceled\".</li> <li>This provides a clear audit trail within the conversation history.</li> </ol> </li> </ul>"},{"location":"planning/2507-state-hitl-auth/03-prompt/","title":"03 prompt","text":"<p>Based on the current state of this project and assuming that changes will be made to achieve the baseline state described in <code>04-01-hitl-baseline.md</code>, create a set of tasks which, when completed will introduce the functionality described in <code>04-02-hitl.md</code>. Save this implementation plan in to a new file called <code>04-03-hitl-implementation-plan-claude.md</code> in the <code>planning/2507-state-hitl-auth</code> directory.</p>"},{"location":"planning/2507-state-hitl-auth/04-01-tool-catalog/","title":"Phase 4 - Plugin Catalog","text":"<p>In this phase, we will introduce the concept of a plugin catalog.</p>"},{"location":"planning/2507-state-hitl-auth/04-01-tool-catalog/#overview","title":"Overview","text":"<p>While we have not yet landed on the technology to use, we will need to continue forward with the design and integration of the concept of a plugin catalog to allow us to move forward with HITL and authorization. The plugin catalog will be the centralized repository for tools made available to agents, and will provide a set of metadata for each tool that can be used to determine things like which authorization server and scopes are required for a particular tool invocation and whether a specific tool requires HITL confirmation prior to execution.</p> <p>Since no decision has been reached on an actual implementation technology, we will proceed with establishing an abstraction layer which, for the time being, will require manual configuration of available tools.</p>"},{"location":"planning/2507-state-hitl-auth/04-01-tool-catalog/#abstraction-layer-design","title":"Abstraction Layer Design","text":"<p>The Plugin concept can be represented as the following:</p> <pre><code>class PluginType(BaseModel):\n    type_name: Literal[\"code\", \"mcp\"]\n\nclass Governance(BaseModel):\n    requires_hitl: bool\n    cost: Literal[\"low\", \"medium\", \"high\"]\n    data_sensitivity: Literal[\"public\", \"proprietary\", \"confidential\", \"sensitive\"]\n\nclass PluginAuth(BaseModel):\n    auth_type: Literal[\"oauth2\"]\n\nclass Oauth2PluginAuth(PluginAuth):\n    auth_server: str\n    scopes: List[str]\n\nclass PluginTool(BaseModel):\n    tool_id: str\n    name: str\n    description: str\n    governance: Governance\n\nclass Plugin(BaseModel):\n    plugin_id: str\n    name: str\n    description: str\n    version: str\n    owner: str\n    plugin_type: Type[PluginType]\n    auth: Type[PluginAuth] | None\n    tools: List[PluginTool]\n</code></pre> <p><code>PluginType</code> will be a base class for the different types of plugins available. Currently, the only two should be <code>code</code> (which refers to a python code plugin) and <code>mcp</code> (which refers to a Streamable HTTP MCP Server). Individual plugin types should have subclasses that provide additional metadata for that specific plugin type, when applicable. I'm thinking that, currently, <code>code</code> type plugins won't require additional metadata, but <code>mcp</code> will, though I'm not sure what it will be yet.</p> <p>Plugin auth will be applied at the plugin level and will be applicable for all tools in a given plugin (is this the right approach?). Governance will be applied to individual tools within a plugin.  I believe the other objects and fields are self-explanatory.</p> <p>The Plugin catalog will need to provide a method which allows the retrieval of the information about the plugin for a given plugin or tool ID. I'm not sure what the most appropriate lookup method will be, so for the time being let's accommodate both.</p> <p>The Plugin catalog should be implemented as an abstract class.</p> <p>We should define a single, initial implementation called <code>LocalPluginCatalog</code> which will simply read a JSON file from the local filesystem which contains the defined plugins.</p> <p>The application should rely on two new environment variables: <code>TA_PLUGIN_CATALOG_MODULE</code> - The path and file name of the module which will implement the desired plugin catalog provider class. <code>TA_PLUGIN_CATALOG_CLASS</code> - The name of the class within the module which implements the plugin catalog.</p> <p>Additionally, the initial <code>LocalPluginCatalog</code> implementation should leverage an additional environment variable <code>TA_PLUGIN_CATALOG_FILE</code> which will be the path to the JSON file containing the plugin definitions.</p> <p>Finally, we should additionally define a Plugin catalog factory which will be responsible for instantiating the plugin catalog based on the environment variables.</p> <p>This should use a Singleton pattern. Note, there's an existing <code>Singleton</code> class in the <code>ska-utils</code> package which can be used for this.</p> <p>Re-review @planning/2507-state-hitl-auth/04-03-hitl-implementation-plan.md to see where this catalog should be hooked in and include appropriate tasks to achieve that.</p>"},{"location":"planning/2507-state-hitl-auth/04-02-tool-catalog-implementation-plan/","title":"Phase 4 Implementation Plan: Plugin Catalog","text":"<p>This document outlines the development tasks to introduce a plugin catalog. This catalog will serve as a centralized repository for tool definitions and their associated metadata, such as governance policies (e.g., HITL requirements) and authentication details.</p> <p>This plan establishes an abstraction layer for the catalog, with an initial implementation that reads from a local JSON file.</p>"},{"location":"planning/2507-state-hitl-auth/04-02-tool-catalog-implementation-plan/#task-1-plugin-catalog-data-models","title":"Task 1: Plugin Catalog Data Models","text":"<p>Objective: Define the core Pydantic models that represent plugins, tools, and their metadata.</p> <ul> <li>File to Create: <code>src/sk_agents/plugincatalog/models.py</code></li> <li>Details: Implement the following Pydantic models. We will use discriminated unions to handle different plugin and auth types.</li> </ul> <pre><code>from typing import List, Literal, Union\nfrom pydantic import BaseModel, Field\n\n# PluginType Models\nclass CodePluginType(BaseModel):\n    type_name: Literal[\"code\"] = \"code\"\n\nclass McpPluginType(BaseModel):\n    type_name: Literal[\"mcp\"] = \"mcp\"\n    # Future metadata for MCP plugins will go here\n\nPluginType = Union[CodePluginType, McpPluginType]\n\n# Governance Model\nclass Governance(BaseModel):\n    requires_hitl: bool = False\n    cost: Literal[\"low\", \"medium\", \"high\"]\n    data_sensitivity: Literal[\"public\", \"proprietary\", \"confidential\", \"sensitive\"]\n\n# PluginAuth Models\nclass Oauth2PluginAuth(BaseModel):\n    auth_type: Literal[\"oauth2\"] = \"oauth2\"\n    auth_server: str\n    scopes: List[str]\n\nPluginAuth = Union[Oauth2PluginAuth]\n\n# Core Plugin Models\nclass PluginTool(BaseModel):\n    tool_id: str # Unique identifier, e.g., \"Shell-execute\"\n    name: str\n    description: str\n    governance: Governance\n\nclass Plugin(BaseModel):\n    plugin_id: str # e.g., \"Shell\"\n    name: str\n    description: str\n    version: str\n    owner: str\n    plugin_type: PluginType = Field(..., discriminator=\"type_name\")\n    auth: PluginAuth | None = Field(None, discriminator=\"auth_type\")\n    tools: List[PluginTool]\n\nclass PluginCatalogDefinition(BaseModel):\n    plugins: List[Plugin]\n</code></pre>"},{"location":"planning/2507-state-hitl-auth/04-02-tool-catalog-implementation-plan/#task-2-plugin-catalog-abstraction-and-factory","title":"Task 2: Plugin Catalog Abstraction and Factory","text":"<p>Objective: Create an abstract base class for the catalog and a singleton factory to instantiate the configured provider.</p> <ul> <li>Files to Create:<ul> <li><code>src/sk_agents/plugincatalog/plugin_catalog.py</code></li> <li><code>src/sk_agents/plugincatalog/plugin_catalog_factory.py</code></li> </ul> </li> <li>Details:<ol> <li>Define <code>PluginCatalog</code> ABC: This class will define the contract for all catalog implementations.     <pre><code># src/sk_agents/plugincatalog/plugin_catalog.py\nfrom abc import ABC, abstractmethod\nfrom .models import Plugin, PluginTool\n\nclass PluginCatalog(ABC):\n    @abstractmethod\n    def get_plugin(self, plugin_id: str) -&gt; Plugin | None:\n        ...\n\n    @abstractmethod\n    def get_tool(self, tool_id: str) -&gt; PluginTool | None:\n        ...\n</code></pre></li> <li>Implement <code>PluginCatalogFactory</code>: This factory will be a singleton responsible for creating the catalog instance based on environment variables. It should use the <code>Singleton</code> class from the <code>ska-utils</code> package.<ul> <li>It will read <code>TA_PLUGIN_CATALOG_MODULE</code> and <code>TA_PLUGIN_CATALOG_CLASS</code> to dynamically import and instantiate the catalog provider.</li> </ul> </li> </ol> </li> </ul>"},{"location":"planning/2507-state-hitl-auth/04-02-tool-catalog-implementation-plan/#task-3-localplugincatalog-implementation","title":"Task 3: <code>LocalPluginCatalog</code> Implementation","text":"<p>Objective: Create a file-based implementation of the <code>PluginCatalog</code> for initial development and testing.</p> <ul> <li>File to Create: <code>src/sk_agents/plugincatalog/local_plugin_catalog.py</code></li> <li>Details:<ol> <li>Implement <code>LocalPluginCatalog</code>:<ul> <li>Inherit from <code>PluginCatalog</code>.</li> <li>In the constructor, read the JSON file path from the <code>TA_PLUGIN_CATALOG_FILE</code> environment variable.</li> <li>Load and parse the JSON file into the Pydantic models defined in Task 1.</li> <li>Create internal dictionaries to provide efficient lookups for <code>get_plugin()</code> and <code>get_tool()</code>.</li> </ul> </li> <li>Example <code>catalog.json</code>: <pre><code>{\n  \"plugins\": [\n    {\n      \"plugin_id\": \"Shell\",\n      \"name\": \"Shell\",\n      \"description\": \"Executes shell commands.\",\n      \"version\": \"1.0\",\n      \"owner\": \"system\",\n      \"plugin_type\": { \"type_name\": \"code\" },\n      \"auth\": null,\n      \"tools\": [\n        {\n          \"tool_id\": \"Shell-execute\",\n          \"name\": \"execute\",\n          \"description\": \"Executes a command in the shell.\",\n          \"governance\": {\n            \"requires_hitl\": true,\n            \"cost\": \"high\",\n            \"data_sensitivity\": \"sensitive\"\n          }\n        }\n      ]\n    }\n  ]\n}\n</code></pre></li> </ol> </li> </ul>"},{"location":"planning/2507-state-hitl-auth/04-02-tool-catalog-implementation-plan/#task-4-integrate-catalog-with-hitl-manager","title":"Task 4: Integrate Catalog with HITL Manager","text":"<p>Objective: Update the HITL logic to use the plugin catalog to decide if an intervention is required.</p> <ul> <li>File to Modify: <code>src/sk_agents/hitl/hitl_manager.py</code></li> <li> <p>Details:</p> <ul> <li>The <code>check_for_intervention</code> function will be updated to use the catalog. The hardcoded logic will be removed.</li> <li>The function will construct a <code>tool_id</code> from the <code>FunctionCallContent</code> provided by the kernel. The convention will be <code>{plugin_name}-{function_name}</code>.</li> </ul> <pre><code># src/sk_agents/hitl/hitl_manager.py\nfrom semantic_kernel.contents.function_call_content import FunctionCallContent\nfrom sk_agents.plugincatalog import plugin_catalog_factory\n\ndef check_for_intervention(tool_call: FunctionCallContent) -&gt; bool:\n    \"\"\"\n    Checks the plugin catalog to determine if a tool call requires\n    Human-in-the-Loop intervention.\n    \"\"\"\n    catalog = plugin_catalog_factory.get_instance()\n    if not catalog:\n        # Fallback if catalog is not configured\n        return False\n\n    tool_id = f\"{tool_call.plugin_name}-{tool_call.function_name}\"\n    tool = catalog.get_tool(tool_id)\n\n    if tool:\n        print(f\"HITL Check: Intercepted call to {tool_id}. Requires HITL: {tool.governance.requires_hitl}\")\n        return tool.governance.requires_hitl\n\n    # Default to no intervention if tool is not in the catalog\n    return False\n</code></pre> </li> </ul>"},{"location":"planning/2507-state-hitl-auth/04-02-tool-catalog-implementation-plan/#task-5-testing-strategy","title":"Task 5: Testing Strategy","text":"<p>Objective: Ensure the plugin catalog is correctly implemented and integrated.</p> <ul> <li>Files to Create/Modify:<ul> <li><code>demos/catalog.json</code> (a sample catalog for testing)</li> <li><code>tests/test_plugin_catalog.py</code> (new test file)</li> <li><code>tests/test_tealagents_handler.py</code> (modify existing tests)</li> </ul> </li> <li>Details:<ol> <li>Unit Tests (<code>test_plugin_catalog.py</code>):<ul> <li>Test <code>LocalPluginCatalog</code> can correctly load, parse, and validate a <code>catalog.json</code> file.</li> <li>Test successful lookups via <code>get_plugin()</code> and <code>get_tool()</code>.</li> <li>Test that lookups for non-existent IDs return <code>None</code>.</li> <li>Test the <code>PluginCatalogFactory</code> correctly instantiates the <code>LocalPluginCatalog</code>.</li> </ul> </li> <li>Integration Tests (<code>test_tealagents_handler.py</code>):<ul> <li>Modify the existing HITL tests.</li> <li>Point <code>TA_PLUGIN_CATALOG_FILE</code> to a test-specific catalog file.</li> <li>Verify that the HITL \"pause\" flow is triggered if and only if a tool with <code>requires_hitl: true</code> is called.</li> <li>Verify that tools not in the catalog or marked as <code>false</code> proceed without intervention.</li> </ul> </li> </ol> </li> </ul>"},{"location":"planning/2507-state-hitl-auth/04-02-tool-catalog-implementation-plan/#task-6-environment-variables-and-configuration","title":"Task 6: Environment Variables and Configuration","text":"<p>Objective: Document the new environment variables for configuring the plugin catalog.</p> <ul> <li>Details: The application will now rely on the following environment variables:<ul> <li><code>TA_PLUGIN_CATALOG_MODULE</code>: The Python module path for the catalog implementation.<ul> <li>Default: <code>sk_agents.plugincatalog.local_plugin_catalog</code></li> </ul> </li> <li><code>TA_PLUGIN_CATALOG_CLASS</code>: The class name of the catalog implementation.<ul> <li>Default: <code>LocalPluginCatalog</code></li> </ul> </li> <li><code>TA_PLUGIN_CATALOG_FILE</code>: The absolute path to the JSON file containing plugin definitions (used by <code>LocalPluginCatalog</code>).<ul> <li>Default: <code>/app/catalog.json</code> (or another suitable default path)</li> </ul> </li> </ul> </li> </ul>"},{"location":"planning/2507-state-hitl-auth/04-prompt/","title":"04 prompt","text":"<p>We are planning work a few weeks out for changes that need to be made to this workspace. Context about the work which is not yet completed is available in the following files:</p> <ul> <li>@planning/2507-state-hitl-auth/01-02-state-refactor-implementation-plan.md</li> <li>@planning/2507-state-hitl-auth/02-02-manual-tool-call-implementation-plan.md</li> <li>@planning/2507-state-hitl-auth/03-03-hitl-implementation-plan.md</li> </ul> <p>If helpful, there are additional files in the <code>planning/2507-state-hitl-auth</code> directory which can provide more context on the changes detailed in the above files.</p> <p>Create a set of tasks which, when completed, will introduce the functionality described in @planning/2507-state-hitl-auth/04-01-tool-catalog.md and save this set of tasks to a file called <code>04-02-tool-catalog-implementation-plan.md</code> in <code>planning/2507-state-hitl-auth</code> directory.</p>"},{"location":"planning/2507-state-hitl-auth/05-01-auth-infra-overview/","title":"Phase 5 - Authorization Overview","text":"<p>This document provides an overview of how the new authorization system will work for Teal Agents. Initially, it will only focus on OAuth 2.0, the design should be extensible to support other authorization types in the future.</p>"},{"location":"planning/2507-state-hitl-auth/05-01-auth-infra-overview/#overview","title":"Overview","text":"<p>The existing auth setup for teal agents is rudimentary and not scalable. As such, we will refactor and include the ability for the platform to dynamically understand the auth requirements for a particular tool and, when required, prompt the calling client to prompt the user to perform the appropriate authorization flow. We will begin with OAuth 2.0. The internal flow will go something like:</p> <ol> <li>Agent decides to use a tool</li> <li>Agent platform intercepts tool call response from LLM and retrieves the tool     metadata from the tool catalog (see phase 4)</li> <li>If the tool requires authorization (for now, OAuth 2.0), the platform will search     for an existing token for the given authorization server and scopes for this user     within the \"Secure Auth Storage Service\"</li> <li>If the token exists, it will be used to invoke the tool</li> <li>If the token does not exist, a new response type will be crafted and returned that     indicates to the client that the user needs to perform the appropriate authorization     flow. Note that the flow must be initiated from the agent platform (or possibly     directly to the authorization server but the callback must be the agent platform).</li> <li>The client will then prompt the user to perform the authorization flow, which will     involve redirecting the user to the authorization server, where they will log in and     authorize the tool. The client must also present an option to \"Resume\" the flow once     authorization has been completed.</li> <li>Once the user has authorized the tool, the authorization server will redirect the     user back to the agent platform with an authorization code. The agent platform will     then exchange this code for an access token and store it in the \"Secure Auth Storage     Service\" for future use.</li> <li>The agent platform will show a message indicating that authorization is complete and     the user can now close this window/tab and resume the agent flow.</li> <li>The user returns to the original client and clicks \"Resume\" to continue the agent     flow.</li> <li>The agent platform will resume the flow, now able to retrieve the appropriate access     token from the \"Secure Auth Storage Service\" and invoke the tool.</li> </ol>"},{"location":"planning/2507-state-hitl-auth/05-01-auth-infra-overview/#implementation-aspects-in-previous-phases","title":"Implementation Aspects in Previous Phases","text":"<p>Many changes are required to accommodate this new authorization flow. Some of the work has already been scoped, in previous phases:</p>"},{"location":"planning/2507-state-hitl-auth/05-01-auth-infra-overview/#phase-1","title":"Phase 1","text":"<ul> <li>Implementation plan defined in   @planning/2507-state-hitl-auth/01-02-state-refactor-implementation-plan.md</li> <li>Integrates the concept of State in to the Agent Platform, which is what will allow   individual agent flows to be paused and resumed.</li> </ul>"},{"location":"planning/2507-state-hitl-auth/05-01-auth-infra-overview/#phase-2","title":"Phase 2","text":"<ul> <li>Implementation plan defined in   @planning/2507-state-hitl-auth/02-02-manual-tool-call-implementation-plan.md</li> <li>Implements the ability for the agent platform to intercept tool calls and provides a   hook for tool evaluation prior to execution of the tool.</li> </ul>"},{"location":"planning/2507-state-hitl-auth/05-01-auth-infra-overview/#phase-3","title":"Phase 3","text":"<ul> <li>Implementation plan defined in   @planning/2507-state-hitl-auth/03-03-hitl-implementation-plan.md</li> <li>Introduces a \"resume\" endpoint that allows the client to resume an agent flow   after a HITL intervention. This is essential for the authorization flow, as it should   be extended to additionally support the resumption of the agent flow after the   authorization flow has been completed.</li> </ul>"},{"location":"planning/2507-state-hitl-auth/05-01-auth-infra-overview/#phase-4","title":"Phase 4","text":"<ul> <li>Implementation plan defined in   @planning/2507-state-hitl-auth/04-02-tool-catalog-implementation-plan.md</li> <li>Implements the tool catalog, which is where the agent platform will retrieve the   tool metadata to determine if authorization is required and, if so, provide the   relevant details to craft the appropriate response to the client.</li> </ul>"},{"location":"planning/2507-state-hitl-auth/05-01-auth-infra-overview/#remaining-work","title":"Remaining Work","text":"<p>Upon completion of phases 1-4, agent task state should be available. We should have the ability to intercept tool calls and evaluate them, and we should have a tool catalog which contains the appropriate metadata for each tool. To introduce tool authorization, we still need to implement the following:</p> <ol> <li>The ability to store and retrieve the required tool authorization information for a    given user and tool.</li> <li>The ability to craft and send an appropriate response to the client when a tool    requires authorization and for which no appropriate authorization information is    available.</li> <li>The ability to either initiate the authorization flow from the agent platform or    simply receive the callback from the authorization server, retrieve/store the needed    authorization information, and inform the user that the agent flow can be resumed.</li> <li>The ability to resume the agent flow once the user has completed the authorization    flow and returned to the client.</li> </ol>"},{"location":"planning/2507-state-hitl-auth/05-02-01-prompt/","title":"05 02 01 prompt","text":"<p>@planning/2507-state-hitl-auth/04-01-tool-catalog.md</p> <p>@planning/2507-state-hitl-auth/01-02-state-refactor-implementation-plan.md</p> <p>@planning/2507-state-hitl-auth/02-01-manual-tool-call.md</p> <p>@planning/2507-state-hitl-auth/02-02-manual-tool-call-implementation-plan.md</p> <p>@planning/2507-state-hitl-auth/04-02-tool-catalog-implementation-plan.md</p> <p>@planning/2507-state-hitl-auth/03-02-hitl.md</p> <p>@planning/2507-state-hitl-auth/00-teal-agents-overview.md</p> <p>@planning/2507-state-hitl-auth/03-01-hitl-baseline.md</p> <p>@planning/2507-state-hitl-auth/03-03-hitl-implementation-plan.md</p> <p>@planning/2507-state-hitl-auth/05-01-auth-infra-overview.md</p> <p>@planning/2507-state-hitl-auth/01-01-state-refactor.md</p> <p>@planning/2507-state-hitl-auth/05-02-01-secure-auth-storage.md</p> <p>We are planning phase 5 of future work to extend this agent platform, which introduces user/tool-specific authorization capability. For an overview of all phase 5 work and relevant background, see 05-01-auth-infra-overview.md (as well as any referenced sources).</p> <p>The scope of this first step in phase 5 is defined in 05-02-01-secure-auth-storage.md.</p> <p>Create a new file at planning/2507-state-hitl-auth/05-02-02-secure-auth-storage-implementation-plan.md which provides a detailed implementation plan for this first step.</p> <p>Notes: * I prefer pydantic BaseModel classes over dataclasses</p>"},{"location":"planning/2507-state-hitl-auth/05-02-01-secure-auth-storage/","title":"Secure Auth Storage Service Requirement","text":"<p>This is the first step in this phase 5 introduction of authorization in to the agent platform. We will introduce an abstraction for the \"Secure Auth Storage Service\" that enable the agent platform to store and retrieve tool authorization information.</p> <p>For an overview of the scope of phase 5, see @planning/2507-state-hitl-auth/05-01-auth-infra-overview.md.</p>"},{"location":"planning/2507-state-hitl-auth/05-02-01-secure-auth-storage/#requirements","title":"Requirements","text":"<ul> <li>Introduce a new abstract class <code>SecureAuthStorageManager</code> that defines the interface   for storing and retrieving tool authorization information for a given user and tool.   We are targeting only OAuth 2.0, presently, but when designing the interface, it   should be flexible enough to accommodate other authorization mechanisms in the future.</li> <li>For OAuth 2.0 implementation type, tokens should be reusable for any tool that   leverages the same authorization server and scopes.</li> <li>Implement a concrete class <code>InMemorySecureAuthStorageManager</code> that implements the   <code>SecureAuthStorageManager</code> interface and stores the authorization information in   memory.</li> <li>Introduce a factor class that will return an appropriate singleton instance of the   configured <code>SecureAuthStorageManager</code> implementation as defined in the environment   variables:<ul> <li><code>TA_SECURE_AUTH_STORAGE_MANAGER_MODULE</code> - The module path to the   <code>SecureAuthStorageManager</code> implementation.</li> <li><code>TA_SECURE_AUTH_STORAGE_MANAGER_CLASS</code> - The class name of the   <code>SecureAuthStorageManager</code> implementation.</li> </ul> </li> </ul>"},{"location":"planning/2507-state-hitl-auth/05-02-02-secure-auth-storage-implementation-plan/","title":"Phase 5 Implementation Plan: Secure Auth Storage Service","text":"<p>This document provides a detailed implementation plan for creating the Secure Auth Storage Service, as required by <code>05-02-01-secure-auth-storage.md</code>. This service will provide a flexible and abstract way to store and retrieve user-specific authorization credentials for tools.</p> <p>The initial implementation will focus on an in-memory storage solution for OAuth 2.0 tokens, with a design that is extensible for future auth mechanisms and persistent storage backends.</p>"},{"location":"planning/2507-state-hitl-auth/05-02-02-secure-auth-storage-implementation-plan/#task-1-data-models-for-authentication-data","title":"Task 1: Data Models for Authentication Data","text":"<p>Objective: Define the Pydantic models for storing different types of authentication credentials. This ensures a structured and validated approach to data handling.</p> <ul> <li>Directory to Create: <code>src/sk_agents/auth_storage/</code></li> <li>File to Create: <code>src/sk_agents/auth_storage/models.py</code></li> <li>Details:<ul> <li>Create a discriminated union of Pydantic models to represent various auth types.</li> <li>The initial implementation will only include a model for OAuth 2.0.</li> </ul> </li> </ul> <pre><code># src/sk_agents/auth_storage/models.py\nfrom datetime import datetime\nfrom typing import List, Literal, Union\nfrom pydantic import BaseModel, Field\n\nclass BaseAuthData(BaseModel):\n    \"\"\"Base model for all authentication data types.\"\"\"\n    auth_type: str\n\nclass OAuth2AuthData(BaseAuthData):\n    \"\"\"Model for storing OAuth 2.0 credentials.\"\"\"\n    auth_type: Literal[\"oauth2\"] = \"oauth2\"\n    access_token: str\n    refresh_token: str | None = None\n    expires_at: datetime\n    # The scopes this token is valid for.\n    scopes: List[str]\n\n# A union of all supported auth data types.\nAuthData = Union[OAuth2AuthData]\n</code></pre>"},{"location":"planning/2507-state-hitl-auth/05-02-02-secure-auth-storage-implementation-plan/#task-2-secure-auth-storage-abstraction","title":"Task 2: Secure Auth Storage Abstraction","text":"<p>Objective: Define an abstract base class (<code>ABC</code>) that establishes the contract for all secure auth storage implementations.</p> <ul> <li>File to Create: <code>src/sk_agents/auth_storage/secure_auth_storage_manager.py</code></li> <li>Details:<ul> <li>The ABC will define the core methods for storing, retrieving, and deleting user-specific auth data based on a key.</li> <li>For OAuth 2.0, the <code>key</code> must be a composite key generated from the authorization server URL and the sorted list of required scopes (e.g., <code>f\"{auth_server}|{sorted(scopes)}\"</code>). This ensures that tokens are only reused when the exact set of permissions is required.</li> </ul> </li> </ul> <pre><code># src/sk_agents/auth_storage/secure_auth_storage_manager.py\nfrom abc import ABC, abstractmethod\nfrom .models import AuthData\n\nclass SecureAuthStorageManager(ABC):\n    \"\"\"Abstract interface for storing and retrieving tool authorization information.\"\"\"\n\n    @abstractmethod\n    def store(self, user_id: str, key: str, data: AuthData) -&gt; None:\n        \"\"\"Stores authorization data for a given user and key.\"\"\"\n        ...\n\n    @abstractmethod\n    def retrieve(self, user_id: str, key: str) -&gt; AuthData | None:\n        \"\"\"Retrieves authorization data for a given user and key.\"\"\"\n        ...\n\n    @abstractmethod\n    def delete(self, user_id: str, key: str) -&gt; None:\n        \"\"\"Deletes authorization data for a given user and key.\"\"\"\n        ...\n</code></pre>"},{"location":"planning/2507-state-hitl-auth/05-02-02-secure-auth-storage-implementation-plan/#task-3-in-memory-storage-implementation","title":"Task 3: In-Memory Storage Implementation","text":"<p>Objective: Create a concrete, thread-safe, in-memory implementation of the <code>SecureAuthStorageManager</code>.</p> <ul> <li>File to Create: <code>src/sk_agents/auth_storage/in_memory_secure_auth_storage_manager.py</code></li> <li>Details:<ul> <li>Implement the <code>InMemorySecureAuthStorageManager</code> class.</li> <li>Use a nested dictionary (<code>dict[str, dict[str, AuthData]]</code>) for storage.</li> <li>Employ <code>threading.Lock</code> to ensure all operations are thread-safe.</li> </ul> </li> </ul> <pre><code># src/sk_agents/auth_storage/in_memory_secure_auth_storage_manager.py\nimport threading\nfrom .models import AuthData\nfrom .secure_auth_storage_manager import SecureAuthStorageManager\n\nclass InMemorySecureAuthStorageManager(SecureAuthStorageManager):\n    \"\"\"A thread-safe, in-memory implementation of the SecureAuthStorageManager.\"\"\"\n    def __init__(self):\n        self._storage: dict[str, dict[str, AuthData]] = {}\n        self._lock = threading.Lock()\n\n    def store(self, user_id: str, key: str, data: AuthData) -&gt; None:\n        with self._lock:\n            if user_id not in self._storage:\n                self._storage[user_id] = {}\n            self._storage[user_id][key] = data\n\n    def retrieve(self, user_id: str, key: str) -&gt; AuthData | None:\n        with self._lock:\n            return self._storage.get(user_id, {}).get(key)\n\n    def delete(self, user_id: str, key: str) -&gt; None:\n        with self._lock:\n            if user_id in self._storage and key in self._storage[user_id]:\n                del self._storage[user_id][key]\n</code></pre>"},{"location":"planning/2507-state-hitl-auth/05-02-02-secure-auth-storage-implementation-plan/#task-4-singleton-factory-implementation","title":"Task 4: Singleton Factory Implementation","text":"<p>Objective: Develop a factory that provides a single, shared instance of the configured <code>SecureAuthStorageManager</code>.</p> <ul> <li>File to Create: <code>src/sk_agents/auth_storage/auth_storage_factory.py</code></li> <li>Details:<ul> <li>The factory will dynamically import and instantiate the manager class based on environment variables.</li> <li>It will follow the singleton pattern used by other factories in the project (e.g., <code>PersistenceFactory</code>).</li> </ul> </li> </ul>"},{"location":"planning/2507-state-hitl-auth/05-02-02-secure-auth-storage-implementation-plan/#task-5-testing-strategy","title":"Task 5: Testing Strategy","text":"<p>Objective: Ensure the reliability, correctness, and thread safety of the new auth storage components.</p> <ul> <li>File to Create: <code>tests/test_secure_auth_storage.py</code></li> <li>Details:<ol> <li>Unit Tests:<ul> <li>Verify that <code>OAuth2AuthData</code> model validation works as expected.</li> <li>Test the <code>InMemorySecureAuthStorageManager</code> for correct <code>store</code>, <code>retrieve</code>, and <code>delete</code> behavior.</li> <li>Write a multi-threaded test to confirm that concurrent read/write operations do not lead to race conditions or data corruption.</li> </ul> </li> <li>Factory Tests:<ul> <li>Test that the <code>AuthStorageFactory</code> correctly instantiates the <code>InMemorySecureAuthStorageManager</code> based on default environment variables.</li> <li>Confirm that the factory always returns the same singleton instance.</li> <li>Test error handling for invalid module or class names in environment variables.</li> </ul> </li> </ol> </li> </ul>"},{"location":"planning/2507-state-hitl-auth/05-02-02-secure-auth-storage-implementation-plan/#task-6-environment-variables-and-configuration","title":"Task 6: Environment Variables and Configuration","text":"<p>Objective: Document the new environment variables required for configuring the Secure Auth Storage Service.</p> <ul> <li>Details: The application will use the following environment variables:<ul> <li><code>TA_SECURE_AUTH_STORAGE_MANAGER_MODULE</code>: The Python module path for the storage manager implementation.<ul> <li>Default: <code>sk_agents.auth_storage.in_memory_secure_auth_storage_manager</code></li> </ul> </li> <li><code>TA_SECURE_AUTH_STORAGE_MANAGER_CLASS</code>: The class name of the storage manager implementation.<ul> <li>Default: <code>InMemorySecureAuthStorageManager</code></li> </ul> </li> </ul> </li> </ul>"}]}